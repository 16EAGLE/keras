% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/autogen-initializers.R
\name{initializer_lecun_normal}
\alias{initializer_lecun_normal}
\title{Lecun normal initializer.}
\usage{
initializer_lecun_normal(seed = NULL)
}
\arguments{
\item{seed}{A Python integer or instance of
\code{keras.backend.SeedGenerator}.
Used to make the behavior of the initializer
deterministic. Note that an initializer seeded with an integer
or \code{None} (unseeded) will produce the same random values
across multiple calls. To get different random values
across multiple calls, use as seed an instance
of \code{keras.backend.SeedGenerator}.}
}
\description{
Initializers allow you to pre-specify an initialization strategy, encoded in
the Initializer object, without knowing the shape and dtype of the variable
being initialized.

Draws samples from a truncated normal distribution centered on 0 with
\code{stddev = sqrt(1 / fan_in)} where \code{fan_in} is the number of input units in
the weight tensor.
}
\section{Examples}{
\if{html}{\out{<div class="sourceCode python">}}\preformatted{# Standalone usage:
initializer = LecunNormal()
values = initializer(shape=(2, 2))
}\if{html}{\out{</div>}}

\if{html}{\out{<div class="sourceCode python">}}\preformatted{# Usage in a Keras layer:
initializer = LecunNormal()
layer = Dense(3, kernel_initializer=initializer)
}\if{html}{\out{</div>}}
}

\section{Reference}{
\itemize{
\item \href{https://arxiv.org/abs/1706.02515}{Klambauer et al., 2017}
}
}

\seealso{
\itemize{
\item \url{https://www.tensorflow.org/api_docs/python/tf/keras/initializers/LecunNormal}
}

Other initializer: 
\code{\link{initializer_constant}()},
\code{\link{initializer_glorot_normal}()},
\code{\link{initializer_glorot_uniform}()},
\code{\link{initializer_he_normal}()},
\code{\link{initializer_he_uniform}()},
\code{\link{initializer_identity}()},
\code{\link{initializer_lecun_uniform}()},
\code{\link{initializer_ones}()},
\code{\link{initializer_orthogonal}()},
\code{\link{initializer_random_normal}()},
\code{\link{initializer_random_uniform}()},
\code{\link{initializer_truncated_normal}()},
\code{\link{initializer_variance_scaling}()},
\code{\link{initializer_zeros}()}
}
\concept{initializer}
