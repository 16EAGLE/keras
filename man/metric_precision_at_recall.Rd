% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/autogen-metrics.R
\name{metric_precision_at_recall}
\alias{metric_precision_at_recall}
\title{Computes best precision where recall is >= specified value.}
\usage{
metric_precision_at_recall(
  ...,
  recall,
  num_thresholds = 200L,
  class_id = NULL,
  name = NULL,
  dtype = NULL
)
}
\arguments{
\item{...}{Passed on to the Python callable}

\item{recall}{A scalar value in range \verb{[0, 1]}.}

\item{num_thresholds}{(Optional) Defaults to 200. The number of thresholds to
use for matching the given recall.}

\item{class_id}{(Optional) Integer class ID for which we want binary metrics.
This must be in the half-open interval \verb{[0, num_classes)}, where
\code{num_classes} is the last dimension of predictions.}

\item{name}{(Optional) string name of the metric instance.}

\item{dtype}{(Optional) data type of the metric result.}
}
\description{
This metric creates four local variables, \code{true_positives},
\code{true_negatives}, \code{false_positives} and \code{false_negatives} that are used to
compute the precision at the given recall. The threshold for the given
recall value is computed and used to evaluate the corresponding precision.

If \code{sample_weight} is \code{NULL}, weights default to 1.
Use \code{sample_weight} of 0 to mask values.

If \code{class_id} is specified, we calculate precision by considering only the
entries in the batch for which \code{class_id} is above the threshold
predictions, and computing the fraction of them for which \code{class_id} is
indeed a correct label.
}
\section{Usage}{
Standalone usage:

\if{html}{\out{<div class="sourceCode r">}}\preformatted{m <- metric_precision_at_recall(recall = 0.5)
m$update_state(c(0, 0, 0, 1, 1), c(0, 0.3, 0.8, 0.3, 0.8))
m$result()
}\if{html}{\out{</div>}}

\if{html}{\out{<div class="sourceCode">}}\preformatted{## [[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
##    18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
##    36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
##    54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
##    72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
##    90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
##   108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
##   126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
##   144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159]]
}\if{html}{\out{</div>}}

\if{html}{\out{<div class="sourceCode">}}\preformatted{## tf.Tensor(0.5, shape=(), dtype=float32)
}\if{html}{\out{</div>}}

\if{html}{\out{<div class="sourceCode r">}}\preformatted{m$reset_state()
m$update_state(c(0, 0, 0, 1, 1), c(0, 0.3, 0.8, 0.3, 0.8),
               sample_weight = c(2, 2, 2, 1, 1))
m$result()
}\if{html}{\out{</div>}}

\if{html}{\out{<div class="sourceCode">}}\preformatted{## [[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
##    18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
##    36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
##    54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
##    72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
##    90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
##   108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
##   126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
##   144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159]]
}\if{html}{\out{</div>}}

\if{html}{\out{<div class="sourceCode">}}\preformatted{## tf.Tensor(0.33333334, shape=(), dtype=float32)
}\if{html}{\out{</div>}}

Usage with \code{compile()} API:

\if{html}{\out{<div class="sourceCode r">}}\preformatted{model \%>\% compile(
  optimizer = 'sgd',
  loss = 'mse',
  metrics = list(metric_precision_at_recall(recall = 0.8))
)
}\if{html}{\out{</div>}}

[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
\subsection{18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35}{
}

\subsection{36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53}{
}

\subsection{54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71}{
}

\subsection{72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89}{
}

\subsection{90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107}{
}

\subsection{108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125}{
}

\subsection{126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143}{
}

\subsection{144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159]: R:\%20\%200\%20\%20\%201\%20\%20\%202\%20\%20\%203\%20\%20\%204\%20\%20\%205\%20\%20\%206\%20\%20\%207\%20\%20\%208\%20\%20\%209\%20\%2010\%20\%2011\%20\%2012\%20\%2013\%20\%2014\%20\%2015\%20\%2016\%20\%2017\%0A##\%20\%20\%20\%2018\%20\%2019\%20\%2020\%20\%2021\%20\%2022\%20\%2023\%20\%2024\%20\%2025\%20\%2026\%20\%2027\%20\%2028\%20\%2029\%20\%2030\%20\%2031\%20\%2032\%20\%2033\%20\%2034\%20\%2035\%0A##\%20\%20\%20\%2036\%20\%2037\%20\%2038\%20\%2039\%20\%2040\%20\%2041\%20\%2042\%20\%2043\%20\%2044\%20\%2045\%20\%2046\%20\%2047\%20\%2048\%20\%2049\%20\%2050\%20\%2051\%20\%2052\%20\%2053\%0A##\%20\%20\%20\%2054\%20\%2055\%20\%2056\%20\%2057\%20\%2058\%20\%2059\%20\%2060\%20\%2061\%20\%2062\%20\%2063\%20\%2064\%20\%2065\%20\%2066\%20\%2067\%20\%2068\%20\%2069\%20\%2070\%20\%2071\%0A##\%20\%20\%20\%2072\%20\%2073\%20\%2074\%20\%2075\%20\%2076\%20\%2077\%20\%2078\%20\%2079\%20\%2080\%20\%2081\%20\%2082\%20\%2083\%20\%2084\%20\%2085\%20\%2086\%20\%2087\%20\%2088\%20\%2089\%0A##\%20\%20\%20\%2090\%20\%2091\%20\%2092\%20\%2093\%20\%2094\%20\%2095\%20\%2096\%20\%2097\%20\%2098\%20\%2099\%20100\%20101\%20102\%20103\%20104\%20105\%20106\%20107\%0A##\%20\%20\%20108\%20109\%20110\%20111\%20112\%20113\%20114\%20115\%20116\%20117\%20118\%20119\%20120\%20121\%20122\%20123\%20124\%20125\%0A##\%20\%20\%20126\%20127\%20128\%20129\%20130\%20131\%20132\%20133\%20134\%20135\%20136\%20137\%20138\%20139\%20140\%20141\%20142\%20143\%0A##\%20\%20\%20144\%20145\%20146\%20147\%20148\%20149\%20150\%20151\%20152\%20153\%20154\%20155\%20156\%20157\%20158\%20159}{

[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
}

\subsection{18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35}{
}

\subsection{36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53}{
}

\subsection{54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71}{
}

\subsection{72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89}{
}

\subsection{90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107}{
}

\subsection{108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125}{
}

\subsection{126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143}{
}

\subsection{144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159]: R:\%20\%200\%20\%20\%201\%20\%20\%202\%20\%20\%203\%20\%20\%204\%20\%20\%205\%20\%20\%206\%20\%20\%207\%20\%20\%208\%20\%20\%209\%20\%2010\%20\%2011\%20\%2012\%20\%2013\%20\%2014\%20\%2015\%20\%2016\%20\%2017\%0A##\%20\%20\%20\%2018\%20\%2019\%20\%2020\%20\%2021\%20\%2022\%20\%2023\%20\%2024\%20\%2025\%20\%2026\%20\%2027\%20\%2028\%20\%2029\%20\%2030\%20\%2031\%20\%2032\%20\%2033\%20\%2034\%20\%2035\%0A##\%20\%20\%20\%2036\%20\%2037\%20\%2038\%20\%2039\%20\%2040\%20\%2041\%20\%2042\%20\%2043\%20\%2044\%20\%2045\%20\%2046\%20\%2047\%20\%2048\%20\%2049\%20\%2050\%20\%2051\%20\%2052\%20\%2053\%0A##\%20\%20\%20\%2054\%20\%2055\%20\%2056\%20\%2057\%20\%2058\%20\%2059\%20\%2060\%20\%2061\%20\%2062\%20\%2063\%20\%2064\%20\%2065\%20\%2066\%20\%2067\%20\%2068\%20\%2069\%20\%2070\%20\%2071\%0A##\%20\%20\%20\%2072\%20\%2073\%20\%2074\%20\%2075\%20\%2076\%20\%2077\%20\%2078\%20\%2079\%20\%2080\%20\%2081\%20\%2082\%20\%2083\%20\%2084\%20\%2085\%20\%2086\%20\%2087\%20\%2088\%20\%2089\%0A##\%20\%20\%20\%2090\%20\%2091\%20\%2092\%20\%2093\%20\%2094\%20\%2095\%20\%2096\%20\%2097\%20\%2098\%20\%2099\%20100\%20101\%20102\%20103\%20104\%20105\%20106\%20107\%0A##\%20\%20\%20108\%20109\%20110\%20111\%20112\%20113\%20114\%20115\%20116\%20117\%20118\%20119\%20120\%20121\%20122\%20123\%20124\%20125\%0A##\%20\%20\%20126\%20127\%20128\%20129\%20130\%20131\%20132\%20133\%20134\%20135\%20136\%20137\%20138\%20139\%20140\%20141\%20142\%20143\%0A##\%20\%20\%20144\%20145\%20146\%20147\%20148\%20149\%20150\%20151\%20152\%20153\%20154\%20155\%20156\%20157\%20158\%20159}{
}
}

\seealso{
\itemize{
\item \url{https:/keras.io/api/metrics/classification_metrics#precisionatrecall-class}
\item \url{https://www.tensorflow.org/api_docs/python/tf/keras/metrics/PrecisionAtRecall}
}

Other confusion metrics: 
\code{\link{metric_auc}()},
\code{\link{metric_false_negatives}()},
\code{\link{metric_false_positives}()},
\code{\link{metric_precision}()},
\code{\link{metric_recall_at_precision}()},
\code{\link{metric_recall}()},
\code{\link{metric_sensitivity_at_specificity}()},
\code{\link{metric_specificity_at_sensitivity}()},
\code{\link{metric_true_negatives}()},
\code{\link{metric_true_positives}()}

Other metrics: 
\code{\link{custom_metric}()},
\code{\link{metric_auc}()},
\code{\link{metric_binary_accuracy}()},
\code{\link{metric_binary_crossentropy}()},
\code{\link{metric_binary_iou}()},
\code{\link{metric_categorical_accuracy}()},
\code{\link{metric_categorical_crossentropy}()},
\code{\link{metric_categorical_hinge}()},
\code{\link{metric_cosine_similarity}()},
\code{\link{metric_f1_score}()},
\code{\link{metric_false_negatives}()},
\code{\link{metric_false_positives}()},
\code{\link{metric_fbeta_score}()},
\code{\link{metric_hinge}()},
\code{\link{metric_iou}()},
\code{\link{metric_kl_divergence}()},
\code{\link{metric_log_cosh_error}()},
\code{\link{metric_mean_absolute_error}()},
\code{\link{metric_mean_absolute_percentage_error}()},
\code{\link{metric_mean_iou}()},
\code{\link{metric_mean_squared_error}()},
\code{\link{metric_mean_squared_logarithmic_error}()},
\code{\link{metric_mean_wrapper}()},
\code{\link{metric_mean}()},
\code{\link{metric_one_hot_iou}()},
\code{\link{metric_one_hot_mean_iou}()},
\code{\link{metric_poisson}()},
\code{\link{metric_precision}()},
\code{\link{metric_r2_score}()},
\code{\link{metric_recall_at_precision}()},
\code{\link{metric_recall}()},
\code{\link{metric_root_mean_squared_error}()},
\code{\link{metric_sensitivity_at_specificity}()},
\code{\link{metric_sparse_categorical_accuracy}()},
\code{\link{metric_sparse_categorical_crossentropy}()},
\code{\link{metric_sparse_top_k_categorical_accuracy}()},
\code{\link{metric_specificity_at_sensitivity}()},
\code{\link{metric_squared_hinge}()},
\code{\link{metric_sum}()},
\code{\link{metric_top_k_categorical_accuracy}()},
\code{\link{metric_true_negatives}()},
\code{\link{metric_true_positives}()}
}
\concept{confusion metrics}
\concept{metrics}
