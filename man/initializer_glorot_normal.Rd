% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/autogen-initializers.R
\name{initializer_glorot_normal}
\alias{initializer_glorot_normal}
\title{The Glorot normal initializer, also called Xavier normal initializer.}
\usage{
initializer_glorot_normal(seed = NULL)
}
\arguments{
\item{seed}{A Python integer or instance of
\code{keras_core.backend.SeedGenerator}.
Used to make the behavior of the initializer
deterministic. Note that an initializer seeded with an integer
or \code{None} (unseeded) will produce the same random values
across multiple calls. To get different random values
across multiple calls, use as seed an instance
of \code{keras_core.backend.SeedGenerator}.}
}
\description{
Draws samples from a truncated normal distribution centered on 0 with
\code{stddev = sqrt(2 / (fan_in + fan_out))} where \code{fan_in} is the number of
input units in the weight tensor and \code{fan_out} is the number of output units
in the weight tensor.
}
\section{Examples}{
\if{html}{\out{<div class="sourceCode python">}}\preformatted{# Standalone usage:
initializer = GlorotNormal()
values = initializer(shape=(2, 2))
}\if{html}{\out{</div>}}

\if{html}{\out{<div class="sourceCode python">}}\preformatted{# Usage in a Keras layer:
initializer = GlorotNormal()
layer = Dense(3, kernel_initializer=initializer)
}\if{html}{\out{</div>}}
}

\section{Reference}{
\itemize{
\item \href{http://proceedings.mlr.press/v9/glorot10a.html}{Glorot et al., 2010}
}
}

\seealso{
\itemize{
\item \url{https://www.tensorflow.org/api_docs/python/tf/keras/initializers/GlorotNormal}
}

Other initializer: 
\code{\link{initializer_constant}()},
\code{\link{initializer_glorot_uniform}()},
\code{\link{initializer_he_normal}()},
\code{\link{initializer_he_uniform}()},
\code{\link{initializer_identity}()},
\code{\link{initializer_lecun_normal}()},
\code{\link{initializer_lecun_uniform}()},
\code{\link{initializer_ones}()},
\code{\link{initializer_orthogonal}()},
\code{\link{initializer_random_normal}()},
\code{\link{initializer_random_uniform}()},
\code{\link{initializer_truncated_normal}()},
\code{\link{initializer_variance_scaling}()},
\code{\link{initializer_zeros}()}
}
\concept{initializer}
