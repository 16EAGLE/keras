% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/autogen-layers-core.R
\name{layer_einsum_dense}
\alias{layer_einsum_dense}
\title{A layer that uses \code{einsum} as the backing computation.}
\usage{
layer_einsum_dense(
  object,
  equation,
  output_shape,
  activation = NULL,
  bias_axes = NULL,
  kernel_initializer = "glorot_uniform",
  bias_initializer = "zeros",
  kernel_regularizer = NULL,
  bias_regularizer = NULL,
  kernel_constraint = NULL,
  bias_constraint = NULL,
  ...
)
}
\arguments{
\item{equation}{An equation describing the einsum to perform.
This equation must be a valid einsum string of the form
\verb{ab,bc->ac}, \verb{...ab,bc->...ac}, or
\verb{ab...,bc->ac...} where 'ab', 'bc', and 'ac' can be any valid einsum
axis expression sequence.}

\item{output_shape}{The expected shape of the output tensor
(excluding the batch dimension and any dimensions
represented by ellipses). You can specify \code{None} for any dimension
that is unknown or can be inferred from the input shape.}

\item{activation}{Activation function to use. If you don't specify anything,
no activation is applied
(that is, a "linear" activation: \code{a(x) = x}).}

\item{bias_axes}{A string containing the output dimension(s)
to apply a bias to. Each character in the \code{bias_axes} string
should correspond to a character in the output portion
of the \code{equation} string.}

\item{kernel_initializer}{Initializer for the \code{kernel} weights matrix.}

\item{bias_initializer}{Initializer for the bias vector.}

\item{kernel_regularizer}{Regularizer function applied to the \code{kernel} weights
matrix.}

\item{bias_regularizer}{Regularizer function applied to the bias vector.}

\item{kernel_constraint}{Constraint function applied to the \code{kernel} weights
matrix.}

\item{bias_constraint}{Constraint function applied to the bias vector.}

\item{...}{Base layer keyword arguments, such as \code{name} and \code{dtype}.}
}
\description{
This layer can perform einsum calculations of arbitrary dimensionality.
}
\section{Examples}{
\strong{Biased dense layer with einsums}

This example shows how to instantiate a standard Keras dense layer using
einsum operations. This example is equivalent to
\code{keras_core.layers.Dense(64, use_bias=True)}.

\if{html}{\out{<div class="sourceCode python">}}\preformatted{layer = keras_core.layers.EinsumDense("ab,bc->ac",
                                      output_shape=64,
                                      bias_axes="c")
input_tensor = keras_core.Input(shape=[32])
output_tensor = layer(input_tensor)
output_tensor.shape
# (None, 64)
}\if{html}{\out{</div>}}

\strong{Applying a dense layer to a sequence}

This example shows how to instantiate a layer that applies the same dense
operation to every element in a sequence. Here, the \code{output_shape} has two
values (since there are two non-batch dimensions in the output); the first
dimension in the \code{output_shape} is \code{None}, because the sequence dimension
\code{b} has an unknown shape.

\if{html}{\out{<div class="sourceCode python">}}\preformatted{layer = keras_core.layers.EinsumDense("abc,cd->abd",
                                      output_shape=(None, 64),
                                      bias_axes="d")
input_tensor = keras_core.Input(shape=[32, 128])
output_tensor = layer(input_tensor)
output_tensor.shape
# (None, 32, 64)
}\if{html}{\out{</div>}}

\strong{Applying a dense layer to a sequence using ellipses}

This example shows how to instantiate a layer that applies the same dense
operation to every element in a sequence, but uses the ellipsis notation
instead of specifying the batch and sequence dimensions.

Because we are using ellipsis notation and have specified only one axis, the
\code{output_shape} arg is a single value. When instantiated in this way, the
layer can handle any number of sequence dimensions - including the case
where no sequence dimension exists.

\if{html}{\out{<div class="sourceCode python">}}\preformatted{layer = keras_core.layers.EinsumDense("...x,xy->...y",
                                      output_shape=64,
                                      bias_axes="y")
input_tensor = keras_core.Input(shape=[32, 128])
output_tensor = layer(input_tensor)
output_tensor.shape
# (None, 32, 64)
}\if{html}{\out{</div>}}
}

\seealso{
\itemize{
\item \url{https://www.tensorflow.org/api_docs/python/tf/keras/layers/EinsumDense}
}

Other core layers: 
\code{\link{layer_dense}()},
\code{\link{layer_embedding}()},
\code{\link{layer_identity}()},
\code{\link{layer_lambda}()},
\code{\link{layer_masking}()},
\code{\link{layer_wrapper}()}
}
\concept{core layers}
