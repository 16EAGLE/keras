% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/autogen-layers-preprocessing.R
\name{layer_hashed_crossing}
\alias{layer_hashed_crossing}
\title{A preprocessing layer which crosses features using the "hashing trick".}
\usage{
layer_hashed_crossing(
  object,
  num_bins,
  output_mode = "int",
  sparse = FALSE,
  name = NULL,
  dtype = NULL,
  ...
)
}
\arguments{
\item{object}{Object to compose the layer with. A tensor, array, or sequential model.}

\item{num_bins}{Number of hash bins.}

\item{output_mode}{Specification for the output of the layer. Values can be
\code{"int"}, or \code{"one_hot"} configuring the layer as follows:
\itemize{
\item \code{"int"}: Return the integer bin indices directly.
\item \code{"one_hot"}: Encodes each individual element in the input into an
array the same size as \code{num_bins}, containing a 1 at the input's
bin index. Defaults to \code{"int"}.
}}

\item{sparse}{Boolean. Only applicable to \code{"one_hot"} mode and only valid
when using the TensorFlow backend. If \code{TRUE}, returns
a \code{SparseTensor} instead of a dense \code{Tensor}. Defaults to \code{FALSE}.}

\item{name}{String, name for the object}

\item{dtype}{datatype (e.g., \code{"float32"}).}

\item{...}{Keyword arguments to construct a layer.}
}
\description{
This layer performs crosses of categorical features using the "hashing
trick". Conceptually, the transformation can be thought of as:
\code{hash(concatenate(features)) \%\% num_bins}.

This layer currently only performs crosses of scalar inputs and batches of
scalar inputs. Valid input shapes are \verb{(batch_size, 1)}, \code{(batch_size)} and
\verb{()}.

\strong{Note:} This layer wraps \code{tf.keras.layers.HashedCrossing}. It cannot
be used as part of the compiled computation graph of a model with
any backend other than TensorFlow.
It can however be used with any backend when running eagerly.
It can also always be used as part of an input preprocessing pipeline
with any backend (outside the model itself), which is how we recommend
to use this layer.

\strong{Note:} This layer is safe to use inside a \code{tfdatasets} pipeline
(independently of which backend you're using).
}
\section{Examples}{
\if{html}{\out{<div class="sourceCode r">}}\preformatted{feat1 <- c('A', 'B', 'A', 'B', 'A') |> as.array()
feat2 <- c(101, 101, 101, 102, 102) |> as.integer() |> as.array()
}\if{html}{\out{</div>}}

\strong{Crossing two scalar features.}

\if{html}{\out{<div class="sourceCode r">}}\preformatted{layer <- layer_hashed_crossing(num_bins = 5)
layer(list(feat1, feat2))
}\if{html}{\out{</div>}}

\if{html}{\out{<div class="sourceCode">}}\preformatted{## tf.Tensor([1 4 1 1 3], shape=(5), dtype=int64)
}\if{html}{\out{</div>}}

\strong{Crossing and one-hotting two scalar features.}

\if{html}{\out{<div class="sourceCode r">}}\preformatted{layer <- layer_hashed_crossing(num_bins = 5, output_mode = 'one_hot')
layer(list(feat1, feat2))
}\if{html}{\out{</div>}}

\if{html}{\out{<div class="sourceCode">}}\preformatted{## tf.Tensor(
## [[0. 1. 0. 0. 0.]
##  [0. 0. 0. 0. 1.]
##  [0. 1. 0. 0. 0.]
##  [0. 1. 0. 0. 0.]
##  [0. 0. 0. 1. 0.]], shape=(5, 5), dtype=float32)
}\if{html}{\out{</div>}}
}

\seealso{
\itemize{
\item \url{https:/keras.io/api/layers/preprocessing_layers/categorical/hashed_crossing#hashedcrossing-class}
\item \url{https://www.tensorflow.org/api_docs/python/tf/keras/layers/HashedCrossing}
}

Other preprocessing layers: 
\code{\link{layer_category_encoding}()},
\code{\link{layer_center_crop}()},
\code{\link{layer_discretization}()},
\code{\link{layer_feature_space}()},
\code{\link{layer_hashing}()},
\code{\link{layer_integer_lookup}()},
\code{\link{layer_normalization}()},
\code{\link{layer_random_brightness}()},
\code{\link{layer_random_contrast}()},
\code{\link{layer_random_crop}()},
\code{\link{layer_random_flip}()},
\code{\link{layer_random_rotation}()},
\code{\link{layer_random_translation}()},
\code{\link{layer_random_zoom}()},
\code{\link{layer_rescaling}()},
\code{\link{layer_resizing}()},
\code{\link{layer_string_lookup}()},
\code{\link{layer_text_vectorization}()}

Other layers: 
\code{\link{bidirectional}()},
\code{\link{layer_activation_elu}()},
\code{\link{layer_activation_leaky_relu}()},
\code{\link{layer_activation_parametric_relu}()},
\code{\link{layer_activation_relu}()},
\code{\link{layer_activation_softmax}()},
\code{\link{layer_activation}()},
\code{\link{layer_activity_regularization}()},
\code{\link{layer_additive_attention}()},
\code{\link{layer_add}()},
\code{\link{layer_attention}()},
\code{\link{layer_average_pooling_1d}()},
\code{\link{layer_average_pooling_2d}()},
\code{\link{layer_average_pooling_3d}()},
\code{\link{layer_average}()},
\code{\link{layer_batch_normalization}()},
\code{\link{layer_category_encoding}()},
\code{\link{layer_center_crop}()},
\code{\link{layer_concatenate}()},
\code{\link{layer_conv_1d_transpose}()},
\code{\link{layer_conv_1d}()},
\code{\link{layer_conv_2d_transpose}()},
\code{\link{layer_conv_2d}()},
\code{\link{layer_conv_3d_transpose}()},
\code{\link{layer_conv_3d}()},
\code{\link{layer_conv_lstm_1d}()},
\code{\link{layer_conv_lstm_2d}()},
\code{\link{layer_conv_lstm_3d}()},
\code{\link{layer_cropping_1d}()},
\code{\link{layer_cropping_2d}()},
\code{\link{layer_cropping_3d}()},
\code{\link{layer_dense}()},
\code{\link{layer_depthwise_conv_1d}()},
\code{\link{layer_depthwise_conv_2d}()},
\code{\link{layer_discretization}()},
\code{\link{layer_dot}()},
\code{\link{layer_dropout}()},
\code{\link{layer_einsum_dense}()},
\code{\link{layer_embedding}()},
\code{\link{layer_feature_space}()},
\code{\link{layer_flatten}()},
\code{\link{layer_gaussian_dropout}()},
\code{\link{layer_gaussian_noise}()},
\code{\link{layer_global_average_pooling_1d}()},
\code{\link{layer_global_average_pooling_2d}()},
\code{\link{layer_global_average_pooling_3d}()},
\code{\link{layer_global_max_pooling_1d}()},
\code{\link{layer_global_max_pooling_2d}()},
\code{\link{layer_global_max_pooling_3d}()},
\code{\link{layer_group_normalization}()},
\code{\link{layer_group_query_attention}()},
\code{\link{layer_gru_cell}()},
\code{\link{layer_gru}()},
\code{\link{layer_hashing}()},
\code{\link{layer_identity}()},
\code{\link{layer_input}()},
\code{\link{layer_integer_lookup}()},
\code{\link{layer_lambda}()},
\code{\link{layer_layer_normalization}()},
\code{\link{layer_lstm_cell}()},
\code{\link{layer_lstm}()},
\code{\link{layer_masking}()},
\code{\link{layer_max_pooling_1d}()},
\code{\link{layer_max_pooling_2d}()},
\code{\link{layer_max_pooling_3d}()},
\code{\link{layer_maximum}()},
\code{\link{layer_minimum}()},
\code{\link{layer_multi_head_attention}()},
\code{\link{layer_multiply}()},
\code{\link{layer_normalization}()},
\code{\link{layer_permute}()},
\code{\link{layer_random_brightness}()},
\code{\link{layer_random_contrast}()},
\code{\link{layer_random_crop}()},
\code{\link{layer_random_flip}()},
\code{\link{layer_random_rotation}()},
\code{\link{layer_random_translation}()},
\code{\link{layer_random_zoom}()},
\code{\link{layer_repeat_vector}()},
\code{\link{layer_rescaling}()},
\code{\link{layer_reshape}()},
\code{\link{layer_resizing}()},
\code{\link{layer_rnn}()},
\code{\link{layer_separable_conv_1d}()},
\code{\link{layer_separable_conv_2d}()},
\code{\link{layer_simple_rnn_cell}()},
\code{\link{layer_simple_rnn}()},
\code{\link{layer_spatial_dropout_1d}()},
\code{\link{layer_spatial_dropout_2d}()},
\code{\link{layer_spatial_dropout_3d}()},
\code{\link{layer_spectral_normalization}()},
\code{\link{layer_stacked_rnn_cells}()},
\code{\link{layer_string_lookup}()},
\code{\link{layer_subtract}()},
\code{\link{layer_text_vectorization}()},
\code{\link{layer_tfsm}()},
\code{\link{layer_time_distributed}()},
\code{\link{layer_unit_normalization}()},
\code{\link{layer_upsampling_1d}()},
\code{\link{layer_upsampling_2d}()},
\code{\link{layer_upsampling_3d}()},
\code{\link{layer_zero_padding_1d}()},
\code{\link{layer_zero_padding_2d}()},
\code{\link{layer_zero_padding_3d}()}
}
\concept{layers}
\concept{preprocessing layers}
