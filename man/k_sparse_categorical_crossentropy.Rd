% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ops.R
\name{k_sparse_categorical_crossentropy}
\alias{k_sparse_categorical_crossentropy}
\title{Computes sparse categorical cross-entropy loss.}
\usage{
k_sparse_categorical_crossentropy(
  target,
  output,
  from_logits = FALSE,
  axis = -1L
)
}
\arguments{
\item{target}{The target tensor representing the true class labels as
integers. Its shape should match the shape of the \code{output}
tensor except for the last dimension.}

\item{output}{The output tensor representing the predicted probabilities
or logits.
Its shape should match the shape of the \code{target} tensor except
for the last dimension.}

\item{from_logits}{(optional) Whether \code{output} is a tensor of logits
or probabilities.
Set it to \code{True} if \code{output} represents logits; otherwise,
set it to \code{False} if \code{output} represents probabilities.
Defaults to\code{False}.}

\item{axis}{(optional) The axis along which the sparse categorical
cross-entropy is computed.
Defaults to \code{-1}, which corresponds to the last dimension
of the tensors.}
}
\description{
The sparse categorical cross-entropy loss is similar to categorical
cross-entropy, but it is used when the target tensor contains integer
class labels instead of one-hot encoded vectors. It measures the
dissimilarity between the target and output probabilities or logits.
}
\section{Returns}{
Integer tensor: The computed sparse categorical cross-entropy
loss between \code{target} and \code{output}.
}

\section{Examples}{
\if{html}{\out{<div class="sourceCode python">}}\preformatted{target = keras_core.ops.convert_to_tensor([0, 1, 2], dtype=int32)
output = keras_core.ops.convert_to_tensor(
[[0.9, 0.05, 0.05],
 [0.1, 0.8, 0.1],
 [0.2, 0.3, 0.5]])
sparse_categorical_crossentropy(target, output)
# array([0.10536056 0.22314355 0.6931472 ], shape=(3,), dtype=float32)
}\if{html}{\out{</div>}}
}

\seealso{
\itemize{
\item \url{https://www.tensorflow.org/api_docs/python/tf/keras/ops/sparse_categorical_crossentropy}
}
}
