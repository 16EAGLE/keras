% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/autogen-metrics.R
\name{metric_sparse_categorical_crossentropy}
\alias{metric_sparse_categorical_crossentropy}
\title{Computes the crossentropy metric between the labels and predictions.}
\usage{
metric_sparse_categorical_crossentropy(
  y_true,
  y_pred,
  from_logits = FALSE,
  ignore_class = NULL,
  axis = -1L,
  ...,
  name = "sparse_categorical_crossentropy",
  dtype = NULL
)
}
\arguments{
\item{y_true}{Ground truth values.}

\item{y_pred}{The predicted values.}

\item{from_logits}{(Optional) Whether output is expected
to be a logits tensor. By default, we consider that output
encodes a probability distribution.}

\item{ignore_class}{Optional integer. The ID of a class to be ignored during
loss computation. This is useful, for example, in segmentation
problems featuring a "void" class (commonly -1 or 255) in
segmentation maps. By default (\code{ignore_class=None}), all classes are
considered.}

\item{axis}{(Optional) Defaults to \code{-1}.
The dimension along which entropy is computed.}

\item{...}{Passed on to the Python callable}

\item{name}{(Optional) string name of the metric instance.}

\item{dtype}{(Optional) data type of the metric result.}
}
\description{
Use this crossentropy metric when there are two or more label classes.
It expects labels to be provided as integers. If you want to provide labels
that are one-hot encoded, please use the \code{CategoricalCrossentropy}
metric instead.

There should be \code{num_classes} floating point values per feature for \code{y_pred}
and a single floating point value per feature for \code{y_true}.
}
\section{Examples}{
\if{html}{\out{<div class="sourceCode python">}}\preformatted{y_true = [1, 2]
y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]
loss = keras.losses.sparse_categorical_crossentropy(y_true, y_pred)
assert loss.shape == (2,)
loss
# array([0.0513, 2.303], dtype=float32)
}\if{html}{\out{</div>}}

Standalone usage:

\if{html}{\out{<div class="sourceCode python">}}\preformatted{# y_true = one_hot(y_true) = [[0, 1, 0], [0, 0, 1]]
# logits = log(y_pred)
# softmax = exp(logits) / sum(exp(logits), axis=-1)
# softmax = [[0.05, 0.95, EPSILON], [0.1, 0.8, 0.1]]
# xent = -sum(y * log(softmax), 1)
# log(softmax) = [[-2.9957, -0.0513, -16.1181],
#                [-2.3026, -0.2231, -2.3026]]
# y_true * log(softmax) = [[0, -0.0513, 0], [0, 0, -2.3026]]
# xent = [0.0513, 2.3026]
# Reduced xent = (0.0513 + 2.3026) / 2
m = keras.metrics.SparseCategoricalCrossentropy()
m.update_state([1, 2],
               [[0.05, 0.95, 0], [0.1, 0.8, 0.1]])
m.result()
# 1.1769392
}\if{html}{\out{</div>}}

\if{html}{\out{<div class="sourceCode python">}}\preformatted{m.reset_state()
m.update_state([1, 2],
               [[0.05, 0.95, 0], [0.1, 0.8, 0.1]],
               sample_weight=np.array([0.3, 0.7]))
m.result()
# 1.6271976
}\if{html}{\out{</div>}}

Usage with \code{compile()} API:

\if{html}{\out{<div class="sourceCode python">}}\preformatted{model.compile(
    optimizer='sgd',
    loss='mse',
    metrics=[keras.metrics.SparseCategoricalCrossentropy()])
}\if{html}{\out{</div>}}
}

\section{Returns}{
Sparse categorical crossentropy loss value.
}

\seealso{
\itemize{
\item \url{https://www.tensorflow.org/api_docs/python/tf/keras/metrics/SparseCategoricalCrossentropy}
}

Other metric: 
\code{\link{metric_auc}()},
\code{\link{metric_binary_accuracy}()},
\code{\link{metric_binary_crossentropy}()},
\code{\link{metric_binary_iou}()},
\code{\link{metric_categorical_accuracy}()},
\code{\link{metric_categorical_crossentropy}()},
\code{\link{metric_categorical_hinge}()},
\code{\link{metric_cosine_similarity}()},
\code{\link{metric_f1_score}()},
\code{\link{metric_false_negatives}()},
\code{\link{metric_false_positives}()},
\code{\link{metric_fbeta_score}()},
\code{\link{metric_hinge}()},
\code{\link{metric_iou}()},
\code{\link{metric_kl_divergence}()},
\code{\link{metric_log_cosh_error}()},
\code{\link{metric_mean_absolute_error}()},
\code{\link{metric_mean_absolute_percentage_error}()},
\code{\link{metric_mean_iou}()},
\code{\link{metric_mean_squared_error}()},
\code{\link{metric_mean_squared_logarithmic_error}()},
\code{\link{metric_mean_wrapper}()},
\code{\link{metric_mean}()},
\code{\link{metric_one_hot_iou}()},
\code{\link{metric_one_hot_mean_iou}()},
\code{\link{metric_poisson}()},
\code{\link{metric_precision_at_recall}()},
\code{\link{metric_precision}()},
\code{\link{metric_r2_score}()},
\code{\link{metric_recall_at_precision}()},
\code{\link{metric_recall}()},
\code{\link{metric_root_mean_squared_error}()},
\code{\link{metric_sensitivity_at_specificity}()},
\code{\link{metric_sparse_categorical_accuracy}()},
\code{\link{metric_sparse_top_k_categorical_accuracy}()},
\code{\link{metric_specificity_at_sensitivity}()},
\code{\link{metric_squared_hinge}()},
\code{\link{metric_sum}()},
\code{\link{metric_top_k_categorical_accuracy}()},
\code{\link{metric_true_negatives}()},
\code{\link{metric_true_positives}()}
}
\concept{metric}
