<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="Overview of how to leverage preprocessing layers to create end-to-end models.">
<title>Working with preprocessing layers • keras3</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/Fira_Mono-0.4.8/font.css" rel="stylesheet">
<!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Working with preprocessing layers">
<meta property="og:description" content="Overview of how to leverage preprocessing layers to create end-to-end models.">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-inverse navbar-expand-lg bg-primary"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">keras3</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">2.13.0.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../index.html">Home</a>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-getting-started">Getting Started</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-getting-started">
    <a class="dropdown-item" href="../articles/intro_to_keras_for_engineers.html">Introduction to Keras for engineers</a>
    <h6 class="dropdown-header" data-toc-skip>Tutorials</h6>
    <a class="dropdown-item" href="../articles/getting_started.html">Getting Started</a>
    <a class="dropdown-item" href="../articles/tutorial_basic_classification.html">Basic Classification</a>
    <a class="dropdown-item" href="../articles/tutorial_basic_text_classification.html">Text Classification</a>
    <a class="dropdown-item" href="../articles/tutorial_basic_regression.html">Basic Regression</a>
    <a class="dropdown-item" href="../articles/tutorial_overfit_underfit.html">Overfitting and Underfitting</a>
    <a class="dropdown-item" href="../articles/tutorial_save_and_restore.html">Save and Restore Models</a>
  </div>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-guides">Guides</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-guides">
    <h6 class="dropdown-header" data-toc-skip>Model definition</h6>
    <a class="dropdown-item" href="../articles/functional_api.html">Functional API</a>
    <a class="dropdown-item" href="../articles/sequential_model.html">Sequential Model</a>
    <h6 class="dropdown-header" data-toc-skip>Extending and customizing</h6>
    <a class="dropdown-item" href="../articles/making_new_layers_and_models_via_subclassing.html">Making new layers and models via subclassing</a>
    <a class="dropdown-item" href="../articles/training_with_built_in_methods.html">Training &amp; evaluation with the built-in methods</a>
    <a class="dropdown-item" href="../articles/writing_a_custom_training_loop_in_tensorflow.html">Writing a training loop from scratch in TensorFlow</a>
    <a class="dropdown-item" href="../articles/writing_your_own_callbacks.html">Writing Your Own Callbacks</a>
    <h6 class="dropdown-header" data-toc-skip>Other topics</h6>
    <a class="dropdown-item" href="../articles/transfer_learning.html">Transfer learning and fine tuning</a>
    <a class="dropdown-item" href="../articles/distributed_training_with_tensorflow.html">Distributed training with TensorFlow</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../articles/examples/index.html">Examples</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">News</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/rstudio/keras/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Working with preprocessing layers</h1>
            
            <h4 data-toc-skip class="date">Last Modified: 2023-11-21;
Last Rendered: 2023-11-24</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/rstudio/keras/blob/HEAD/vignettes/preprocessing_layers.Rmd" class="external-link"><code>vignettes/preprocessing_layers.Rmd</code></a></small>
      <div class="d-none name"><code>preprocessing_layers.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="keras-preprocessing">Keras preprocessing<a class="anchor" aria-label="anchor" href="#keras-preprocessing"></a>
</h2>
<p>The Keras preprocessing layers API allows developers to build
Keras-native input processing pipelines. These input processing
pipelines can be used as independent preprocessing code in non-Keras
workflows, combined directly with Keras models, and exported as part of
a Keras SavedModel.</p>
<p>With Keras preprocessing layers, you can build and export models that
are truly end-to-end: models that accept raw images or raw structured
data as input; models that handle feature normalization or feature value
indexing on their own.</p>
</div>
<div class="section level2">
<h2 id="available-preprocessing">Available preprocessing<a class="anchor" aria-label="anchor" href="#available-preprocessing"></a>
</h2>
<div class="section level3">
<h3 id="text-preprocessing">Text preprocessing<a class="anchor" aria-label="anchor" href="#text-preprocessing"></a>
</h3>
<ul>
<li>
<code>layer_text_vectorization</code>: turns raw strings into an
encoded representation that can be read by an <code>Embedding</code>
layer or <code>Dense</code> layer.</li>
</ul>
</div>
<div class="section level3">
<h3 id="numerical-features-preprocessing">Numerical features preprocessing<a class="anchor" aria-label="anchor" href="#numerical-features-preprocessing"></a>
</h3>
<ul>
<li>
<code>layer_normalization</code>: performs feature-wise
normalization of input features.</li>
<li>
<code>layer_discretization</code>: turns continuous numerical
features into integer categorical features.</li>
</ul>
</div>
<div class="section level3">
<h3 id="categorical-features-preprocessing">Categorical features preprocessing<a class="anchor" aria-label="anchor" href="#categorical-features-preprocessing"></a>
</h3>
<ul>
<li>
<code>layer_category_encoding</code>: turns integer categorical
features into one-hot, multi-hot, or count dense representations.</li>
<li>
<code>layer_hashing</code>: performs categorical feature hashing,
also known as the “hashing trick”.</li>
<li>
<code>layer_string_lookup</code>: turns string categorical values
into an encoded representation that can be read by an
<code>Embedding</code> layer or <code>Dense</code> layer.</li>
<li>
<code>layer_integer_lookup</code>: turns integer categorical values
into an encoded representation that can be read by an
<code>Embedding</code> layer or <code>Dense</code> layer.</li>
</ul>
</div>
<div class="section level3">
<h3 id="image-preprocessing">Image preprocessing<a class="anchor" aria-label="anchor" href="#image-preprocessing"></a>
</h3>
<p>These layers are for standardizing the inputs of an image model.</p>
<ul>
<li>
<code>layer_resizing</code>: resizes a batch of images to a target
size.</li>
<li>
<code>layer_rescaling</code>: rescales and offsets the values of a
batch of images (e.g. go from inputs in the <code>[0, 255]</code> range
to inputs in the <code>[0, 1]</code> range.</li>
<li>
<code>layer_center_crop</code>: returns a center crop of a batch of
images.</li>
</ul>
</div>
<div class="section level3">
<h3 id="image-data-augmentation">Image data augmentation<a class="anchor" aria-label="anchor" href="#image-data-augmentation"></a>
</h3>
<p>These layers apply random augmentation transforms to a batch of
images. They are only active during training.</p>
<ul>
<li><code>layer_random_clip</code></li>
<li><code>layer_random_flip</code></li>
<li><code>layer_random_translation</code></li>
<li><code>layer_random_rotation</code></li>
<li><code>layer_random_zoom</code></li>
<li><code>layer_random_contrast</code></li>
</ul>
</div>
</div>
<div class="section level2">
<h2 id="the-adapt-method">The <code>adapt()</code> method<a class="anchor" aria-label="anchor" href="#the-adapt-method"></a>
</h2>
<p>Some preprocessing layers have an internal state that can be computed
based on a sample of the training data. The list of stateful
preprocessing layers is:</p>
<ul>
<li>
<code>TextVectorization</code>: holds a mapping between string
tokens and integer indices</li>
<li>
<code>StringLookup</code> and <code>IntegerLookup</code>: hold a
mapping between input values and integer indices.</li>
<li>
<code>Normalization</code>: holds the mean and standard deviation of
the features.</li>
<li>
<code>Discretization</code>: holds information about value bucket
boundaries.</li>
</ul>
<p>Crucially, these layers are <strong>non-trainable</strong>. Their
state is not set during training; it must be set <strong>before
training</strong>, either by initializing them from a precomputed
constant, or by “adapting” them on data.</p>
<p>You set the state of a preprocessing layer by exposing it to training
data, via the <code><a href="../reference/adapt.html">adapt()</a></code> method:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https:/keras.posit.co/">keras3</a></span><span class="op">)</span></span>
<span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.1</span>, <span class="fl">0.2</span>, <span class="fl">0.3</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.8</span>, <span class="fl">0.9</span>, <span class="fl">1.0</span><span class="op">)</span>,</span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1.5</span>, <span class="fl">1.6</span>, <span class="fl">1.7</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="va">layer</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/layer_normalization.html">layer_normalization</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">layer</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="../reference/adapt.html">adapt</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span>
<span><span class="va">normalized_data</span> <span class="op">&lt;-</span> <span class="fu">layer</span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="../reference/op_mean.html">op_mean</a></span><span class="op">(</span><span class="va">normalized_data</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## tf.Tensor(-2.6490953e-08, shape=(), dtype=float32)</span></span></code></pre>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/op_std.html">op_std</a></span><span class="op">(</span><span class="va">normalized_data</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## tf.Tensor(1.0, shape=(), dtype=float32)</span></span></code></pre>
<p>The <code><a href="../reference/adapt.html">adapt()</a></code> method takes either a Numpy array or a
<code>tf.data.Dataset</code> object. In the case of
<code>StringLookup</code> and <code>TextVectorization</code>, you can
also pass a list of strings:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span></span>
<span>    <span class="st">"ξεῖν᾽, ἦ τοι μὲν ὄνειροι ἀμήχανοι ἀκριτόμυθοι"</span>,</span>
<span>    <span class="st">"γίγνοντ᾽, οὐδέ τι πάντα τελείεται ἀνθρώποισι."</span>,</span>
<span>    <span class="st">"δοιαὶ γάρ τε πύλαι ἀμενηνῶν εἰσὶν ὀνείρων:"</span>,</span>
<span>    <span class="st">"αἱ μὲν γὰρ κεράεσσι τετεύχαται, αἱ δ᾽ ἐλέφαντι:"</span>,</span>
<span>    <span class="st">"τῶν οἳ μέν κ᾽ ἔλθωσι διὰ πριστοῦ ἐλέφαντος,"</span>,</span>
<span>    <span class="st">"οἵ ῥ᾽ ἐλεφαίρονται, ἔπε᾽ ἀκράαντα φέροντες:"</span>,</span>
<span>    <span class="st">"οἱ δὲ διὰ ξεστῶν κεράων ἔλθωσι θύραζε,"</span>,</span>
<span>    <span class="st">"οἵ ῥ᾽ ἔτυμα κραίνουσι, βροτῶν ὅτε κέν τις ἴδηται."</span></span>
<span><span class="op">)</span></span>
<span><span class="va">layer</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/layer_text_vectorization.html">layer_text_vectorization</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">layer</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="../reference/adapt.html">adapt</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span>
<span><span class="va">vectorized_text</span> <span class="op">&lt;-</span> <span class="fu">layer</span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span>
<span><span class="va">vectorized_text</span></span></code></pre></div>
<pre><code><span><span class="co">## tf.Tensor(</span></span>
<span><span class="co">## [[37 12 25  5  9 20 21  0  0]</span></span>
<span><span class="co">##  [51 34 27 33 29 18  0  0  0]</span></span>
<span><span class="co">##  [49 52 30 31 19 46 10  0  0]</span></span>
<span><span class="co">##  [ 7  5 50 43 28  7 47 17  0]</span></span>
<span><span class="co">##  [24 35 39 40  3  6 32 16  0]</span></span>
<span><span class="co">##  [ 4  2 15 14 22 23  0  0  0]</span></span>
<span><span class="co">##  [36 48  6 38 42  3 45  0  0]</span></span>
<span><span class="co">##  [ 4  2 13 41 53  8 44 26 11]], shape=(8, 9), dtype=int64)</span></span></code></pre>
<p>In addition, adaptable layers always expose an option to directly set
state via constructor arguments or weight assignment. If the intended
state values are known at layer construction time, or are calculated
outside of the <code><a href="../reference/adapt.html">adapt()</a></code> call, they can be set without
relying on the layer’s internal computation. For instance, if external
vocabulary files for the <code>TextVectorization</code>,
<code>StringLookup</code>, or <code>IntegerLookup</code> layers already
exist, those can be loaded directly into the lookup tables by passing a
path to the vocabulary file in the layer’s constructor arguments.</p>
<p>Here’s an example where you instantiate a <code>StringLookup</code>
layer with precomputed vocabulary:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">vocab</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"a"</span>, <span class="st">"b"</span>, <span class="st">"c"</span>, <span class="st">"d"</span><span class="op">)</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"a"</span>, <span class="st">"c"</span>, <span class="st">"d"</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"d"</span>, <span class="st">"z"</span>, <span class="st">"b"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">layer</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/layer_string_lookup.html">layer_string_lookup</a></span><span class="op">(</span>vocabulary<span class="op">=</span><span class="va">vocab</span><span class="op">)</span></span>
<span><span class="va">vectorized_data</span> <span class="op">&lt;-</span> <span class="fu">layer</span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span>
<span><span class="va">vectorized_data</span></span></code></pre></div>
<pre><code><span><span class="co">## tf.Tensor(</span></span>
<span><span class="co">## [[1 3 4]</span></span>
<span><span class="co">##  [4 0 2]], shape=(2, 3), dtype=int64)</span></span></code></pre>
</div>
<div class="section level2">
<h2 id="preprocessing-data-before-the-model-or-inside-the-model">Preprocessing data before the model or inside the model<a class="anchor" aria-label="anchor" href="#preprocessing-data-before-the-model-or-inside-the-model"></a>
</h2>
<p>There are two ways you could be using preprocessing layers:</p>
<p><strong>Option 1:</strong> Make them part of the model, like
this:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/layer_input.html">layer_input</a></span><span class="op">(</span>shape<span class="op">=</span><span class="va">input_shape</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu">preprocessing_layer</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span></span>
<span><span class="va">outputs</span> <span class="op">&lt;-</span> <span class="fu">rest_of_the_model</span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/keras_model.html">keras_model</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="va">outputs</span><span class="op">)</span></span></code></pre></div>
<p>With this option, preprocessing will happen on device, synchronously
with the rest of the model execution, meaning that it will benefit from
GPU acceleration. If you’re training on a GPU, this is the best option
for the <code>Normalization</code> layer, and for all image
preprocessing and data augmentation layers.</p>
<p><strong>Option 2:</strong> apply it to your
<code>tf.data.Dataset</code>, so as to obtain a dataset that yields
batches of preprocessed data, like this:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dataset</span> <span class="op">&lt;-</span> <span class="va">dataset</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_map.html" class="external-link">dataset_map</a></span><span class="op">(</span><span class="kw">function</span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="fu">preprocessing_layer</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, <span class="va">y</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>With this option, your preprocessing will happen on a CPU,
asynchronously, and will be buffered before going into the model. In
addition, if you call <code>dataset.prefetch(tf.data.AUTOTUNE)</code> on
your dataset, the preprocessing will happen efficiently in parallel with
training:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dataset</span> <span class="op">&lt;-</span> <span class="va">dataset</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_map.html" class="external-link">dataset_map</a></span><span class="op">(</span><span class="kw">function</span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="fu">preprocessing_layer</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, <span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_prefetch.html" class="external-link">dataset_prefetch</a></span><span class="op">(</span><span class="va">tf</span><span class="op">$</span><span class="va">data</span><span class="op">$</span><span class="va">AUTOTUNE</span><span class="op">)</span></span>
<span><span class="va">model</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span><span class="va">dataset</span>, <span class="va">...</span><span class="op">)</span></span></code></pre></div>
<p>This is the best option for <code>TextVectorization</code>, and all
structured data preprocessing layers. It can also be a good option if
you’re training on a CPU and you use image preprocessing layers.</p>
<p>Note that the <code>TextVectorization</code> layer can only be
executed on a CPU, as it is mostly a dictionary lookup operation.
Therefore, if you are training your model on a GPU or a TPU, you should
put the <code>TextVectorization</code> layer in the <code>tf.data</code>
pipeline to get the best performance.</p>
<p><strong>When running on a TPU, you should always place preprocessing
layers in the <code>tf$data</code> pipeline</strong> (with the exception
of <code>Normalization</code> and <code>Rescaling</code>, which run fine
on a TPU and are commonly used as the first layer in an image
model).</p>
</div>
<div class="section level2">
<h2 id="benefits-of-doing-preprocessing-inside-the-model-at-inference-time">Benefits of doing preprocessing inside the model at inference
time<a class="anchor" aria-label="anchor" href="#benefits-of-doing-preprocessing-inside-the-model-at-inference-time"></a>
</h2>
<p>Even if you go with option 2, you may later want to export an
inference-only end-to-end model that will include the preprocessing
layers. The key benefit to doing this is that <strong>it makes your
model portable</strong> and it <strong>helps reduce the <a href="https://developers.google.com/machine-learning/guides/rules-of-ml#training-serving_skew" class="external-link">training/serving
skew</a></strong>.</p>
<p>When all data preprocessing is part of the model, other people can
load and use your model without having to be aware of how each feature
is expected to be encoded &amp; normalized. Your inference model will be
able to process raw images or raw structured data, and will not require
users of the model to be aware of the details of e.g. the tokenization
scheme used for text, the indexing scheme used for categorical features,
whether image pixel values are normalized to <code>[-1, +1]</code> or to
<code>[0, 1]</code>, etc. This is especially powerful if you’re
exporting your model to another runtime, such as TensorFlow.js: you
won’t have to reimplement your preprocessing pipeline in JavaScript.</p>
<p>If you initially put your preprocessing layers in your
<code>tf.data</code> pipeline, you can export an inference model that
packages the preprocessing. Simply instantiate a new model that chains
your preprocessing layers and your training model:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/layer_input.html">layer_input</a></span><span class="op">(</span>shape<span class="op">=</span><span class="va">input_shape</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu">preprocessing_layer</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span></span>
<span><span class="va">outputs</span> <span class="op">&lt;-</span> <span class="fu">training_model</span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="va">inference_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/keras_model.html">keras_model</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="va">outputs</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="preprocessing-during-multi-worker-training">Preprocessing during multi-worker training<a class="anchor" aria-label="anchor" href="#preprocessing-during-multi-worker-training"></a>
</h2>
<p>Preprocessing layers are compatible with the <a href="https://www.tensorflow.org/api_docs/python/tf/distribute" class="external-link">tf$distribute</a>
API for running training across multiple machines.</p>
<p>In general, preprocessing layers should be placed inside a
<code>tf.distribute.Strategy.scope()</code> and called either inside or
before the model as discussed above.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/with.html" class="external-link">with</a></span> <span class="op">(</span><span class="va">strategy</span><span class="op">$</span><span class="fu">scope</span><span class="op">(</span><span class="op">)</span>, <span class="op">{</span></span>
<span>  <span class="va">inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/layer_input.html">layer_input</a></span><span class="op">(</span>shape<span class="op">=</span><span class="va">input_shape</span><span class="op">)</span></span>
<span>  <span class="va">preprocessing_layer</span> <span class="op">=</span> <span class="fu"><a href="../reference/layer_hashing.html">layer_hashing</a></span><span class="op">(</span><span class="fl">10</span><span class="op">)</span></span>
<span>  <span class="va">dense_layer</span> <span class="op">=</span> <span class="fu">tf.keras.layers.Dense</span><span class="op">(</span><span class="fl">16</span><span class="op">)</span></span>
<span><span class="op">}</span><span class="op">)</span></span></code></pre></div>
<p>For more details, refer to the <em>Data preprocessing</em> section of
the <a href="https://www.tensorflow.org/tutorials/distribute/input" class="external-link">Distributed
input</a> tutorial.</p>
</div>
<div class="section level2">
<h2 id="quick-recipes">Quick recipes<a class="anchor" aria-label="anchor" href="#quick-recipes"></a>
</h2>
<div class="section level3">
<h3 id="image-data-augmentation-1">Image data augmentation<a class="anchor" aria-label="anchor" href="#image-data-augmentation-1"></a>
</h3>
<p>Note that image data augmentation layers are only active during
training (similarly to the <code>Dropout</code> layer).</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Create a data augmentation stage with horizontal flipping, rotations, zooms</span></span>
<span><span class="va">data_augmentation</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/keras_model_sequential.html">keras_model_sequential</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="../reference/layer_random_flip.html">layer_random_flip</a></span><span class="op">(</span><span class="st">"horizontal"</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="../reference/layer_random_rotation.html">layer_random_rotation</a></span><span class="op">(</span><span class="fl">0.1</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="../reference/layer_random_zoom.html">layer_random_zoom</a></span><span class="op">(</span><span class="fl">0.1</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Load some data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">x_train</span>, <span class="va">y_train</span><span class="op">)</span>, <span class="va">.</span><span class="op">)</span> <span class="op"><a href="../reference/multi-assign.html">%&lt;-%</a></span> <span class="fu"><a href="../reference/dataset_cifar10.html">dataset_cifar10</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">input_shape</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">x_train</span><span class="op">)</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span></span>
<span><span class="va">classes</span> <span class="op">&lt;-</span> <span class="fl">10</span></span>
<span></span>
<span><span class="co"># Create a tf.data pipeline of augmented images (and their labels)</span></span>
<span><span class="va">train_dataset</span> <span class="op">&lt;-</span> <span class="fu">tfdatasets</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/tensor_slices_dataset.html" class="external-link">tensor_slices_dataset</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">x_train</span>, <span class="va">y_train</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">tfdatasets</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_batch.html" class="external-link">dataset_batch</a></span><span class="op">(</span><span class="fl">16</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">tfdatasets</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_map.html" class="external-link">dataset_map</a></span><span class="op">(</span><span class="kw">function</span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="fu">data_augmentation</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, <span class="va">y</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Create a model and train it on the augmented image data</span></span>
<span><span class="va">inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/layer_input.html">layer_input</a></span><span class="op">(</span>shape<span class="op">=</span><span class="va">input_shape</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/layer_rescaling.html">layer_rescaling</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="fl">1.0</span> <span class="op">/</span> <span class="fl">255</span><span class="op">)</span><span class="co"># Rescale inputs</span></span>
<span><span class="va">outputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/application_resnet50.html">application_resnet50</a></span><span class="op">(</span>  <span class="co"># Add the rest of the model</span></span>
<span>    weights<span class="op">=</span><span class="cn">NULL</span>, input_shape<span class="op">=</span><span class="va">input_shape</span>, classes<span class="op">=</span><span class="va">classes</span></span>
<span><span class="op">)</span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/keras_model.html">keras_model</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="va">outputs</span><span class="op">)</span></span>
<span><span class="va">model</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html" class="external-link">compile</a></span><span class="op">(</span>optimizer<span class="op">=</span><span class="st">"rmsprop"</span>, loss<span class="op">=</span><span class="st">"sparse_categorical_crossentropy"</span><span class="op">)</span></span>
<span><span class="va">model</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span><span class="va">train_dataset</span>, steps_per_epoch<span class="op">=</span><span class="fl">5</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Epoch 1/10</span></span>
<span><span class="co">## 5/5 - 7s - 1s/step - loss: 7.4957</span></span>
<span><span class="co">## Epoch 2/10</span></span>
<span><span class="co">## 5/5 - 1s - 151ms/step - loss: 4.6604</span></span>
<span><span class="co">## Epoch 3/10</span></span>
<span><span class="co">## 5/5 - 1s - 150ms/step - loss: 3.5557</span></span>
<span><span class="co">## Epoch 4/10</span></span>
<span><span class="co">## 5/5 - 1s - 148ms/step - loss: 3.5326</span></span>
<span><span class="co">## Epoch 5/10</span></span>
<span><span class="co">## 5/5 - 1s - 149ms/step - loss: 3.3773</span></span>
<span><span class="co">## Epoch 6/10</span></span>
<span><span class="co">## 5/5 - 1s - 150ms/step - loss: 4.4809</span></span>
<span><span class="co">## Epoch 7/10</span></span>
<span><span class="co">## 5/5 - 1s - 150ms/step - loss: 4.4726</span></span>
<span><span class="co">## Epoch 8/10</span></span>
<span><span class="co">## 5/5 - 1s - 149ms/step - loss: 4.3798</span></span>
<span><span class="co">## Epoch 9/10</span></span>
<span><span class="co">## 5/5 - 1s - 149ms/step - loss: 3.7721</span></span>
<span><span class="co">## Epoch 10/10</span></span>
<span><span class="co">## 5/5 - 1s - 150ms/step - loss: 3.2425</span></span></code></pre>
<p>You can see a similar setup in action in the example <a href="https://keras.io/examples/vision/image_classification_from_scratch/" class="external-link">image
classification from scratch</a>.</p>
</div>
<div class="section level3">
<h3 id="normalizing-numerical-features">Normalizing numerical features<a class="anchor" aria-label="anchor" href="#normalizing-numerical-features"></a>
</h3>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Load some data</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">x_train</span>, <span class="va">y_train</span><span class="op">)</span>, <span class="va">.</span><span class="op">)</span> <span class="op"><a href="../reference/multi-assign.html">%&lt;-%</a></span> <span class="fu"><a href="../reference/dataset_cifar10.html">dataset_cifar10</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">x_train</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rstudio.github.io/reticulate/reference/array_reshape.html" class="external-link">array_reshape</a></span><span class="op">(</span><span class="va">x_train</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">x_train</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, <span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">input_shape</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">x_train</span><span class="op">)</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span></span>
<span><span class="va">classes</span> <span class="op">&lt;-</span> <span class="fl">10</span></span>
<span></span>
<span><span class="co"># Create a Normalization layer and set its internal state using the training data</span></span>
<span><span class="va">normalizer</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/layer_normalization.html">layer_normalization</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="va">normalizer</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="../reference/adapt.html">adapt</a></span><span class="op">(</span><span class="va">x_train</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Create a model that include the normalization layer</span></span>
<span><span class="va">inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/layer_input.html">layer_input</a></span><span class="op">(</span>shape<span class="op">=</span><span class="va">input_shape</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu">normalizer</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span></span>
<span><span class="va">outputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">classes</span>, activation<span class="op">=</span><span class="st">"softmax"</span><span class="op">)</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/keras_model.html">keras_model</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="va">outputs</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Train the model</span></span>
<span><span class="va">model</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html" class="external-link">compile</a></span><span class="op">(</span>optimizer<span class="op">=</span><span class="st">"adam"</span>, loss<span class="op">=</span><span class="st">"sparse_categorical_crossentropy"</span><span class="op">)</span></span>
<span><span class="va">model</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span><span class="va">x_train</span>, <span class="va">y_train</span>, epochs <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## 1563/1563 - 1s - 752us/step - loss: 2.1387</span></span></code></pre>
</div>
<div class="section level3">
<h3 id="encoding-string-categorical-features-via-one-hot-encoding">Encoding string categorical features via one-hot encoding<a class="anchor" aria-label="anchor" href="#encoding-string-categorical-features-via-one-hot-encoding"></a>
</h3>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Define some toy data</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span><span class="st">"a"</span>, <span class="st">"b"</span>, <span class="st">"c"</span>, <span class="st">"b"</span>, <span class="st">"c"</span>, <span class="st">"a"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Use StringLookup to build an index of the feature values and encode output.</span></span>
<span><span class="va">lookup</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/layer_string_lookup.html">layer_string_lookup</a></span><span class="op">(</span>output_mode<span class="op">=</span><span class="st">"one_hot"</span><span class="op">)</span></span>
<span><span class="va">lookup</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="../reference/adapt.html">adapt</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Convert new test data (which includes unknown feature values)</span></span>
<span><span class="va">test_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span><span class="st">"a"</span>, <span class="st">"b"</span>, <span class="st">"c"</span>, <span class="st">"b"</span>, <span class="st">"c"</span>, <span class="st">""</span><span class="op">)</span></span>
<span><span class="va">encoded_data</span> <span class="op">&lt;-</span> <span class="fu">lookup</span><span class="op">(</span><span class="va">test_data</span><span class="op">)</span></span>
<span><span class="va">encoded_data</span></span></code></pre></div>
<pre><code><span><span class="co">## tf.Tensor(</span></span>
<span><span class="co">## [[0 0 0 1]</span></span>
<span><span class="co">##  [0 0 1 0]</span></span>
<span><span class="co">##  [0 1 0 0]</span></span>
<span><span class="co">##  [0 0 1 0]</span></span>
<span><span class="co">##  [0 1 0 0]</span></span>
<span><span class="co">##  [1 0 0 0]], shape=(6, 4), dtype=int64)</span></span></code></pre>
<p>Note that, here, index 0 is reserved for out-of-vocabulary values
(values that were not seen during <code><a href="../reference/adapt.html">adapt()</a></code>).</p>
<p>You can see the <code>StringLookup</code> in action in the <a href="https://keras.io/examples/structured_data/structured_data_classification_from_scratch/" class="external-link">Structured
data classification from scratch</a> example.</p>
</div>
<div class="section level3">
<h3 id="encoding-integer-categorical-features-via-one-hot-encoding">Encoding integer categorical features via one-hot encoding<a class="anchor" aria-label="anchor" href="#encoding-integer-categorical-features-via-one-hot-encoding"></a>
</h3>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Define some toy data</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span><span class="fl">10</span>, <span class="fl">20</span>, <span class="fl">20</span>, <span class="fl">10</span>, <span class="fl">30</span>, <span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Use IntegerLookup to build an index of the feature values and encode output.</span></span>
<span><span class="va">lookup</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/layer_integer_lookup.html">layer_integer_lookup</a></span><span class="op">(</span>output_mode<span class="op">=</span><span class="st">"one_hot"</span><span class="op">)</span></span>
<span><span class="va">lookup</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="../reference/adapt.html">adapt</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Convert new test data (which includes unknown feature values)</span></span>
<span><span class="va">test_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span><span class="fl">10</span>, <span class="fl">10</span>, <span class="fl">20</span>, <span class="fl">50</span>, <span class="fl">60</span>, <span class="fl">0</span><span class="op">)</span></span>
<span><span class="va">encoded_data</span> <span class="op">&lt;-</span> <span class="fu">lookup</span><span class="op">(</span><span class="va">test_data</span><span class="op">)</span></span>
<span><span class="va">encoded_data</span></span></code></pre></div>
<pre><code><span><span class="co">## tf.Tensor(</span></span>
<span><span class="co">## [[0 0 1 0 0]</span></span>
<span><span class="co">##  [0 0 1 0 0]</span></span>
<span><span class="co">##  [0 1 0 0 0]</span></span>
<span><span class="co">##  [1 0 0 0 0]</span></span>
<span><span class="co">##  [1 0 0 0 0]</span></span>
<span><span class="co">##  [0 0 0 0 1]], shape=(6, 5), dtype=int64)</span></span></code></pre>
<p>Note that index 0 is reserved for missing values (which you should
specify as the value 0), and index 1 is reserved for out-of-vocabulary
values (values that were not seen during <code><a href="../reference/adapt.html">adapt()</a></code>). You can
configure this by using the <code>mask_token</code> and
<code>oov_token</code> constructor arguments of
<code>IntegerLookup</code>.</p>
<p>You can see the <code>IntegerLookup</code> in action in the example
<a href="https://keras.io/examples/structured_data/structured_data_classification_from_scratch/" class="external-link">structured
data classification from scratch</a>.</p>
</div>
<div class="section level3">
<h3 id="applying-the-hashing-trick-to-an-integer-categorical-feature">Applying the hashing trick to an integer categorical feature<a class="anchor" aria-label="anchor" href="#applying-the-hashing-trick-to-an-integer-categorical-feature"></a>
</h3>
<p>If you have a categorical feature that can take many different values
(on the order of 10e3 or higher), where each value only appears a few
times in the data, it becomes impractical and ineffective to index and
one-hot encode the feature values. Instead, it can be a good idea to
apply the “hashing trick”: hash the values to a vector of fixed size.
This keeps the size of the feature space manageable, and removes the
need for explicit indexing.</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Sample data: 10,000 random integers with values between 0 and 100,000</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/random_integer.html">random_integer</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">100000</span>, shape<span class="op">=</span><span class="fu"><a href="../reference/shape.html">shape</a></span><span class="op">(</span><span class="fl">10000</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Use the Hashing layer to hash the values to the range [0, 64]</span></span>
<span><span class="va">hasher</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/layer_hashing.html">layer_hashing</a></span><span class="op">(</span>num_bins<span class="op">=</span><span class="fl">64</span>, salt<span class="op">=</span><span class="fl">1337</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Use the CategoryEncoding layer to multi-hot encode the hashed values</span></span>
<span><span class="va">encoder</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/layer_category_encoding.html">layer_category_encoding</a></span><span class="op">(</span>num_tokens<span class="op">=</span><span class="fl">64</span>, output_mode<span class="op">=</span><span class="st">"multi_hot"</span><span class="op">)</span></span>
<span><span class="va">encoded_data</span> <span class="op">&lt;-</span> <span class="fu">encoder</span><span class="op">(</span><span class="fu">hasher</span><span class="op">(</span><span class="va">data</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">encoded_data</span><span class="op">$</span><span class="va">shape</span></span></code></pre></div>
<pre><code><span><span class="co">## TensorShape([10000, 64])</span></span></code></pre>
</div>
<div class="section level3">
<h3 id="encoding-text-as-a-sequence-of-token-indices">Encoding text as a sequence of token indices<a class="anchor" aria-label="anchor" href="#encoding-text-as-a-sequence-of-token-indices"></a>
</h3>
<p>This is how you should preprocess text to be passed to an
<code>Embedding</code> layer.</p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Define some text data to adapt the layer</span></span>
<span><span class="va">adapt_data</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span></span>
<span>  <span class="st">"The Brain is wider than the Sky"</span>,</span>
<span>  <span class="st">"For put them side by side"</span>,</span>
<span>  <span class="st">"The one the other will contain"</span>,</span>
<span>  <span class="st">"With ease and You beside"</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Create a TextVectorization layer</span></span>
<span><span class="va">text_vectorizer</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/layer_text_vectorization.html">layer_text_vectorization</a></span><span class="op">(</span>output_mode<span class="op">=</span><span class="st">"int"</span><span class="op">)</span></span>
<span><span class="co"># Index the vocabulary via `adapt()`</span></span>
<span><span class="va">text_vectorizer</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="../reference/adapt.html">adapt</a></span><span class="op">(</span><span class="va">adapt_data</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Try out the layer</span></span>
<span><span class="fu">text_vectorizer</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span><span class="st">"The Brain is deeper than the sea"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## tf.Tensor([[ 2 19 14  1  9  2  1]], shape=(1, 7), dtype=int64)</span></span></code></pre>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Create a simple model</span></span>
<span><span class="va">inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/layer_input.html">layer_input</a></span><span class="op">(</span>shape<span class="op">=</span><span class="fu"><a href="../reference/shape.html">shape</a></span><span class="op">(</span><span class="cn">NULL</span><span class="op">)</span>, dtype<span class="op">=</span><span class="st">"int64"</span><span class="op">)</span></span>
<span><span class="va">outputs</span> <span class="op">&lt;-</span> <span class="va">inputs</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="../reference/layer_embedding.html">layer_embedding</a></span><span class="op">(</span>input_dim<span class="op">=</span><span class="va">text_vectorizer</span><span class="op">$</span><span class="fu">vocabulary_size</span><span class="op">(</span><span class="op">)</span>, output_dim<span class="op">=</span><span class="fl">16</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="../reference/layer_gru.html">layer_gru</a></span><span class="op">(</span>units<span class="op">=</span><span class="fl">8</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span>units<span class="op">=</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/keras_model.html">keras_model</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="va">outputs</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Create a labeled dataset (which includes unknown tokens)</span></span>
<span><span class="va">train_dataset</span> <span class="op">&lt;-</span> <span class="fu">tfdatasets</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/tensor_slices_dataset.html" class="external-link">tensor_slices_dataset</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span><span class="st">"The Brain is deeper than the sea"</span>, <span class="st">"for if they are held Blue to Blue"</span><span class="op">)</span>,</span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span></span>
<span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Preprocess the string inputs, turning them into int sequences</span></span>
<span><span class="va">train_dataset</span> <span class="op">&lt;-</span> <span class="va">train_dataset</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">tfdatasets</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_batch.html" class="external-link">dataset_batch</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">tfdatasets</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_map.html" class="external-link">dataset_map</a></span><span class="op">(</span><span class="kw">function</span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="fu">text_vectorizer</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, <span class="va">y</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Train the model on the int sequences</span></span>
<span><span class="va">model</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html" class="external-link">compile</a></span><span class="op">(</span>optimizer<span class="op">=</span><span class="st">"rmsprop"</span>, loss<span class="op">=</span><span class="st">"mse"</span><span class="op">)</span></span>
<span><span class="va">model</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span><span class="va">train_dataset</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Epoch 1/10</span></span>
<span><span class="co">## 1/1 - 1s - 596ms/step - loss: 0.5097</span></span>
<span><span class="co">## Epoch 2/10</span></span>
<span><span class="co">## 1/1 - 0s - 12ms/step - loss: 0.4756</span></span>
<span><span class="co">## Epoch 3/10</span></span>
<span><span class="co">## 1/1 - 0s - 12ms/step - loss: 0.4529</span></span>
<span><span class="co">## Epoch 4/10</span></span>
<span><span class="co">## 1/1 - 0s - 12ms/step - loss: 0.4347</span></span>
<span><span class="co">## Epoch 5/10</span></span>
<span><span class="co">## 1/1 - 0s - 12ms/step - loss: 0.4191</span></span>
<span><span class="co">## Epoch 6/10</span></span>
<span><span class="co">## 1/1 - 0s - 12ms/step - loss: 0.4050</span></span>
<span><span class="co">## Epoch 7/10</span></span>
<span><span class="co">## 1/1 - 0s - 12ms/step - loss: 0.3921</span></span>
<span><span class="co">## Epoch 8/10</span></span>
<span><span class="co">## 1/1 - 0s - 12ms/step - loss: 0.3800</span></span>
<span><span class="co">## Epoch 9/10</span></span>
<span><span class="co">## 1/1 - 0s - 12ms/step - loss: 0.3686</span></span>
<span><span class="co">## Epoch 10/10</span></span>
<span><span class="co">## 1/1 - 0s - 11ms/step - loss: 0.3577</span></span></code></pre>
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># For inference, you can export a model that accepts strings as input</span></span>
<span><span class="va">inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/layer_input.html">layer_input</a></span><span class="op">(</span>shape <span class="op">=</span> <span class="fl">1</span>, dtype<span class="op">=</span><span class="st">"string"</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu">text_vectorizer</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span></span>
<span><span class="va">outputs</span> <span class="op">&lt;-</span> <span class="fu">model</span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="va">end_to_end_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/keras_model.html">keras_model</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="va">outputs</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Call the end-to-end model on test data (which includes unknown tokens)</span></span>
<span><span class="va">test_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span><span class="st">"The one the other will absorb"</span><span class="op">)</span></span>
<span><span class="va">test_output</span> <span class="op">&lt;-</span> <span class="fu">end_to_end_model</span><span class="op">(</span><span class="va">test_data</span><span class="op">)</span></span>
<span><span class="va">test_output</span></span></code></pre></div>
<pre><code><span><span class="co">## tf.Tensor([[0.1398402]], shape=(1, 1), dtype=float32)</span></span></code></pre>
<p>You can see the <code>TextVectorization</code> layer in action,
combined with an <code>Embedding</code> mode, in the example <a href="https://keras.io/examples/nlp/text_classification_from_scratch/" class="external-link">text
classification from scratch</a>.</p>
<p>Note that when training such a model, for best performance, you
should always use the <code>TextVectorization</code> layer as part of
the input pipeline.</p>
</div>
<div class="section level3">
<h3 id="encoding-text-as-a-dense-matrix-of-n-grams-with-multi-hot-encoding">Encoding text as a dense matrix of N-grams with multi-hot
encoding<a class="anchor" aria-label="anchor" href="#encoding-text-as-a-dense-matrix-of-n-grams-with-multi-hot-encoding"></a>
</h3>
<p>This is how you should preprocess text to be passed to a
<code>Dense</code> layer.</p>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Define some text data to adapt the layer</span></span>
<span><span class="va">adapt_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span></span>
<span>  <span class="st">"The Brain is wider than the Sky"</span>,</span>
<span>  <span class="st">"For put them side by side"</span>,</span>
<span>  <span class="st">"The one the other will contain"</span>,</span>
<span>  <span class="st">"With ease and You beside"</span></span>
<span><span class="op">)</span></span>
<span><span class="co"># Instantiate TextVectorization with "multi_hot" output_mode</span></span>
<span><span class="co"># and ngrams=2 (index all bigrams)</span></span>
<span><span class="va">text_vectorizer</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/layer_text_vectorization.html">layer_text_vectorization</a></span><span class="op">(</span>output_mode<span class="op">=</span><span class="st">"multi_hot"</span>, ngrams<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="co"># Index the bigrams via `adapt()`</span></span>
<span><span class="va">text_vectorizer</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="../reference/adapt.html">adapt</a></span><span class="op">(</span><span class="va">adapt_data</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Try out the layer</span></span>
<span><span class="fu">text_vectorizer</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span><span class="st">"The Brain is deeper than the sea"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## tf.Tensor(</span></span>
<span><span class="co">## [[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0</span></span>
<span><span class="co">##   1 1 0 0 0]], shape=(1, 41), dtype=int64)</span></span></code></pre>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Create a simple model</span></span>
<span><span class="va">inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/layer_input.html">layer_input</a></span><span class="op">(</span>shape <span class="op">=</span> <span class="va">text_vectorizer</span><span class="op">$</span><span class="fu">vocabulary_size</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">outputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/keras_model.html">keras_model</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="va">outputs</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Create a labeled dataset (which includes unknown tokens)</span></span>
<span><span class="va">train_dataset</span> <span class="op">&lt;-</span> <span class="fu">tfdatasets</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/tensor_slices_dataset.html" class="external-link">tensor_slices_dataset</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span><span class="st">"The Brain is deeper than the sea"</span>, <span class="st">"for if they are held Blue to Blue"</span><span class="op">)</span>,</span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span></span>
<span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Preprocess the string inputs, turning them into int sequences</span></span>
<span><span class="va">train_dataset</span> <span class="op">&lt;-</span> <span class="va">train_dataset</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">tfdatasets</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_batch.html" class="external-link">dataset_batch</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">tfdatasets</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_map.html" class="external-link">dataset_map</a></span><span class="op">(</span><span class="kw">function</span><span class="op">(</span><span class="va">x</span>,<span class="va">y</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="fu">text_vectorizer</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, <span class="va">y</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co"># Train the model on the int sequences</span></span>
<span><span class="va">model</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html" class="external-link">compile</a></span><span class="op">(</span>optimizer<span class="op">=</span><span class="st">"rmsprop"</span>, loss<span class="op">=</span><span class="st">"mse"</span><span class="op">)</span></span>
<span><span class="va">model</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span><span class="va">train_dataset</span>, epochs <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Epoch 1/2</span></span>
<span><span class="co">## 1/1 - 0s - 112ms/step - loss: 1.2181</span></span>
<span><span class="co">## Epoch 2/2</span></span>
<span><span class="co">## 1/1 - 0s - 13ms/step - loss: 1.1751</span></span></code></pre>
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># For inference, you can export a model that accepts strings as input</span></span>
<span><span class="va">inputs</span> <span class="op">=</span> <span class="fu"><a href="../reference/layer_input.html">layer_input</a></span><span class="op">(</span>shape<span class="op">=</span><span class="fl">1</span>, dtype<span class="op">=</span><span class="st">"string"</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu">text_vectorizer</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span></span>
<span><span class="va">outputs</span> <span class="op">&lt;-</span> <span class="fu">model</span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="va">end_to_end_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/keras_model.html">keras_model</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="va">outputs</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Call the end-to-end model on test data (which includes unknown tokens)</span></span>
<span><span class="va">test_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span><span class="st">"The one the other will absorb"</span><span class="op">)</span></span>
<span><span class="va">test_output</span> <span class="op">&lt;-</span> <span class="fu">end_to_end_model</span><span class="op">(</span><span class="va">test_data</span><span class="op">)</span></span>
<span><span class="va">test_output</span></span></code></pre></div>
<pre><code><span><span class="co">## tf.Tensor([[-0.17866345]], shape=(1, 1), dtype=float32)</span></span></code></pre>
</div>
<div class="section level3">
<h3 id="encoding-text-as-a-dense-matrix-of-n-grams-with-tf-idf-weighting">Encoding text as a dense matrix of N-grams with TF-IDF
weighting<a class="anchor" aria-label="anchor" href="#encoding-text-as-a-dense-matrix-of-n-grams-with-tf-idf-weighting"></a>
</h3>
<p>This is an alternative way of preprocessing text before passing it to
a <code>Dense</code> layer.</p>
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Define some text data to adapt the layer</span></span>
<span><span class="va">adapt_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span></span>
<span>  <span class="st">"The Brain is wider than the Sky"</span>,</span>
<span>  <span class="st">"For put them side by side"</span>,</span>
<span>  <span class="st">"The one the other will contain"</span>,</span>
<span>  <span class="st">"With ease and You beside"</span></span>
<span><span class="op">)</span></span>
<span><span class="co"># Instantiate TextVectorization with "tf-idf" output_mode</span></span>
<span><span class="co"># (multi-hot with TF-IDF weighting) and ngrams=2 (index all bigrams)</span></span>
<span><span class="va">text_vectorizer</span> <span class="op">=</span> <span class="fu"><a href="../reference/layer_text_vectorization.html">layer_text_vectorization</a></span><span class="op">(</span>output_mode<span class="op">=</span><span class="st">"tf-idf"</span>, ngrams<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="co"># Index the bigrams and learn the TF-IDF weights via `adapt()`</span></span>
<span><span class="va">text_vectorizer</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="../reference/adapt.html">adapt</a></span><span class="op">(</span><span class="va">adapt_data</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Try out the layer</span></span>
<span><span class="fu">text_vectorizer</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span><span class="st">"The Brain is deeper than the sea"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## tf.Tensor(</span></span>
<span><span class="co">## [[5.461647  1.6945957 0.        0.        0.        0.        0.</span></span>
<span><span class="co">##   0.        0.        0.        0.        0.        0.        0.</span></span>
<span><span class="co">##   0.        0.        1.0986123 1.0986123 1.0986123 0.        0.</span></span>
<span><span class="co">##   0.        0.        0.        0.        0.        0.        0.</span></span>
<span><span class="co">##   1.0986123 0.        0.        0.        0.        0.        0.</span></span>
<span><span class="co">##   0.        1.0986123 1.0986123 0.        0.        0.       ]], shape=(1, 41), dtype=float32)</span></span></code></pre>
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Create a simple model</span></span>
<span><span class="va">inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/layer_input.html">layer_input</a></span><span class="op">(</span>shape <span class="op">=</span> <span class="va">text_vectorizer</span><span class="op">$</span><span class="fu">vocabulary_size</span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">outputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/keras_model.html">keras_model</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="va">outputs</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Create a labeled dataset (which includes unknown tokens)</span></span>
<span><span class="va">train_dataset</span> <span class="op">&lt;-</span> <span class="fu">tfdatasets</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/tensor_slices_dataset.html" class="external-link">tensor_slices_dataset</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span><span class="st">"The Brain is deeper than the sea"</span>, <span class="st">"for if they are held Blue to Blue"</span><span class="op">)</span>,</span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span></span>
<span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Preprocess the string inputs, turning them into int sequences</span></span>
<span><span class="va">train_dataset</span> <span class="op">&lt;-</span> <span class="va">train_dataset</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">tfdatasets</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_batch.html" class="external-link">dataset_batch</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu">tfdatasets</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/tfdatasets/man/dataset_map.html" class="external-link">dataset_map</a></span><span class="op">(</span><span class="kw">function</span><span class="op">(</span><span class="va">x</span>,<span class="va">y</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="fu">text_vectorizer</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, <span class="va">y</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Train the model on the int sequences</span></span>
<span><span class="va">model</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html" class="external-link">compile</a></span><span class="op">(</span>optimizer<span class="op">=</span><span class="st">"rmsprop"</span>, loss<span class="op">=</span><span class="st">"mse"</span><span class="op">)</span></span>
<span><span class="va">model</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span><span class="va">train_dataset</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Epoch 1/10</span></span>
<span><span class="co">## 1/1 - 0s - 113ms/step - loss: 7.9392</span></span>
<span><span class="co">## Epoch 2/10</span></span>
<span><span class="co">## 1/1 - 0s - 14ms/step - loss: 7.6545</span></span>
<span><span class="co">## Epoch 3/10</span></span>
<span><span class="co">## 1/1 - 0s - 14ms/step - loss: 7.4529</span></span>
<span><span class="co">## Epoch 4/10</span></span>
<span><span class="co">## 1/1 - 0s - 13ms/step - loss: 7.2871</span></span>
<span><span class="co">## Epoch 5/10</span></span>
<span><span class="co">## 1/1 - 0s - 15ms/step - loss: 7.1420</span></span>
<span><span class="co">## Epoch 6/10</span></span>
<span><span class="co">## 1/1 - 0s - 14ms/step - loss: 7.0108</span></span>
<span><span class="co">## Epoch 7/10</span></span>
<span><span class="co">## 1/1 - 0s - 14ms/step - loss: 6.8896</span></span>
<span><span class="co">## Epoch 8/10</span></span>
<span><span class="co">## 1/1 - 0s - 14ms/step - loss: 6.7760</span></span>
<span><span class="co">## Epoch 9/10</span></span>
<span><span class="co">## 1/1 - 0s - 14ms/step - loss: 6.6684</span></span>
<span><span class="co">## Epoch 10/10</span></span>
<span><span class="co">## 1/1 - 0s - 13ms/step - loss: 6.5657</span></span></code></pre>
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># For inference, you can export a model that accepts strings as input</span></span>
<span><span class="va">inputs</span> <span class="op">=</span> <span class="fu"><a href="../reference/layer_input.html">layer_input</a></span><span class="op">(</span>shape<span class="op">=</span><span class="fl">1</span>, dtype<span class="op">=</span><span class="st">"string"</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu">text_vectorizer</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span></span>
<span><span class="va">outputs</span> <span class="op">&lt;-</span> <span class="fu">model</span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="va">end_to_end_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/keras_model.html">keras_model</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="va">outputs</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Call the end-to-end model on test data (which includes unknown tokens)</span></span>
<span><span class="va">test_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span><span class="st">"The one the other will absorb"</span><span class="op">)</span></span>
<span><span class="va">test_output</span> <span class="op">&lt;-</span> <span class="fu">end_to_end_model</span><span class="op">(</span><span class="va">test_data</span><span class="op">)</span></span>
<span><span class="va">test_output</span></span></code></pre></div>
<pre><code><span><span class="co">## tf.Tensor([[0.35116184]], shape=(1, 1), dtype=float32)</span></span></code></pre>
</div>
</div>
<div class="section level2">
<h2 id="important-gotchas">Important gotchas<a class="anchor" aria-label="anchor" href="#important-gotchas"></a>
</h2>
<div class="section level3">
<h3 id="working-with-lookup-layers-with-very-large-vocabularies">Working with lookup layers with very large vocabularies<a class="anchor" aria-label="anchor" href="#working-with-lookup-layers-with-very-large-vocabularies"></a>
</h3>
<p>You may find yourself working with a very large vocabulary in a
<code>TextVectorization</code>, a <code>StringLookup</code> layer, or an
<code>IntegerLookup</code> layer. Typically, a vocabulary larger than
500MB would be considered “very large”.</p>
<p>In such a case, for best performance, you should avoid using
<code><a href="../reference/adapt.html">adapt()</a></code>. Instead, pre-compute your vocabulary in advance
(you could use Apache Beam or TF Transform for this) and store it in a
file. Then load the vocabulary into the layer at construction time by
passing the file path as the <code>vocabulary</code> argument.</p>
</div>
<div class="section level3">
<h3 id="using-lookup-layers-on-a-tpu-pod-or-with-parameterserverstrategy-">Using lookup layers on a TPU pod or with
<code>ParameterServerStrategy</code>.<a class="anchor" aria-label="anchor" href="#using-lookup-layers-on-a-tpu-pod-or-with-parameterserverstrategy-"></a>
</h3>
<p>There is an outstanding issue that causes performance to degrade when
using a <code>TextVectorization</code>, <code>StringLookup</code>, or
<code>IntegerLookup</code> layer while training on a TPU pod or on
multiple machines via <code>ParameterServerStrategy</code>. This is
slated to be fixed in TensorFlow 2.7.</p>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Tomasz Kalinowski, JJ Allaire, François Chollet, Posit Software, PBC, Google.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
