<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>WGAN-GP overriding `Model.train_step` • keras</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../../apple-touch-icon-60x60.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../../bootstrap-toc.css">
<script src="../../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../../pkgdown.css" rel="stylesheet">
<script src="../../pkgdown.js"></script><link href="../../extra.css" rel="stylesheet">
<script src="../../extra.js"></script><meta property="og:title" content="WGAN-GP overriding `Model.train_step`">
<meta property="og:description" content="Implementation of Wasserstein GAN with Gradient Penalty.">
<meta property="og:image" content="https://keras.posit.co/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    

    <div class="container template-article">
      <header><div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../../index.html">keras</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">2.13.0.9000</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../../index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Tutorials
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/getting_started.html">Getting Started</a>
    </li>
    <li>
      <a href="../../articles/tutorial_basic_classification.html">Basic Classification</a>
    </li>
    <li>
      <a href="../../articles/tutorial_basic_text_classification.html">Text Classification</a>
    </li>
    <li>
      <a href="../../articles/tutorial_basic_regression.html">Basic Regression</a>
    </li>
    <li>
      <a href="../../articles/tutorial_overfit_underfit.html">Overfitting and Underfitting</a>
    </li>
    <li>
      <a href="../../articles/tutorial_save_and_restore.html">Save and Restore Models</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Guides
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/writing_your_own_callbacks.html">Writing Your Own Callbacks</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li class="dropdown-header">Guides (New for TF 2.6)</li>
    <li>
      <a href="../../articles/new-guides/python_subclasses.html">Python Subclasses</a>
    </li>
    <li>
      <a href="../../articles/new-guides/making_new_layers_and_models_via_subclassing.html">Making New Layers and Models via Subclassing</a>
    </li>
    <li>
      <a href="../../articles/new-guides/customizing_what_happens_in_fit.html">Customizing What Happens in Fit</a>
    </li>
    <li>
      <a href="../../articles/new-guides/writing_your_own_callbacks.html">Writing Your Own Callbacks</a>
    </li>
    <li>
      <a href="../../articles/new-guides/preprocessing_layers.html">Working with Preprocessing Layers</a>
    </li>
    <li>
      <a href="../../argicles/new-guides/working_with_rnns.html">Working with RNNs</a>
    </li>
    <li class="divider">
    </li>
<li class="dropdown-header">Using Keras</li>
    <li>
      <a href="../../articles/guide_keras.html">Guide to Keras Basics</a>
    </li>
    <li>
      <a href="../../articles/sequential_model.html">Sequential Model in Depth</a>
    </li>
    <li>
      <a href="../../articles/functional_api.html">Functional API in Depth</a>
    </li>
    <li>
      <a href="../../articles/about_keras_models.html">About Keras Models</a>
    </li>
    <li>
      <a href="../../articles/about_keras_layers.html">About Keras Layers</a>
    </li>
    <li>
      <a href="../../articles/training_visualization.html">Training Visualization</a>
    </li>
    <li>
      <a href="../../articles/applications.html">Pre-Trained Models</a>
    </li>
    <li>
      <a href="../../articles/faq.html">Frequently Asked Questions</a>
    </li>
    <li>
      <a href="../../articles/why_use_keras.html">Why Use Keras?</a>
    </li>
    <li class="divider">
    </li>
<li class="dropdown-header">Advanced</li>
    <li>
      <a href="../../articles/eager_guide.html">Eager Execution</a>
    </li>
    <li>
      <a href="../../articles/training_callbacks.html">Training Callbacks</a>
    </li>
    <li>
      <a href="../../articles/backend.html">Keras Backend</a>
    </li>
    <li>
      <a href="../../articles/custom_layers.html">Custom Layers</a>
    </li>
    <li>
      <a href="../../articles/custom_models.html">Custom Models</a>
    </li>
    <li>
      <a href="../../articles/saving_serializing.html">Saving and serializing</a>
    </li>
  </ul>
</li>
<li>
  <a href="../../articles/learn.html">Learn</a>
</li>
<li>
  <a href="../../articles/tools.html">Tools</a>
</li>
<li>
  <a href="../../articles/examples/index.html">Examples</a>
</li>
<li>
  <a href="../../reference/index.html">Reference</a>
</li>
<li>
  <a href="../../news/index.html">News</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/rstudio/keras/" class="external-link">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>WGAN-GP overriding
<code>Model.train_step</code>
</h1>
                        <h4 data-toc-skip class="author"><a href="https://twitter.com/A_K_Nain" class="external-link">A_K_Nain</a></h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/rstudio/keras/blob/HEAD/vignettes/examples/wgan_gp.Rmd" class="external-link"><code>vignettes/examples/wgan_gp.Rmd</code></a></small>
      <div class="hidden name"><code>wgan_gp.Rmd</code></div>

    </div>

    
    
<div class="section level2">
<h2 id="wasserstein-gan-wgan-with-gradient-penalty-gp">Wasserstein GAN (WGAN) with Gradient Penalty (GP)<a class="anchor" aria-label="anchor" href="#wasserstein-gan-wgan-with-gradient-penalty-gp"></a>
</h2>
<p>The original <a href="https://arxiv.org/abs/1701.07875" class="external-link">Wasserstein
GAN</a> leverages the Wasserstein distance to produce a value function
that has better theoretical properties than the value function used in
the original GAN paper. WGAN requires that the discriminator (aka the
critic) lie within the space of 1-Lipschitz functions. The authors
proposed the idea of weight clipping to achieve this constraint. Though
weight clipping works, it can be a problematic way to enforce
1-Lipschitz constraint and can cause undesirable behavior, e.g. a very
deep WGAN discriminator (critic) often fails to converge.</p>
<p>The <a href="https://arxiv.org/abs/1704.00028" class="external-link">WGAN-GP</a> method
proposes an alternative to weight clipping to ensure smooth training.
Instead of clipping the weights, the authors proposed a “gradient
penalty” by adding a loss term that keeps the L2 norm of the
discriminator gradients close to 1.</p>
</div>
<div class="section level2">
<h2 id="setup">Setup<a class="anchor" aria-label="anchor" href="#setup"></a>
</h2>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">import</span> keras <span class="im">as</span> keras</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">from</span> keras <span class="im">import</span> layers</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="prepare-the-fashion-mnist-data">Prepare the Fashion-MNIST data<a class="anchor" aria-label="anchor" href="#prepare-the-fashion-mnist-data"></a>
</h2>
<p>To demonstrate how to train WGAN-GP, we will be using the <a href="https://github.com/zalandoresearch/fashion-mnist" class="external-link">Fashion-MNIST</a>
dataset. Each sample in this dataset is a 28x28 grayscale image
associated with a label from 10 classes (e.g. trouser, pullover,
sneaker, etc.)</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>IMG_SHAPE <span class="op">=</span> (<span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">1</span>)</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>BATCH_SIZE <span class="op">=</span> <span class="dv">512</span></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a><span class="co"># Size of the noise vector</span></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>noise_dim <span class="op">=</span> <span class="dv">128</span></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>fashion_mnist <span class="op">=</span> keras.datasets.fashion_mnist</span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>(train_images, train_labels), (</span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a>    test_images,</span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a>    test_labels,</span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a>) <span class="op">=</span> fashion_mnist.load_data()</span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of examples: </span><span class="sc">{</span><span class="bu">len</span>(train_images)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Shape of the images in the dataset: </span><span class="sc">{</span>train_images<span class="sc">.</span>shape[<span class="dv">1</span>:]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" tabindex="-1"></a><span class="co"># Reshape each sample to (28, 28, 1) and normalize the pixel values in the [-1, 1] range</span></span>
<span id="cb2-16"><a href="#cb2-16" tabindex="-1"></a>train_images <span class="op">=</span> train_images.reshape(train_images.shape[<span class="dv">0</span>], <span class="op">*</span>IMG_SHAPE).astype(</span>
<span id="cb2-17"><a href="#cb2-17" tabindex="-1"></a>    <span class="st">"float32"</span></span>
<span id="cb2-18"><a href="#cb2-18" tabindex="-1"></a>)</span>
<span id="cb2-19"><a href="#cb2-19" tabindex="-1"></a>train_images <span class="op">=</span> (train_images <span class="op">-</span> <span class="fl">127.5</span>) <span class="op">/</span> <span class="fl">127.5</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="create-the-discriminator-the-critic-in-the-original-wgan">Create the discriminator (the critic in the original WGAN)<a class="anchor" aria-label="anchor" href="#create-the-discriminator-the-critic-in-the-original-wgan"></a>
</h2>
<p>The samples in the dataset have a (28, 28, 1) shape. Because we will
be using strided convolutions, this can result in a shape with odd
dimensions. For example,
<code>(28, 28) -&gt; Conv_s2 -&gt; (14, 14) -&gt; Conv_s2 -&gt; (7, 7) -&gt; Conv_s2 -&gt;(3, 3)</code>.</p>
<p>While peforming upsampling in the generator part of the network, we
won’t get the same input shape as the original images if we aren’t
careful. To avoid this, we will do something much simpler: - In the
discriminator: “zero pad” the input to change the shape to
<code>(32, 32, 1)</code> for each sample; and - Ihe generator: crop the
final output to match the shape with input shape.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="kw">def</span> conv_block(</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>    x,</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>    filters,</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>    activation,</span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>    kernel_size<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">3</span>),</span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a>    strides<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>),</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a>    padding<span class="op">=</span><span class="st">"same"</span>,</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>    use_bias<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a>    use_bn<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a>    use_dropout<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a>    drop_value<span class="op">=</span><span class="fl">0.5</span>,</span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a>):</span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a>    x <span class="op">=</span> layers.Conv2D(</span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a>        filters,</span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a>        kernel_size,</span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a>        strides<span class="op">=</span>strides,</span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a>        padding<span class="op">=</span>padding,</span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a>        use_bias<span class="op">=</span>use_bias,</span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a>    )(x)</span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a>    <span class="cf">if</span> use_bn:</span>
<span id="cb3-21"><a href="#cb3-21" tabindex="-1"></a>        x <span class="op">=</span> layers.BatchNormalization()(x)</span>
<span id="cb3-22"><a href="#cb3-22" tabindex="-1"></a>    x <span class="op">=</span> activation(x)</span>
<span id="cb3-23"><a href="#cb3-23" tabindex="-1"></a>    <span class="cf">if</span> use_dropout:</span>
<span id="cb3-24"><a href="#cb3-24" tabindex="-1"></a>        x <span class="op">=</span> layers.Dropout(drop_value)(x)</span>
<span id="cb3-25"><a href="#cb3-25" tabindex="-1"></a>    <span class="cf">return</span> x</span>
<span id="cb3-26"><a href="#cb3-26" tabindex="-1"></a></span>
<span id="cb3-27"><a href="#cb3-27" tabindex="-1"></a></span>
<span id="cb3-28"><a href="#cb3-28" tabindex="-1"></a><span class="kw">def</span> get_discriminator_model():</span>
<span id="cb3-29"><a href="#cb3-29" tabindex="-1"></a>    img_input <span class="op">=</span> layers.Input(shape<span class="op">=</span>IMG_SHAPE)</span>
<span id="cb3-30"><a href="#cb3-30" tabindex="-1"></a>    <span class="co"># Zero pad the input to make the input images size to (32, 32, 1).</span></span>
<span id="cb3-31"><a href="#cb3-31" tabindex="-1"></a>    x <span class="op">=</span> layers.ZeroPadding2D((<span class="dv">2</span>, <span class="dv">2</span>))(img_input)</span>
<span id="cb3-32"><a href="#cb3-32" tabindex="-1"></a>    x <span class="op">=</span> conv_block(</span>
<span id="cb3-33"><a href="#cb3-33" tabindex="-1"></a>        x,</span>
<span id="cb3-34"><a href="#cb3-34" tabindex="-1"></a>        <span class="dv">64</span>,</span>
<span id="cb3-35"><a href="#cb3-35" tabindex="-1"></a>        kernel_size<span class="op">=</span>(<span class="dv">5</span>, <span class="dv">5</span>),</span>
<span id="cb3-36"><a href="#cb3-36" tabindex="-1"></a>        strides<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>),</span>
<span id="cb3-37"><a href="#cb3-37" tabindex="-1"></a>        use_bn<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb3-38"><a href="#cb3-38" tabindex="-1"></a>        use_bias<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb3-39"><a href="#cb3-39" tabindex="-1"></a>        activation<span class="op">=</span>layers.LeakyReLU(<span class="fl">0.2</span>),</span>
<span id="cb3-40"><a href="#cb3-40" tabindex="-1"></a>        use_dropout<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb3-41"><a href="#cb3-41" tabindex="-1"></a>        drop_value<span class="op">=</span><span class="fl">0.3</span>,</span>
<span id="cb3-42"><a href="#cb3-42" tabindex="-1"></a>    )</span>
<span id="cb3-43"><a href="#cb3-43" tabindex="-1"></a>    x <span class="op">=</span> conv_block(</span>
<span id="cb3-44"><a href="#cb3-44" tabindex="-1"></a>        x,</span>
<span id="cb3-45"><a href="#cb3-45" tabindex="-1"></a>        <span class="dv">128</span>,</span>
<span id="cb3-46"><a href="#cb3-46" tabindex="-1"></a>        kernel_size<span class="op">=</span>(<span class="dv">5</span>, <span class="dv">5</span>),</span>
<span id="cb3-47"><a href="#cb3-47" tabindex="-1"></a>        strides<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>),</span>
<span id="cb3-48"><a href="#cb3-48" tabindex="-1"></a>        use_bn<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb3-49"><a href="#cb3-49" tabindex="-1"></a>        activation<span class="op">=</span>layers.LeakyReLU(<span class="fl">0.2</span>),</span>
<span id="cb3-50"><a href="#cb3-50" tabindex="-1"></a>        use_bias<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb3-51"><a href="#cb3-51" tabindex="-1"></a>        use_dropout<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb3-52"><a href="#cb3-52" tabindex="-1"></a>        drop_value<span class="op">=</span><span class="fl">0.3</span>,</span>
<span id="cb3-53"><a href="#cb3-53" tabindex="-1"></a>    )</span>
<span id="cb3-54"><a href="#cb3-54" tabindex="-1"></a>    x <span class="op">=</span> conv_block(</span>
<span id="cb3-55"><a href="#cb3-55" tabindex="-1"></a>        x,</span>
<span id="cb3-56"><a href="#cb3-56" tabindex="-1"></a>        <span class="dv">256</span>,</span>
<span id="cb3-57"><a href="#cb3-57" tabindex="-1"></a>        kernel_size<span class="op">=</span>(<span class="dv">5</span>, <span class="dv">5</span>),</span>
<span id="cb3-58"><a href="#cb3-58" tabindex="-1"></a>        strides<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>),</span>
<span id="cb3-59"><a href="#cb3-59" tabindex="-1"></a>        use_bn<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb3-60"><a href="#cb3-60" tabindex="-1"></a>        activation<span class="op">=</span>layers.LeakyReLU(<span class="fl">0.2</span>),</span>
<span id="cb3-61"><a href="#cb3-61" tabindex="-1"></a>        use_bias<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb3-62"><a href="#cb3-62" tabindex="-1"></a>        use_dropout<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb3-63"><a href="#cb3-63" tabindex="-1"></a>        drop_value<span class="op">=</span><span class="fl">0.3</span>,</span>
<span id="cb3-64"><a href="#cb3-64" tabindex="-1"></a>    )</span>
<span id="cb3-65"><a href="#cb3-65" tabindex="-1"></a>    x <span class="op">=</span> conv_block(</span>
<span id="cb3-66"><a href="#cb3-66" tabindex="-1"></a>        x,</span>
<span id="cb3-67"><a href="#cb3-67" tabindex="-1"></a>        <span class="dv">512</span>,</span>
<span id="cb3-68"><a href="#cb3-68" tabindex="-1"></a>        kernel_size<span class="op">=</span>(<span class="dv">5</span>, <span class="dv">5</span>),</span>
<span id="cb3-69"><a href="#cb3-69" tabindex="-1"></a>        strides<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>),</span>
<span id="cb3-70"><a href="#cb3-70" tabindex="-1"></a>        use_bn<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb3-71"><a href="#cb3-71" tabindex="-1"></a>        activation<span class="op">=</span>layers.LeakyReLU(<span class="fl">0.2</span>),</span>
<span id="cb3-72"><a href="#cb3-72" tabindex="-1"></a>        use_bias<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb3-73"><a href="#cb3-73" tabindex="-1"></a>        use_dropout<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb3-74"><a href="#cb3-74" tabindex="-1"></a>        drop_value<span class="op">=</span><span class="fl">0.3</span>,</span>
<span id="cb3-75"><a href="#cb3-75" tabindex="-1"></a>    )</span>
<span id="cb3-76"><a href="#cb3-76" tabindex="-1"></a></span>
<span id="cb3-77"><a href="#cb3-77" tabindex="-1"></a>    x <span class="op">=</span> layers.Flatten()(x)</span>
<span id="cb3-78"><a href="#cb3-78" tabindex="-1"></a>    x <span class="op">=</span> layers.Dropout(<span class="fl">0.2</span>)(x)</span>
<span id="cb3-79"><a href="#cb3-79" tabindex="-1"></a>    x <span class="op">=</span> layers.Dense(<span class="dv">1</span>)(x)</span>
<span id="cb3-80"><a href="#cb3-80" tabindex="-1"></a></span>
<span id="cb3-81"><a href="#cb3-81" tabindex="-1"></a>    d_model <span class="op">=</span> keras.models.Model(img_input, x, name<span class="op">=</span><span class="st">"discriminator"</span>)</span>
<span id="cb3-82"><a href="#cb3-82" tabindex="-1"></a>    <span class="cf">return</span> d_model</span>
<span id="cb3-83"><a href="#cb3-83" tabindex="-1"></a></span>
<span id="cb3-84"><a href="#cb3-84" tabindex="-1"></a></span>
<span id="cb3-85"><a href="#cb3-85" tabindex="-1"></a>d_model <span class="op">=</span> get_discriminator_model()</span>
<span id="cb3-86"><a href="#cb3-86" tabindex="-1"></a>d_model.summary()</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="create-the-generator">Create the generator<a class="anchor" aria-label="anchor" href="#create-the-generator"></a>
</h2>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="kw">def</span> upsample_block(</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>    x,</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>    filters,</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>    activation,</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a>    kernel_size<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">3</span>),</span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a>    strides<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>),</span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>    up_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>),</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a>    padding<span class="op">=</span><span class="st">"same"</span>,</span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a>    use_bn<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a>    use_bias<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a>    use_dropout<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a>    drop_value<span class="op">=</span><span class="fl">0.3</span>,</span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a>):</span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a>    x <span class="op">=</span> layers.UpSampling2D(up_size)(x)</span>
<span id="cb4-15"><a href="#cb4-15" tabindex="-1"></a>    x <span class="op">=</span> layers.Conv2D(</span>
<span id="cb4-16"><a href="#cb4-16" tabindex="-1"></a>        filters,</span>
<span id="cb4-17"><a href="#cb4-17" tabindex="-1"></a>        kernel_size,</span>
<span id="cb4-18"><a href="#cb4-18" tabindex="-1"></a>        strides<span class="op">=</span>strides,</span>
<span id="cb4-19"><a href="#cb4-19" tabindex="-1"></a>        padding<span class="op">=</span>padding,</span>
<span id="cb4-20"><a href="#cb4-20" tabindex="-1"></a>        use_bias<span class="op">=</span>use_bias,</span>
<span id="cb4-21"><a href="#cb4-21" tabindex="-1"></a>    )(x)</span>
<span id="cb4-22"><a href="#cb4-22" tabindex="-1"></a></span>
<span id="cb4-23"><a href="#cb4-23" tabindex="-1"></a>    <span class="cf">if</span> use_bn:</span>
<span id="cb4-24"><a href="#cb4-24" tabindex="-1"></a>        x <span class="op">=</span> layers.BatchNormalization()(x)</span>
<span id="cb4-25"><a href="#cb4-25" tabindex="-1"></a></span>
<span id="cb4-26"><a href="#cb4-26" tabindex="-1"></a>    <span class="cf">if</span> activation:</span>
<span id="cb4-27"><a href="#cb4-27" tabindex="-1"></a>        x <span class="op">=</span> activation(x)</span>
<span id="cb4-28"><a href="#cb4-28" tabindex="-1"></a>    <span class="cf">if</span> use_dropout:</span>
<span id="cb4-29"><a href="#cb4-29" tabindex="-1"></a>        x <span class="op">=</span> layers.Dropout(drop_value)(x)</span>
<span id="cb4-30"><a href="#cb4-30" tabindex="-1"></a>    <span class="cf">return</span> x</span>
<span id="cb4-31"><a href="#cb4-31" tabindex="-1"></a></span>
<span id="cb4-32"><a href="#cb4-32" tabindex="-1"></a></span>
<span id="cb4-33"><a href="#cb4-33" tabindex="-1"></a><span class="kw">def</span> get_generator_model():</span>
<span id="cb4-34"><a href="#cb4-34" tabindex="-1"></a>    noise <span class="op">=</span> layers.Input(shape<span class="op">=</span>(noise_dim,))</span>
<span id="cb4-35"><a href="#cb4-35" tabindex="-1"></a>    x <span class="op">=</span> layers.Dense(<span class="dv">4</span> <span class="op">*</span> <span class="dv">4</span> <span class="op">*</span> <span class="dv">256</span>, use_bias<span class="op">=</span><span class="va">False</span>)(noise)</span>
<span id="cb4-36"><a href="#cb4-36" tabindex="-1"></a>    x <span class="op">=</span> layers.BatchNormalization()(x)</span>
<span id="cb4-37"><a href="#cb4-37" tabindex="-1"></a>    x <span class="op">=</span> layers.LeakyReLU(<span class="fl">0.2</span>)(x)</span>
<span id="cb4-38"><a href="#cb4-38" tabindex="-1"></a></span>
<span id="cb4-39"><a href="#cb4-39" tabindex="-1"></a>    x <span class="op">=</span> layers.Reshape((<span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">256</span>))(x)</span>
<span id="cb4-40"><a href="#cb4-40" tabindex="-1"></a>    x <span class="op">=</span> upsample_block(</span>
<span id="cb4-41"><a href="#cb4-41" tabindex="-1"></a>        x,</span>
<span id="cb4-42"><a href="#cb4-42" tabindex="-1"></a>        <span class="dv">128</span>,</span>
<span id="cb4-43"><a href="#cb4-43" tabindex="-1"></a>        layers.LeakyReLU(<span class="fl">0.2</span>),</span>
<span id="cb4-44"><a href="#cb4-44" tabindex="-1"></a>        strides<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>),</span>
<span id="cb4-45"><a href="#cb4-45" tabindex="-1"></a>        use_bias<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb4-46"><a href="#cb4-46" tabindex="-1"></a>        use_bn<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb4-47"><a href="#cb4-47" tabindex="-1"></a>        padding<span class="op">=</span><span class="st">"same"</span>,</span>
<span id="cb4-48"><a href="#cb4-48" tabindex="-1"></a>        use_dropout<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb4-49"><a href="#cb4-49" tabindex="-1"></a>    )</span>
<span id="cb4-50"><a href="#cb4-50" tabindex="-1"></a>    x <span class="op">=</span> upsample_block(</span>
<span id="cb4-51"><a href="#cb4-51" tabindex="-1"></a>        x,</span>
<span id="cb4-52"><a href="#cb4-52" tabindex="-1"></a>        <span class="dv">64</span>,</span>
<span id="cb4-53"><a href="#cb4-53" tabindex="-1"></a>        layers.LeakyReLU(<span class="fl">0.2</span>),</span>
<span id="cb4-54"><a href="#cb4-54" tabindex="-1"></a>        strides<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>),</span>
<span id="cb4-55"><a href="#cb4-55" tabindex="-1"></a>        use_bias<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb4-56"><a href="#cb4-56" tabindex="-1"></a>        use_bn<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb4-57"><a href="#cb4-57" tabindex="-1"></a>        padding<span class="op">=</span><span class="st">"same"</span>,</span>
<span id="cb4-58"><a href="#cb4-58" tabindex="-1"></a>        use_dropout<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb4-59"><a href="#cb4-59" tabindex="-1"></a>    )</span>
<span id="cb4-60"><a href="#cb4-60" tabindex="-1"></a>    x <span class="op">=</span> upsample_block(</span>
<span id="cb4-61"><a href="#cb4-61" tabindex="-1"></a>        x,</span>
<span id="cb4-62"><a href="#cb4-62" tabindex="-1"></a>        <span class="dv">1</span>,</span>
<span id="cb4-63"><a href="#cb4-63" tabindex="-1"></a>        layers.Activation(<span class="st">"tanh"</span>),</span>
<span id="cb4-64"><a href="#cb4-64" tabindex="-1"></a>        strides<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>),</span>
<span id="cb4-65"><a href="#cb4-65" tabindex="-1"></a>        use_bias<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb4-66"><a href="#cb4-66" tabindex="-1"></a>        use_bn<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb4-67"><a href="#cb4-67" tabindex="-1"></a>    )</span>
<span id="cb4-68"><a href="#cb4-68" tabindex="-1"></a>    <span class="co"># At this point, we have an output which has the same shape as the input, (32, 32, 1).</span></span>
<span id="cb4-69"><a href="#cb4-69" tabindex="-1"></a>    <span class="co"># We will use a Cropping2D layer to make it (28, 28, 1).</span></span>
<span id="cb4-70"><a href="#cb4-70" tabindex="-1"></a>    x <span class="op">=</span> layers.Cropping2D((<span class="dv">2</span>, <span class="dv">2</span>))(x)</span>
<span id="cb4-71"><a href="#cb4-71" tabindex="-1"></a></span>
<span id="cb4-72"><a href="#cb4-72" tabindex="-1"></a>    g_model <span class="op">=</span> keras.models.Model(noise, x, name<span class="op">=</span><span class="st">"generator"</span>)</span>
<span id="cb4-73"><a href="#cb4-73" tabindex="-1"></a>    <span class="cf">return</span> g_model</span>
<span id="cb4-74"><a href="#cb4-74" tabindex="-1"></a></span>
<span id="cb4-75"><a href="#cb4-75" tabindex="-1"></a></span>
<span id="cb4-76"><a href="#cb4-76" tabindex="-1"></a>g_model <span class="op">=</span> get_generator_model()</span>
<span id="cb4-77"><a href="#cb4-77" tabindex="-1"></a>g_model.summary()</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="create-the-wgan-gp-model">Create the WGAN-GP model<a class="anchor" aria-label="anchor" href="#create-the-wgan-gp-model"></a>
</h2>
<p>Now that we have defined our generator and discriminator, it’s time
to implement the WGAN-GP model. We will also override the
<code>train_step</code> for training.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="kw">class</span> WGAN(keras.Model):</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>        <span class="va">self</span>,</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>        discriminator,</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>        generator,</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>        latent_dim,</span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a>        discriminator_extra_steps<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a>        gp_weight<span class="op">=</span><span class="fl">10.0</span>,</span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a>    ):</span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a>        <span class="va">self</span>.discriminator <span class="op">=</span> discriminator</span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a>        <span class="va">self</span>.generator <span class="op">=</span> generator</span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a>        <span class="va">self</span>.latent_dim <span class="op">=</span> latent_dim</span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a>        <span class="va">self</span>.d_steps <span class="op">=</span> discriminator_extra_steps</span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a>        <span class="va">self</span>.gp_weight <span class="op">=</span> gp_weight</span>
<span id="cb5-16"><a href="#cb5-16" tabindex="-1"></a></span>
<span id="cb5-17"><a href="#cb5-17" tabindex="-1"></a>    <span class="kw">def</span> <span class="bu">compile</span>(<span class="va">self</span>, d_optimizer, g_optimizer, d_loss_fn, g_loss_fn):</span>
<span id="cb5-18"><a href="#cb5-18" tabindex="-1"></a>        <span class="bu">super</span>().<span class="bu">compile</span>()</span>
<span id="cb5-19"><a href="#cb5-19" tabindex="-1"></a>        <span class="va">self</span>.d_optimizer <span class="op">=</span> d_optimizer</span>
<span id="cb5-20"><a href="#cb5-20" tabindex="-1"></a>        <span class="va">self</span>.g_optimizer <span class="op">=</span> g_optimizer</span>
<span id="cb5-21"><a href="#cb5-21" tabindex="-1"></a>        <span class="va">self</span>.d_loss_fn <span class="op">=</span> d_loss_fn</span>
<span id="cb5-22"><a href="#cb5-22" tabindex="-1"></a>        <span class="va">self</span>.g_loss_fn <span class="op">=</span> g_loss_fn</span>
<span id="cb5-23"><a href="#cb5-23" tabindex="-1"></a></span>
<span id="cb5-24"><a href="#cb5-24" tabindex="-1"></a>    <span class="kw">def</span> gradient_penalty(<span class="va">self</span>, batch_size, real_images, fake_images):</span>
<span id="cb5-25"><a href="#cb5-25" tabindex="-1"></a>        <span class="co">"""Calculates the gradient penalty.</span></span>
<span id="cb5-26"><a href="#cb5-26" tabindex="-1"></a></span>
<span id="cb5-27"><a href="#cb5-27" tabindex="-1"></a><span class="co">        This loss is calculated on an interpolated image</span></span>
<span id="cb5-28"><a href="#cb5-28" tabindex="-1"></a><span class="co">        and added to the discriminator loss.</span></span>
<span id="cb5-29"><a href="#cb5-29" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb5-30"><a href="#cb5-30" tabindex="-1"></a>        <span class="co"># Get the interpolated image</span></span>
<span id="cb5-31"><a href="#cb5-31" tabindex="-1"></a>        alpha <span class="op">=</span> tf.random.normal([batch_size, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>], <span class="fl">0.0</span>, <span class="fl">1.0</span>)</span>
<span id="cb5-32"><a href="#cb5-32" tabindex="-1"></a>        diff <span class="op">=</span> fake_images <span class="op">-</span> real_images</span>
<span id="cb5-33"><a href="#cb5-33" tabindex="-1"></a>        interpolated <span class="op">=</span> real_images <span class="op">+</span> alpha <span class="op">*</span> diff</span>
<span id="cb5-34"><a href="#cb5-34" tabindex="-1"></a></span>
<span id="cb5-35"><a href="#cb5-35" tabindex="-1"></a>        <span class="cf">with</span> tf.GradientTape() <span class="im">as</span> gp_tape:</span>
<span id="cb5-36"><a href="#cb5-36" tabindex="-1"></a>            gp_tape.watch(interpolated)</span>
<span id="cb5-37"><a href="#cb5-37" tabindex="-1"></a>            <span class="co"># 1. Get the discriminator output for this interpolated image.</span></span>
<span id="cb5-38"><a href="#cb5-38" tabindex="-1"></a>            pred <span class="op">=</span> <span class="va">self</span>.discriminator(interpolated, training<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-39"><a href="#cb5-39" tabindex="-1"></a></span>
<span id="cb5-40"><a href="#cb5-40" tabindex="-1"></a>        <span class="co"># 2. Calculate the gradients w.r.t to this interpolated image.</span></span>
<span id="cb5-41"><a href="#cb5-41" tabindex="-1"></a>        grads <span class="op">=</span> gp_tape.gradient(pred, [interpolated])[<span class="dv">0</span>]</span>
<span id="cb5-42"><a href="#cb5-42" tabindex="-1"></a>        <span class="co"># 3. Calculate the norm of the gradients.</span></span>
<span id="cb5-43"><a href="#cb5-43" tabindex="-1"></a>        norm <span class="op">=</span> tf.sqrt(tf.reduce_sum(tf.square(grads), axis<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>]))</span>
<span id="cb5-44"><a href="#cb5-44" tabindex="-1"></a>        gp <span class="op">=</span> tf.reduce_mean((norm <span class="op">-</span> <span class="fl">1.0</span>) <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb5-45"><a href="#cb5-45" tabindex="-1"></a>        <span class="cf">return</span> gp</span>
<span id="cb5-46"><a href="#cb5-46" tabindex="-1"></a></span>
<span id="cb5-47"><a href="#cb5-47" tabindex="-1"></a>    <span class="kw">def</span> train_step(<span class="va">self</span>, real_images):</span>
<span id="cb5-48"><a href="#cb5-48" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(real_images, <span class="bu">tuple</span>):</span>
<span id="cb5-49"><a href="#cb5-49" tabindex="-1"></a>            real_images <span class="op">=</span> real_images[<span class="dv">0</span>]</span>
<span id="cb5-50"><a href="#cb5-50" tabindex="-1"></a></span>
<span id="cb5-51"><a href="#cb5-51" tabindex="-1"></a>        <span class="co"># Get the batch size</span></span>
<span id="cb5-52"><a href="#cb5-52" tabindex="-1"></a>        batch_size <span class="op">=</span> tf.shape(real_images)[<span class="dv">0</span>]</span>
<span id="cb5-53"><a href="#cb5-53" tabindex="-1"></a></span>
<span id="cb5-54"><a href="#cb5-54" tabindex="-1"></a>        <span class="co"># For each batch, we are going to perform the</span></span>
<span id="cb5-55"><a href="#cb5-55" tabindex="-1"></a>        <span class="co"># following steps as laid out in the original paper:</span></span>
<span id="cb5-56"><a href="#cb5-56" tabindex="-1"></a>        <span class="co"># 1. Train the generator and get the generator loss</span></span>
<span id="cb5-57"><a href="#cb5-57" tabindex="-1"></a>        <span class="co"># 2. Train the discriminator and get the discriminator loss</span></span>
<span id="cb5-58"><a href="#cb5-58" tabindex="-1"></a>        <span class="co"># 3. Calculate the gradient penalty</span></span>
<span id="cb5-59"><a href="#cb5-59" tabindex="-1"></a>        <span class="co"># 4. Multiply this gradient penalty with a constant weight factor</span></span>
<span id="cb5-60"><a href="#cb5-60" tabindex="-1"></a>        <span class="co"># 5. Add the gradient penalty to the discriminator loss</span></span>
<span id="cb5-61"><a href="#cb5-61" tabindex="-1"></a>        <span class="co"># 6. Return the generator and discriminator losses as a loss dictionary</span></span>
<span id="cb5-62"><a href="#cb5-62" tabindex="-1"></a></span>
<span id="cb5-63"><a href="#cb5-63" tabindex="-1"></a>        <span class="co"># Train the discriminator first. The original paper recommends training</span></span>
<span id="cb5-64"><a href="#cb5-64" tabindex="-1"></a>        <span class="co"># the discriminator for `x` more steps (typically 5) as compared to</span></span>
<span id="cb5-65"><a href="#cb5-65" tabindex="-1"></a>        <span class="co"># one step of the generator. Here we will train it for 3 extra steps</span></span>
<span id="cb5-66"><a href="#cb5-66" tabindex="-1"></a>        <span class="co"># as compared to 5 to reduce the training time.</span></span>
<span id="cb5-67"><a href="#cb5-67" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.d_steps):</span>
<span id="cb5-68"><a href="#cb5-68" tabindex="-1"></a>            <span class="co"># Get the latent vector</span></span>
<span id="cb5-69"><a href="#cb5-69" tabindex="-1"></a>            random_latent_vectors <span class="op">=</span> tf.random.normal(</span>
<span id="cb5-70"><a href="#cb5-70" tabindex="-1"></a>                shape<span class="op">=</span>(batch_size, <span class="va">self</span>.latent_dim)</span>
<span id="cb5-71"><a href="#cb5-71" tabindex="-1"></a>            )</span>
<span id="cb5-72"><a href="#cb5-72" tabindex="-1"></a>            <span class="cf">with</span> tf.GradientTape() <span class="im">as</span> tape:</span>
<span id="cb5-73"><a href="#cb5-73" tabindex="-1"></a>                <span class="co"># Generate fake images from the latent vector</span></span>
<span id="cb5-74"><a href="#cb5-74" tabindex="-1"></a>                fake_images <span class="op">=</span> <span class="va">self</span>.generator(</span>
<span id="cb5-75"><a href="#cb5-75" tabindex="-1"></a>                    random_latent_vectors, training<span class="op">=</span><span class="va">True</span></span>
<span id="cb5-76"><a href="#cb5-76" tabindex="-1"></a>                )</span>
<span id="cb5-77"><a href="#cb5-77" tabindex="-1"></a>                <span class="co"># Get the logits for the fake images</span></span>
<span id="cb5-78"><a href="#cb5-78" tabindex="-1"></a>                fake_logits <span class="op">=</span> <span class="va">self</span>.discriminator(fake_images, training<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-79"><a href="#cb5-79" tabindex="-1"></a>                <span class="co"># Get the logits for the real images</span></span>
<span id="cb5-80"><a href="#cb5-80" tabindex="-1"></a>                real_logits <span class="op">=</span> <span class="va">self</span>.discriminator(real_images, training<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-81"><a href="#cb5-81" tabindex="-1"></a></span>
<span id="cb5-82"><a href="#cb5-82" tabindex="-1"></a>                <span class="co"># Calculate the discriminator loss using the fake and real image logits</span></span>
<span id="cb5-83"><a href="#cb5-83" tabindex="-1"></a>                d_cost <span class="op">=</span> <span class="va">self</span>.d_loss_fn(</span>
<span id="cb5-84"><a href="#cb5-84" tabindex="-1"></a>                    real_img<span class="op">=</span>real_logits, fake_img<span class="op">=</span>fake_logits</span>
<span id="cb5-85"><a href="#cb5-85" tabindex="-1"></a>                )</span>
<span id="cb5-86"><a href="#cb5-86" tabindex="-1"></a>                <span class="co"># Calculate the gradient penalty</span></span>
<span id="cb5-87"><a href="#cb5-87" tabindex="-1"></a>                gp <span class="op">=</span> <span class="va">self</span>.gradient_penalty(batch_size, real_images, fake_images)</span>
<span id="cb5-88"><a href="#cb5-88" tabindex="-1"></a>                <span class="co"># Add the gradient penalty to the original discriminator loss</span></span>
<span id="cb5-89"><a href="#cb5-89" tabindex="-1"></a>                d_loss <span class="op">=</span> d_cost <span class="op">+</span> gp <span class="op">*</span> <span class="va">self</span>.gp_weight</span>
<span id="cb5-90"><a href="#cb5-90" tabindex="-1"></a></span>
<span id="cb5-91"><a href="#cb5-91" tabindex="-1"></a>            <span class="co"># Get the gradients w.r.t the discriminator loss</span></span>
<span id="cb5-92"><a href="#cb5-92" tabindex="-1"></a>            d_gradient <span class="op">=</span> tape.gradient(</span>
<span id="cb5-93"><a href="#cb5-93" tabindex="-1"></a>                d_loss, <span class="va">self</span>.discriminator.trainable_variables</span>
<span id="cb5-94"><a href="#cb5-94" tabindex="-1"></a>            )</span>
<span id="cb5-95"><a href="#cb5-95" tabindex="-1"></a>            <span class="co"># Update the weights of the discriminator using the discriminator optimizer</span></span>
<span id="cb5-96"><a href="#cb5-96" tabindex="-1"></a>            <span class="va">self</span>.d_optimizer.apply_gradients(</span>
<span id="cb5-97"><a href="#cb5-97" tabindex="-1"></a>                <span class="bu">zip</span>(d_gradient, <span class="va">self</span>.discriminator.trainable_variables)</span>
<span id="cb5-98"><a href="#cb5-98" tabindex="-1"></a>            )</span>
<span id="cb5-99"><a href="#cb5-99" tabindex="-1"></a></span>
<span id="cb5-100"><a href="#cb5-100" tabindex="-1"></a>        <span class="co"># Train the generator</span></span>
<span id="cb5-101"><a href="#cb5-101" tabindex="-1"></a>        <span class="co"># Get the latent vector</span></span>
<span id="cb5-102"><a href="#cb5-102" tabindex="-1"></a>        random_latent_vectors <span class="op">=</span> tf.random.normal(</span>
<span id="cb5-103"><a href="#cb5-103" tabindex="-1"></a>            shape<span class="op">=</span>(batch_size, <span class="va">self</span>.latent_dim)</span>
<span id="cb5-104"><a href="#cb5-104" tabindex="-1"></a>        )</span>
<span id="cb5-105"><a href="#cb5-105" tabindex="-1"></a>        <span class="cf">with</span> tf.GradientTape() <span class="im">as</span> tape:</span>
<span id="cb5-106"><a href="#cb5-106" tabindex="-1"></a>            <span class="co"># Generate fake images using the generator</span></span>
<span id="cb5-107"><a href="#cb5-107" tabindex="-1"></a>            generated_images <span class="op">=</span> <span class="va">self</span>.generator(</span>
<span id="cb5-108"><a href="#cb5-108" tabindex="-1"></a>                random_latent_vectors, training<span class="op">=</span><span class="va">True</span></span>
<span id="cb5-109"><a href="#cb5-109" tabindex="-1"></a>            )</span>
<span id="cb5-110"><a href="#cb5-110" tabindex="-1"></a>            <span class="co"># Get the discriminator logits for fake images</span></span>
<span id="cb5-111"><a href="#cb5-111" tabindex="-1"></a>            gen_img_logits <span class="op">=</span> <span class="va">self</span>.discriminator(generated_images, training<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-112"><a href="#cb5-112" tabindex="-1"></a>            <span class="co"># Calculate the generator loss</span></span>
<span id="cb5-113"><a href="#cb5-113" tabindex="-1"></a>            g_loss <span class="op">=</span> <span class="va">self</span>.g_loss_fn(gen_img_logits)</span>
<span id="cb5-114"><a href="#cb5-114" tabindex="-1"></a></span>
<span id="cb5-115"><a href="#cb5-115" tabindex="-1"></a>        <span class="co"># Get the gradients w.r.t the generator loss</span></span>
<span id="cb5-116"><a href="#cb5-116" tabindex="-1"></a>        gen_gradient <span class="op">=</span> tape.gradient(g_loss, <span class="va">self</span>.generator.trainable_variables)</span>
<span id="cb5-117"><a href="#cb5-117" tabindex="-1"></a>        <span class="co"># Update the weights of the generator using the generator optimizer</span></span>
<span id="cb5-118"><a href="#cb5-118" tabindex="-1"></a>        <span class="va">self</span>.g_optimizer.apply_gradients(</span>
<span id="cb5-119"><a href="#cb5-119" tabindex="-1"></a>            <span class="bu">zip</span>(gen_gradient, <span class="va">self</span>.generator.trainable_variables)</span>
<span id="cb5-120"><a href="#cb5-120" tabindex="-1"></a>        )</span>
<span id="cb5-121"><a href="#cb5-121" tabindex="-1"></a>        <span class="cf">return</span> {<span class="st">"d_loss"</span>: d_loss, <span class="st">"g_loss"</span>: g_loss}</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="create-a-keras-callback-that-periodically-saves-generated-images">Create a Keras callback that periodically saves generated
images<a class="anchor" aria-label="anchor" href="#create-a-keras-callback-that-periodically-saves-generated-images"></a>
</h2>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="kw">class</span> GANMonitor(keras.callbacks.Callback):</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_img<span class="op">=</span><span class="dv">6</span>, latent_dim<span class="op">=</span><span class="dv">128</span>):</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>        <span class="va">self</span>.num_img <span class="op">=</span> num_img</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a>        <span class="va">self</span>.latent_dim <span class="op">=</span> latent_dim</span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>    <span class="kw">def</span> on_epoch_end(<span class="va">self</span>, epoch, logs<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a>        random_latent_vectors <span class="op">=</span> tf.random.normal(</span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a>            shape<span class="op">=</span>(<span class="va">self</span>.num_img, <span class="va">self</span>.latent_dim)</span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a>        )</span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a>        generated_images <span class="op">=</span> <span class="va">self</span>.model.generator(random_latent_vectors)</span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a>        generated_images <span class="op">=</span> (generated_images <span class="op">*</span> <span class="fl">127.5</span>) <span class="op">+</span> <span class="fl">127.5</span></span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.num_img):</span>
<span id="cb6-14"><a href="#cb6-14" tabindex="-1"></a>            img <span class="op">=</span> generated_images[i].numpy()</span>
<span id="cb6-15"><a href="#cb6-15" tabindex="-1"></a>            img <span class="op">=</span> keras.utils.array_to_img(img)</span>
<span id="cb6-16"><a href="#cb6-16" tabindex="-1"></a>            img.save(<span class="st">"generated_img_</span><span class="sc">{i}</span><span class="st">_</span><span class="sc">{epoch}</span><span class="st">.png"</span>.<span class="bu">format</span>(i<span class="op">=</span>i, epoch<span class="op">=</span>epoch))</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="train-the-end-to-end-model">Train the end-to-end model<a class="anchor" aria-label="anchor" href="#train-the-end-to-end-model"></a>
</h2>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="co"># Instantiate the optimizer for both networks</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a><span class="co"># (learning_rate=0.0002, beta_1=0.5 are recommended)</span></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>generator_optimizer <span class="op">=</span> keras.optimizers.Adam(</span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>    learning_rate<span class="op">=</span><span class="fl">0.0002</span>, beta_1<span class="op">=</span><span class="fl">0.5</span>, beta_2<span class="op">=</span><span class="fl">0.9</span></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>)</span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a>discriminator_optimizer <span class="op">=</span> keras.optimizers.Adam(</span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a>    learning_rate<span class="op">=</span><span class="fl">0.0002</span>, beta_1<span class="op">=</span><span class="fl">0.5</span>, beta_2<span class="op">=</span><span class="fl">0.9</span></span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a>)</span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a></span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a><span class="co"># Define the loss functions for the discriminator,</span></span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a><span class="co"># which should be (fake_loss - real_loss).</span></span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a><span class="co"># We will add the gradient penalty later to this loss function.</span></span>
<span id="cb7-14"><a href="#cb7-14" tabindex="-1"></a><span class="kw">def</span> discriminator_loss(real_img, fake_img):</span>
<span id="cb7-15"><a href="#cb7-15" tabindex="-1"></a>    real_loss <span class="op">=</span> tf.reduce_mean(real_img)</span>
<span id="cb7-16"><a href="#cb7-16" tabindex="-1"></a>    fake_loss <span class="op">=</span> tf.reduce_mean(fake_img)</span>
<span id="cb7-17"><a href="#cb7-17" tabindex="-1"></a>    <span class="cf">return</span> fake_loss <span class="op">-</span> real_loss</span>
<span id="cb7-18"><a href="#cb7-18" tabindex="-1"></a></span>
<span id="cb7-19"><a href="#cb7-19" tabindex="-1"></a></span>
<span id="cb7-20"><a href="#cb7-20" tabindex="-1"></a><span class="co"># Define the loss functions for the generator.</span></span>
<span id="cb7-21"><a href="#cb7-21" tabindex="-1"></a><span class="kw">def</span> generator_loss(fake_img):</span>
<span id="cb7-22"><a href="#cb7-22" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span>tf.reduce_mean(fake_img)</span>
<span id="cb7-23"><a href="#cb7-23" tabindex="-1"></a></span>
<span id="cb7-24"><a href="#cb7-24" tabindex="-1"></a></span>
<span id="cb7-25"><a href="#cb7-25" tabindex="-1"></a><span class="co"># Set the number of epochs for trainining.</span></span>
<span id="cb7-26"><a href="#cb7-26" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb7-27"><a href="#cb7-27" tabindex="-1"></a></span>
<span id="cb7-28"><a href="#cb7-28" tabindex="-1"></a><span class="co"># Instantiate the customer `GANMonitor` Keras callback.</span></span>
<span id="cb7-29"><a href="#cb7-29" tabindex="-1"></a>cbk <span class="op">=</span> GANMonitor(num_img<span class="op">=</span><span class="dv">3</span>, latent_dim<span class="op">=</span>noise_dim)</span>
<span id="cb7-30"><a href="#cb7-30" tabindex="-1"></a></span>
<span id="cb7-31"><a href="#cb7-31" tabindex="-1"></a><span class="co"># Get the wgan model</span></span>
<span id="cb7-32"><a href="#cb7-32" tabindex="-1"></a>wgan <span class="op">=</span> WGAN(</span>
<span id="cb7-33"><a href="#cb7-33" tabindex="-1"></a>    discriminator<span class="op">=</span>d_model,</span>
<span id="cb7-34"><a href="#cb7-34" tabindex="-1"></a>    generator<span class="op">=</span>g_model,</span>
<span id="cb7-35"><a href="#cb7-35" tabindex="-1"></a>    latent_dim<span class="op">=</span>noise_dim,</span>
<span id="cb7-36"><a href="#cb7-36" tabindex="-1"></a>    discriminator_extra_steps<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb7-37"><a href="#cb7-37" tabindex="-1"></a>)</span>
<span id="cb7-38"><a href="#cb7-38" tabindex="-1"></a></span>
<span id="cb7-39"><a href="#cb7-39" tabindex="-1"></a><span class="co"># Compile the wgan model</span></span>
<span id="cb7-40"><a href="#cb7-40" tabindex="-1"></a>wgan.<span class="bu">compile</span>(</span>
<span id="cb7-41"><a href="#cb7-41" tabindex="-1"></a>    d_optimizer<span class="op">=</span>discriminator_optimizer,</span>
<span id="cb7-42"><a href="#cb7-42" tabindex="-1"></a>    g_optimizer<span class="op">=</span>generator_optimizer,</span>
<span id="cb7-43"><a href="#cb7-43" tabindex="-1"></a>    g_loss_fn<span class="op">=</span>generator_loss,</span>
<span id="cb7-44"><a href="#cb7-44" tabindex="-1"></a>    d_loss_fn<span class="op">=</span>discriminator_loss,</span>
<span id="cb7-45"><a href="#cb7-45" tabindex="-1"></a>)</span>
<span id="cb7-46"><a href="#cb7-46" tabindex="-1"></a></span>
<span id="cb7-47"><a href="#cb7-47" tabindex="-1"></a><span class="co"># Start training</span></span>
<span id="cb7-48"><a href="#cb7-48" tabindex="-1"></a>wgan.fit(train_images, batch_size<span class="op">=</span>BATCH_SIZE, epochs<span class="op">=</span>epochs, callbacks<span class="op">=</span>[cbk])</span></code></pre></div>
<p>Display the last generated images:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> Image, display</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>display(Image(<span class="st">"generated_img_0_19.png"</span>))</span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>display(Image(<span class="st">"generated_img_1_19.png"</span>))</span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a>display(Image(<span class="st">"generated_img_2_19.png"</span>))</span></code></pre></div>
<p>Example available on HuggingFace.</p>
<table class="table">
<colgroup>
<col width="50%">
<col width="50%">
</colgroup>
<thead><tr class="header">
<th align="center">Trained Model</th>
<th align="center">Demo</th>
</tr></thead>
<tbody><tr class="odd">
<td align="center"><a href="https://huggingface.co/keras-io/WGAN-GP" class="external-link"><img src="https://img.shields.io/badge/%F0%9F%A4%97%20Model-WGAN%20GP-black.svg" alt="Generic badge"></a></td>
<td align="center"><a href="https://huggingface.co/spaces/keras-io/WGAN-GP" class="external-link"><img src="https://img.shields.io/badge/%F0%9F%A4%97%20Spaces-WGAN%20GP-black.svg" alt="Generic badge"></a></td>
</tr></tbody>
</table>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by Tomasz Kalinowski, JJ Allaire, François Chollet, RStudio, Google.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

      </footer>
</div>

  


  

  </body>
</html>
