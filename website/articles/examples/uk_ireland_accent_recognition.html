<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="Training a model to classify UK &amp; Ireland accents using feature extraction from Yamnet.">
<title>English speaker accent recognition using Transfer Learning • keras</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../../apple-touch-icon-60x60.png">
<script src="../../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../../pkgdown.js"></script><link href="../../extra.css" rel="stylesheet">
<script src="../../extra.js"></script><meta property="og:title" content="English speaker accent recognition using Transfer Learning">
<meta property="og:description" content="Training a model to classify UK &amp; Ireland accents using feature extraction from Yamnet.">
<meta property="og:image" content="/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-inverse navbar-expand-lg bg-primary"><div class="container">
    
    <a class="navbar-brand me-2" href="../../index.html">keras</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">2.13.0.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../../index.html">Home</a>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-tutorials">Tutorials</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-tutorials">
    <a class="dropdown-item" href="../../articles/getting_started.html">Getting Started</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_classification.html">Basic Classification</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_text_classification.html">Text Classification</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_regression.html">Basic Regression</a>
    <a class="dropdown-item" href="../../articles/tutorial_overfit_underfit.html">Overfitting and Underfitting</a>
    <a class="dropdown-item" href="../../articles/tutorial_save_and_restore.html">Save and Restore Models</a>
  </div>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-guides">Guides</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-guides">
    <a class="dropdown-item" href="../../writing_your_own_callbacks.html">Writing Your Own Callbacks</a>
  </div>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <h6 class="dropdown-header" data-toc-skip>Guides (New for TF 2.6)</h6>
    <a class="dropdown-item" href="../../articles/new-guides/python_subclasses.html">Python Subclasses</a>
    <a class="dropdown-item" href="../../articles/new-guides/making_new_layers_and_models_via_subclassing.html">Making New Layers and Models via Subclassing</a>
    <a class="dropdown-item" href="../../articles/new-guides/customizing_what_happens_in_fit.html">Customizing What Happens in Fit</a>
    <a class="dropdown-item" href="../../articles/new-guides/writing_your_own_callbacks.html">Writing Your Own Callbacks</a>
    <a class="dropdown-item" href="../../articles/new-guides/preprocessing_layers.html">Working with Preprocessing Layers</a>
    <a class="dropdown-item" href="../../argicles/new-guides/working_with_rnns.html">Working with RNNs</a>
    <div class="dropdown-divider"></div>
    <h6 class="dropdown-header" data-toc-skip>Using Keras</h6>
    <a class="dropdown-item" href="../../articles/guide_keras.html">Guide to Keras Basics</a>
    <a class="dropdown-item" href="../../articles/sequential_model.html">Sequential Model in Depth</a>
    <a class="dropdown-item" href="../../articles/functional_api.html">Functional API in Depth</a>
    <a class="dropdown-item" href="../../articles/about_keras_models.html">About Keras Models</a>
    <a class="dropdown-item" href="../../articles/about_keras_layers.html">About Keras Layers</a>
    <a class="dropdown-item" href="../../articles/training_visualization.html">Training Visualization</a>
    <a class="dropdown-item" href="../../articles/applications.html">Pre-Trained Models</a>
    <a class="dropdown-item" href="../../articles/faq.html">Frequently Asked Questions</a>
    <a class="dropdown-item" href="../../articles/why_use_keras.html">Why Use Keras?</a>
    <div class="dropdown-divider"></div>
    <h6 class="dropdown-header" data-toc-skip>Advanced</h6>
    <a class="dropdown-item" href="../../articles/eager_guide.html">Eager Execution</a>
    <a class="dropdown-item" href="../../articles/training_callbacks.html">Training Callbacks</a>
    <a class="dropdown-item" href="../../articles/backend.html">Keras Backend</a>
    <a class="dropdown-item" href="../../articles/custom_layers.html">Custom Layers</a>
    <a class="dropdown-item" href="../../articles/custom_models.html">Custom Models</a>
    <a class="dropdown-item" href="../../articles/saving_serializing.html">Saving and serializing</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../articles/learn.html">Learn</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../articles/tools.html">Tools</a>
</li>
<li class="active nav-item">
  <a class="nav-link" href="../../articles/examples/index.html">Examples</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../reference/index.html">Reference</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../news/index.html">News</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/rstudio/keras/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../../logo.png" class="logo" alt=""><h1>English speaker accent recognition using Transfer Learning</h1>
                        <h4 data-toc-skip class="author"><a href="https://twitter.com/fadibadine" class="external-link">Fadi Badine</a></h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/rstudio/keras/blob/HEAD/vignettes/examples/uk_ireland_accent_recognition.Rmd" class="external-link"><code>vignettes/examples/uk_ireland_accent_recognition.Rmd</code></a></small>
      <div class="d-none name"><code>uk_ireland_accent_recognition.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>The following example shows how to use feature extraction in order to
train a model to classify the English accent spoken in an audio
wave.</p>
<p>Instead of training a model from scratch, transfer learning enables
us to take advantage of existing state-of-the-art deep learning models
and use them as feature extractors.</p>
<p>Our process:</p>
<ul>
<li>Use a TF Hub pre-trained model (Yamnet) and apply it as part of the
tf.data pipeline which transforms the audio files into feature
vectors.</li>
<li>Train a dense model on the feature vectors.</li>
<li>Use the trained model for inference on a new audio file.</li>
</ul>
<p>Note:</p>
<ul>
<li>We need to install TensorFlow IO in order to resample audio files to
16 kHz as required by Yamnet model.</li>
<li>In the test section, ffmpeg is used to convert the mp3 file to
wav.</li>
</ul>
<p>You can install TensorFlow IO with the following command:</p>
<p>pip install -U -q tensorflow_io</p>
</div>
<div class="section level2">
<h2 id="configuration">Configuration<a class="anchor" aria-label="anchor" href="#configuration"></a>
</h2>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a>SEED <span class="op">=</span> <span class="dv">1337</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a>EPOCHS <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a>BATCH_SIZE <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a>VALIDATION_RATIO <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a>MODEL_NAME <span class="op">=</span> <span class="st">"uk_irish_accent_recognition"</span></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="co"># Location where the dataset will be downloaded.</span></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="co"># By default (None), keras.utils.get_file will use ~/.keras/ as the CACHE_DIR</span></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a>CACHE_DIR <span class="op">=</span> <span class="va">None</span></span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="co"># The location of the dataset</span></span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a>URL_PATH <span class="op">=</span> <span class="st">"https://www.openslr.org/resources/83/"</span></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a><span class="co"># List of datasets compressed files that contain the audio files</span></span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a>zip_files <span class="op">=</span> {</span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a>    <span class="dv">0</span>: <span class="st">"irish_english_male.zip"</span>,</span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a>    <span class="dv">1</span>: <span class="st">"midlands_english_female.zip"</span>,</span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a>    <span class="dv">2</span>: <span class="st">"midlands_english_male.zip"</span>,</span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a>    <span class="dv">3</span>: <span class="st">"northern_english_female.zip"</span>,</span>
<span id="cb1-20"><a href="#cb1-20" tabindex="-1"></a>    <span class="dv">4</span>: <span class="st">"northern_english_male.zip"</span>,</span>
<span id="cb1-21"><a href="#cb1-21" tabindex="-1"></a>    <span class="dv">5</span>: <span class="st">"scottish_english_female.zip"</span>,</span>
<span id="cb1-22"><a href="#cb1-22" tabindex="-1"></a>    <span class="dv">6</span>: <span class="st">"scottish_english_male.zip"</span>,</span>
<span id="cb1-23"><a href="#cb1-23" tabindex="-1"></a>    <span class="dv">7</span>: <span class="st">"southern_english_female.zip"</span>,</span>
<span id="cb1-24"><a href="#cb1-24" tabindex="-1"></a>    <span class="dv">8</span>: <span class="st">"southern_english_male.zip"</span>,</span>
<span id="cb1-25"><a href="#cb1-25" tabindex="-1"></a>    <span class="dv">9</span>: <span class="st">"welsh_english_female.zip"</span>,</span>
<span id="cb1-26"><a href="#cb1-26" tabindex="-1"></a>    <span class="dv">10</span>: <span class="st">"welsh_english_male.zip"</span>,</span>
<span id="cb1-27"><a href="#cb1-27" tabindex="-1"></a>}</span>
<span id="cb1-28"><a href="#cb1-28" tabindex="-1"></a></span>
<span id="cb1-29"><a href="#cb1-29" tabindex="-1"></a><span class="co"># We see that there are 2 compressed files for each accent (except Irish):</span></span>
<span id="cb1-30"><a href="#cb1-30" tabindex="-1"></a><span class="co"># - One for male speakers</span></span>
<span id="cb1-31"><a href="#cb1-31" tabindex="-1"></a><span class="co"># - One for female speakers</span></span>
<span id="cb1-32"><a href="#cb1-32" tabindex="-1"></a><span class="co"># However, we will be using a gender agnostic dataset.</span></span>
<span id="cb1-33"><a href="#cb1-33" tabindex="-1"></a></span>
<span id="cb1-34"><a href="#cb1-34" tabindex="-1"></a><span class="co"># List of gender agnostic categories</span></span>
<span id="cb1-35"><a href="#cb1-35" tabindex="-1"></a>gender_agnostic_categories <span class="op">=</span> [</span>
<span id="cb1-36"><a href="#cb1-36" tabindex="-1"></a>    <span class="st">"ir"</span>,  <span class="co"># Irish</span></span>
<span id="cb1-37"><a href="#cb1-37" tabindex="-1"></a>    <span class="st">"mi"</span>,  <span class="co"># Midlands</span></span>
<span id="cb1-38"><a href="#cb1-38" tabindex="-1"></a>    <span class="st">"no"</span>,  <span class="co"># Northern</span></span>
<span id="cb1-39"><a href="#cb1-39" tabindex="-1"></a>    <span class="st">"sc"</span>,  <span class="co"># Scottish</span></span>
<span id="cb1-40"><a href="#cb1-40" tabindex="-1"></a>    <span class="st">"so"</span>,  <span class="co"># Southern</span></span>
<span id="cb1-41"><a href="#cb1-41" tabindex="-1"></a>    <span class="st">"we"</span>,  <span class="co"># Welsh</span></span>
<span id="cb1-42"><a href="#cb1-42" tabindex="-1"></a>]</span>
<span id="cb1-43"><a href="#cb1-43" tabindex="-1"></a></span>
<span id="cb1-44"><a href="#cb1-44" tabindex="-1"></a>class_names <span class="op">=</span> [</span>
<span id="cb1-45"><a href="#cb1-45" tabindex="-1"></a>    <span class="st">"Irish"</span>,</span>
<span id="cb1-46"><a href="#cb1-46" tabindex="-1"></a>    <span class="st">"Midlands"</span>,</span>
<span id="cb1-47"><a href="#cb1-47" tabindex="-1"></a>    <span class="st">"Northern"</span>,</span>
<span id="cb1-48"><a href="#cb1-48" tabindex="-1"></a>    <span class="st">"Scottish"</span>,</span>
<span id="cb1-49"><a href="#cb1-49" tabindex="-1"></a>    <span class="st">"Southern"</span>,</span>
<span id="cb1-50"><a href="#cb1-50" tabindex="-1"></a>    <span class="st">"Welsh"</span>,</span>
<span id="cb1-51"><a href="#cb1-51" tabindex="-1"></a>    <span class="st">"Not a speech"</span>,</span>
<span id="cb1-52"><a href="#cb1-52" tabindex="-1"></a>]</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="imports">Imports<a class="anchor" aria-label="anchor" href="#imports"></a>
</h2>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>os.environ[<span class="st">"KERAS_BACKEND"</span>] <span class="op">=</span> <span class="st">"tensorflow"</span></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a><span class="im">import</span> io</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a><span class="im">import</span> csv</span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a><span class="im">import</span> tensorflow_hub <span class="im">as</span> hub</span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a><span class="im">import</span> tensorflow_io <span class="im">as</span> tfio</span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a><span class="im">import</span> keras <span class="im">as</span> keras</span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb2-15"><a href="#cb2-15" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats</span>
<span id="cb2-16"><a href="#cb2-16" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> Audio</span>
<span id="cb2-17"><a href="#cb2-17" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" tabindex="-1"></a><span class="co"># Set all random seeds in order to get reproducible results</span></span>
<span id="cb2-20"><a href="#cb2-20" tabindex="-1"></a>keras.utils.set_random_seed(SEED)</span>
<span id="cb2-21"><a href="#cb2-21" tabindex="-1"></a></span>
<span id="cb2-22"><a href="#cb2-22" tabindex="-1"></a><span class="co"># Where to download the dataset</span></span>
<span id="cb2-23"><a href="#cb2-23" tabindex="-1"></a>DATASET_DESTINATION <span class="op">=</span> os.path.join(</span>
<span id="cb2-24"><a href="#cb2-24" tabindex="-1"></a>    CACHE_DIR <span class="cf">if</span> CACHE_DIR <span class="cf">else</span> <span class="st">"~/.keras/"</span>, <span class="st">"datasets"</span></span>
<span id="cb2-25"><a href="#cb2-25" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="yamnet-model">Yamnet Model<a class="anchor" aria-label="anchor" href="#yamnet-model"></a>
</h2>
<p>Yamnet is an audio event classifier trained on the AudioSet dataset
to predict audio events from the AudioSet ontology. It is available on
TensorFlow Hub.</p>
<p>Yamnet accepts a 1-D tensor of audio samples with a sample rate of 16
kHz. As output, the model returns a 3-tuple:</p>
<ul>
<li>Scores of shape <code>(N, 521)</code> representing the scores of the
521 classes.</li>
<li>Embeddings of shape <code>(N, 1024)</code>.</li>
<li>The log-mel spectrogram of the entire audio frame.</li>
</ul>
<p>We will use the embeddings, which are the features extracted from the
audio samples, as the input to our dense model.</p>
<p>For more detailed information about Yamnet, please refer to its <a href="https://tfhub.dev/google/yamnet/1" class="external-link">TensorFlow Hub</a> page.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>yamnet_model <span class="op">=</span> hub.load(<span class="st">"https://tfhub.dev/google/yamnet/1"</span>)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="dataset">Dataset<a class="anchor" aria-label="anchor" href="#dataset"></a>
</h2>
<p>The dataset used is the <a href="https://openslr.org/83/" class="external-link">Crowdsourced high-quality UK and Ireland
English Dialect speech data set</a> which consists of a total of 17,877
high-quality audio wav files.</p>
<p>This dataset includes over 31 hours of recording from 120 volunteers
who self-identify as native speakers of Southern England, Midlands,
Northern England, Wales, Scotland and Ireland.</p>
<p>For more info, please refer to the above link or to the following
paper: <a href="https://aclanthology.org/2020.lrec-1.804.pdf" class="external-link">Open-source
Multi-speaker Corpora of the English Accents in the British
Isles</a></p>
</div>
<div class="section level2">
<h2 id="download-the-data">Download the data<a class="anchor" aria-label="anchor" href="#download-the-data"></a>
</h2>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co"># CSV file that contains information about the dataset. For each entry, we have:</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="co"># - ID</span></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a><span class="co"># - wav file name</span></span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a><span class="co"># - transcript</span></span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a>line_index_file <span class="op">=</span> keras.utils.get_file(</span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a>    fname<span class="op">=</span><span class="st">"line_index_file"</span>, origin<span class="op">=</span>URL_PATH <span class="op">+</span> <span class="st">"line_index_all.csv"</span></span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>)</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a><span class="co"># Download the list of compressed files that contain the audio wav files</span></span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> zip_files:</span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a>    fname <span class="op">=</span> zip_files[i].split(<span class="st">"."</span>)[<span class="dv">0</span>]</span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a>    url <span class="op">=</span> URL_PATH <span class="op">+</span> zip_files[i]</span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a></span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a>    zip_file <span class="op">=</span> keras.utils.get_file(fname<span class="op">=</span>fname, origin<span class="op">=</span>url, extract<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-15"><a href="#cb4-15" tabindex="-1"></a>    os.remove(zip_file)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="load-the-data-in-a-dataframe">Load the data in a Dataframe<a class="anchor" aria-label="anchor" href="#load-the-data-in-a-dataframe"></a>
</h2>
<p>Of the 3 columns (ID, filename and transcript), we are only
interested in the filename column in order to read the audio file. We
will ignore the other two.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>dataframe <span class="op">=</span> pd.read_csv(</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>    line_index_file,</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>    names<span class="op">=</span>[<span class="st">"id"</span>, <span class="st">"filename"</span>, <span class="st">"transcript"</span>],</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>    usecols<span class="op">=</span>[<span class="st">"filename"</span>],</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>)</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>dataframe.head()</span></code></pre></div>
<p>Let’s now preprocess the dataset by:</p>
<ul>
<li>Adjusting the filename (removing a leading space &amp; adding “.wav”
extension to the filename).</li>
<li>Creating a label using the first 2 characters of the filename which
indicate the accent.</li>
<li>Shuffling the samples.</li>
</ul>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="co"># The purpose of this function is to preprocess the dataframe by applying the following:</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a><span class="co"># - Cleaning the filename from a leading space</span></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a><span class="co"># - Generating a label column that is gender agnostic i.e.</span></span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a><span class="co">#   welsh english male and welsh english female for example are both labeled as</span></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a><span class="co">#   welsh english</span></span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a><span class="co"># - Add extension .wav to the filename</span></span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a><span class="co"># - Shuffle samples</span></span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a><span class="kw">def</span> preprocess_dataframe(dataframe):</span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a>    <span class="co"># Remove leading space in filename column</span></span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a>    dataframe[<span class="st">"filename"</span>] <span class="op">=</span> dataframe.<span class="bu">apply</span>(</span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a>        <span class="kw">lambda</span> row: row[<span class="st">"filename"</span>].strip(), axis<span class="op">=</span><span class="dv">1</span></span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a>    )</span>
<span id="cb6-13"><a href="#cb6-13" tabindex="-1"></a></span>
<span id="cb6-14"><a href="#cb6-14" tabindex="-1"></a>    <span class="co"># Create gender agnostic labels based on the filename first 2 letters</span></span>
<span id="cb6-15"><a href="#cb6-15" tabindex="-1"></a>    dataframe[<span class="st">"label"</span>] <span class="op">=</span> dataframe.<span class="bu">apply</span>(</span>
<span id="cb6-16"><a href="#cb6-16" tabindex="-1"></a>        <span class="kw">lambda</span> row: gender_agnostic_categories.index(row[<span class="st">"filename"</span>][:<span class="dv">2</span>]),</span>
<span id="cb6-17"><a href="#cb6-17" tabindex="-1"></a>        axis<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb6-18"><a href="#cb6-18" tabindex="-1"></a>    )</span>
<span id="cb6-19"><a href="#cb6-19" tabindex="-1"></a></span>
<span id="cb6-20"><a href="#cb6-20" tabindex="-1"></a>    <span class="co"># Add the file path to the name</span></span>
<span id="cb6-21"><a href="#cb6-21" tabindex="-1"></a>    dataframe[<span class="st">"filename"</span>] <span class="op">=</span> dataframe.<span class="bu">apply</span>(</span>
<span id="cb6-22"><a href="#cb6-22" tabindex="-1"></a>        <span class="kw">lambda</span> row: os.path.join(DATASET_DESTINATION, row[<span class="st">"filename"</span>] <span class="op">+</span> <span class="st">".wav"</span>),</span>
<span id="cb6-23"><a href="#cb6-23" tabindex="-1"></a>        axis<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb6-24"><a href="#cb6-24" tabindex="-1"></a>    )</span>
<span id="cb6-25"><a href="#cb6-25" tabindex="-1"></a></span>
<span id="cb6-26"><a href="#cb6-26" tabindex="-1"></a>    <span class="co"># Shuffle the samples</span></span>
<span id="cb6-27"><a href="#cb6-27" tabindex="-1"></a>    dataframe <span class="op">=</span> dataframe.sample(frac<span class="op">=</span><span class="dv">1</span>, random_state<span class="op">=</span>SEED).reset_index(</span>
<span id="cb6-28"><a href="#cb6-28" tabindex="-1"></a>        drop<span class="op">=</span><span class="va">True</span></span>
<span id="cb6-29"><a href="#cb6-29" tabindex="-1"></a>    )</span>
<span id="cb6-30"><a href="#cb6-30" tabindex="-1"></a></span>
<span id="cb6-31"><a href="#cb6-31" tabindex="-1"></a>    <span class="cf">return</span> dataframe</span>
<span id="cb6-32"><a href="#cb6-32" tabindex="-1"></a></span>
<span id="cb6-33"><a href="#cb6-33" tabindex="-1"></a></span>
<span id="cb6-34"><a href="#cb6-34" tabindex="-1"></a>dataframe <span class="op">=</span> preprocess_dataframe(dataframe)</span>
<span id="cb6-35"><a href="#cb6-35" tabindex="-1"></a>dataframe.head()</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="prepare-training-validation-sets">Prepare training &amp; validation sets<a class="anchor" aria-label="anchor" href="#prepare-training-validation-sets"></a>
</h2>
<p>Let’s split the samples creating training and validation sets.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>split <span class="op">=</span> <span class="bu">int</span>(<span class="bu">len</span>(dataframe) <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> VALIDATION_RATIO))</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>train_df <span class="op">=</span> dataframe[:split]</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>valid_df <span class="op">=</span> dataframe[split:]</span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a>    <span class="ss">f"We have </span><span class="sc">{</span>train_df<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> training samples &amp; </span><span class="sc">{</span>valid_df<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> validation ones"</span></span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="prepare-a-tensorflow-dataset">Prepare a TensorFlow Dataset<a class="anchor" aria-label="anchor" href="#prepare-a-tensorflow-dataset"></a>
</h2>
<p>Next, we need to create a <code>tf.data.Dataset</code>. This is done
by creating a <code>dataframe_to_dataset</code> function that does the
following:</p>
<ul>
<li>Create a dataset using filenames and labels.</li>
<li>Get the Yamnet embeddings by calling another function
<code>filepath_to_embeddings</code>.</li>
<li>Apply caching, reshuffling and setting batch size.</li>
</ul>
<p>The <code>filepath_to_embeddings</code> does the following:</p>
<ul>
<li>Load audio file.</li>
<li>Resample audio to 16 kHz.</li>
<li>Generate scores and embeddings from Yamnet model.</li>
<li>Since Yamnet generates multiple samples for each audio file, this
function also duplicates the label for all the generated samples that
have <code>score=0</code> (speech) whereas sets the label for the others
as ‘other’ indicating that this audio segment is not a speech and we
won’t label it as one of the accents.</li>
</ul>
<p>The below <code>load_16k_audio_file</code> is copied from the
following tutorial <a href="https://www.tensorflow.org/tutorials/audio/transfer_learning_audio" class="external-link">Transfer
learning with YAMNet for environmental sound classification</a></p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="at">@tf.function</span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a><span class="kw">def</span> load_16k_audio_wav(filename):</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>    <span class="co"># Read file content</span></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>    file_content <span class="op">=</span> tf.io.read_file(filename)</span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a>    <span class="co"># Decode audio wave</span></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a>    audio_wav, sample_rate <span class="op">=</span> tf.audio.decode_wav(</span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a>        file_content, desired_channels<span class="op">=</span><span class="dv">1</span></span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a>    )</span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a>    audio_wav <span class="op">=</span> tf.squeeze(audio_wav, axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a>    sample_rate <span class="op">=</span> tf.cast(sample_rate, dtype<span class="op">=</span>tf.int64)</span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a></span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a>    <span class="co"># Resample to 16k</span></span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a>    audio_wav <span class="op">=</span> tfio.audio.resample(</span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a>        audio_wav, rate_in<span class="op">=</span>sample_rate, rate_out<span class="op">=</span><span class="dv">16000</span></span>
<span id="cb8-16"><a href="#cb8-16" tabindex="-1"></a>    )</span>
<span id="cb8-17"><a href="#cb8-17" tabindex="-1"></a></span>
<span id="cb8-18"><a href="#cb8-18" tabindex="-1"></a>    <span class="cf">return</span> audio_wav</span>
<span id="cb8-19"><a href="#cb8-19" tabindex="-1"></a></span>
<span id="cb8-20"><a href="#cb8-20" tabindex="-1"></a></span>
<span id="cb8-21"><a href="#cb8-21" tabindex="-1"></a><span class="kw">def</span> filepath_to_embeddings(filename, label):</span>
<span id="cb8-22"><a href="#cb8-22" tabindex="-1"></a>    <span class="co"># Load 16k audio wave</span></span>
<span id="cb8-23"><a href="#cb8-23" tabindex="-1"></a>    audio_wav <span class="op">=</span> load_16k_audio_wav(filename)</span>
<span id="cb8-24"><a href="#cb8-24" tabindex="-1"></a></span>
<span id="cb8-25"><a href="#cb8-25" tabindex="-1"></a>    <span class="co"># Get audio embeddings &amp; scores.</span></span>
<span id="cb8-26"><a href="#cb8-26" tabindex="-1"></a>    <span class="co"># The embeddings are the audio features extracted using transfer learning</span></span>
<span id="cb8-27"><a href="#cb8-27" tabindex="-1"></a>    <span class="co"># while scores will be used to identify time slots that are not speech</span></span>
<span id="cb8-28"><a href="#cb8-28" tabindex="-1"></a>    <span class="co"># which will then be gathered into a specific new category 'other'</span></span>
<span id="cb8-29"><a href="#cb8-29" tabindex="-1"></a>    scores, embeddings, _ <span class="op">=</span> yamnet_model(audio_wav)</span>
<span id="cb8-30"><a href="#cb8-30" tabindex="-1"></a></span>
<span id="cb8-31"><a href="#cb8-31" tabindex="-1"></a>    <span class="co"># Number of embeddings in order to know how many times to repeat the label</span></span>
<span id="cb8-32"><a href="#cb8-32" tabindex="-1"></a>    embeddings_num <span class="op">=</span> tf.shape(embeddings)[<span class="dv">0</span>]</span>
<span id="cb8-33"><a href="#cb8-33" tabindex="-1"></a>    labels <span class="op">=</span> tf.repeat(label, embeddings_num)</span>
<span id="cb8-34"><a href="#cb8-34" tabindex="-1"></a></span>
<span id="cb8-35"><a href="#cb8-35" tabindex="-1"></a>    <span class="co"># Change labels for time-slots that are not speech into a new category 'other'</span></span>
<span id="cb8-36"><a href="#cb8-36" tabindex="-1"></a>    labels <span class="op">=</span> tf.where(</span>
<span id="cb8-37"><a href="#cb8-37" tabindex="-1"></a>        tf.argmax(scores, axis<span class="op">=</span><span class="dv">1</span>) <span class="op">==</span> <span class="dv">0</span>, label, <span class="bu">len</span>(class_names) <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb8-38"><a href="#cb8-38" tabindex="-1"></a>    )</span>
<span id="cb8-39"><a href="#cb8-39" tabindex="-1"></a></span>
<span id="cb8-40"><a href="#cb8-40" tabindex="-1"></a>    <span class="co"># Using one-hot in order to use AUC</span></span>
<span id="cb8-41"><a href="#cb8-41" tabindex="-1"></a>    <span class="cf">return</span> (embeddings, tf.one_hot(labels, <span class="bu">len</span>(class_names)))</span>
<span id="cb8-42"><a href="#cb8-42" tabindex="-1"></a></span>
<span id="cb8-43"><a href="#cb8-43" tabindex="-1"></a></span>
<span id="cb8-44"><a href="#cb8-44" tabindex="-1"></a><span class="kw">def</span> dataframe_to_dataset(dataframe, batch_size<span class="op">=</span><span class="dv">64</span>):</span>
<span id="cb8-45"><a href="#cb8-45" tabindex="-1"></a>    dataset <span class="op">=</span> tf.data.Dataset.from_tensor_slices(</span>
<span id="cb8-46"><a href="#cb8-46" tabindex="-1"></a>        (dataframe[<span class="st">"filename"</span>], dataframe[<span class="st">"label"</span>])</span>
<span id="cb8-47"><a href="#cb8-47" tabindex="-1"></a>    )</span>
<span id="cb8-48"><a href="#cb8-48" tabindex="-1"></a></span>
<span id="cb8-49"><a href="#cb8-49" tabindex="-1"></a>    dataset <span class="op">=</span> dataset.<span class="bu">map</span>(</span>
<span id="cb8-50"><a href="#cb8-50" tabindex="-1"></a>        <span class="kw">lambda</span> x, y: filepath_to_embeddings(x, y),</span>
<span id="cb8-51"><a href="#cb8-51" tabindex="-1"></a>        num_parallel_calls<span class="op">=</span>tf.data.experimental.AUTOTUNE,</span>
<span id="cb8-52"><a href="#cb8-52" tabindex="-1"></a>    ).unbatch()</span>
<span id="cb8-53"><a href="#cb8-53" tabindex="-1"></a></span>
<span id="cb8-54"><a href="#cb8-54" tabindex="-1"></a>    <span class="cf">return</span> dataset.cache().batch(batch_size).prefetch(tf.data.AUTOTUNE)</span>
<span id="cb8-55"><a href="#cb8-55" tabindex="-1"></a></span>
<span id="cb8-56"><a href="#cb8-56" tabindex="-1"></a></span>
<span id="cb8-57"><a href="#cb8-57" tabindex="-1"></a>train_ds <span class="op">=</span> dataframe_to_dataset(train_df)</span>
<span id="cb8-58"><a href="#cb8-58" tabindex="-1"></a>valid_ds <span class="op">=</span> dataframe_to_dataset(valid_df)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="build-the-model">Build the model<a class="anchor" aria-label="anchor" href="#build-the-model"></a>
</h2>
<p>The model that we use consists of:</p>
<ul>
<li>An input layer which is the embedding output of the Yamnet
classifier.</li>
<li>4 dense hidden layers and 4 dropout layers.</li>
<li>An output dense layer.</li>
</ul>
<p>The model’s hyperparameters were selected using <a href="https://keras.io/keras_tuner/" class="external-link">KerasTuner</a>.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>keras.backend.clear_session()</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a><span class="kw">def</span> build_and_compile_model():</span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a>    inputs <span class="op">=</span> keras.layers.Input(shape<span class="op">=</span>(<span class="dv">1024</span>,), name<span class="op">=</span><span class="st">"embedding"</span>)</span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Dense(<span class="dv">256</span>, activation<span class="op">=</span><span class="st">"relu"</span>, name<span class="op">=</span><span class="st">"dense_1"</span>)(inputs)</span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Dropout(<span class="fl">0.15</span>, name<span class="op">=</span><span class="st">"dropout_1"</span>)(x)</span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a></span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Dense(<span class="dv">384</span>, activation<span class="op">=</span><span class="st">"relu"</span>, name<span class="op">=</span><span class="st">"dense_2"</span>)(x)</span>
<span id="cb9-11"><a href="#cb9-11" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Dropout(<span class="fl">0.2</span>, name<span class="op">=</span><span class="st">"dropout_2"</span>)(x)</span>
<span id="cb9-12"><a href="#cb9-12" tabindex="-1"></a></span>
<span id="cb9-13"><a href="#cb9-13" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Dense(<span class="dv">192</span>, activation<span class="op">=</span><span class="st">"relu"</span>, name<span class="op">=</span><span class="st">"dense_3"</span>)(x)</span>
<span id="cb9-14"><a href="#cb9-14" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Dropout(<span class="fl">0.25</span>, name<span class="op">=</span><span class="st">"dropout_3"</span>)(x)</span>
<span id="cb9-15"><a href="#cb9-15" tabindex="-1"></a></span>
<span id="cb9-16"><a href="#cb9-16" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Dense(<span class="dv">384</span>, activation<span class="op">=</span><span class="st">"relu"</span>, name<span class="op">=</span><span class="st">"dense_4"</span>)(x)</span>
<span id="cb9-17"><a href="#cb9-17" tabindex="-1"></a>    x <span class="op">=</span> keras.layers.Dropout(<span class="fl">0.2</span>, name<span class="op">=</span><span class="st">"dropout_4"</span>)(x)</span>
<span id="cb9-18"><a href="#cb9-18" tabindex="-1"></a></span>
<span id="cb9-19"><a href="#cb9-19" tabindex="-1"></a>    outputs <span class="op">=</span> keras.layers.Dense(</span>
<span id="cb9-20"><a href="#cb9-20" tabindex="-1"></a>        <span class="bu">len</span>(class_names), activation<span class="op">=</span><span class="st">"softmax"</span>, name<span class="op">=</span><span class="st">"ouput"</span></span>
<span id="cb9-21"><a href="#cb9-21" tabindex="-1"></a>    )(x)</span>
<span id="cb9-22"><a href="#cb9-22" tabindex="-1"></a></span>
<span id="cb9-23"><a href="#cb9-23" tabindex="-1"></a>    model <span class="op">=</span> keras.Model(</span>
<span id="cb9-24"><a href="#cb9-24" tabindex="-1"></a>        inputs<span class="op">=</span>inputs, outputs<span class="op">=</span>outputs, name<span class="op">=</span><span class="st">"accent_recognition"</span></span>
<span id="cb9-25"><a href="#cb9-25" tabindex="-1"></a>    )</span>
<span id="cb9-26"><a href="#cb9-26" tabindex="-1"></a></span>
<span id="cb9-27"><a href="#cb9-27" tabindex="-1"></a>    model.<span class="bu">compile</span>(</span>
<span id="cb9-28"><a href="#cb9-28" tabindex="-1"></a>        optimizer<span class="op">=</span>keras.optimizers.Adam(learning_rate<span class="op">=</span><span class="fl">1.9644e-5</span>),</span>
<span id="cb9-29"><a href="#cb9-29" tabindex="-1"></a>        loss<span class="op">=</span>keras.losses.CategoricalCrossentropy(),</span>
<span id="cb9-30"><a href="#cb9-30" tabindex="-1"></a>        metrics<span class="op">=</span>[<span class="st">"accuracy"</span>, keras.metrics.AUC(name<span class="op">=</span><span class="st">"auc"</span>)],</span>
<span id="cb9-31"><a href="#cb9-31" tabindex="-1"></a>    )</span>
<span id="cb9-32"><a href="#cb9-32" tabindex="-1"></a></span>
<span id="cb9-33"><a href="#cb9-33" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb9-34"><a href="#cb9-34" tabindex="-1"></a></span>
<span id="cb9-35"><a href="#cb9-35" tabindex="-1"></a></span>
<span id="cb9-36"><a href="#cb9-36" tabindex="-1"></a>model <span class="op">=</span> build_and_compile_model()</span>
<span id="cb9-37"><a href="#cb9-37" tabindex="-1"></a>model.summary()</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="class-weights-calculation">Class weights calculation<a class="anchor" aria-label="anchor" href="#class-weights-calculation"></a>
</h2>
<p>Since the dataset is quite unbalanced, we wil use
<code>class_weight</code> argument during training.</p>
<p>Getting the class weights is a little tricky because even though we
know the number of audio files for each class, it does not represent the
number of samples for that class since Yamnet transforms each audio file
into multiple audio samples of 0.96 seconds each. So every audio file
will be split into a number of samples that is proportional to its
length.</p>
<p>Therefore, to get those weights, we have to calculate the number of
samples for each class after preprocessing through Yamnet.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a>class_counts <span class="op">=</span> tf.zeros(shape<span class="op">=</span>(<span class="bu">len</span>(class_names),), dtype<span class="op">=</span>tf.int32)</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a><span class="cf">for</span> x, y <span class="kw">in</span> <span class="bu">iter</span>(train_ds):</span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a>    class_counts <span class="op">=</span> class_counts <span class="op">+</span> tf.math.bincount(</span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a>        tf.cast(tf.math.argmax(y, axis<span class="op">=</span><span class="dv">1</span>), tf.int32), minlength<span class="op">=</span><span class="bu">len</span>(class_names)</span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a>    )</span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a>class_weight <span class="op">=</span> {</span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a>    i: tf.math.reduce_sum(class_counts).numpy() <span class="op">/</span> class_counts[i].numpy()</span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(class_counts))</span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a>}</span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a></span>
<span id="cb10-13"><a href="#cb10-13" tabindex="-1"></a><span class="bu">print</span>(class_weight)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="callbacks">Callbacks<a class="anchor" aria-label="anchor" href="#callbacks"></a>
</h2>
<p>We use Keras callbacks in order to:</p>
<ul>
<li>Stop whenever the validation AUC stops improving.</li>
<li>Save the best model.</li>
<li>Call TensorBoard in order to later view the training and validation
logs.</li>
</ul>
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>early_stopping_cb <span class="op">=</span> keras.callbacks.EarlyStopping(</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>    monitor<span class="op">=</span><span class="st">"val_auc"</span>, patience<span class="op">=</span><span class="dv">10</span>, restore_best_weights<span class="op">=</span><span class="va">True</span></span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>)</span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a>model_checkpoint_cb <span class="op">=</span> keras.callbacks.ModelCheckpoint(</span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a>    MODEL_NAME <span class="op">+</span> <span class="st">".keras"</span>, monitor<span class="op">=</span><span class="st">"val_auc"</span>, save_best_only<span class="op">=</span><span class="va">True</span></span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a>)</span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a>tensorboard_cb <span class="op">=</span> keras.callbacks.TensorBoard(</span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a>    os.path.join(os.curdir, <span class="st">"logs"</span>, model.name)</span>
<span id="cb11-11"><a href="#cb11-11" tabindex="-1"></a>)</span>
<span id="cb11-12"><a href="#cb11-12" tabindex="-1"></a></span>
<span id="cb11-13"><a href="#cb11-13" tabindex="-1"></a>callbacks <span class="op">=</span> [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="training">Training<a class="anchor" aria-label="anchor" href="#training"></a>
</h2>
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a>history <span class="op">=</span> model.fit(</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a>    train_ds,</span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>    epochs<span class="op">=</span>EPOCHS,</span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a>    validation_data<span class="op">=</span>valid_ds,</span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a>    class_weight<span class="op">=</span>class_weight,</span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a>    callbacks<span class="op">=</span>callbacks,</span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb12-8"><a href="#cb12-8" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="results">Results<a class="anchor" aria-label="anchor" href="#results"></a>
</h2>
<p>Let’s plot the training and validation AUC and accuracy.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(nrows<span class="op">=</span><span class="dv">1</span>, ncols<span class="op">=</span><span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">5</span>))</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a>axs[<span class="dv">0</span>].plot(<span class="bu">range</span>(EPOCHS), history.history[<span class="st">"accuracy"</span>], label<span class="op">=</span><span class="st">"Training"</span>)</span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a>axs[<span class="dv">0</span>].plot(<span class="bu">range</span>(EPOCHS), history.history[<span class="st">"val_accuracy"</span>], label<span class="op">=</span><span class="st">"Validation"</span>)</span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a>axs[<span class="dv">0</span>].set_xlabel(<span class="st">"Epochs"</span>)</span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a>axs[<span class="dv">0</span>].set_title(<span class="st">"Training &amp; Validation Accuracy"</span>)</span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a>axs[<span class="dv">0</span>].legend()</span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a>axs[<span class="dv">0</span>].grid(<span class="va">True</span>)</span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a></span>
<span id="cb13-10"><a href="#cb13-10" tabindex="-1"></a>axs[<span class="dv">1</span>].plot(<span class="bu">range</span>(EPOCHS), history.history[<span class="st">"auc"</span>], label<span class="op">=</span><span class="st">"Training"</span>)</span>
<span id="cb13-11"><a href="#cb13-11" tabindex="-1"></a>axs[<span class="dv">1</span>].plot(<span class="bu">range</span>(EPOCHS), history.history[<span class="st">"val_auc"</span>], label<span class="op">=</span><span class="st">"Validation"</span>)</span>
<span id="cb13-12"><a href="#cb13-12" tabindex="-1"></a>axs[<span class="dv">1</span>].set_xlabel(<span class="st">"Epochs"</span>)</span>
<span id="cb13-13"><a href="#cb13-13" tabindex="-1"></a>axs[<span class="dv">1</span>].set_title(<span class="st">"Training &amp; Validation AUC"</span>)</span>
<span id="cb13-14"><a href="#cb13-14" tabindex="-1"></a>axs[<span class="dv">1</span>].legend()</span>
<span id="cb13-15"><a href="#cb13-15" tabindex="-1"></a>axs[<span class="dv">1</span>].grid(<span class="va">True</span>)</span>
<span id="cb13-16"><a href="#cb13-16" tabindex="-1"></a></span>
<span id="cb13-17"><a href="#cb13-17" tabindex="-1"></a>plt.show()</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="evaluation">Evaluation<a class="anchor" aria-label="anchor" href="#evaluation"></a>
</h2>
<div class="sourceCode" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a>train_loss, train_acc, train_auc <span class="op">=</span> model.evaluate(train_ds)</span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a>valid_loss, valid_acc, valid_auc <span class="op">=</span> model.evaluate(valid_ds)</span></code></pre></div>
<p>Let’s try to compare our model’s performance to Yamnet’s using one of
Yamnet metrics (d-prime) Yamnet achieved a d-prime value of 2.318. Let’s
check our model’s performance.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="co"># The following function calculates the d-prime score from the AUC</span></span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a><span class="kw">def</span> d_prime(auc):</span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a>    standard_normal <span class="op">=</span> stats.norm()</span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a>    d_prime <span class="op">=</span> standard_normal.ppf(auc) <span class="op">*</span> np.sqrt(<span class="fl">2.0</span>)</span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a>    <span class="cf">return</span> d_prime</span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a></span>
<span id="cb15-7"><a href="#cb15-7" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb15-9"><a href="#cb15-9" tabindex="-1"></a>    <span class="st">"train d-prime: </span><span class="sc">{0:.3f}</span><span class="st">, validation d-prime: </span><span class="sc">{1:.3f}</span><span class="st">"</span>.<span class="bu">format</span>(</span>
<span id="cb15-10"><a href="#cb15-10" tabindex="-1"></a>        d_prime(train_auc), d_prime(valid_auc)</span>
<span id="cb15-11"><a href="#cb15-11" tabindex="-1"></a>    )</span>
<span id="cb15-12"><a href="#cb15-12" tabindex="-1"></a>)</span></code></pre></div>
<p>We can see that the model achieves the following results:</p>
<table class="table">
<thead><tr class="header">
<th>Results</th>
<th>Training</th>
<th>Validation</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Accuracy</td>
<td>54%</td>
<td>51%</td>
</tr>
<tr class="even">
<td>AUC</td>
<td>0.91</td>
<td>0.89</td>
</tr>
<tr class="odd">
<td>d-prime</td>
<td>1.882</td>
<td>1.740</td>
</tr>
</tbody>
</table>
</div>
<div class="section level2">
<h2 id="confusion-matrix">Confusion Matrix<a class="anchor" aria-label="anchor" href="#confusion-matrix"></a>
</h2>
<p>Let’s now plot the confusion matrix for the validation dataset.</p>
<p>The confusion matrix lets us see, for every class, not only how many
samples were correctly classified, but also which other classes were the
samples confused with.</p>
<p>It allows us to calculate the precision and recall for every
class.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="co"># Create x and y tensors</span></span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a>x_valid <span class="op">=</span> <span class="va">None</span></span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a>y_valid <span class="op">=</span> <span class="va">None</span></span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a><span class="cf">for</span> x, y <span class="kw">in</span> <span class="bu">iter</span>(valid_ds):</span>
<span id="cb16-6"><a href="#cb16-6" tabindex="-1"></a>    <span class="cf">if</span> x_valid <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb16-7"><a href="#cb16-7" tabindex="-1"></a>        x_valid <span class="op">=</span> x.numpy()</span>
<span id="cb16-8"><a href="#cb16-8" tabindex="-1"></a>        y_valid <span class="op">=</span> y.numpy()</span>
<span id="cb16-9"><a href="#cb16-9" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb16-10"><a href="#cb16-10" tabindex="-1"></a>        x_valid <span class="op">=</span> np.concatenate((x_valid, x.numpy()), axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb16-11"><a href="#cb16-11" tabindex="-1"></a>        y_valid <span class="op">=</span> np.concatenate((y_valid, y.numpy()), axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb16-12"><a href="#cb16-12" tabindex="-1"></a></span>
<span id="cb16-13"><a href="#cb16-13" tabindex="-1"></a><span class="co"># Generate predictions</span></span>
<span id="cb16-14"><a href="#cb16-14" tabindex="-1"></a>y_pred <span class="op">=</span> model.predict(x_valid)</span>
<span id="cb16-15"><a href="#cb16-15" tabindex="-1"></a></span>
<span id="cb16-16"><a href="#cb16-16" tabindex="-1"></a><span class="co"># Calculate confusion matrix</span></span>
<span id="cb16-17"><a href="#cb16-17" tabindex="-1"></a>confusion_mtx <span class="op">=</span> tf.math.confusion_matrix(</span>
<span id="cb16-18"><a href="#cb16-18" tabindex="-1"></a>    np.argmax(y_valid, axis<span class="op">=</span><span class="dv">1</span>), np.argmax(y_pred, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb16-19"><a href="#cb16-19" tabindex="-1"></a>)</span>
<span id="cb16-20"><a href="#cb16-20" tabindex="-1"></a></span>
<span id="cb16-21"><a href="#cb16-21" tabindex="-1"></a><span class="co"># Plot the confusion matrix</span></span>
<span id="cb16-22"><a href="#cb16-22" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb16-23"><a href="#cb16-23" tabindex="-1"></a>sns.heatmap(</span>
<span id="cb16-24"><a href="#cb16-24" tabindex="-1"></a>    confusion_mtx,</span>
<span id="cb16-25"><a href="#cb16-25" tabindex="-1"></a>    xticklabels<span class="op">=</span>class_names,</span>
<span id="cb16-26"><a href="#cb16-26" tabindex="-1"></a>    yticklabels<span class="op">=</span>class_names,</span>
<span id="cb16-27"><a href="#cb16-27" tabindex="-1"></a>    annot<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb16-28"><a href="#cb16-28" tabindex="-1"></a>    fmt<span class="op">=</span><span class="st">"g"</span>,</span>
<span id="cb16-29"><a href="#cb16-29" tabindex="-1"></a>)</span>
<span id="cb16-30"><a href="#cb16-30" tabindex="-1"></a>plt.xlabel(<span class="st">"Prediction"</span>)</span>
<span id="cb16-31"><a href="#cb16-31" tabindex="-1"></a>plt.ylabel(<span class="st">"Label"</span>)</span>
<span id="cb16-32"><a href="#cb16-32" tabindex="-1"></a>plt.title(<span class="st">"Validation Confusion Matrix"</span>)</span>
<span id="cb16-33"><a href="#cb16-33" tabindex="-1"></a>plt.show()</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="precision-recall">Precision &amp; recall<a class="anchor" aria-label="anchor" href="#precision-recall"></a>
</h2>
<p>For every class:</p>
<ul>
<li>Recall is the ratio of correctly classified samples i.e. it shows
how many samples of this specific class, the model is able to detect. It
is the ratio of diagonal elements to the sum of all elements in the
row.</li>
<li>Precision shows the accuracy of the classifier. It is the ratio of
correctly predicted samples among the ones classified as belonging to
this class. It is the ratio of diagonal elements to the sum of all
elements in the column.</li>
</ul>
<div class="sourceCode" id="cb17"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="cf">for</span> i, label <span class="kw">in</span> <span class="bu">enumerate</span>(class_names):</span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a>    precision <span class="op">=</span> confusion_mtx[i, i] <span class="op">/</span> np.<span class="bu">sum</span>(confusion_mtx[:, i])</span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a>    recall <span class="op">=</span> confusion_mtx[i, i] <span class="op">/</span> np.<span class="bu">sum</span>(confusion_mtx[i, :])</span>
<span id="cb17-4"><a href="#cb17-4" tabindex="-1"></a>    <span class="bu">print</span>(</span>
<span id="cb17-5"><a href="#cb17-5" tabindex="-1"></a>        <span class="st">"</span><span class="sc">{0:15}</span><span class="st"> Precision:</span><span class="sc">{1:.2f}</span><span class="st">%; Recall:</span><span class="sc">{2:.2f}</span><span class="st">%"</span>.<span class="bu">format</span>(</span>
<span id="cb17-6"><a href="#cb17-6" tabindex="-1"></a>            label, precision <span class="op">*</span> <span class="dv">100</span>, recall <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb17-7"><a href="#cb17-7" tabindex="-1"></a>        )</span>
<span id="cb17-8"><a href="#cb17-8" tabindex="-1"></a>    )</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="run-inference-on-test-data">Run inference on test data<a class="anchor" aria-label="anchor" href="#run-inference-on-test-data"></a>
</h2>
<p>Let’s now run a test on a single audio file. Let’s check this example
from <a href="https://www.thescottishvoice.org.uk/home/" class="external-link">The Scottish
Voice</a></p>
<p>We will:</p>
<ul>
<li>Download the mp3 file.</li>
<li>Convert it to a 16k wav file.</li>
<li>Run the model on the wav file.</li>
<li>Plot the results.</li>
</ul>
<div class="sourceCode" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a>filename <span class="op">=</span> <span class="st">"audio-sample-Stuart"</span></span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a>url <span class="op">=</span> <span class="st">"https://www.thescottishvoice.org.uk/files/cm/files/"</span></span>
<span id="cb18-3"><a href="#cb18-3" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" tabindex="-1"></a><span class="cf">if</span> os.path.exists(filename <span class="op">+</span> <span class="st">".wav"</span>) <span class="op">==</span> <span class="va">False</span>:</span>
<span id="cb18-5"><a href="#cb18-5" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Downloading </span><span class="sc">{</span>filename<span class="sc">}</span><span class="ss">.mp3 from </span><span class="sc">{</span>url<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb18-6"><a href="#cb18-6" tabindex="-1"></a>    command <span class="op">=</span> <span class="ss">f"wget </span><span class="sc">{</span>url<span class="sc">}{</span>filename<span class="sc">}</span><span class="ss">.mp3"</span></span>
<span id="cb18-7"><a href="#cb18-7" tabindex="-1"></a>    os.system(command)</span>
<span id="cb18-8"><a href="#cb18-8" tabindex="-1"></a></span>
<span id="cb18-9"><a href="#cb18-9" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Converting mp3 to wav and resampling to 16 kHZ"</span>)</span>
<span id="cb18-10"><a href="#cb18-10" tabindex="-1"></a>    command <span class="op">=</span> (</span>
<span id="cb18-11"><a href="#cb18-11" tabindex="-1"></a>        <span class="ss">f"ffmpeg -hide_banner -loglevel panic -y -i </span><span class="sc">{</span>filename<span class="sc">}</span><span class="ss">.mp3 -acodec "</span></span>
<span id="cb18-12"><a href="#cb18-12" tabindex="-1"></a>        <span class="ss">f"pcm_s16le -ac 1 -ar 16000 </span><span class="sc">{</span>filename<span class="sc">}</span><span class="ss">.wav"</span></span>
<span id="cb18-13"><a href="#cb18-13" tabindex="-1"></a>    )</span>
<span id="cb18-14"><a href="#cb18-14" tabindex="-1"></a>    os.system(command)</span>
<span id="cb18-15"><a href="#cb18-15" tabindex="-1"></a></span>
<span id="cb18-16"><a href="#cb18-16" tabindex="-1"></a>filename <span class="op">=</span> filename <span class="op">+</span> <span class="st">".wav"</span></span></code></pre></div>
<p>The below function <code>yamnet_class_names_from_csv</code> was
copied and very slightly changed from this <a href="https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/yamnet.ipynb" class="external-link">Yamnet
Notebook</a>.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a><span class="kw">def</span> yamnet_class_names_from_csv(yamnet_class_map_csv_text):</span>
<span id="cb19-2"><a href="#cb19-2" tabindex="-1"></a>    <span class="co">"""Returns list of class names corresponding to score vector."""</span></span>
<span id="cb19-3"><a href="#cb19-3" tabindex="-1"></a>    yamnet_class_map_csv <span class="op">=</span> io.StringIO(yamnet_class_map_csv_text)</span>
<span id="cb19-4"><a href="#cb19-4" tabindex="-1"></a>    yamnet_class_names <span class="op">=</span> [</span>
<span id="cb19-5"><a href="#cb19-5" tabindex="-1"></a>        name <span class="cf">for</span> (class_index, mid, name) <span class="kw">in</span> csv.reader(yamnet_class_map_csv)</span>
<span id="cb19-6"><a href="#cb19-6" tabindex="-1"></a>    ]</span>
<span id="cb19-7"><a href="#cb19-7" tabindex="-1"></a>    yamnet_class_names <span class="op">=</span> yamnet_class_names[<span class="dv">1</span>:]  <span class="co"># Skip CSV header</span></span>
<span id="cb19-8"><a href="#cb19-8" tabindex="-1"></a>    <span class="cf">return</span> yamnet_class_names</span>
<span id="cb19-9"><a href="#cb19-9" tabindex="-1"></a></span>
<span id="cb19-10"><a href="#cb19-10" tabindex="-1"></a></span>
<span id="cb19-11"><a href="#cb19-11" tabindex="-1"></a>yamnet_class_map_path <span class="op">=</span> yamnet_model.class_map_path().numpy()</span>
<span id="cb19-12"><a href="#cb19-12" tabindex="-1"></a>yamnet_class_names <span class="op">=</span> yamnet_class_names_from_csv(</span>
<span id="cb19-13"><a href="#cb19-13" tabindex="-1"></a>    tf.io.read_file(yamnet_class_map_path).numpy().decode(<span class="st">"utf-8"</span>)</span>
<span id="cb19-14"><a href="#cb19-14" tabindex="-1"></a>)</span>
<span id="cb19-15"><a href="#cb19-15" tabindex="-1"></a></span>
<span id="cb19-16"><a href="#cb19-16" tabindex="-1"></a></span>
<span id="cb19-17"><a href="#cb19-17" tabindex="-1"></a><span class="kw">def</span> calculate_number_of_non_speech(scores):</span>
<span id="cb19-18"><a href="#cb19-18" tabindex="-1"></a>    number_of_non_speech <span class="op">=</span> tf.math.reduce_sum(</span>
<span id="cb19-19"><a href="#cb19-19" tabindex="-1"></a>        tf.where(</span>
<span id="cb19-20"><a href="#cb19-20" tabindex="-1"></a>            tf.math.argmax(scores, axis<span class="op">=</span><span class="dv">1</span>, output_type<span class="op">=</span>tf.int32) <span class="op">!=</span> <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span></span>
<span id="cb19-21"><a href="#cb19-21" tabindex="-1"></a>        )</span>
<span id="cb19-22"><a href="#cb19-22" tabindex="-1"></a>    )</span>
<span id="cb19-23"><a href="#cb19-23" tabindex="-1"></a></span>
<span id="cb19-24"><a href="#cb19-24" tabindex="-1"></a>    <span class="cf">return</span> number_of_non_speech</span>
<span id="cb19-25"><a href="#cb19-25" tabindex="-1"></a></span>
<span id="cb19-26"><a href="#cb19-26" tabindex="-1"></a></span>
<span id="cb19-27"><a href="#cb19-27" tabindex="-1"></a><span class="kw">def</span> filename_to_predictions(filename):</span>
<span id="cb19-28"><a href="#cb19-28" tabindex="-1"></a>    <span class="co"># Load 16k audio wave</span></span>
<span id="cb19-29"><a href="#cb19-29" tabindex="-1"></a>    audio_wav <span class="op">=</span> load_16k_audio_wav(filename)</span>
<span id="cb19-30"><a href="#cb19-30" tabindex="-1"></a></span>
<span id="cb19-31"><a href="#cb19-31" tabindex="-1"></a>    <span class="co"># Get audio embeddings &amp; scores.</span></span>
<span id="cb19-32"><a href="#cb19-32" tabindex="-1"></a>    scores, embeddings, mel_spectrogram <span class="op">=</span> yamnet_model(audio_wav)</span>
<span id="cb19-33"><a href="#cb19-33" tabindex="-1"></a></span>
<span id="cb19-34"><a href="#cb19-34" tabindex="-1"></a>    <span class="bu">print</span>(</span>
<span id="cb19-35"><a href="#cb19-35" tabindex="-1"></a>        <span class="st">"Out of </span><span class="sc">{}</span><span class="st"> samples, </span><span class="sc">{}</span><span class="st"> are not speech"</span>.<span class="bu">format</span>(</span>
<span id="cb19-36"><a href="#cb19-36" tabindex="-1"></a>            scores.shape[<span class="dv">0</span>], calculate_number_of_non_speech(scores)</span>
<span id="cb19-37"><a href="#cb19-37" tabindex="-1"></a>        )</span>
<span id="cb19-38"><a href="#cb19-38" tabindex="-1"></a>    )</span>
<span id="cb19-39"><a href="#cb19-39" tabindex="-1"></a></span>
<span id="cb19-40"><a href="#cb19-40" tabindex="-1"></a>    <span class="co"># Predict the output of the accent recognition model with embeddings as input</span></span>
<span id="cb19-41"><a href="#cb19-41" tabindex="-1"></a>    predictions <span class="op">=</span> model.predict(embeddings)</span>
<span id="cb19-42"><a href="#cb19-42" tabindex="-1"></a></span>
<span id="cb19-43"><a href="#cb19-43" tabindex="-1"></a>    <span class="cf">return</span> audio_wav, predictions, mel_spectrogram</span></code></pre></div>
<p>Let’s run the model on the audio file:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a>audio_wav, predictions, mel_spectrogram <span class="op">=</span> filename_to_predictions(filename)</span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" tabindex="-1"></a>infered_class <span class="op">=</span> class_names[predictions.mean(axis<span class="op">=</span><span class="dv">0</span>).argmax()]</span>
<span id="cb20-4"><a href="#cb20-4" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"The main accent is: </span><span class="sc">{</span>infered_class<span class="sc">}</span><span class="ss"> English"</span>)</span></code></pre></div>
<p>Listen to the audio</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a>Audio(audio_wav, rate<span class="op">=</span><span class="dv">16000</span>)</span></code></pre></div>
<p>The below function was copied from this <a href="tinyurl.com/4a8xn7at">Yamnet notebook</a> and adjusted to our
need.</p>
<p>This function plots the following:</p>
<ul>
<li>Audio waveform</li>
<li>Mel spectrogram</li>
<li>Predictions for every time step</li>
</ul>
<div class="sourceCode" id="cb22"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb22-2"><a href="#cb22-2" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" tabindex="-1"></a><span class="co"># Plot the waveform.</span></span>
<span id="cb22-4"><a href="#cb22-4" tabindex="-1"></a>plt.subplot(<span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb22-5"><a href="#cb22-5" tabindex="-1"></a>plt.plot(audio_wav)</span>
<span id="cb22-6"><a href="#cb22-6" tabindex="-1"></a>plt.xlim([<span class="dv">0</span>, <span class="bu">len</span>(audio_wav)])</span>
<span id="cb22-7"><a href="#cb22-7" tabindex="-1"></a></span>
<span id="cb22-8"><a href="#cb22-8" tabindex="-1"></a><span class="co"># Plot the log-mel spectrogram (returned by the model).</span></span>
<span id="cb22-9"><a href="#cb22-9" tabindex="-1"></a>plt.subplot(<span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb22-10"><a href="#cb22-10" tabindex="-1"></a>plt.imshow(</span>
<span id="cb22-11"><a href="#cb22-11" tabindex="-1"></a>    mel_spectrogram.numpy().T,</span>
<span id="cb22-12"><a href="#cb22-12" tabindex="-1"></a>    aspect<span class="op">=</span><span class="st">"auto"</span>,</span>
<span id="cb22-13"><a href="#cb22-13" tabindex="-1"></a>    interpolation<span class="op">=</span><span class="st">"nearest"</span>,</span>
<span id="cb22-14"><a href="#cb22-14" tabindex="-1"></a>    origin<span class="op">=</span><span class="st">"lower"</span>,</span>
<span id="cb22-15"><a href="#cb22-15" tabindex="-1"></a>)</span>
<span id="cb22-16"><a href="#cb22-16" tabindex="-1"></a></span>
<span id="cb22-17"><a href="#cb22-17" tabindex="-1"></a><span class="co"># Plot and label the model output scores for the top-scoring classes.</span></span>
<span id="cb22-18"><a href="#cb22-18" tabindex="-1"></a>mean_predictions <span class="op">=</span> np.mean(predictions, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb22-19"><a href="#cb22-19" tabindex="-1"></a></span>
<span id="cb22-20"><a href="#cb22-20" tabindex="-1"></a>top_class_indices <span class="op">=</span> np.argsort(mean_predictions)[::<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb22-21"><a href="#cb22-21" tabindex="-1"></a>plt.subplot(<span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">3</span>)</span>
<span id="cb22-22"><a href="#cb22-22" tabindex="-1"></a>plt.imshow(</span>
<span id="cb22-23"><a href="#cb22-23" tabindex="-1"></a>    predictions[:, top_class_indices].T,</span>
<span id="cb22-24"><a href="#cb22-24" tabindex="-1"></a>    aspect<span class="op">=</span><span class="st">"auto"</span>,</span>
<span id="cb22-25"><a href="#cb22-25" tabindex="-1"></a>    interpolation<span class="op">=</span><span class="st">"nearest"</span>,</span>
<span id="cb22-26"><a href="#cb22-26" tabindex="-1"></a>    cmap<span class="op">=</span><span class="st">"gray_r"</span>,</span>
<span id="cb22-27"><a href="#cb22-27" tabindex="-1"></a>)</span>
<span id="cb22-28"><a href="#cb22-28" tabindex="-1"></a></span>
<span id="cb22-29"><a href="#cb22-29" tabindex="-1"></a><span class="co"># patch_padding = (PATCH_WINDOW_SECONDS / 2) / PATCH_HOP_SECONDS</span></span>
<span id="cb22-30"><a href="#cb22-30" tabindex="-1"></a><span class="co"># values from the model documentation</span></span>
<span id="cb22-31"><a href="#cb22-31" tabindex="-1"></a>patch_padding <span class="op">=</span> (<span class="fl">0.025</span> <span class="op">/</span> <span class="dv">2</span>) <span class="op">/</span> <span class="fl">0.01</span></span>
<span id="cb22-32"><a href="#cb22-32" tabindex="-1"></a>plt.xlim([<span class="op">-</span>patch_padding <span class="op">-</span> <span class="fl">0.5</span>, predictions.shape[<span class="dv">0</span>] <span class="op">+</span> patch_padding <span class="op">-</span> <span class="fl">0.5</span>])</span>
<span id="cb22-33"><a href="#cb22-33" tabindex="-1"></a><span class="co"># Label the top_N classes.</span></span>
<span id="cb22-34"><a href="#cb22-34" tabindex="-1"></a>yticks <span class="op">=</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(class_names), <span class="dv">1</span>)</span>
<span id="cb22-35"><a href="#cb22-35" tabindex="-1"></a>plt.yticks(yticks, [class_names[top_class_indices[x]] <span class="cf">for</span> x <span class="kw">in</span> yticks])</span>
<span id="cb22-36"><a href="#cb22-36" tabindex="-1"></a>_ <span class="op">=</span> plt.ylim(<span class="op">-</span><span class="fl">0.5</span> <span class="op">+</span> np.array([<span class="bu">len</span>(class_names), <span class="dv">0</span>]))</span></code></pre></div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Tomasz Kalinowski, JJ Allaire, François Chollet, RStudio, Google.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
