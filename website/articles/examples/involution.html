<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content='Deep dive into location-specific and channel-agnostic "involution" kernels.'>
<title>Involutional neural networks • keras</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../../apple-touch-icon-60x60.png">
<script src="../../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../../pkgdown.js"></script><link href="../../extra.css" rel="stylesheet">
<script src="../../extra.js"></script><meta property="og:title" content="Involutional neural networks">
<meta property="og:description" content='Deep dive into location-specific and channel-agnostic "involution" kernels.'>
<meta property="og:image" content="/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-inverse navbar-expand-lg bg-primary"><div class="container">
    
    <a class="navbar-brand me-2" href="../../index.html">keras</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">2.13.0.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../../index.html">Home</a>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-tutorials">Tutorials</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-tutorials">
    <a class="dropdown-item" href="../../articles/getting_started.html">Getting Started</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_classification.html">Basic Classification</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_text_classification.html">Text Classification</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_regression.html">Basic Regression</a>
    <a class="dropdown-item" href="../../articles/tutorial_overfit_underfit.html">Overfitting and Underfitting</a>
    <a class="dropdown-item" href="../../articles/tutorial_save_and_restore.html">Save and Restore Models</a>
  </div>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-guides">Guides</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-guides">
    <a class="dropdown-item" href="../../writing_your_own_callbacks.html">Writing Your Own Callbacks</a>
  </div>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <h6 class="dropdown-header" data-toc-skip>Guides (New for TF 2.6)</h6>
    <a class="dropdown-item" href="../../articles/new-guides/python_subclasses.html">Python Subclasses</a>
    <a class="dropdown-item" href="../../articles/new-guides/making_new_layers_and_models_via_subclassing.html">Making New Layers and Models via Subclassing</a>
    <a class="dropdown-item" href="../../articles/new-guides/customizing_what_happens_in_fit.html">Customizing What Happens in Fit</a>
    <a class="dropdown-item" href="../../articles/new-guides/writing_your_own_callbacks.html">Writing Your Own Callbacks</a>
    <a class="dropdown-item" href="../../articles/new-guides/preprocessing_layers.html">Working with Preprocessing Layers</a>
    <a class="dropdown-item" href="../../argicles/new-guides/working_with_rnns.html">Working with RNNs</a>
    <div class="dropdown-divider"></div>
    <h6 class="dropdown-header" data-toc-skip>Using Keras</h6>
    <a class="dropdown-item" href="../../articles/guide_keras.html">Guide to Keras Basics</a>
    <a class="dropdown-item" href="../../articles/sequential_model.html">Sequential Model in Depth</a>
    <a class="dropdown-item" href="../../articles/functional_api.html">Functional API in Depth</a>
    <a class="dropdown-item" href="../../articles/about_keras_models.html">About Keras Models</a>
    <a class="dropdown-item" href="../../articles/about_keras_layers.html">About Keras Layers</a>
    <a class="dropdown-item" href="../../articles/training_visualization.html">Training Visualization</a>
    <a class="dropdown-item" href="../../articles/applications.html">Pre-Trained Models</a>
    <a class="dropdown-item" href="../../articles/faq.html">Frequently Asked Questions</a>
    <a class="dropdown-item" href="../../articles/why_use_keras.html">Why Use Keras?</a>
    <div class="dropdown-divider"></div>
    <h6 class="dropdown-header" data-toc-skip>Advanced</h6>
    <a class="dropdown-item" href="../../articles/eager_guide.html">Eager Execution</a>
    <a class="dropdown-item" href="../../articles/training_callbacks.html">Training Callbacks</a>
    <a class="dropdown-item" href="../../articles/backend.html">Keras Backend</a>
    <a class="dropdown-item" href="../../articles/custom_layers.html">Custom Layers</a>
    <a class="dropdown-item" href="../../articles/custom_models.html">Custom Models</a>
    <a class="dropdown-item" href="../../articles/saving_serializing.html">Saving and serializing</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../articles/learn.html">Learn</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../articles/tools.html">Tools</a>
</li>
<li class="active nav-item">
  <a class="nav-link" href="../../articles/examples/index.html">Examples</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../reference/index.html">Reference</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../news/index.html">News</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/rstudio/keras/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../../logo.png" class="logo" alt=""><h1>Involutional neural networks</h1>
                        <h4 data-toc-skip class="author"><a href="https://twitter.com/ariG23498" class="external-link">Aritra Roy Gosthipaty</a></h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/rstudio/keras/blob/HEAD/vignettes/examples/involution.Rmd" class="external-link"><code>vignettes/examples/involution.Rmd</code></a></small>
      <div class="d-none name"><code>involution.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>Convolution has been the basis of most modern neural networks for
computer vision. A convolution kernel is spatial-agnostic and
channel-specific. Because of this, it isn’t able to adapt to different
visual patterns with respect to different spatial locations. Along with
location-related problems, the receptive field of convolution creates
challenges with regard to capturing long-range spatial interactions.</p>
<p>To address the above issues, Li et. al. rethink the properties of
convolution in <a href="https://arxiv.org/abs/2103.06255" class="external-link">Involution:
Inverting the Inherence of Convolution for VisualRecognition</a>. The
authors propose the “involution kernel”, that is location-specific and
channel-agnostic. Due to the location-specific nature of the operation,
the authors say that self-attention falls under the design paradigm of
involution.</p>
<p>This example describes the involution kernel, compares two image
classification models, one with convolution and the other with
involution, and also tries drawing a parallel with the self-attention
layer.</p>
</div>
<div class="section level2">
<h2 id="setup">Setup<a class="anchor" aria-label="anchor" href="#setup"></a>
</h2>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">import</span> keras <span class="im">as</span> keras</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="co"># Set seed for reproducibility.</span></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a>tf.random.set_seed(<span class="dv">42</span>)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="convolution">Convolution<a class="anchor" aria-label="anchor" href="#convolution"></a>
</h2>
<p>Convolution remains the mainstay of deep neural networks for computer
vision. To understand Involution, it is necessary to talk about the
convolution operation.</p>
<div class="float">
<img src="https://i.imgur.com/MSKLsm5.png" alt="Imgur"><div class="figcaption">Imgur</div>
</div>
<p>Consider an input tensor <strong>X</strong> with dimensions
<strong>H</strong>, <strong>W</strong> and <strong>C_in</strong>. We
take a collection of <strong>C_out</strong> convolution kernels each of
shape <strong>K</strong>, <strong>K</strong>, <strong>C_in</strong>.
With the multiply-add operation between the input tensor and the kernels
we obtain an output tensor <strong>Y</strong> with dimensions
<strong>H</strong>, <strong>W</strong>, <strong>C_out</strong>.</p>
<p>In the diagram above <code>C_out=3</code>. This makes the output
tensor of shape H, W and 3. One can notice that the convoltuion kernel
does not depend on the spatial position of the input tensor which makes
it <strong>location-agnostic</strong>. On the other hand, each channel
in the output tensor is based on a specific convolution filter which
makes is <strong>channel-specific</strong>.</p>
</div>
<div class="section level2">
<h2 id="involution">Involution<a class="anchor" aria-label="anchor" href="#involution"></a>
</h2>
<p>The idea is to have an operation that is both
<strong>location-specific</strong> and
<strong>channel-agnostic</strong>. Trying to implement these specific
properties poses a challenge. With a fixed number of involution kernels
(for each spatial position) we will <strong>not</strong> be able to
process variable-resolution input tensors.</p>
<p>To solve this problem, the authors have considered
<em>generating</em> each kernel conditioned on specific spatial
positions. With this method, we should be able to process
variable-resolution input tensors with ease. The diagram below provides
an intuition on this kernel generation method.</p>
<div class="float">
<img src="https://i.imgur.com/jtrGGQg.png" alt="Imgur"><div class="figcaption">Imgur</div>
</div>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="kw">class</span> Involution(keras.layers.Layer):</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>        <span class="va">self</span>, channel, group_number, kernel_size, stride, reduction_ratio, name</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>    ):</span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(name<span class="op">=</span>name)</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>        <span class="co"># Initialize the parameters.</span></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>        <span class="va">self</span>.channel <span class="op">=</span> channel</span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a>        <span class="va">self</span>.group_number <span class="op">=</span> group_number</span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a>        <span class="va">self</span>.kernel_size <span class="op">=</span> kernel_size</span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a>        <span class="va">self</span>.stride <span class="op">=</span> stride</span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a>        <span class="va">self</span>.reduction_ratio <span class="op">=</span> reduction_ratio</span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a>    <span class="kw">def</span> build(<span class="va">self</span>, input_shape):</span>
<span id="cb2-15"><a href="#cb2-15" tabindex="-1"></a>        <span class="co"># Get the shape of the input.</span></span>
<span id="cb2-16"><a href="#cb2-16" tabindex="-1"></a>        (_, height, width, num_channels) <span class="op">=</span> input_shape</span>
<span id="cb2-17"><a href="#cb2-17" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" tabindex="-1"></a>        <span class="co"># Scale the height and width with respect to the strides.</span></span>
<span id="cb2-19"><a href="#cb2-19" tabindex="-1"></a>        height <span class="op">=</span> height <span class="op">//</span> <span class="va">self</span>.stride</span>
<span id="cb2-20"><a href="#cb2-20" tabindex="-1"></a>        width <span class="op">=</span> width <span class="op">//</span> <span class="va">self</span>.stride</span>
<span id="cb2-21"><a href="#cb2-21" tabindex="-1"></a></span>
<span id="cb2-22"><a href="#cb2-22" tabindex="-1"></a>        <span class="co"># Define a layer that average pools the input tensor</span></span>
<span id="cb2-23"><a href="#cb2-23" tabindex="-1"></a>        <span class="co"># if stride is more than 1.</span></span>
<span id="cb2-24"><a href="#cb2-24" tabindex="-1"></a>        <span class="va">self</span>.stride_layer <span class="op">=</span> (</span>
<span id="cb2-25"><a href="#cb2-25" tabindex="-1"></a>            keras.layers.AveragePooling2D(</span>
<span id="cb2-26"><a href="#cb2-26" tabindex="-1"></a>                pool_size<span class="op">=</span><span class="va">self</span>.stride, strides<span class="op">=</span><span class="va">self</span>.stride, padding<span class="op">=</span><span class="st">"same"</span></span>
<span id="cb2-27"><a href="#cb2-27" tabindex="-1"></a>            )</span>
<span id="cb2-28"><a href="#cb2-28" tabindex="-1"></a>            <span class="cf">if</span> <span class="va">self</span>.stride <span class="op">&gt;</span> <span class="dv">1</span></span>
<span id="cb2-29"><a href="#cb2-29" tabindex="-1"></a>            <span class="cf">else</span> tf.identity</span>
<span id="cb2-30"><a href="#cb2-30" tabindex="-1"></a>        )</span>
<span id="cb2-31"><a href="#cb2-31" tabindex="-1"></a>        <span class="co"># Define the kernel generation layer.</span></span>
<span id="cb2-32"><a href="#cb2-32" tabindex="-1"></a>        <span class="va">self</span>.kernel_gen <span class="op">=</span> keras.Sequential(</span>
<span id="cb2-33"><a href="#cb2-33" tabindex="-1"></a>            [</span>
<span id="cb2-34"><a href="#cb2-34" tabindex="-1"></a>                keras.layers.Conv2D(</span>
<span id="cb2-35"><a href="#cb2-35" tabindex="-1"></a>                    filters<span class="op">=</span><span class="va">self</span>.channel <span class="op">//</span> <span class="va">self</span>.reduction_ratio, kernel_size<span class="op">=</span><span class="dv">1</span></span>
<span id="cb2-36"><a href="#cb2-36" tabindex="-1"></a>                ),</span>
<span id="cb2-37"><a href="#cb2-37" tabindex="-1"></a>                keras.layers.BatchNormalization(),</span>
<span id="cb2-38"><a href="#cb2-38" tabindex="-1"></a>                keras.layers.ReLU(),</span>
<span id="cb2-39"><a href="#cb2-39" tabindex="-1"></a>                keras.layers.Conv2D(</span>
<span id="cb2-40"><a href="#cb2-40" tabindex="-1"></a>                    filters<span class="op">=</span><span class="va">self</span>.kernel_size</span>
<span id="cb2-41"><a href="#cb2-41" tabindex="-1"></a>                    <span class="op">*</span> <span class="va">self</span>.kernel_size</span>
<span id="cb2-42"><a href="#cb2-42" tabindex="-1"></a>                    <span class="op">*</span> <span class="va">self</span>.group_number,</span>
<span id="cb2-43"><a href="#cb2-43" tabindex="-1"></a>                    kernel_size<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb2-44"><a href="#cb2-44" tabindex="-1"></a>                ),</span>
<span id="cb2-45"><a href="#cb2-45" tabindex="-1"></a>            ]</span>
<span id="cb2-46"><a href="#cb2-46" tabindex="-1"></a>        )</span>
<span id="cb2-47"><a href="#cb2-47" tabindex="-1"></a>        <span class="co"># Define reshape layers</span></span>
<span id="cb2-48"><a href="#cb2-48" tabindex="-1"></a>        <span class="va">self</span>.kernel_reshape <span class="op">=</span> keras.layers.Reshape(</span>
<span id="cb2-49"><a href="#cb2-49" tabindex="-1"></a>            target_shape<span class="op">=</span>(</span>
<span id="cb2-50"><a href="#cb2-50" tabindex="-1"></a>                height,</span>
<span id="cb2-51"><a href="#cb2-51" tabindex="-1"></a>                width,</span>
<span id="cb2-52"><a href="#cb2-52" tabindex="-1"></a>                <span class="va">self</span>.kernel_size <span class="op">*</span> <span class="va">self</span>.kernel_size,</span>
<span id="cb2-53"><a href="#cb2-53" tabindex="-1"></a>                <span class="dv">1</span>,</span>
<span id="cb2-54"><a href="#cb2-54" tabindex="-1"></a>                <span class="va">self</span>.group_number,</span>
<span id="cb2-55"><a href="#cb2-55" tabindex="-1"></a>            )</span>
<span id="cb2-56"><a href="#cb2-56" tabindex="-1"></a>        )</span>
<span id="cb2-57"><a href="#cb2-57" tabindex="-1"></a>        <span class="va">self</span>.input_patches_reshape <span class="op">=</span> keras.layers.Reshape(</span>
<span id="cb2-58"><a href="#cb2-58" tabindex="-1"></a>            target_shape<span class="op">=</span>(</span>
<span id="cb2-59"><a href="#cb2-59" tabindex="-1"></a>                height,</span>
<span id="cb2-60"><a href="#cb2-60" tabindex="-1"></a>                width,</span>
<span id="cb2-61"><a href="#cb2-61" tabindex="-1"></a>                <span class="va">self</span>.kernel_size <span class="op">*</span> <span class="va">self</span>.kernel_size,</span>
<span id="cb2-62"><a href="#cb2-62" tabindex="-1"></a>                num_channels <span class="op">//</span> <span class="va">self</span>.group_number,</span>
<span id="cb2-63"><a href="#cb2-63" tabindex="-1"></a>                <span class="va">self</span>.group_number,</span>
<span id="cb2-64"><a href="#cb2-64" tabindex="-1"></a>            )</span>
<span id="cb2-65"><a href="#cb2-65" tabindex="-1"></a>        )</span>
<span id="cb2-66"><a href="#cb2-66" tabindex="-1"></a>        <span class="va">self</span>.output_reshape <span class="op">=</span> keras.layers.Reshape(</span>
<span id="cb2-67"><a href="#cb2-67" tabindex="-1"></a>            target_shape<span class="op">=</span>(height, width, num_channels)</span>
<span id="cb2-68"><a href="#cb2-68" tabindex="-1"></a>        )</span>
<span id="cb2-69"><a href="#cb2-69" tabindex="-1"></a></span>
<span id="cb2-70"><a href="#cb2-70" tabindex="-1"></a>    <span class="kw">def</span> call(<span class="va">self</span>, x):</span>
<span id="cb2-71"><a href="#cb2-71" tabindex="-1"></a>        <span class="co"># Generate the kernel with respect to the input tensor.</span></span>
<span id="cb2-72"><a href="#cb2-72" tabindex="-1"></a>        <span class="co"># B, H, W, K*K*G</span></span>
<span id="cb2-73"><a href="#cb2-73" tabindex="-1"></a>        kernel_input <span class="op">=</span> <span class="va">self</span>.stride_layer(x)</span>
<span id="cb2-74"><a href="#cb2-74" tabindex="-1"></a>        kernel <span class="op">=</span> <span class="va">self</span>.kernel_gen(kernel_input)</span>
<span id="cb2-75"><a href="#cb2-75" tabindex="-1"></a></span>
<span id="cb2-76"><a href="#cb2-76" tabindex="-1"></a>        <span class="co"># reshape the kerenl</span></span>
<span id="cb2-77"><a href="#cb2-77" tabindex="-1"></a>        <span class="co"># B, H, W, K*K, 1, G</span></span>
<span id="cb2-78"><a href="#cb2-78" tabindex="-1"></a>        kernel <span class="op">=</span> <span class="va">self</span>.kernel_reshape(kernel)</span>
<span id="cb2-79"><a href="#cb2-79" tabindex="-1"></a></span>
<span id="cb2-80"><a href="#cb2-80" tabindex="-1"></a>        <span class="co"># Extract input patches.</span></span>
<span id="cb2-81"><a href="#cb2-81" tabindex="-1"></a>        <span class="co"># B, H, W, K*K*C</span></span>
<span id="cb2-82"><a href="#cb2-82" tabindex="-1"></a>        input_patches <span class="op">=</span> tf.image.extract_patches(</span>
<span id="cb2-83"><a href="#cb2-83" tabindex="-1"></a>            images<span class="op">=</span>x,</span>
<span id="cb2-84"><a href="#cb2-84" tabindex="-1"></a>            sizes<span class="op">=</span>[<span class="dv">1</span>, <span class="va">self</span>.kernel_size, <span class="va">self</span>.kernel_size, <span class="dv">1</span>],</span>
<span id="cb2-85"><a href="#cb2-85" tabindex="-1"></a>            strides<span class="op">=</span>[<span class="dv">1</span>, <span class="va">self</span>.stride, <span class="va">self</span>.stride, <span class="dv">1</span>],</span>
<span id="cb2-86"><a href="#cb2-86" tabindex="-1"></a>            rates<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>],</span>
<span id="cb2-87"><a href="#cb2-87" tabindex="-1"></a>            padding<span class="op">=</span><span class="st">"SAME"</span>,</span>
<span id="cb2-88"><a href="#cb2-88" tabindex="-1"></a>        )</span>
<span id="cb2-89"><a href="#cb2-89" tabindex="-1"></a></span>
<span id="cb2-90"><a href="#cb2-90" tabindex="-1"></a>        <span class="co"># Reshape the input patches to align with later operations.</span></span>
<span id="cb2-91"><a href="#cb2-91" tabindex="-1"></a>        <span class="co"># B, H, W, K*K, C//G, G</span></span>
<span id="cb2-92"><a href="#cb2-92" tabindex="-1"></a>        input_patches <span class="op">=</span> <span class="va">self</span>.input_patches_reshape(input_patches)</span>
<span id="cb2-93"><a href="#cb2-93" tabindex="-1"></a></span>
<span id="cb2-94"><a href="#cb2-94" tabindex="-1"></a>        <span class="co"># Compute the multiply-add operation of kernels and patches.</span></span>
<span id="cb2-95"><a href="#cb2-95" tabindex="-1"></a>        <span class="co"># B, H, W, K*K, C//G, G</span></span>
<span id="cb2-96"><a href="#cb2-96" tabindex="-1"></a>        output <span class="op">=</span> tf.multiply(kernel, input_patches)</span>
<span id="cb2-97"><a href="#cb2-97" tabindex="-1"></a>        <span class="co"># B, H, W, C//G, G</span></span>
<span id="cb2-98"><a href="#cb2-98" tabindex="-1"></a>        output <span class="op">=</span> tf.reduce_sum(output, axis<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb2-99"><a href="#cb2-99" tabindex="-1"></a></span>
<span id="cb2-100"><a href="#cb2-100" tabindex="-1"></a>        <span class="co"># Reshape the output kernel.</span></span>
<span id="cb2-101"><a href="#cb2-101" tabindex="-1"></a>        <span class="co"># B, H, W, C</span></span>
<span id="cb2-102"><a href="#cb2-102" tabindex="-1"></a>        output <span class="op">=</span> <span class="va">self</span>.output_reshape(output)</span>
<span id="cb2-103"><a href="#cb2-103" tabindex="-1"></a></span>
<span id="cb2-104"><a href="#cb2-104" tabindex="-1"></a>        <span class="co"># Return the output tensor and the kernel.</span></span>
<span id="cb2-105"><a href="#cb2-105" tabindex="-1"></a>        <span class="cf">return</span> output, kernel</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="testing-the-involution-layer">Testing the Involution layer<a class="anchor" aria-label="anchor" href="#testing-the-involution-layer"></a>
</h2>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="co"># Define the input tensor.</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>input_tensor <span class="op">=</span> tf.random.normal((<span class="dv">32</span>, <span class="dv">256</span>, <span class="dv">256</span>, <span class="dv">3</span>))</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a><span class="co"># Compute involution with stride 1.</span></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>output_tensor, _ <span class="op">=</span> Involution(</span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a>    channel<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a>    group_number<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>    kernel_size<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a>    stride<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a>    reduction_ratio<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a>    name<span class="op">=</span><span class="st">"inv_1"</span>,</span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a>)(input_tensor)</span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"with stride 1 ouput shape: </span><span class="sc">{</span>output_tensor<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a><span class="co"># Compute involution with stride 2.</span></span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a>output_tensor, _ <span class="op">=</span> Involution(</span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a>    channel<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a>    group_number<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a>    kernel_size<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a>    stride<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb3-21"><a href="#cb3-21" tabindex="-1"></a>    reduction_ratio<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb3-22"><a href="#cb3-22" tabindex="-1"></a>    name<span class="op">=</span><span class="st">"inv_2"</span>,</span>
<span id="cb3-23"><a href="#cb3-23" tabindex="-1"></a>)(input_tensor)</span>
<span id="cb3-24"><a href="#cb3-24" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"with stride 2 ouput shape: </span><span class="sc">{</span>output_tensor<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-25"><a href="#cb3-25" tabindex="-1"></a></span>
<span id="cb3-26"><a href="#cb3-26" tabindex="-1"></a><span class="co"># Compute involution with stride 1, channel 16 and reduction ratio 2.</span></span>
<span id="cb3-27"><a href="#cb3-27" tabindex="-1"></a>output_tensor, _ <span class="op">=</span> Involution(</span>
<span id="cb3-28"><a href="#cb3-28" tabindex="-1"></a>    channel<span class="op">=</span><span class="dv">16</span>,</span>
<span id="cb3-29"><a href="#cb3-29" tabindex="-1"></a>    group_number<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb3-30"><a href="#cb3-30" tabindex="-1"></a>    kernel_size<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb3-31"><a href="#cb3-31" tabindex="-1"></a>    stride<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb3-32"><a href="#cb3-32" tabindex="-1"></a>    reduction_ratio<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb3-33"><a href="#cb3-33" tabindex="-1"></a>    name<span class="op">=</span><span class="st">"inv_3"</span>,</span>
<span id="cb3-34"><a href="#cb3-34" tabindex="-1"></a>)(input_tensor)</span>
<span id="cb3-35"><a href="#cb3-35" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb3-36"><a href="#cb3-36" tabindex="-1"></a>    <span class="st">"with channel 16 and reduction ratio 2 ouput shape: </span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(</span>
<span id="cb3-37"><a href="#cb3-37" tabindex="-1"></a>        output_tensor.shape</span>
<span id="cb3-38"><a href="#cb3-38" tabindex="-1"></a>    )</span>
<span id="cb3-39"><a href="#cb3-39" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="image-classification">Image Classification<a class="anchor" aria-label="anchor" href="#image-classification"></a>
</h2>
<p>In this section, we will build an image-classifier model. There will
be two models one with convolutions and the other with involutions.</p>
<p>The image-classification model is heavily inspired by this <a href="https://www.tensorflow.org/tutorials/images/cnn" class="external-link">Convolutional
Neural Network (CNN)</a> tutorial from Google.</p>
</div>
<div class="section level2">
<h2 id="get-the-cifar10-dataset">Get the CIFAR10 Dataset<a class="anchor" aria-label="anchor" href="#get-the-cifar10-dataset"></a>
</h2>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co"># Load the CIFAR10 dataset.</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"loading the CIFAR10 dataset..."</span>)</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>(</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>    (train_images, train_labels),</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a>    (</span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a>        test_images,</span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>        test_labels,</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a>    ),</span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a>) <span class="op">=</span> keras.datasets.cifar10.load_data()</span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a><span class="co"># Normalize pixel values to be between 0 and 1.</span></span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a>(train_images, test_images) <span class="op">=</span> (train_images <span class="op">/</span> <span class="fl">255.0</span>, test_images <span class="op">/</span> <span class="fl">255.0</span>)</span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a></span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a><span class="co"># Shuffle and batch the dataset.</span></span>
<span id="cb4-15"><a href="#cb4-15" tabindex="-1"></a>train_ds <span class="op">=</span> (</span>
<span id="cb4-16"><a href="#cb4-16" tabindex="-1"></a>    tf.data.Dataset.from_tensor_slices((train_images, train_labels))</span>
<span id="cb4-17"><a href="#cb4-17" tabindex="-1"></a>    .shuffle(<span class="dv">256</span>)</span>
<span id="cb4-18"><a href="#cb4-18" tabindex="-1"></a>    .batch(<span class="dv">256</span>)</span>
<span id="cb4-19"><a href="#cb4-19" tabindex="-1"></a>)</span>
<span id="cb4-20"><a href="#cb4-20" tabindex="-1"></a>test_ds <span class="op">=</span> tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(</span>
<span id="cb4-21"><a href="#cb4-21" tabindex="-1"></a>    <span class="dv">256</span></span>
<span id="cb4-22"><a href="#cb4-22" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="visualise-the-data">Visualise the data<a class="anchor" aria-label="anchor" href="#visualise-the-data"></a>
</h2>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>class_names <span class="op">=</span> [</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>    <span class="st">"airplane"</span>,</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>    <span class="st">"automobile"</span>,</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>    <span class="st">"bird"</span>,</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>    <span class="st">"cat"</span>,</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>    <span class="st">"deer"</span>,</span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a>    <span class="st">"dog"</span>,</span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a>    <span class="st">"frog"</span>,</span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a>    <span class="st">"horse"</span>,</span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a>    <span class="st">"ship"</span>,</span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a>    <span class="st">"truck"</span>,</span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a>]</span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a></span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>))</span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">25</span>):</span>
<span id="cb5-16"><a href="#cb5-16" tabindex="-1"></a>    plt.subplot(<span class="dv">5</span>, <span class="dv">5</span>, i <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb5-17"><a href="#cb5-17" tabindex="-1"></a>    plt.xticks([])</span>
<span id="cb5-18"><a href="#cb5-18" tabindex="-1"></a>    plt.yticks([])</span>
<span id="cb5-19"><a href="#cb5-19" tabindex="-1"></a>    plt.grid(<span class="va">False</span>)</span>
<span id="cb5-20"><a href="#cb5-20" tabindex="-1"></a>    plt.imshow(train_images[i])</span>
<span id="cb5-21"><a href="#cb5-21" tabindex="-1"></a>    plt.xlabel(class_names[train_labels[i][<span class="dv">0</span>]])</span>
<span id="cb5-22"><a href="#cb5-22" tabindex="-1"></a>plt.show()</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="convolutional-neural-network">Convolutional Neural Network<a class="anchor" aria-label="anchor" href="#convolutional-neural-network"></a>
</h2>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="co"># Build the conv model.</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"building the convolution model..."</span>)</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>conv_model <span class="op">=</span> keras.Sequential(</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a>    [</span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a>        keras.layers.Conv2D(</span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>            <span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), input_shape<span class="op">=</span>(<span class="dv">32</span>, <span class="dv">32</span>, <span class="dv">3</span>), padding<span class="op">=</span><span class="st">"same"</span></span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a>        ),</span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a>        keras.layers.ReLU(name<span class="op">=</span><span class="st">"relu1"</span>),</span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a>        keras.layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)),</span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a>        keras.layers.Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), padding<span class="op">=</span><span class="st">"same"</span>),</span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a>        keras.layers.ReLU(name<span class="op">=</span><span class="st">"relu2"</span>),</span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a>        keras.layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>)),</span>
<span id="cb6-13"><a href="#cb6-13" tabindex="-1"></a>        keras.layers.Conv2D(<span class="dv">64</span>, (<span class="dv">3</span>, <span class="dv">3</span>), padding<span class="op">=</span><span class="st">"same"</span>),</span>
<span id="cb6-14"><a href="#cb6-14" tabindex="-1"></a>        keras.layers.ReLU(name<span class="op">=</span><span class="st">"relu3"</span>),</span>
<span id="cb6-15"><a href="#cb6-15" tabindex="-1"></a>        keras.layers.Flatten(),</span>
<span id="cb6-16"><a href="#cb6-16" tabindex="-1"></a>        keras.layers.Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">"relu"</span>),</span>
<span id="cb6-17"><a href="#cb6-17" tabindex="-1"></a>        keras.layers.Dense(<span class="dv">10</span>),</span>
<span id="cb6-18"><a href="#cb6-18" tabindex="-1"></a>    ]</span>
<span id="cb6-19"><a href="#cb6-19" tabindex="-1"></a>)</span>
<span id="cb6-20"><a href="#cb6-20" tabindex="-1"></a></span>
<span id="cb6-21"><a href="#cb6-21" tabindex="-1"></a><span class="co"># Compile the mode with the necessary loss function and optimizer.</span></span>
<span id="cb6-22"><a href="#cb6-22" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"compiling the convolution model..."</span>)</span>
<span id="cb6-23"><a href="#cb6-23" tabindex="-1"></a>conv_model.<span class="bu">compile</span>(</span>
<span id="cb6-24"><a href="#cb6-24" tabindex="-1"></a>    optimizer<span class="op">=</span><span class="st">"adam"</span>,</span>
<span id="cb6-25"><a href="#cb6-25" tabindex="-1"></a>    loss<span class="op">=</span>keras.losses.SparseCategoricalCrossentropy(from_logits<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb6-26"><a href="#cb6-26" tabindex="-1"></a>    metrics<span class="op">=</span>[<span class="st">"accuracy"</span>],</span>
<span id="cb6-27"><a href="#cb6-27" tabindex="-1"></a>    jit_compile<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb6-28"><a href="#cb6-28" tabindex="-1"></a>)</span>
<span id="cb6-29"><a href="#cb6-29" tabindex="-1"></a></span>
<span id="cb6-30"><a href="#cb6-30" tabindex="-1"></a><span class="co"># Train the model.</span></span>
<span id="cb6-31"><a href="#cb6-31" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"conv model training..."</span>)</span>
<span id="cb6-32"><a href="#cb6-32" tabindex="-1"></a>conv_hist <span class="op">=</span> conv_model.fit(train_ds, epochs<span class="op">=</span><span class="dv">20</span>, validation_data<span class="op">=</span>test_ds)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="involutional-neural-network">Involutional Neural Network<a class="anchor" aria-label="anchor" href="#involutional-neural-network"></a>
</h2>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="co"># Build the involution model.</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"building the involution model..."</span>)</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>inputs <span class="op">=</span> keras.Input(shape<span class="op">=</span>(<span class="dv">32</span>, <span class="dv">32</span>, <span class="dv">3</span>))</span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>x, _ <span class="op">=</span> Involution(</span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a>    channel<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a>    group_number<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a>    kernel_size<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a>    stride<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a>    reduction_ratio<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a>    name<span class="op">=</span><span class="st">"inv_1"</span>,</span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a>)(inputs)</span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a>x <span class="op">=</span> keras.layers.ReLU()(x)</span>
<span id="cb7-14"><a href="#cb7-14" tabindex="-1"></a>x <span class="op">=</span> keras.layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>))(x)</span>
<span id="cb7-15"><a href="#cb7-15" tabindex="-1"></a>x, _ <span class="op">=</span> Involution(</span>
<span id="cb7-16"><a href="#cb7-16" tabindex="-1"></a>    channel<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb7-17"><a href="#cb7-17" tabindex="-1"></a>    group_number<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb7-18"><a href="#cb7-18" tabindex="-1"></a>    kernel_size<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb7-19"><a href="#cb7-19" tabindex="-1"></a>    stride<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb7-20"><a href="#cb7-20" tabindex="-1"></a>    reduction_ratio<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb7-21"><a href="#cb7-21" tabindex="-1"></a>    name<span class="op">=</span><span class="st">"inv_2"</span>,</span>
<span id="cb7-22"><a href="#cb7-22" tabindex="-1"></a>)(x)</span>
<span id="cb7-23"><a href="#cb7-23" tabindex="-1"></a>x <span class="op">=</span> keras.layers.ReLU()(x)</span>
<span id="cb7-24"><a href="#cb7-24" tabindex="-1"></a>x <span class="op">=</span> keras.layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>))(x)</span>
<span id="cb7-25"><a href="#cb7-25" tabindex="-1"></a>x, _ <span class="op">=</span> Involution(</span>
<span id="cb7-26"><a href="#cb7-26" tabindex="-1"></a>    channel<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb7-27"><a href="#cb7-27" tabindex="-1"></a>    group_number<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb7-28"><a href="#cb7-28" tabindex="-1"></a>    kernel_size<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb7-29"><a href="#cb7-29" tabindex="-1"></a>    stride<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb7-30"><a href="#cb7-30" tabindex="-1"></a>    reduction_ratio<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb7-31"><a href="#cb7-31" tabindex="-1"></a>    name<span class="op">=</span><span class="st">"inv_3"</span>,</span>
<span id="cb7-32"><a href="#cb7-32" tabindex="-1"></a>)(x)</span>
<span id="cb7-33"><a href="#cb7-33" tabindex="-1"></a>x <span class="op">=</span> keras.layers.ReLU()(x)</span>
<span id="cb7-34"><a href="#cb7-34" tabindex="-1"></a>x <span class="op">=</span> keras.layers.Flatten()(x)</span>
<span id="cb7-35"><a href="#cb7-35" tabindex="-1"></a>x <span class="op">=</span> keras.layers.Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">"relu"</span>)(x)</span>
<span id="cb7-36"><a href="#cb7-36" tabindex="-1"></a>outputs <span class="op">=</span> keras.layers.Dense(<span class="dv">10</span>)(x)</span>
<span id="cb7-37"><a href="#cb7-37" tabindex="-1"></a></span>
<span id="cb7-38"><a href="#cb7-38" tabindex="-1"></a>inv_model <span class="op">=</span> keras.Model(inputs<span class="op">=</span>[inputs], outputs<span class="op">=</span>[outputs], name<span class="op">=</span><span class="st">"inv_model"</span>)</span>
<span id="cb7-39"><a href="#cb7-39" tabindex="-1"></a></span>
<span id="cb7-40"><a href="#cb7-40" tabindex="-1"></a><span class="co"># Compile the mode with the necessary loss function and optimizer.</span></span>
<span id="cb7-41"><a href="#cb7-41" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"compiling the involution model..."</span>)</span>
<span id="cb7-42"><a href="#cb7-42" tabindex="-1"></a>inv_model.<span class="bu">compile</span>(</span>
<span id="cb7-43"><a href="#cb7-43" tabindex="-1"></a>    optimizer<span class="op">=</span><span class="st">"adam"</span>,</span>
<span id="cb7-44"><a href="#cb7-44" tabindex="-1"></a>    loss<span class="op">=</span>keras.losses.SparseCategoricalCrossentropy(from_logits<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb7-45"><a href="#cb7-45" tabindex="-1"></a>    metrics<span class="op">=</span>[<span class="st">"accuracy"</span>],</span>
<span id="cb7-46"><a href="#cb7-46" tabindex="-1"></a>    jit_compile<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb7-47"><a href="#cb7-47" tabindex="-1"></a>)</span>
<span id="cb7-48"><a href="#cb7-48" tabindex="-1"></a></span>
<span id="cb7-49"><a href="#cb7-49" tabindex="-1"></a><span class="co"># train the model</span></span>
<span id="cb7-50"><a href="#cb7-50" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"inv model training..."</span>)</span>
<span id="cb7-51"><a href="#cb7-51" tabindex="-1"></a>inv_hist <span class="op">=</span> inv_model.fit(train_ds, epochs<span class="op">=</span><span class="dv">20</span>, validation_data<span class="op">=</span>test_ds)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="comparisons">Comparisons<a class="anchor" aria-label="anchor" href="#comparisons"></a>
</h2>
<p>In this section, we will be looking at both the models and compare a
few pointers.</p>
<div class="section level3">
<h3 id="parameters">Parameters<a class="anchor" aria-label="anchor" href="#parameters"></a>
</h3>
<p>One can see that with a similar architecture the parameters in a CNN
is much larger than that of an INN (Involutional Neural Network).</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a>conv_model.summary()</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>inv_model.summary()</span></code></pre></div>
</div>
<div class="section level3">
<h3 id="loss-and-accuracy-plots">Loss and Accuracy Plots<a class="anchor" aria-label="anchor" href="#loss-and-accuracy-plots"></a>
</h3>
<p>Here, the loss and the accuracy plots demonstrate that INNs are slow
learners (with lower parameters).</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">5</span>))</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>plt.title(<span class="st">"Convolution Loss"</span>)</span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a>plt.plot(conv_hist.history[<span class="st">"loss"</span>], label<span class="op">=</span><span class="st">"loss"</span>)</span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a>plt.plot(conv_hist.history[<span class="st">"val_loss"</span>], label<span class="op">=</span><span class="st">"val_loss"</span>)</span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a>plt.legend()</span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a></span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a>plt.title(<span class="st">"Involution Loss"</span>)</span>
<span id="cb9-11"><a href="#cb9-11" tabindex="-1"></a>plt.plot(inv_hist.history[<span class="st">"loss"</span>], label<span class="op">=</span><span class="st">"loss"</span>)</span>
<span id="cb9-12"><a href="#cb9-12" tabindex="-1"></a>plt.plot(inv_hist.history[<span class="st">"val_loss"</span>], label<span class="op">=</span><span class="st">"val_loss"</span>)</span>
<span id="cb9-13"><a href="#cb9-13" tabindex="-1"></a>plt.legend()</span>
<span id="cb9-14"><a href="#cb9-14" tabindex="-1"></a></span>
<span id="cb9-15"><a href="#cb9-15" tabindex="-1"></a>plt.show()</span>
<span id="cb9-16"><a href="#cb9-16" tabindex="-1"></a></span>
<span id="cb9-17"><a href="#cb9-17" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">5</span>))</span>
<span id="cb9-18"><a href="#cb9-18" tabindex="-1"></a></span>
<span id="cb9-19"><a href="#cb9-19" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb9-20"><a href="#cb9-20" tabindex="-1"></a>plt.title(<span class="st">"Convolution Accuracy"</span>)</span>
<span id="cb9-21"><a href="#cb9-21" tabindex="-1"></a>plt.plot(conv_hist.history[<span class="st">"accuracy"</span>], label<span class="op">=</span><span class="st">"accuracy"</span>)</span>
<span id="cb9-22"><a href="#cb9-22" tabindex="-1"></a>plt.plot(conv_hist.history[<span class="st">"val_accuracy"</span>], label<span class="op">=</span><span class="st">"val_accuracy"</span>)</span>
<span id="cb9-23"><a href="#cb9-23" tabindex="-1"></a>plt.legend()</span>
<span id="cb9-24"><a href="#cb9-24" tabindex="-1"></a></span>
<span id="cb9-25"><a href="#cb9-25" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb9-26"><a href="#cb9-26" tabindex="-1"></a>plt.title(<span class="st">"Involution Accuracy"</span>)</span>
<span id="cb9-27"><a href="#cb9-27" tabindex="-1"></a>plt.plot(inv_hist.history[<span class="st">"accuracy"</span>], label<span class="op">=</span><span class="st">"accuracy"</span>)</span>
<span id="cb9-28"><a href="#cb9-28" tabindex="-1"></a>plt.plot(inv_hist.history[<span class="st">"val_accuracy"</span>], label<span class="op">=</span><span class="st">"val_accuracy"</span>)</span>
<span id="cb9-29"><a href="#cb9-29" tabindex="-1"></a>plt.legend()</span>
<span id="cb9-30"><a href="#cb9-30" tabindex="-1"></a></span>
<span id="cb9-31"><a href="#cb9-31" tabindex="-1"></a>plt.show()</span></code></pre></div>
</div>
</div>
<div class="section level2">
<h2 id="visualizing-involution-kernels">Visualizing Involution Kernels<a class="anchor" aria-label="anchor" href="#visualizing-involution-kernels"></a>
</h2>
<p>To visualize the kernels, we take the sum of <strong>K×K</strong>
values from each involution kernel. <strong>All the representatives at
different spatial locations frame the corresponding heat
map.</strong></p>
<p>The authors mention:</p>
<p>“Our proposed involution is reminiscent of self-attention and
essentially could become a generalized version of it.”</p>
<p>With the visualization of the kernel we can indeed obtain an
attention map of the image. The learned involution kernels provides
attention to individual spatial positions of the input tensor. The
<strong>location-specific</strong> property makes involution a generic
space of models in which self-attention belongs.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a>layer_names <span class="op">=</span> [<span class="st">"inv_1"</span>, <span class="st">"inv_2"</span>, <span class="st">"inv_3"</span>]</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a><span class="co"># The kernel is the second output of the layer</span></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a>outputs <span class="op">=</span> [inv_model.get_layer(name).output[<span class="dv">1</span>] <span class="cf">for</span> name <span class="kw">in</span> layer_names]</span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a>vis_model <span class="op">=</span> keras.Model(inv_model.<span class="bu">input</span>, outputs)</span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(nrows<span class="op">=</span><span class="dv">10</span>, ncols<span class="op">=</span><span class="dv">4</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">30</span>))</span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a><span class="cf">for</span> ax, test_image <span class="kw">in</span> <span class="bu">zip</span>(axes, test_images[:<span class="dv">10</span>]):</span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a>    inv_out <span class="op">=</span> vis_model.predict(test_image[<span class="va">None</span>, ...])</span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a>    inv1_kernel, inv2_kernel, inv3_kernel <span class="op">=</span> inv_out</span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a></span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a>    inv1_kernel <span class="op">=</span> tf.reduce_sum(inv1_kernel, axis<span class="op">=</span>[<span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">2</span>, <span class="op">-</span><span class="dv">3</span>])</span>
<span id="cb10-13"><a href="#cb10-13" tabindex="-1"></a>    inv2_kernel <span class="op">=</span> tf.reduce_sum(inv2_kernel, axis<span class="op">=</span>[<span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">2</span>, <span class="op">-</span><span class="dv">3</span>])</span>
<span id="cb10-14"><a href="#cb10-14" tabindex="-1"></a>    inv3_kernel <span class="op">=</span> tf.reduce_sum(inv3_kernel, axis<span class="op">=</span>[<span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">2</span>, <span class="op">-</span><span class="dv">3</span>])</span>
<span id="cb10-15"><a href="#cb10-15" tabindex="-1"></a></span>
<span id="cb10-16"><a href="#cb10-16" tabindex="-1"></a>    ax[<span class="dv">0</span>].imshow(keras.utils.array_to_img(test_image))</span>
<span id="cb10-17"><a href="#cb10-17" tabindex="-1"></a>    ax[<span class="dv">0</span>].set_title(<span class="st">"Input Image"</span>)</span>
<span id="cb10-18"><a href="#cb10-18" tabindex="-1"></a></span>
<span id="cb10-19"><a href="#cb10-19" tabindex="-1"></a>    ax[<span class="dv">1</span>].imshow(keras.utils.array_to_img(inv1_kernel[<span class="dv">0</span>, ..., <span class="va">None</span>]))</span>
<span id="cb10-20"><a href="#cb10-20" tabindex="-1"></a>    ax[<span class="dv">1</span>].set_title(<span class="st">"Involution Kernel 1"</span>)</span>
<span id="cb10-21"><a href="#cb10-21" tabindex="-1"></a></span>
<span id="cb10-22"><a href="#cb10-22" tabindex="-1"></a>    ax[<span class="dv">2</span>].imshow(keras.utils.array_to_img(inv2_kernel[<span class="dv">0</span>, ..., <span class="va">None</span>]))</span>
<span id="cb10-23"><a href="#cb10-23" tabindex="-1"></a>    ax[<span class="dv">2</span>].set_title(<span class="st">"Involution Kernel 2"</span>)</span>
<span id="cb10-24"><a href="#cb10-24" tabindex="-1"></a></span>
<span id="cb10-25"><a href="#cb10-25" tabindex="-1"></a>    ax[<span class="dv">3</span>].imshow(keras.utils.array_to_img(inv3_kernel[<span class="dv">0</span>, ..., <span class="va">None</span>]))</span>
<span id="cb10-26"><a href="#cb10-26" tabindex="-1"></a>    ax[<span class="dv">3</span>].set_title(<span class="st">"Involution Kernel 3"</span>)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="conclusions">Conclusions<a class="anchor" aria-label="anchor" href="#conclusions"></a>
</h2>
<p>In this example, the main focus was to build an
<code>Involution</code> layer which can be easily reused. While our
comparisons were based on a specific task, feel free to use the layer
for different tasks and report your results.</p>
<p>According to me, the key take-away of involution is its relationship
with self-attention. The intuition behind location-specific and
channel-spefic processing makes sense in a lot of tasks.</p>
<p>Moving forward one can:</p>
<ul>
<li>Look at <a href="https://youtu.be/pH2jZun8MoY" class="external-link">Yannick’s video</a>
on involution for a better understanding.</li>
<li>Experiment with the various hyperparameters of the involution
layer.</li>
<li>Build different models with the involution layer.</li>
<li>Try building a different kernel generation method altogether.</li>
</ul>
<p>You can use the trained model hosted on <a href="https://huggingface.co/keras-io/involution" class="external-link">Hugging Face Hub</a>
and try the demo on <a href="https://huggingface.co/spaces/keras-io/involution" class="external-link">Hugging Face
Spaces</a>.</p>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Tomasz Kalinowski, JJ Allaire, François Chollet, RStudio, Google.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
