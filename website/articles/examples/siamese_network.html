<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="Training a Siamese Network to compare the similarity of images using a triplet loss function.">
<title>Image similarity estimation using a Siamese Network with a triplet loss â€¢ keras3</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../../apple-touch-icon-60x60.png">
<script src="../../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../../deps/Fira_Mono-0.4.7/font.css" rel="stylesheet">
<!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../../pkgdown.js"></script><meta property="og:title" content="Image similarity estimation using a Siamese Network with a triplet loss">
<meta property="og:description" content="Training a Siamese Network to compare the similarity of images using a triplet loss function.">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-inverse navbar-expand-lg bg-primary"><div class="container">
    
    <a class="navbar-brand me-2" href="../../index.html">keras3</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">2.13.0.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../../index.html">Home</a>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-getting-started">Getting Started</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-getting-started">
    <a class="dropdown-item" href="../../articles/intro_to_keras_for_engineers.html">Introduction to Keras for engineers</a>
    <h6 class="dropdown-header" data-toc-skip>Tutorials</h6>
    <a class="dropdown-item" href="../../articles/getting_started.html">Getting Started</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_classification.html">Basic Classification</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_text_classification.html">Text Classification</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_regression.html">Basic Regression</a>
    <a class="dropdown-item" href="../../articles/tutorial_overfit_underfit.html">Overfitting and Underfitting</a>
    <a class="dropdown-item" href="../../articles/tutorial_save_and_restore.html">Save and Restore Models</a>
  </div>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-guides">Guides</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-guides">
    <h6 class="dropdown-header" data-toc-skip>Model definition</h6>
    <a class="dropdown-item" href="../../articles/functional_api.html">Functional API</a>
    <a class="dropdown-item" href="../../articles/sequential_model.html">Sequential Model</a>
    <h6 class="dropdown-header" data-toc-skip>Extending and customizing</h6>
    <a class="dropdown-item" href="../../articles/making_new_layers_and_models_via_subclassing.html">Making new layers and models via subclassing</a>
    <a class="dropdown-item" href="../../articles/training_with_built_in_methods.html">Training &amp; evaluation with the built-in methods</a>
    <a class="dropdown-item" href="../../articles/writing_a_custom_training_loop_in_tensorflow.html">Writing a training loop from scratch in TensorFlow</a>
    <a class="dropdown-item" href="../../articles/writing_your_own_callbacks.html">Writing Your Own Callbacks</a>
    <h6 class="dropdown-header" data-toc-skip>Other topics</h6>
    <a class="dropdown-item" href="../../articles/transfer_learning.html">Transfer learning and fine tuning</a>
    <a class="dropdown-item" href="../../articles/distributed_training_with_tensorflow.html">Distributed training with TensorFlow</a>
  </div>
</li>
<li class="active nav-item">
  <a class="nav-link" href="../../articles/examples/index.html">Examples</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../reference/index.html">Reference</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../news/index.html">News</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/rstudio/keras/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Image similarity estimation using a Siamese Network with a triplet loss</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/rstudio/keras/blob/HEAD/vignettes/examples/siamese_network.Rmd" class="external-link"><code>vignettes/examples/siamese_network.Rmd</code></a></small>
      <div class="d-none name"><code>siamese_network.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>A <a href="https://en.wikipedia.org/wiki/Siamese_neural_network" class="external-link">Siamese
Network</a> is a type of network architecture that contains two or more
identical subnetworks used to generate feature vectors for each input
and compare them.</p>
<p>Siamese Networks can be applied to different use cases, like
detecting duplicates, finding anomalies, and face recognition.</p>
<p>This example uses a Siamese Network with three identical subnetworks.
We will provide three images to the model, where two of them will be
similar (<em>anchor</em> and <em>positive</em> samples), and the third
will be unrelated (a <em>negative</em> example.) Our goal is for the
model to learn to estimate the similarity between images.</p>
<p>For the network to learn, we use a triplet loss function. You can
find an introduction to triplet loss in the <a href="https://arxiv.org/pdf/1503.03832.pdf" class="external-link">FaceNet paper</a> by Schroff
et al,. 2015. In this example, we define the triplet loss function as
follows:</p>
<p><code>L(A, P, N) = max(â€–f(A) - f(P)â€–Â² - â€–f(A) - f(N)â€–Â² + margin, 0)</code></p>
<p>This example uses the <a href="https://sites.google.com/view/totally-looks-like-dataset" class="external-link">Totally
Looks Like dataset</a> by <a href="https://arxiv.org/pdf/1803.01485v3.pdf" class="external-link">Rosenfeld et al.,
2018</a>.</p>
</div>
<div class="section level2">
<h2 id="setup">Setup<a class="anchor" aria-label="anchor" href="#setup"></a>
</h2>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="im">from</span> keras <span class="im">import</span> layers</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="im">from</span> keras <span class="im">import</span> optimizers</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="im">from</span> keras <span class="im">import</span> metrics</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="im">from</span> keras <span class="im">import</span> Model</span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a><span class="im">from</span> keras.applications <span class="im">import</span> resnet</span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a>target_shape <span class="op">=</span> (<span class="dv">200</span>, <span class="dv">200</span>)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="load-the-dataset">Load the dataset<a class="anchor" aria-label="anchor" href="#load-the-dataset"></a>
</h2>
<p>We are going to load the <em>Totally Looks Like</em> dataset and
unzip it inside the <code>~/.keras</code> directory in the local
environment.</p>
<p>The dataset consists of two separate files:</p>
<ul>
<li>
<code>left.zip</code> contains the images that we will use as the
anchor.</li>
<li>
<code>right.zip</code> contains the images that we will use as the
positive sample (an image that looks like the anchor).</li>
</ul>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>cache_dir <span class="op">=</span> Path(Path.home()) <span class="op">/</span> <span class="st">".keras"</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>anchor_images_path <span class="op">=</span> cache_dir <span class="op">/</span> <span class="st">"left"</span></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>positive_images_path <span class="op">=</span> cache_dir <span class="op">/</span> <span class="st">"right"</span></span></code></pre></div>
<p>gdown â€“id 1jvkbTr_giSP3Ru8OwGNCg6B4PvVbcO34 gdown â€“id
1EzBZUb_mh_Dp_FKD0P4XiYYSd0QBH5zW unzip -oq left.zip -d $cache_dir unzip
-oq right.zip -d $cache_dir</p>
</div>
<div class="section level2">
<h2 id="preparing-the-data">Preparing the data<a class="anchor" aria-label="anchor" href="#preparing-the-data"></a>
</h2>
<p>We are going to use a <code>tf.data</code> pipeline to load the data
and generate the triplets that we need to train the Siamese network.</p>
<p>Weâ€™ll set up the pipeline using a zipped list with anchor, positive,
and negative filenames as the source. The pipeline will load and
preprocess the corresponding images.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="kw">def</span> preprocess_image(filename):</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a><span class="co">    Load the specified file as a JPEG image, preprocess it and</span></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a><span class="co">    resize it to the target shape.</span></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a>    image_string <span class="op">=</span> tf.io.read_file(filename)</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>    image <span class="op">=</span> tf.image.decode_jpeg(image_string, channels<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a>    image <span class="op">=</span> tf.image.convert_image_dtype(image, tf.float32)</span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a>    image <span class="op">=</span> tf.image.resize(image, target_shape)</span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a>    <span class="cf">return</span> image</span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a><span class="kw">def</span> preprocess_triplets(anchor, positive, negative):</span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a><span class="co">    Given the filenames corresponding to the three images, load and</span></span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a><span class="co">    preprocess them.</span></span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a></span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a>    <span class="cf">return</span> (</span>
<span id="cb3-21"><a href="#cb3-21" tabindex="-1"></a>        preprocess_image(anchor),</span>
<span id="cb3-22"><a href="#cb3-22" tabindex="-1"></a>        preprocess_image(positive),</span>
<span id="cb3-23"><a href="#cb3-23" tabindex="-1"></a>        preprocess_image(negative),</span>
<span id="cb3-24"><a href="#cb3-24" tabindex="-1"></a>    )</span></code></pre></div>
<p>Letâ€™s setup our data pipeline using a zipped list with an anchor,
positive, and negative image filename as the source. The output of the
pipeline contains the same triplet with every image loaded and
preprocessed.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co"># We need to make sure both the anchor and positive images are loaded in</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="co"># sorted order so we can match them together.</span></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>anchor_images <span class="op">=</span> <span class="bu">sorted</span>(</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>    [<span class="bu">str</span>(anchor_images_path <span class="op">/</span> f) <span class="cf">for</span> f <span class="kw">in</span> os.listdir(anchor_images_path)]</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a>)</span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>positive_images <span class="op">=</span> <span class="bu">sorted</span>(</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a>    [<span class="bu">str</span>(positive_images_path <span class="op">/</span> f) <span class="cf">for</span> f <span class="kw">in</span> os.listdir(positive_images_path)]</span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a>)</span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a>image_count <span class="op">=</span> <span class="bu">len</span>(anchor_images)</span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a>anchor_dataset <span class="op">=</span> tf.data.Dataset.from_tensor_slices(anchor_images)</span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a>positive_dataset <span class="op">=</span> tf.data.Dataset.from_tensor_slices(positive_images)</span>
<span id="cb4-15"><a href="#cb4-15" tabindex="-1"></a></span>
<span id="cb4-16"><a href="#cb4-16" tabindex="-1"></a><span class="co"># To generate the list of negative images, let's randomize the list of</span></span>
<span id="cb4-17"><a href="#cb4-17" tabindex="-1"></a><span class="co"># available images and concatenate them together.</span></span>
<span id="cb4-18"><a href="#cb4-18" tabindex="-1"></a>rng <span class="op">=</span> np.random.RandomState(seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb4-19"><a href="#cb4-19" tabindex="-1"></a>rng.shuffle(anchor_images)</span>
<span id="cb4-20"><a href="#cb4-20" tabindex="-1"></a>rng.shuffle(positive_images)</span>
<span id="cb4-21"><a href="#cb4-21" tabindex="-1"></a></span>
<span id="cb4-22"><a href="#cb4-22" tabindex="-1"></a>negative_images <span class="op">=</span> anchor_images <span class="op">+</span> positive_images</span>
<span id="cb4-23"><a href="#cb4-23" tabindex="-1"></a>np.random.RandomState(seed<span class="op">=</span><span class="dv">32</span>).shuffle(negative_images)</span>
<span id="cb4-24"><a href="#cb4-24" tabindex="-1"></a></span>
<span id="cb4-25"><a href="#cb4-25" tabindex="-1"></a>negative_dataset <span class="op">=</span> tf.data.Dataset.from_tensor_slices(negative_images)</span>
<span id="cb4-26"><a href="#cb4-26" tabindex="-1"></a>negative_dataset <span class="op">=</span> negative_dataset.shuffle(buffer_size<span class="op">=</span><span class="dv">4096</span>)</span>
<span id="cb4-27"><a href="#cb4-27" tabindex="-1"></a></span>
<span id="cb4-28"><a href="#cb4-28" tabindex="-1"></a>dataset <span class="op">=</span> tf.data.Dataset.<span class="bu">zip</span>(</span>
<span id="cb4-29"><a href="#cb4-29" tabindex="-1"></a>    (anchor_dataset, positive_dataset, negative_dataset)</span>
<span id="cb4-30"><a href="#cb4-30" tabindex="-1"></a>)</span>
<span id="cb4-31"><a href="#cb4-31" tabindex="-1"></a>dataset <span class="op">=</span> dataset.shuffle(buffer_size<span class="op">=</span><span class="dv">1024</span>)</span>
<span id="cb4-32"><a href="#cb4-32" tabindex="-1"></a>dataset <span class="op">=</span> dataset.<span class="bu">map</span>(preprocess_triplets)</span>
<span id="cb4-33"><a href="#cb4-33" tabindex="-1"></a></span>
<span id="cb4-34"><a href="#cb4-34" tabindex="-1"></a><span class="co"># Let's now split our dataset in train and validation.</span></span>
<span id="cb4-35"><a href="#cb4-35" tabindex="-1"></a>train_dataset <span class="op">=</span> dataset.take(<span class="bu">round</span>(image_count <span class="op">*</span> <span class="fl">0.8</span>))</span>
<span id="cb4-36"><a href="#cb4-36" tabindex="-1"></a>val_dataset <span class="op">=</span> dataset.skip(<span class="bu">round</span>(image_count <span class="op">*</span> <span class="fl">0.8</span>))</span>
<span id="cb4-37"><a href="#cb4-37" tabindex="-1"></a></span>
<span id="cb4-38"><a href="#cb4-38" tabindex="-1"></a>train_dataset <span class="op">=</span> train_dataset.batch(<span class="dv">32</span>, drop_remainder<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb4-39"><a href="#cb4-39" tabindex="-1"></a>train_dataset <span class="op">=</span> train_dataset.prefetch(tf.data.AUTOTUNE)</span>
<span id="cb4-40"><a href="#cb4-40" tabindex="-1"></a></span>
<span id="cb4-41"><a href="#cb4-41" tabindex="-1"></a>val_dataset <span class="op">=</span> val_dataset.batch(<span class="dv">32</span>, drop_remainder<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb4-42"><a href="#cb4-42" tabindex="-1"></a>val_dataset <span class="op">=</span> val_dataset.prefetch(tf.data.AUTOTUNE)</span></code></pre></div>
<p>Letâ€™s take a look at a few examples of triplets. Notice how the first
two images look alike while the third one is always different.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="kw">def</span> visualize(anchor, positive, negative):</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>    <span class="co">"""Visualize a few triplets from the supplied batches."""</span></span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>    <span class="kw">def</span> show(ax, image):</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>        ax.imshow(image)</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>        ax.get_xaxis().set_visible(<span class="va">False</span>)</span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a>        ax.get_yaxis().set_visible(<span class="va">False</span>)</span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a>    fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">9</span>, <span class="dv">9</span>))</span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a>    axs <span class="op">=</span> fig.subplots(<span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a>        show(axs[i, <span class="dv">0</span>], anchor[i])</span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a>        show(axs[i, <span class="dv">1</span>], positive[i])</span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a>        show(axs[i, <span class="dv">2</span>], negative[i])</span>
<span id="cb5-16"><a href="#cb5-16" tabindex="-1"></a></span>
<span id="cb5-17"><a href="#cb5-17" tabindex="-1"></a></span>
<span id="cb5-18"><a href="#cb5-18" tabindex="-1"></a>visualize(<span class="op">*</span><span class="bu">list</span>(train_dataset.take(<span class="dv">1</span>).as_numpy_iterator())[<span class="dv">0</span>])</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="setting-up-the-embedding-generator-model">Setting up the embedding generator model<a class="anchor" aria-label="anchor" href="#setting-up-the-embedding-generator-model"></a>
</h2>
<p>Our Siamese Network will generate embeddings for each of the images
of the triplet. To do this, we will use a ResNet50 model pretrained on
ImageNet and connect a few <code>Dense</code> layers to it so we can
learn to separate these embeddings.</p>
<p>We will freeze the weights of all the layers of the model up until
the layer <code>conv5_block1_out</code>. This is important to avoid
affecting the weights that the model has already learned. We are going
to leave the bottom few layers trainable, so that we can fine-tune their
weights during training.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>base_cnn <span class="op">=</span> resnet.ResNet50(</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>    weights<span class="op">=</span><span class="st">"imagenet"</span>, input_shape<span class="op">=</span>target_shape <span class="op">+</span> (<span class="dv">3</span>,), include_top<span class="op">=</span><span class="va">False</span></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>)</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a>flatten <span class="op">=</span> layers.Flatten()(base_cnn.output)</span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>dense1 <span class="op">=</span> layers.Dense(<span class="dv">512</span>, activation<span class="op">=</span><span class="st">"relu"</span>)(flatten)</span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a>dense1 <span class="op">=</span> layers.BatchNormalization()(dense1)</span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a>dense2 <span class="op">=</span> layers.Dense(<span class="dv">256</span>, activation<span class="op">=</span><span class="st">"relu"</span>)(dense1)</span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a>dense2 <span class="op">=</span> layers.BatchNormalization()(dense2)</span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a>output <span class="op">=</span> layers.Dense(<span class="dv">256</span>)(dense2)</span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a>embedding <span class="op">=</span> Model(base_cnn.<span class="bu">input</span>, output, name<span class="op">=</span><span class="st">"Embedding"</span>)</span>
<span id="cb6-13"><a href="#cb6-13" tabindex="-1"></a></span>
<span id="cb6-14"><a href="#cb6-14" tabindex="-1"></a>trainable <span class="op">=</span> <span class="va">False</span></span>
<span id="cb6-15"><a href="#cb6-15" tabindex="-1"></a><span class="cf">for</span> layer <span class="kw">in</span> base_cnn.layers:</span>
<span id="cb6-16"><a href="#cb6-16" tabindex="-1"></a>    <span class="cf">if</span> layer.name <span class="op">==</span> <span class="st">"conv5_block1_out"</span>:</span>
<span id="cb6-17"><a href="#cb6-17" tabindex="-1"></a>        trainable <span class="op">=</span> <span class="va">True</span></span>
<span id="cb6-18"><a href="#cb6-18" tabindex="-1"></a>    layer.trainable <span class="op">=</span> trainable</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="setting-up-the-siamese-network-model">Setting up the Siamese Network model<a class="anchor" aria-label="anchor" href="#setting-up-the-siamese-network-model"></a>
</h2>
<p>The Siamese network will receive each of the triplet images as an
input, generate the embeddings, and output the distance between the
anchor and the positive embedding, as well as the distance between the
anchor and the negative embedding.</p>
<p>To compute the distance, we can use a custom layer
<code>DistanceLayer</code> that returns both values as a tuple.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="kw">class</span> DistanceLayer(layers.Layer):</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a><span class="co">    This layer is responsible for computing the distance between the anchor</span></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a><span class="co">    embedding and the positive embedding, and the anchor embedding and the</span></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a><span class="co">    negative embedding.</span></span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, <span class="op">**</span>kwargs):</span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(<span class="op">**</span>kwargs)</span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a>    <span class="kw">def</span> call(<span class="va">self</span>, anchor, positive, negative):</span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a>        ap_distance <span class="op">=</span> tf.reduce_sum(tf.square(anchor <span class="op">-</span> positive), <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a>        an_distance <span class="op">=</span> tf.reduce_sum(tf.square(anchor <span class="op">-</span> negative), <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb7-14"><a href="#cb7-14" tabindex="-1"></a>        <span class="cf">return</span> (ap_distance, an_distance)</span>
<span id="cb7-15"><a href="#cb7-15" tabindex="-1"></a></span>
<span id="cb7-16"><a href="#cb7-16" tabindex="-1"></a></span>
<span id="cb7-17"><a href="#cb7-17" tabindex="-1"></a>anchor_input <span class="op">=</span> layers.Input(name<span class="op">=</span><span class="st">"anchor"</span>, shape<span class="op">=</span>target_shape <span class="op">+</span> (<span class="dv">3</span>,))</span>
<span id="cb7-18"><a href="#cb7-18" tabindex="-1"></a>positive_input <span class="op">=</span> layers.Input(name<span class="op">=</span><span class="st">"positive"</span>, shape<span class="op">=</span>target_shape <span class="op">+</span> (<span class="dv">3</span>,))</span>
<span id="cb7-19"><a href="#cb7-19" tabindex="-1"></a>negative_input <span class="op">=</span> layers.Input(name<span class="op">=</span><span class="st">"negative"</span>, shape<span class="op">=</span>target_shape <span class="op">+</span> (<span class="dv">3</span>,))</span>
<span id="cb7-20"><a href="#cb7-20" tabindex="-1"></a></span>
<span id="cb7-21"><a href="#cb7-21" tabindex="-1"></a>distances <span class="op">=</span> DistanceLayer()(</span>
<span id="cb7-22"><a href="#cb7-22" tabindex="-1"></a>    embedding(resnet.preprocess_input(anchor_input)),</span>
<span id="cb7-23"><a href="#cb7-23" tabindex="-1"></a>    embedding(resnet.preprocess_input(positive_input)),</span>
<span id="cb7-24"><a href="#cb7-24" tabindex="-1"></a>    embedding(resnet.preprocess_input(negative_input)),</span>
<span id="cb7-25"><a href="#cb7-25" tabindex="-1"></a>)</span>
<span id="cb7-26"><a href="#cb7-26" tabindex="-1"></a></span>
<span id="cb7-27"><a href="#cb7-27" tabindex="-1"></a>siamese_network <span class="op">=</span> Model(</span>
<span id="cb7-28"><a href="#cb7-28" tabindex="-1"></a>    inputs<span class="op">=</span>[anchor_input, positive_input, negative_input], outputs<span class="op">=</span>distances</span>
<span id="cb7-29"><a href="#cb7-29" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="putting-everything-together">Putting everything together<a class="anchor" aria-label="anchor" href="#putting-everything-together"></a>
</h2>
<p>We now need to implement a model with custom training loop so we can
compute the triplet loss using the three embeddings produced by the
Siamese network.</p>
<p>Letâ€™s create a <code>Mean</code> metric instance to track the loss of
the training process.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="kw">class</span> SiameseModel(Model):</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>    <span class="co">"""The Siamese Network model with a custom training and testing loops.</span></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a><span class="co">    Computes the triplet loss using the three embeddings produced by the</span></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a><span class="co">    Siamese Network.</span></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a><span class="co">    The triplet loss is defined as:</span></span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a><span class="co">       L(A, P, N) = max(â€–f(A) - f(P)â€–Â² - â€–f(A) - f(N)â€–Â² + margin, 0)</span></span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a></span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, siamese_network, margin<span class="op">=</span><span class="fl">0.5</span>):</span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a>        <span class="va">self</span>.siamese_network <span class="op">=</span> siamese_network</span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a>        <span class="va">self</span>.margin <span class="op">=</span> margin</span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a>        <span class="va">self</span>.loss_tracker <span class="op">=</span> metrics.Mean(name<span class="op">=</span><span class="st">"loss"</span>)</span>
<span id="cb8-16"><a href="#cb8-16" tabindex="-1"></a></span>
<span id="cb8-17"><a href="#cb8-17" tabindex="-1"></a>    <span class="kw">def</span> call(<span class="va">self</span>, inputs):</span>
<span id="cb8-18"><a href="#cb8-18" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.siamese_network(inputs)</span>
<span id="cb8-19"><a href="#cb8-19" tabindex="-1"></a></span>
<span id="cb8-20"><a href="#cb8-20" tabindex="-1"></a>    <span class="kw">def</span> train_step(<span class="va">self</span>, data):</span>
<span id="cb8-21"><a href="#cb8-21" tabindex="-1"></a>        <span class="co"># GradientTape is a context manager that records every operation that</span></span>
<span id="cb8-22"><a href="#cb8-22" tabindex="-1"></a>        <span class="co"># you do inside. We are using it here to compute the loss so we can get</span></span>
<span id="cb8-23"><a href="#cb8-23" tabindex="-1"></a>        <span class="co"># the gradients and apply them using the optimizer specified in</span></span>
<span id="cb8-24"><a href="#cb8-24" tabindex="-1"></a>        <span class="co"># `compile()`.</span></span>
<span id="cb8-25"><a href="#cb8-25" tabindex="-1"></a>        <span class="cf">with</span> tf.GradientTape() <span class="im">as</span> tape:</span>
<span id="cb8-26"><a href="#cb8-26" tabindex="-1"></a>            loss <span class="op">=</span> <span class="va">self</span>._compute_loss(data)</span>
<span id="cb8-27"><a href="#cb8-27" tabindex="-1"></a></span>
<span id="cb8-28"><a href="#cb8-28" tabindex="-1"></a>        <span class="co"># Storing the gradients of the loss function with respect to the</span></span>
<span id="cb8-29"><a href="#cb8-29" tabindex="-1"></a>        <span class="co"># weights/parameters.</span></span>
<span id="cb8-30"><a href="#cb8-30" tabindex="-1"></a>        gradients <span class="op">=</span> tape.gradient(loss, <span class="va">self</span>.siamese_network.trainable_weights)</span>
<span id="cb8-31"><a href="#cb8-31" tabindex="-1"></a></span>
<span id="cb8-32"><a href="#cb8-32" tabindex="-1"></a>        <span class="co"># Applying the gradients on the model using the specified optimizer</span></span>
<span id="cb8-33"><a href="#cb8-33" tabindex="-1"></a>        <span class="va">self</span>.optimizer.apply_gradients(</span>
<span id="cb8-34"><a href="#cb8-34" tabindex="-1"></a>            <span class="bu">zip</span>(gradients, <span class="va">self</span>.siamese_network.trainable_weights)</span>
<span id="cb8-35"><a href="#cb8-35" tabindex="-1"></a>        )</span>
<span id="cb8-36"><a href="#cb8-36" tabindex="-1"></a></span>
<span id="cb8-37"><a href="#cb8-37" tabindex="-1"></a>        <span class="co"># Let's update and return the training loss metric.</span></span>
<span id="cb8-38"><a href="#cb8-38" tabindex="-1"></a>        <span class="va">self</span>.loss_tracker.update_state(loss)</span>
<span id="cb8-39"><a href="#cb8-39" tabindex="-1"></a>        <span class="cf">return</span> {<span class="st">"loss"</span>: <span class="va">self</span>.loss_tracker.result()}</span>
<span id="cb8-40"><a href="#cb8-40" tabindex="-1"></a></span>
<span id="cb8-41"><a href="#cb8-41" tabindex="-1"></a>    <span class="kw">def</span> test_step(<span class="va">self</span>, data):</span>
<span id="cb8-42"><a href="#cb8-42" tabindex="-1"></a>        loss <span class="op">=</span> <span class="va">self</span>._compute_loss(data)</span>
<span id="cb8-43"><a href="#cb8-43" tabindex="-1"></a></span>
<span id="cb8-44"><a href="#cb8-44" tabindex="-1"></a>        <span class="co"># Let's update and return the loss metric.</span></span>
<span id="cb8-45"><a href="#cb8-45" tabindex="-1"></a>        <span class="va">self</span>.loss_tracker.update_state(loss)</span>
<span id="cb8-46"><a href="#cb8-46" tabindex="-1"></a>        <span class="cf">return</span> {<span class="st">"loss"</span>: <span class="va">self</span>.loss_tracker.result()}</span>
<span id="cb8-47"><a href="#cb8-47" tabindex="-1"></a></span>
<span id="cb8-48"><a href="#cb8-48" tabindex="-1"></a>    <span class="kw">def</span> _compute_loss(<span class="va">self</span>, data):</span>
<span id="cb8-49"><a href="#cb8-49" tabindex="-1"></a>        <span class="co"># The output of the network is a tuple containing the distances</span></span>
<span id="cb8-50"><a href="#cb8-50" tabindex="-1"></a>        <span class="co"># between the anchor and the positive example, and the anchor and</span></span>
<span id="cb8-51"><a href="#cb8-51" tabindex="-1"></a>        <span class="co"># the negative example.</span></span>
<span id="cb8-52"><a href="#cb8-52" tabindex="-1"></a>        ap_distance, an_distance <span class="op">=</span> <span class="va">self</span>.siamese_network(data)</span>
<span id="cb8-53"><a href="#cb8-53" tabindex="-1"></a></span>
<span id="cb8-54"><a href="#cb8-54" tabindex="-1"></a>        <span class="co"># Computing the Triplet Loss by subtracting both distances and</span></span>
<span id="cb8-55"><a href="#cb8-55" tabindex="-1"></a>        <span class="co"># making sure we don't get a negative value.</span></span>
<span id="cb8-56"><a href="#cb8-56" tabindex="-1"></a>        loss <span class="op">=</span> ap_distance <span class="op">-</span> an_distance</span>
<span id="cb8-57"><a href="#cb8-57" tabindex="-1"></a>        loss <span class="op">=</span> tf.maximum(loss <span class="op">+</span> <span class="va">self</span>.margin, <span class="fl">0.0</span>)</span>
<span id="cb8-58"><a href="#cb8-58" tabindex="-1"></a>        <span class="cf">return</span> loss</span>
<span id="cb8-59"><a href="#cb8-59" tabindex="-1"></a></span>
<span id="cb8-60"><a href="#cb8-60" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb8-61"><a href="#cb8-61" tabindex="-1"></a>    <span class="kw">def</span> metrics(<span class="va">self</span>):</span>
<span id="cb8-62"><a href="#cb8-62" tabindex="-1"></a>        <span class="co"># We need to list our metrics here so the `reset_states()` can be</span></span>
<span id="cb8-63"><a href="#cb8-63" tabindex="-1"></a>        <span class="co"># called automatically.</span></span>
<span id="cb8-64"><a href="#cb8-64" tabindex="-1"></a>        <span class="cf">return</span> [<span class="va">self</span>.loss_tracker]</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="training">Training<a class="anchor" aria-label="anchor" href="#training"></a>
</h2>
<p>We are now ready to train our model.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>siamese_model <span class="op">=</span> SiameseModel(siamese_network)</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>siamese_model.<span class="bu">compile</span>(optimizer<span class="op">=</span>optimizers.Adam(<span class="fl">0.0001</span>))</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a>siamese_model.fit(train_dataset, epochs<span class="op">=</span><span class="dv">10</span>, validation_data<span class="op">=</span>val_dataset)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="inspecting-what-the-network-has-learned">Inspecting what the network has learned<a class="anchor" aria-label="anchor" href="#inspecting-what-the-network-has-learned"></a>
</h2>
<p>At this point, we can check how the network learned to separate the
embeddings depending on whether they belong to similar images.</p>
<p>We can use <a href="https://en.wikipedia.org/wiki/Cosine_similarity" class="external-link">cosine
similarity</a> to measure the similarity between embeddings.</p>
<p>Letâ€™s pick a sample from the dataset to check the similarity between
the embeddings generated for each image.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a>sample <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(train_dataset))</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>visualize(<span class="op">*</span>sample)</span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a>anchor, positive, negative <span class="op">=</span> sample</span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a>anchor_embedding, positive_embedding, negative_embedding <span class="op">=</span> (</span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a>    embedding(resnet.preprocess_input(anchor)),</span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a>    embedding(resnet.preprocess_input(positive)),</span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a>    embedding(resnet.preprocess_input(negative)),</span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a>)</span></code></pre></div>
<p>Finally, we can compute the cosine similarity between the anchor and
positive images and compare it with the similarity between the anchor
and the negative images.</p>
<p>We should expect the similarity between the anchor and positive
images to be larger than the similarity between the anchor and the
negative images.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>cosine_similarity <span class="op">=</span> metrics.CosineSimilarity()</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>positive_similarity <span class="op">=</span> cosine_similarity(anchor_embedding, positive_embedding)</span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Positive similarity:"</span>, positive_similarity.numpy())</span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a></span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a>negative_similarity <span class="op">=</span> cosine_similarity(anchor_embedding, negative_embedding)</span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Negative similarity"</span>, negative_similarity.numpy())</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="summary">Summary<a class="anchor" aria-label="anchor" href="#summary"></a>
</h2>
<ol style="list-style-type: decimal">
<li><p>The <code>tf.data</code> API enables you to build efficient input
pipelines for your model. It is particularly useful if you have a large
dataset. You can learn more about <code>tf.data</code> pipelines in <a href="https://www.tensorflow.org/guide/data" class="external-link">tf.data: Build TensorFlow
input pipelines</a>.</p></li>
<li><p>In this example, we use a pre-trained ResNet50 as part of the
subnetwork that generates the feature embeddings. By using <a href="https://www.tensorflow.org/guide/keras/transfer_learning?hl=en" class="external-link">transfer
learning</a>, we can significantly reduce the training time and size of
the dataset.</p></li>
<li><p>Notice how we are <a href="https://www.tensorflow.org/guide/keras/transfer_learning?hl=en#fine-tuning" class="external-link">fine-tuning</a>
the weights of the final layers of the ResNet50 network but keeping the
rest of the layers untouched. Using the name assigned to each layer, we
can freeze the weights to a certain point and keep the last few layers
open.</p></li>
<li><p>We can create custom layers by creating a class that inherits
from <code>tf.keras.layers.Layer</code>, as we did in the
<code>DistanceLayer</code> class.</p></li>
<li><p>We used a cosine similarity metric to measure how to 2 output
embeddings are similar to each other.</p></li>
<li><p>You can implement a custom training loop by overriding the
<code>train_step()</code> method. <code>train_step()</code> uses <a href="https://www.tensorflow.org/api_docs/python/tf/GradientTape" class="external-link"><code>tf.GradientTape</code></a>,
which records every operation that you perform inside it. In this
example, we use it to access the gradients passed to the optimizer to
update the model weights at every step. For more details, check out the
<a href="https://keras.io/getting_started/intro_to_keras_for_researchers/" class="external-link">Intro
to Keras for researchers</a> and <a href="https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch?hl=en" class="external-link">Writing
a training loop from scratch</a>.</p></li>
</ol>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Tomasz Kalinowski, JJ Allaire, FranÃ§ois Chollet, Posit Software, PBC, Google.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
