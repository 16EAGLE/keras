<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="This example demonstrates how to do timeseries forecasting over graphs.">
<title>Traffic forecasting using graph neural networks and LSTM • keras</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../../apple-touch-icon-60x60.png">
<script src="../../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../../pkgdown.js"></script><link href="../../extra.css" rel="stylesheet">
<script src="../../extra.js"></script><meta property="og:title" content="Traffic forecasting using graph neural networks and LSTM">
<meta property="og:description" content="This example demonstrates how to do timeseries forecasting over graphs.">
<meta property="og:image" content="/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-inverse navbar-expand-lg bg-primary"><div class="container">
    
    <a class="navbar-brand me-2" href="../../index.html">keras</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">2.13.0.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../../index.html">Home</a>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-tutorials">Tutorials</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-tutorials">
    <a class="dropdown-item" href="../../articles/getting_started.html">Getting Started</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_classification.html">Basic Classification</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_text_classification.html">Text Classification</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_regression.html">Basic Regression</a>
    <a class="dropdown-item" href="../../articles/tutorial_overfit_underfit.html">Overfitting and Underfitting</a>
    <a class="dropdown-item" href="../../articles/tutorial_save_and_restore.html">Save and Restore Models</a>
  </div>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-guides">Guides</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-guides">
    <a class="dropdown-item" href="../../writing_your_own_callbacks.html">Writing Your Own Callbacks</a>
  </div>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <h6 class="dropdown-header" data-toc-skip>Guides (New for TF 2.6)</h6>
    <a class="dropdown-item" href="../../articles/new-guides/python_subclasses.html">Python Subclasses</a>
    <a class="dropdown-item" href="../../articles/new-guides/making_new_layers_and_models_via_subclassing.html">Making New Layers and Models via Subclassing</a>
    <a class="dropdown-item" href="../../articles/new-guides/customizing_what_happens_in_fit.html">Customizing What Happens in Fit</a>
    <a class="dropdown-item" href="../../articles/new-guides/writing_your_own_callbacks.html">Writing Your Own Callbacks</a>
    <a class="dropdown-item" href="../../articles/new-guides/preprocessing_layers.html">Working with Preprocessing Layers</a>
    <a class="dropdown-item" href="../../argicles/new-guides/working_with_rnns.html">Working with RNNs</a>
    <div class="dropdown-divider"></div>
    <h6 class="dropdown-header" data-toc-skip>Using Keras</h6>
    <a class="dropdown-item" href="../../articles/guide_keras.html">Guide to Keras Basics</a>
    <a class="dropdown-item" href="../../articles/sequential_model.html">Sequential Model in Depth</a>
    <a class="dropdown-item" href="../../articles/functional_api.html">Functional API in Depth</a>
    <a class="dropdown-item" href="../../articles/about_keras_models.html">About Keras Models</a>
    <a class="dropdown-item" href="../../articles/about_keras_layers.html">About Keras Layers</a>
    <a class="dropdown-item" href="../../articles/training_visualization.html">Training Visualization</a>
    <a class="dropdown-item" href="../../articles/applications.html">Pre-Trained Models</a>
    <a class="dropdown-item" href="../../articles/faq.html">Frequently Asked Questions</a>
    <a class="dropdown-item" href="../../articles/why_use_keras.html">Why Use Keras?</a>
    <div class="dropdown-divider"></div>
    <h6 class="dropdown-header" data-toc-skip>Advanced</h6>
    <a class="dropdown-item" href="../../articles/eager_guide.html">Eager Execution</a>
    <a class="dropdown-item" href="../../articles/training_callbacks.html">Training Callbacks</a>
    <a class="dropdown-item" href="../../articles/backend.html">Keras Backend</a>
    <a class="dropdown-item" href="../../articles/custom_layers.html">Custom Layers</a>
    <a class="dropdown-item" href="../../articles/custom_models.html">Custom Models</a>
    <a class="dropdown-item" href="../../articles/saving_serializing.html">Saving and serializing</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../articles/learn.html">Learn</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../articles/tools.html">Tools</a>
</li>
<li class="active nav-item">
  <a class="nav-link" href="../../articles/examples/index.html">Examples</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../reference/index.html">Reference</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../news/index.html">News</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/rstudio/keras/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../../logo.png" class="logo" alt=""><h1>Traffic forecasting using graph neural networks and LSTM</h1>
                        <h4 data-toc-skip class="author"><a href="https://www.linkedin.com/in/arash-khodadadi-08a02490/" class="external-link">Arash
Khodadadi</a></h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/rstudio/keras/blob/HEAD/vignettes/examples/timeseries_traffic_forecasting.Rmd" class="external-link"><code>vignettes/examples/timeseries_traffic_forecasting.Rmd</code></a></small>
      <div class="d-none name"><code>timeseries_traffic_forecasting.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>This example shows how to forecast traffic condition using graph
neural networks and LSTM. Specifically, we are interested in predicting
the future values of the traffic speed given a history of the traffic
speed for a collection of road segments.</p>
<p>One popular method to solve this problem is to consider each road
segment’s traffic speed as a separate timeseries and predict the future
values of each timeseries using the past values of the same
timeseries.</p>
<p>This method, however, ignores the dependency of the traffic speed of
one road segment on the neighboring segments. To be able to take into
account the complex interactions between the traffic speed on a
collection of neighboring roads, we can define the traffic network as a
graph and consider the traffic speed as a signal on this graph. In this
example, we implement a neural network architecture which can process
timeseries data over a graph. We first show how to process the data and
create a <a href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset" class="external-link">tf.data.Dataset</a>
for forecasting over graphs. Then, we implement a model which uses graph
convolution and LSTM layers to perform forecasting over a graph.</p>
<p>The data processing and the model architecture are inspired by this
paper:</p>
<p>Yu, Bing, Haoteng Yin, and Zhanxing Zhu. “Spatio-temporal graph
convolutional networks: a deep learning framework for traffic
forecasting.” Proceedings of the 27th International Joint Conference on
Artificial Intelligence, 2018. (<a href="https://github.com/VeritasYin/STGCN_IJCAI-18" class="external-link">github</a>)</p>
</div>
<div class="section level2">
<h2 id="setup">Setup<a class="anchor" aria-label="anchor" href="#setup"></a>
</h2>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">import</span> typing</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="im">import</span> keras <span class="im">as</span> keras</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="im">from</span> keras <span class="im">import</span> layers</span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a><span class="im">from</span> keras.utils <span class="im">import</span> timeseries_dataset_from_array</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="data-preparation">Data preparation<a class="anchor" aria-label="anchor" href="#data-preparation"></a>
</h2>
<div class="section level3">
<h3 id="data-description">Data description<a class="anchor" aria-label="anchor" href="#data-description"></a>
</h3>
<p>We use a real-world traffic speed dataset named <code>PeMSD7</code>.
We use the version collected and prepared by <a href="https://arxiv.org/abs/1709.04875" class="external-link">Yu et al., 2018</a> and
available <a href="https://github.com/VeritasYin/STGCN_IJCAI-18/tree/master/dataset" class="external-link">here</a>.</p>
<p>The data consists of two files:</p>
<ul>
<li>
<code>PeMSD7_W_228.csv</code> contains the distances between 228
stations across the District 7 of California.</li>
<li>
<code>PeMSD7_V_228.csv</code> contains traffic speed collected for
those stations in the weekdays of May and June of 2012.</li>
</ul>
<p>The full description of the dataset can be found in <a href="https://arxiv.org/abs/1709.04875" class="external-link">Yu et al., 2018</a>.</p>
</div>
<div class="section level3">
<h3 id="loading-data">Loading data<a class="anchor" aria-label="anchor" href="#loading-data"></a>
</h3>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>url <span class="op">=</span> <span class="st">"https://github.com/VeritasYin/STGCN_IJCAI-18/raw/master/dataset/PeMSD7_Full.zip"</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>data_dir <span class="op">=</span> keras.utils.get_file(origin<span class="op">=</span>url, extract<span class="op">=</span><span class="va">True</span>, archive_format<span class="op">=</span><span class="st">"zip"</span>)</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>data_dir <span class="op">=</span> data_dir.rstrip(<span class="st">"PeMSD7_Full.zip"</span>)</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>route_distances <span class="op">=</span> pd.read_csv(</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a>    os.path.join(data_dir, <span class="st">"PeMSD7_W_228.csv"</span>), header<span class="op">=</span><span class="va">None</span></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>).to_numpy()</span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>speeds_array <span class="op">=</span> pd.read_csv(</span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a>    os.path.join(data_dir, <span class="st">"PeMSD7_V_228.csv"</span>), header<span class="op">=</span><span class="va">None</span></span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a>).to_numpy()</span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"route_distances shape=</span><span class="sc">{</span>route_distances<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"speeds_array shape=</span><span class="sc">{</span>speeds_array<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div>
</div>
<div class="section level3">
<h3 id="sub-sampling-roads">sub-sampling roads<a class="anchor" aria-label="anchor" href="#sub-sampling-roads"></a>
</h3>
<p>To reduce the problem size and make the training faster, we will only
work with a sample of 26 roads out of the 228 roads in the dataset. We
have chosen the roads by starting from road 0, choosing the 5 closest
roads to it, and continuing this process until we get 25 roads. You can
choose any other subset of the roads. We chose the roads in this way to
increase the likelihood of having roads with correlated speed
timeseries. <code>sample_routes</code> contains the IDs of the selected
roads.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>sample_routes <span class="op">=</span> [</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>    <span class="dv">0</span>,</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>    <span class="dv">1</span>,</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>    <span class="dv">4</span>,</span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>    <span class="dv">7</span>,</span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a>    <span class="dv">8</span>,</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a>    <span class="dv">11</span>,</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>    <span class="dv">15</span>,</span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a>    <span class="dv">108</span>,</span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a>    <span class="dv">109</span>,</span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a>    <span class="dv">114</span>,</span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a>    <span class="dv">115</span>,</span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a>    <span class="dv">118</span>,</span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a>    <span class="dv">120</span>,</span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a>    <span class="dv">123</span>,</span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a>    <span class="dv">124</span>,</span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a>    <span class="dv">126</span>,</span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a>    <span class="dv">127</span>,</span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a>    <span class="dv">129</span>,</span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a>    <span class="dv">130</span>,</span>
<span id="cb3-21"><a href="#cb3-21" tabindex="-1"></a>    <span class="dv">132</span>,</span>
<span id="cb3-22"><a href="#cb3-22" tabindex="-1"></a>    <span class="dv">133</span>,</span>
<span id="cb3-23"><a href="#cb3-23" tabindex="-1"></a>    <span class="dv">136</span>,</span>
<span id="cb3-24"><a href="#cb3-24" tabindex="-1"></a>    <span class="dv">139</span>,</span>
<span id="cb3-25"><a href="#cb3-25" tabindex="-1"></a>    <span class="dv">144</span>,</span>
<span id="cb3-26"><a href="#cb3-26" tabindex="-1"></a>    <span class="dv">147</span>,</span>
<span id="cb3-27"><a href="#cb3-27" tabindex="-1"></a>    <span class="dv">216</span>,</span>
<span id="cb3-28"><a href="#cb3-28" tabindex="-1"></a>]</span>
<span id="cb3-29"><a href="#cb3-29" tabindex="-1"></a>route_distances <span class="op">=</span> route_distances[np.ix_(sample_routes, sample_routes)]</span>
<span id="cb3-30"><a href="#cb3-30" tabindex="-1"></a>speeds_array <span class="op">=</span> speeds_array[:, sample_routes]</span>
<span id="cb3-31"><a href="#cb3-31" tabindex="-1"></a></span>
<span id="cb3-32"><a href="#cb3-32" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"route_distances shape=</span><span class="sc">{</span>route_distances<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-33"><a href="#cb3-33" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"speeds_array shape=</span><span class="sc">{</span>speeds_array<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div>
</div>
<div class="section level3">
<h3 id="data-visualization">Data visualization<a class="anchor" aria-label="anchor" href="#data-visualization"></a>
</h3>
<p>Here are the timeseries of the traffic speed for two of the
routes:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">18</span>, <span class="dv">6</span>))</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>plt.plot(speeds_array[:, [<span class="dv">0</span>, <span class="op">-</span><span class="dv">1</span>]])</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>plt.legend([<span class="st">"route_0"</span>, <span class="st">"route_25"</span>])</span></code></pre></div>
<p>We can also visualize the correlation between the timeseries in
different routes.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">8</span>))</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>plt.matshow(np.corrcoef(speeds_array.T), <span class="dv">0</span>)</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>plt.xlabel(<span class="st">"road number"</span>)</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>plt.ylabel(<span class="st">"road number"</span>)</span></code></pre></div>
<p>Using this correlation heatmap, we can see that for example the speed
in routes 4, 5, 6 are highly correlated.</p>
</div>
<div class="section level3">
<h3 id="splitting-and-normalizing-data">Splitting and normalizing data<a class="anchor" aria-label="anchor" href="#splitting-and-normalizing-data"></a>
</h3>
<p>Next, we split the speed values array into train/validation/test
sets, and normalize the resulting arrays:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>train_size, val_size <span class="op">=</span> <span class="fl">0.5</span>, <span class="fl">0.2</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a><span class="kw">def</span> preprocess(data_array: np.ndarray, train_size: <span class="bu">float</span>, val_size: <span class="bu">float</span>):</span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a>    <span class="co">"""Splits data into train/val/test sets and normalizes the data.</span></span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a><span class="co">        data_array: ndarray of shape `(num_time_steps, num_routes)`</span></span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a><span class="co">        train_size: A float value between 0.0 and 1.0 that represent the proportion of the dataset</span></span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a><span class="co">            to include in the train split.</span></span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a><span class="co">        val_size: A float value between 0.0 and 1.0 that represent the proportion of the dataset</span></span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a><span class="co">            to include in the validation split.</span></span>
<span id="cb6-13"><a href="#cb6-13" tabindex="-1"></a></span>
<span id="cb6-14"><a href="#cb6-14" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb6-15"><a href="#cb6-15" tabindex="-1"></a><span class="co">        `train_array`, `val_array`, `test_array`</span></span>
<span id="cb6-16"><a href="#cb6-16" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-17"><a href="#cb6-17" tabindex="-1"></a></span>
<span id="cb6-18"><a href="#cb6-18" tabindex="-1"></a>    num_time_steps <span class="op">=</span> data_array.shape[<span class="dv">0</span>]</span>
<span id="cb6-19"><a href="#cb6-19" tabindex="-1"></a>    num_train, num_val <span class="op">=</span> (</span>
<span id="cb6-20"><a href="#cb6-20" tabindex="-1"></a>        <span class="bu">int</span>(num_time_steps <span class="op">*</span> train_size),</span>
<span id="cb6-21"><a href="#cb6-21" tabindex="-1"></a>        <span class="bu">int</span>(num_time_steps <span class="op">*</span> val_size),</span>
<span id="cb6-22"><a href="#cb6-22" tabindex="-1"></a>    )</span>
<span id="cb6-23"><a href="#cb6-23" tabindex="-1"></a>    train_array <span class="op">=</span> data_array[:num_train]</span>
<span id="cb6-24"><a href="#cb6-24" tabindex="-1"></a>    mean, std <span class="op">=</span> train_array.mean(axis<span class="op">=</span><span class="dv">0</span>), train_array.std(axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb6-25"><a href="#cb6-25" tabindex="-1"></a></span>
<span id="cb6-26"><a href="#cb6-26" tabindex="-1"></a>    train_array <span class="op">=</span> (train_array <span class="op">-</span> mean) <span class="op">/</span> std</span>
<span id="cb6-27"><a href="#cb6-27" tabindex="-1"></a>    val_array <span class="op">=</span> (data_array[num_train : (num_train <span class="op">+</span> num_val)] <span class="op">-</span> mean) <span class="op">/</span> std</span>
<span id="cb6-28"><a href="#cb6-28" tabindex="-1"></a>    test_array <span class="op">=</span> (data_array[(num_train <span class="op">+</span> num_val) :] <span class="op">-</span> mean) <span class="op">/</span> std</span>
<span id="cb6-29"><a href="#cb6-29" tabindex="-1"></a></span>
<span id="cb6-30"><a href="#cb6-30" tabindex="-1"></a>    <span class="cf">return</span> train_array, val_array, test_array</span>
<span id="cb6-31"><a href="#cb6-31" tabindex="-1"></a></span>
<span id="cb6-32"><a href="#cb6-32" tabindex="-1"></a></span>
<span id="cb6-33"><a href="#cb6-33" tabindex="-1"></a>train_array, val_array, test_array <span class="op">=</span> preprocess(</span>
<span id="cb6-34"><a href="#cb6-34" tabindex="-1"></a>    speeds_array, train_size, val_size</span>
<span id="cb6-35"><a href="#cb6-35" tabindex="-1"></a>)</span>
<span id="cb6-36"><a href="#cb6-36" tabindex="-1"></a></span>
<span id="cb6-37"><a href="#cb6-37" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"train set size: </span><span class="sc">{</span>train_array<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-38"><a href="#cb6-38" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"validation set size: </span><span class="sc">{</span>val_array<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-39"><a href="#cb6-39" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"test set size: </span><span class="sc">{</span>test_array<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div>
</div>
<div class="section level3">
<h3 id="creating-tensorflow-datasets">Creating TensorFlow Datasets<a class="anchor" aria-label="anchor" href="#creating-tensorflow-datasets"></a>
</h3>
<p>Next, we create the datasets for our forecasting problem. The
forecasting problem can be stated as follows: given a sequence of the
road speed values at times <code>t+1, t+2, ..., t+T</code>, we want to
predict the future values of the roads speed for times
<code>t+T+1, ..., t+T+h</code>. So for each time <code>t</code> the
inputs to our model are <code>T</code> vectors each of size
<code>N</code> and the targets are <code>h</code> vectors each of size
<code>N</code>, where <code>N</code> is the number of roads.</p>
<p>We use the Keras built-in function <a href="https://www.tensorflow.org/api_docs/python/tf/keras/utils/timeseries_dataset_from_array" class="external-link"><code>timeseries_dataset_from_array()</code></a>.
The function <code>create_tf_dataset()</code> below takes as input a
<code>numpy.ndarray</code> and returns a <code>tf.data.Dataset</code>.
In this function <code>input_sequence_length=T</code> and
<code>forecast_horizon=h</code>.</p>
<p>The argument <code>multi_horizon</code> needs more explanation.
Assume <code>forecast_horizon=3</code>. If
<code>multi_horizon=True</code> then the model will make a forecast for
time steps <code>t+T+1, t+T+2, t+T+3</code>. So the target will have
shape <code>(T,3)</code>. But if <code>multi_horizon=False</code>, the
model will make a forecast only for time step <code>t+T+3</code> and so
the target will have shape <code>(T, 1)</code>.</p>
<p>You may notice that the input tensor in each batch has shape
<code>(batch_size, input_sequence_length, num_routes, 1)</code>. The
last dimension is added to make the model more general: at each time
step, the input features for each raod may contain multiple timeseries.
For instance, one might want to use temperature timeseries in addition
to historical values of the speed as input features. In this example,
however, the last dimension of the input is always 1.</p>
<p>We use the last 12 values of the speed in each road to forecast the
speed for 3 time steps ahead:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>input_sequence_length <span class="op">=</span> <span class="dv">12</span></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>forecast_horizon <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>multi_horizon <span class="op">=</span> <span class="va">False</span></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a><span class="kw">def</span> create_tf_dataset(</span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a>    data_array: np.ndarray,</span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a>    input_sequence_length: <span class="bu">int</span>,</span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a>    forecast_horizon: <span class="bu">int</span>,</span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a>    batch_size: <span class="bu">int</span> <span class="op">=</span> <span class="dv">128</span>,</span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a>    shuffle<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a>    multi_horizon<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb7-14"><a href="#cb7-14" tabindex="-1"></a>):</span>
<span id="cb7-15"><a href="#cb7-15" tabindex="-1"></a>    <span class="co">"""Creates tensorflow dataset from numpy array.</span></span>
<span id="cb7-16"><a href="#cb7-16" tabindex="-1"></a></span>
<span id="cb7-17"><a href="#cb7-17" tabindex="-1"></a><span class="co">    This function creates a dataset where each element is a tuple `(inputs, targets)`.</span></span>
<span id="cb7-18"><a href="#cb7-18" tabindex="-1"></a><span class="co">    `inputs` is a Tensor</span></span>
<span id="cb7-19"><a href="#cb7-19" tabindex="-1"></a><span class="co">    of shape `(batch_size, input_sequence_length, num_routes, 1)` containing</span></span>
<span id="cb7-20"><a href="#cb7-20" tabindex="-1"></a><span class="co">    the `input_sequence_length` past values of the timeseries for each node.</span></span>
<span id="cb7-21"><a href="#cb7-21" tabindex="-1"></a><span class="co">    `targets` is a Tensor of shape `(batch_size, forecast_horizon, num_routes)`</span></span>
<span id="cb7-22"><a href="#cb7-22" tabindex="-1"></a><span class="co">    containing the `forecast_horizon`</span></span>
<span id="cb7-23"><a href="#cb7-23" tabindex="-1"></a><span class="co">    future values of the timeseries for each node.</span></span>
<span id="cb7-24"><a href="#cb7-24" tabindex="-1"></a></span>
<span id="cb7-25"><a href="#cb7-25" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb7-26"><a href="#cb7-26" tabindex="-1"></a><span class="co">        data_array: np.ndarray with shape `(num_time_steps, num_routes)`</span></span>
<span id="cb7-27"><a href="#cb7-27" tabindex="-1"></a><span class="co">        input_sequence_length: Length of the input sequence (in number of timesteps).</span></span>
<span id="cb7-28"><a href="#cb7-28" tabindex="-1"></a><span class="co">        forecast_horizon: If `multi_horizon=True`, the target will be the values of the timeseries for 1 to</span></span>
<span id="cb7-29"><a href="#cb7-29" tabindex="-1"></a><span class="co">            `forecast_horizon` timesteps ahead. If `multi_horizon=False`, the target will be the value of the</span></span>
<span id="cb7-30"><a href="#cb7-30" tabindex="-1"></a><span class="co">            timeseries `forecast_horizon` steps ahead (only one value).</span></span>
<span id="cb7-31"><a href="#cb7-31" tabindex="-1"></a><span class="co">        batch_size: Number of timeseries samples in each batch.</span></span>
<span id="cb7-32"><a href="#cb7-32" tabindex="-1"></a><span class="co">        shuffle: Whether to shuffle output samples, or instead draw them in chronological order.</span></span>
<span id="cb7-33"><a href="#cb7-33" tabindex="-1"></a><span class="co">        multi_horizon: See `forecast_horizon`.</span></span>
<span id="cb7-34"><a href="#cb7-34" tabindex="-1"></a></span>
<span id="cb7-35"><a href="#cb7-35" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb7-36"><a href="#cb7-36" tabindex="-1"></a><span class="co">        A tf.data.Dataset instance.</span></span>
<span id="cb7-37"><a href="#cb7-37" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb7-38"><a href="#cb7-38" tabindex="-1"></a></span>
<span id="cb7-39"><a href="#cb7-39" tabindex="-1"></a>    inputs <span class="op">=</span> timeseries_dataset_from_array(</span>
<span id="cb7-40"><a href="#cb7-40" tabindex="-1"></a>        np.expand_dims(data_array[:<span class="op">-</span>forecast_horizon], axis<span class="op">=-</span><span class="dv">1</span>),</span>
<span id="cb7-41"><a href="#cb7-41" tabindex="-1"></a>        <span class="va">None</span>,</span>
<span id="cb7-42"><a href="#cb7-42" tabindex="-1"></a>        sequence_length<span class="op">=</span>input_sequence_length,</span>
<span id="cb7-43"><a href="#cb7-43" tabindex="-1"></a>        shuffle<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb7-44"><a href="#cb7-44" tabindex="-1"></a>        batch_size<span class="op">=</span>batch_size,</span>
<span id="cb7-45"><a href="#cb7-45" tabindex="-1"></a>    )</span>
<span id="cb7-46"><a href="#cb7-46" tabindex="-1"></a></span>
<span id="cb7-47"><a href="#cb7-47" tabindex="-1"></a>    target_offset <span class="op">=</span> (</span>
<span id="cb7-48"><a href="#cb7-48" tabindex="-1"></a>        input_sequence_length</span>
<span id="cb7-49"><a href="#cb7-49" tabindex="-1"></a>        <span class="cf">if</span> multi_horizon</span>
<span id="cb7-50"><a href="#cb7-50" tabindex="-1"></a>        <span class="cf">else</span> input_sequence_length <span class="op">+</span> forecast_horizon <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb7-51"><a href="#cb7-51" tabindex="-1"></a>    )</span>
<span id="cb7-52"><a href="#cb7-52" tabindex="-1"></a>    target_seq_length <span class="op">=</span> forecast_horizon <span class="cf">if</span> multi_horizon <span class="cf">else</span> <span class="dv">1</span></span>
<span id="cb7-53"><a href="#cb7-53" tabindex="-1"></a>    targets <span class="op">=</span> timeseries_dataset_from_array(</span>
<span id="cb7-54"><a href="#cb7-54" tabindex="-1"></a>        data_array[target_offset:],</span>
<span id="cb7-55"><a href="#cb7-55" tabindex="-1"></a>        <span class="va">None</span>,</span>
<span id="cb7-56"><a href="#cb7-56" tabindex="-1"></a>        sequence_length<span class="op">=</span>target_seq_length,</span>
<span id="cb7-57"><a href="#cb7-57" tabindex="-1"></a>        shuffle<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb7-58"><a href="#cb7-58" tabindex="-1"></a>        batch_size<span class="op">=</span>batch_size,</span>
<span id="cb7-59"><a href="#cb7-59" tabindex="-1"></a>    )</span>
<span id="cb7-60"><a href="#cb7-60" tabindex="-1"></a></span>
<span id="cb7-61"><a href="#cb7-61" tabindex="-1"></a>    dataset <span class="op">=</span> tf.data.Dataset.<span class="bu">zip</span>((inputs, targets))</span>
<span id="cb7-62"><a href="#cb7-62" tabindex="-1"></a>    <span class="cf">if</span> shuffle:</span>
<span id="cb7-63"><a href="#cb7-63" tabindex="-1"></a>        dataset <span class="op">=</span> dataset.shuffle(<span class="dv">100</span>)</span>
<span id="cb7-64"><a href="#cb7-64" tabindex="-1"></a></span>
<span id="cb7-65"><a href="#cb7-65" tabindex="-1"></a>    <span class="cf">return</span> dataset.prefetch(<span class="dv">16</span>).cache()</span>
<span id="cb7-66"><a href="#cb7-66" tabindex="-1"></a></span>
<span id="cb7-67"><a href="#cb7-67" tabindex="-1"></a></span>
<span id="cb7-68"><a href="#cb7-68" tabindex="-1"></a>train_dataset, val_dataset <span class="op">=</span> (</span>
<span id="cb7-69"><a href="#cb7-69" tabindex="-1"></a>    create_tf_dataset(</span>
<span id="cb7-70"><a href="#cb7-70" tabindex="-1"></a>        data_array, input_sequence_length, forecast_horizon, batch_size</span>
<span id="cb7-71"><a href="#cb7-71" tabindex="-1"></a>    )</span>
<span id="cb7-72"><a href="#cb7-72" tabindex="-1"></a>    <span class="cf">for</span> data_array <span class="kw">in</span> [train_array, val_array]</span>
<span id="cb7-73"><a href="#cb7-73" tabindex="-1"></a>)</span>
<span id="cb7-74"><a href="#cb7-74" tabindex="-1"></a></span>
<span id="cb7-75"><a href="#cb7-75" tabindex="-1"></a>test_dataset <span class="op">=</span> create_tf_dataset(</span>
<span id="cb7-76"><a href="#cb7-76" tabindex="-1"></a>    test_array,</span>
<span id="cb7-77"><a href="#cb7-77" tabindex="-1"></a>    input_sequence_length,</span>
<span id="cb7-78"><a href="#cb7-78" tabindex="-1"></a>    forecast_horizon,</span>
<span id="cb7-79"><a href="#cb7-79" tabindex="-1"></a>    batch_size<span class="op">=</span>test_array.shape[<span class="dv">0</span>],</span>
<span id="cb7-80"><a href="#cb7-80" tabindex="-1"></a>    shuffle<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb7-81"><a href="#cb7-81" tabindex="-1"></a>    multi_horizon<span class="op">=</span>multi_horizon,</span>
<span id="cb7-82"><a href="#cb7-82" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="section level3">
<h3 id="roads-graph">Roads Graph<a class="anchor" aria-label="anchor" href="#roads-graph"></a>
</h3>
<p>As mentioned before, we assume that the road segments form a graph.
The <code>PeMSD7</code> dataset has the road segments distance. The next
step is to create the graph adjacency matrix from these distances.
Following <a href="https://arxiv.org/abs/1709.04875" class="external-link">Yu et al., 2018</a>
(equation 10) we assume there is an edge between two nodes in the graph
if the distance between the corresponding roads is less than a
threshold.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="kw">def</span> compute_adjacency_matrix(</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>    route_distances: np.ndarray, sigma2: <span class="bu">float</span>, epsilon: <span class="bu">float</span></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>):</span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>    <span class="co">"""Computes the adjacency matrix from distances matrix.</span></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a><span class="co">    It uses the formula in https://github.com/VeritasYin/STGCN_IJCAI-18#data-preprocessing to</span></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a><span class="co">    compute an adjacency matrix from the distance matrix.</span></span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a><span class="co">    The implementation follows that paper.</span></span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a><span class="co">        route_distances: np.ndarray of shape `(num_routes, num_routes)`. Entry `i,j` of this array is the</span></span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a><span class="co">            distance between roads `i,j`.</span></span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a><span class="co">        sigma2: Determines the width of the Gaussian kernel applied to the square distances matrix.</span></span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a><span class="co">        epsilon: A threshold specifying if there is an edge between two nodes. Specifically, `A[i,j]=1`</span></span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a><span class="co">            if `np.exp(-w2[i,j] / sigma2) &gt;= epsilon` and `A[i,j]=0` otherwise, where `A` is the adjacency</span></span>
<span id="cb8-16"><a href="#cb8-16" tabindex="-1"></a><span class="co">            matrix and `w2=route_distances * route_distances`</span></span>
<span id="cb8-17"><a href="#cb8-17" tabindex="-1"></a></span>
<span id="cb8-18"><a href="#cb8-18" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb8-19"><a href="#cb8-19" tabindex="-1"></a><span class="co">        A boolean graph adjacency matrix.</span></span>
<span id="cb8-20"><a href="#cb8-20" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb8-21"><a href="#cb8-21" tabindex="-1"></a>    num_routes <span class="op">=</span> route_distances.shape[<span class="dv">0</span>]</span>
<span id="cb8-22"><a href="#cb8-22" tabindex="-1"></a>    route_distances <span class="op">=</span> route_distances <span class="op">/</span> <span class="fl">10000.0</span></span>
<span id="cb8-23"><a href="#cb8-23" tabindex="-1"></a>    w2, w_mask <span class="op">=</span> (</span>
<span id="cb8-24"><a href="#cb8-24" tabindex="-1"></a>        route_distances <span class="op">*</span> route_distances,</span>
<span id="cb8-25"><a href="#cb8-25" tabindex="-1"></a>        np.ones([num_routes, num_routes]) <span class="op">-</span> np.identity(num_routes),</span>
<span id="cb8-26"><a href="#cb8-26" tabindex="-1"></a>    )</span>
<span id="cb8-27"><a href="#cb8-27" tabindex="-1"></a>    <span class="cf">return</span> (np.exp(<span class="op">-</span>w2 <span class="op">/</span> sigma2) <span class="op">&gt;=</span> epsilon) <span class="op">*</span> w_mask</span></code></pre></div>
<p>The function <code>compute_adjacency_matrix()</code> returns a
boolean adjacency matrix where 1 means there is an edge between two
nodes. We use the following class to store the information about the
graph.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="kw">class</span> GraphInfo:</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, edges: typing.Tuple[<span class="bu">list</span>, <span class="bu">list</span>], num_nodes: <span class="bu">int</span>):</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a>        <span class="va">self</span>.edges <span class="op">=</span> edges</span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>        <span class="va">self</span>.num_nodes <span class="op">=</span> num_nodes</span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a>sigma2 <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a>epsilon <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a>adjacency_matrix <span class="op">=</span> compute_adjacency_matrix(route_distances, sigma2, epsilon)</span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a>node_indices, neighbor_indices <span class="op">=</span> np.where(adjacency_matrix <span class="op">==</span> <span class="dv">1</span>)</span>
<span id="cb9-11"><a href="#cb9-11" tabindex="-1"></a>graph <span class="op">=</span> GraphInfo(</span>
<span id="cb9-12"><a href="#cb9-12" tabindex="-1"></a>    edges<span class="op">=</span>(node_indices.tolist(), neighbor_indices.tolist()),</span>
<span id="cb9-13"><a href="#cb9-13" tabindex="-1"></a>    num_nodes<span class="op">=</span>adjacency_matrix.shape[<span class="dv">0</span>],</span>
<span id="cb9-14"><a href="#cb9-14" tabindex="-1"></a>)</span>
<span id="cb9-15"><a href="#cb9-15" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb9-16"><a href="#cb9-16" tabindex="-1"></a>    <span class="ss">f"number of nodes: </span><span class="sc">{</span>graph<span class="sc">.</span>num_nodes<span class="sc">}</span><span class="ss">, number of edges: </span><span class="sc">{</span><span class="bu">len</span>(graph.edges[<span class="dv">0</span>])<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb9-17"><a href="#cb9-17" tabindex="-1"></a>)</span></code></pre></div>
</div>
</div>
<div class="section level2">
<h2 id="network-architecture">Network architecture<a class="anchor" aria-label="anchor" href="#network-architecture"></a>
</h2>
<p>Our model for forecasting over the graph consists of a graph
convolution layer and a LSTM layer.</p>
<div class="section level3">
<h3 id="graph-convolution-layer">Graph convolution layer<a class="anchor" aria-label="anchor" href="#graph-convolution-layer"></a>
</h3>
<p>Our implementation of the graph convolution layer resembles the
implementation in <a href="https://keras.io/examples/graph/gnn_citations/" class="external-link">this Keras
example</a>. Note that in that example input to the layer is a 2D tensor
of shape <code>(num_nodes,in_feat)</code> but in our example the input
to the layer is a 4D tensor of shape
<code>(num_nodes, batch_size, input_seq_length, in_feat)</code>. The
graph convolution layer performs the following steps:</p>
<ul>
<li>The nodes’ representations are computed in
<code>self.compute_nodes_representation()</code> by multiplying the
input features by <code>self.weight</code>
</li>
<li>The aggregated neighbors’ messages are computed in
<code>self.compute_aggregated_messages()</code> by first aggregating the
neighbors’ representations and then multiplying the results by
<code>self.weight</code>
</li>
<li>The final output of the layer is computed in
<code>self.update()</code> by combining the nodes representations and
the neighbors’ aggregated messages</li>
</ul>
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="kw">class</span> GraphConv(layers.Layer):</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a>        <span class="va">self</span>,</span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a>        in_feat,</span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a>        out_feat,</span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a>        graph_info: GraphInfo,</span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a>        aggregation_type<span class="op">=</span><span class="st">"mean"</span>,</span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a>        combination_type<span class="op">=</span><span class="st">"concat"</span>,</span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a>        activation: typing.Optional[<span class="bu">str</span>] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a>        <span class="op">**</span>kwargs,</span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a>    ):</span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(<span class="op">**</span>kwargs)</span>
<span id="cb10-13"><a href="#cb10-13" tabindex="-1"></a>        <span class="va">self</span>.in_feat <span class="op">=</span> in_feat</span>
<span id="cb10-14"><a href="#cb10-14" tabindex="-1"></a>        <span class="va">self</span>.out_feat <span class="op">=</span> out_feat</span>
<span id="cb10-15"><a href="#cb10-15" tabindex="-1"></a>        <span class="va">self</span>.graph_info <span class="op">=</span> graph_info</span>
<span id="cb10-16"><a href="#cb10-16" tabindex="-1"></a>        <span class="va">self</span>.aggregation_type <span class="op">=</span> aggregation_type</span>
<span id="cb10-17"><a href="#cb10-17" tabindex="-1"></a>        <span class="va">self</span>.combination_type <span class="op">=</span> combination_type</span>
<span id="cb10-18"><a href="#cb10-18" tabindex="-1"></a>        <span class="va">self</span>.weight <span class="op">=</span> tf.Variable(</span>
<span id="cb10-19"><a href="#cb10-19" tabindex="-1"></a>            initial_value<span class="op">=</span>keras.initializers.GlorotUniform()(</span>
<span id="cb10-20"><a href="#cb10-20" tabindex="-1"></a>                shape<span class="op">=</span>(in_feat, out_feat), dtype<span class="op">=</span><span class="st">"float32"</span></span>
<span id="cb10-21"><a href="#cb10-21" tabindex="-1"></a>            ),</span>
<span id="cb10-22"><a href="#cb10-22" tabindex="-1"></a>            trainable<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb10-23"><a href="#cb10-23" tabindex="-1"></a>        )</span>
<span id="cb10-24"><a href="#cb10-24" tabindex="-1"></a>        <span class="va">self</span>.activation <span class="op">=</span> layers.Activation(activation)</span>
<span id="cb10-25"><a href="#cb10-25" tabindex="-1"></a></span>
<span id="cb10-26"><a href="#cb10-26" tabindex="-1"></a>    <span class="kw">def</span> aggregate(<span class="va">self</span>, neighbour_representations: tf.Tensor):</span>
<span id="cb10-27"><a href="#cb10-27" tabindex="-1"></a>        aggregation_func <span class="op">=</span> {</span>
<span id="cb10-28"><a href="#cb10-28" tabindex="-1"></a>            <span class="st">"sum"</span>: tf.math.unsorted_segment_sum,</span>
<span id="cb10-29"><a href="#cb10-29" tabindex="-1"></a>            <span class="st">"mean"</span>: tf.math.unsorted_segment_mean,</span>
<span id="cb10-30"><a href="#cb10-30" tabindex="-1"></a>            <span class="st">"max"</span>: tf.math.unsorted_segment_max,</span>
<span id="cb10-31"><a href="#cb10-31" tabindex="-1"></a>        }.get(<span class="va">self</span>.aggregation_type)</span>
<span id="cb10-32"><a href="#cb10-32" tabindex="-1"></a></span>
<span id="cb10-33"><a href="#cb10-33" tabindex="-1"></a>        <span class="cf">if</span> aggregation_func:</span>
<span id="cb10-34"><a href="#cb10-34" tabindex="-1"></a>            <span class="cf">return</span> aggregation_func(</span>
<span id="cb10-35"><a href="#cb10-35" tabindex="-1"></a>                neighbour_representations,</span>
<span id="cb10-36"><a href="#cb10-36" tabindex="-1"></a>                <span class="va">self</span>.graph_info.edges[<span class="dv">0</span>],</span>
<span id="cb10-37"><a href="#cb10-37" tabindex="-1"></a>                num_segments<span class="op">=</span><span class="va">self</span>.graph_info.num_nodes,</span>
<span id="cb10-38"><a href="#cb10-38" tabindex="-1"></a>            )</span>
<span id="cb10-39"><a href="#cb10-39" tabindex="-1"></a></span>
<span id="cb10-40"><a href="#cb10-40" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"Invalid aggregation type: </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>aggregation_type<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb10-41"><a href="#cb10-41" tabindex="-1"></a></span>
<span id="cb10-42"><a href="#cb10-42" tabindex="-1"></a>    <span class="kw">def</span> compute_nodes_representation(<span class="va">self</span>, features: tf.Tensor):</span>
<span id="cb10-43"><a href="#cb10-43" tabindex="-1"></a>        <span class="co">"""Computes each node's representation.</span></span>
<span id="cb10-44"><a href="#cb10-44" tabindex="-1"></a></span>
<span id="cb10-45"><a href="#cb10-45" tabindex="-1"></a><span class="co">        The nodes' representations are obtained by multiplying the features tensor with</span></span>
<span id="cb10-46"><a href="#cb10-46" tabindex="-1"></a><span class="co">        `self.weight`. Note that</span></span>
<span id="cb10-47"><a href="#cb10-47" tabindex="-1"></a><span class="co">        `self.weight` has shape `(in_feat, out_feat)`.</span></span>
<span id="cb10-48"><a href="#cb10-48" tabindex="-1"></a></span>
<span id="cb10-49"><a href="#cb10-49" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb10-50"><a href="#cb10-50" tabindex="-1"></a><span class="co">            features: Tensor of shape `(num_nodes, batch_size, input_seq_len, in_feat)`</span></span>
<span id="cb10-51"><a href="#cb10-51" tabindex="-1"></a></span>
<span id="cb10-52"><a href="#cb10-52" tabindex="-1"></a><span class="co">        Returns:</span></span>
<span id="cb10-53"><a href="#cb10-53" tabindex="-1"></a><span class="co">            A tensor of shape `(num_nodes, batch_size, input_seq_len, out_feat)`</span></span>
<span id="cb10-54"><a href="#cb10-54" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb10-55"><a href="#cb10-55" tabindex="-1"></a>        <span class="cf">return</span> tf.matmul(features, <span class="va">self</span>.weight)</span>
<span id="cb10-56"><a href="#cb10-56" tabindex="-1"></a></span>
<span id="cb10-57"><a href="#cb10-57" tabindex="-1"></a>    <span class="kw">def</span> compute_aggregated_messages(<span class="va">self</span>, features: tf.Tensor):</span>
<span id="cb10-58"><a href="#cb10-58" tabindex="-1"></a>        neighbour_representations <span class="op">=</span> tf.gather(</span>
<span id="cb10-59"><a href="#cb10-59" tabindex="-1"></a>            features, <span class="va">self</span>.graph_info.edges[<span class="dv">1</span>]</span>
<span id="cb10-60"><a href="#cb10-60" tabindex="-1"></a>        )</span>
<span id="cb10-61"><a href="#cb10-61" tabindex="-1"></a>        aggregated_messages <span class="op">=</span> <span class="va">self</span>.aggregate(neighbour_representations)</span>
<span id="cb10-62"><a href="#cb10-62" tabindex="-1"></a>        <span class="cf">return</span> tf.matmul(aggregated_messages, <span class="va">self</span>.weight)</span>
<span id="cb10-63"><a href="#cb10-63" tabindex="-1"></a></span>
<span id="cb10-64"><a href="#cb10-64" tabindex="-1"></a>    <span class="kw">def</span> update(</span>
<span id="cb10-65"><a href="#cb10-65" tabindex="-1"></a>        <span class="va">self</span>, nodes_representation: tf.Tensor, aggregated_messages: tf.Tensor</span>
<span id="cb10-66"><a href="#cb10-66" tabindex="-1"></a>    ):</span>
<span id="cb10-67"><a href="#cb10-67" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.combination_type <span class="op">==</span> <span class="st">"concat"</span>:</span>
<span id="cb10-68"><a href="#cb10-68" tabindex="-1"></a>            h <span class="op">=</span> tf.concat([nodes_representation, aggregated_messages], axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb10-69"><a href="#cb10-69" tabindex="-1"></a>        <span class="cf">elif</span> <span class="va">self</span>.combination_type <span class="op">==</span> <span class="st">"add"</span>:</span>
<span id="cb10-70"><a href="#cb10-70" tabindex="-1"></a>            h <span class="op">=</span> nodes_representation <span class="op">+</span> aggregated_messages</span>
<span id="cb10-71"><a href="#cb10-71" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb10-72"><a href="#cb10-72" tabindex="-1"></a>            <span class="cf">raise</span> <span class="pp">ValueError</span>(</span>
<span id="cb10-73"><a href="#cb10-73" tabindex="-1"></a>                <span class="ss">f"Invalid combination type: </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>combination_type<span class="sc">}</span><span class="ss">."</span></span>
<span id="cb10-74"><a href="#cb10-74" tabindex="-1"></a>            )</span>
<span id="cb10-75"><a href="#cb10-75" tabindex="-1"></a></span>
<span id="cb10-76"><a href="#cb10-76" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.activation(h)</span>
<span id="cb10-77"><a href="#cb10-77" tabindex="-1"></a></span>
<span id="cb10-78"><a href="#cb10-78" tabindex="-1"></a>    <span class="kw">def</span> call(<span class="va">self</span>, features: tf.Tensor):</span>
<span id="cb10-79"><a href="#cb10-79" tabindex="-1"></a>        <span class="co">"""Forward pass.</span></span>
<span id="cb10-80"><a href="#cb10-80" tabindex="-1"></a></span>
<span id="cb10-81"><a href="#cb10-81" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb10-82"><a href="#cb10-82" tabindex="-1"></a><span class="co">            features: tensor of shape `(num_nodes, batch_size, input_seq_len, in_feat)`</span></span>
<span id="cb10-83"><a href="#cb10-83" tabindex="-1"></a></span>
<span id="cb10-84"><a href="#cb10-84" tabindex="-1"></a><span class="co">        Returns:</span></span>
<span id="cb10-85"><a href="#cb10-85" tabindex="-1"></a><span class="co">            A tensor of shape `(num_nodes, batch_size, input_seq_len, out_feat)`</span></span>
<span id="cb10-86"><a href="#cb10-86" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb10-87"><a href="#cb10-87" tabindex="-1"></a>        nodes_representation <span class="op">=</span> <span class="va">self</span>.compute_nodes_representation(features)</span>
<span id="cb10-88"><a href="#cb10-88" tabindex="-1"></a>        aggregated_messages <span class="op">=</span> <span class="va">self</span>.compute_aggregated_messages(features)</span>
<span id="cb10-89"><a href="#cb10-89" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.update(nodes_representation, aggregated_messages)</span></code></pre></div>
</div>
<div class="section level3">
<h3 id="lstm-plus-graph-convolution">LSTM plus graph convolution<a class="anchor" aria-label="anchor" href="#lstm-plus-graph-convolution"></a>
</h3>
<p>By applying the graph convolution layer to the input tensor, we get
another tensor containing the nodes’ representations over time (another
4D tensor). For each time step, a node’s representation is informed by
the information from its neighbors.</p>
<p>To make good forecasts, however, we need not only information from
the neighbors but also we need to process the information over time. To
this end, we can pass each node’s tensor through a recurrent layer. The
<code>LSTMGC</code> layer below, first applies a graph convolution layer
to the inputs and then passes the results through a <code>LSTM</code>
layer.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="kw">class</span> LSTMGC(layers.Layer):</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>    <span class="co">"""Layer comprising a convolution layer followed by LSTM and dense layers."""</span></span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a>        <span class="va">self</span>,</span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a>        in_feat,</span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a>        out_feat,</span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a>        lstm_units: <span class="bu">int</span>,</span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a>        input_seq_len: <span class="bu">int</span>,</span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a>        output_seq_len: <span class="bu">int</span>,</span>
<span id="cb11-11"><a href="#cb11-11" tabindex="-1"></a>        graph_info: GraphInfo,</span>
<span id="cb11-12"><a href="#cb11-12" tabindex="-1"></a>        graph_conv_params: typing.Optional[<span class="bu">dict</span>] <span class="op">=</span> <span class="va">None</span>,</span>
<span id="cb11-13"><a href="#cb11-13" tabindex="-1"></a>        <span class="op">**</span>kwargs,</span>
<span id="cb11-14"><a href="#cb11-14" tabindex="-1"></a>    ):</span>
<span id="cb11-15"><a href="#cb11-15" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(<span class="op">**</span>kwargs)</span>
<span id="cb11-16"><a href="#cb11-16" tabindex="-1"></a></span>
<span id="cb11-17"><a href="#cb11-17" tabindex="-1"></a>        <span class="co"># graph conv layer</span></span>
<span id="cb11-18"><a href="#cb11-18" tabindex="-1"></a>        <span class="cf">if</span> graph_conv_params <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb11-19"><a href="#cb11-19" tabindex="-1"></a>            graph_conv_params <span class="op">=</span> {</span>
<span id="cb11-20"><a href="#cb11-20" tabindex="-1"></a>                <span class="st">"aggregation_type"</span>: <span class="st">"mean"</span>,</span>
<span id="cb11-21"><a href="#cb11-21" tabindex="-1"></a>                <span class="st">"combination_type"</span>: <span class="st">"concat"</span>,</span>
<span id="cb11-22"><a href="#cb11-22" tabindex="-1"></a>                <span class="st">"activation"</span>: <span class="va">None</span>,</span>
<span id="cb11-23"><a href="#cb11-23" tabindex="-1"></a>            }</span>
<span id="cb11-24"><a href="#cb11-24" tabindex="-1"></a>        <span class="va">self</span>.graph_conv <span class="op">=</span> GraphConv(</span>
<span id="cb11-25"><a href="#cb11-25" tabindex="-1"></a>            in_feat, out_feat, graph_info, <span class="op">**</span>graph_conv_params</span>
<span id="cb11-26"><a href="#cb11-26" tabindex="-1"></a>        )</span>
<span id="cb11-27"><a href="#cb11-27" tabindex="-1"></a></span>
<span id="cb11-28"><a href="#cb11-28" tabindex="-1"></a>        <span class="va">self</span>.lstm <span class="op">=</span> layers.LSTM(lstm_units, activation<span class="op">=</span><span class="st">"relu"</span>)</span>
<span id="cb11-29"><a href="#cb11-29" tabindex="-1"></a>        <span class="va">self</span>.dense <span class="op">=</span> layers.Dense(output_seq_len)</span>
<span id="cb11-30"><a href="#cb11-30" tabindex="-1"></a></span>
<span id="cb11-31"><a href="#cb11-31" tabindex="-1"></a>        <span class="va">self</span>.input_seq_len, <span class="va">self</span>.output_seq_len <span class="op">=</span> input_seq_len, output_seq_len</span>
<span id="cb11-32"><a href="#cb11-32" tabindex="-1"></a></span>
<span id="cb11-33"><a href="#cb11-33" tabindex="-1"></a>    <span class="kw">def</span> call(<span class="va">self</span>, inputs):</span>
<span id="cb11-34"><a href="#cb11-34" tabindex="-1"></a>        <span class="co">"""Forward pass.</span></span>
<span id="cb11-35"><a href="#cb11-35" tabindex="-1"></a></span>
<span id="cb11-36"><a href="#cb11-36" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb11-37"><a href="#cb11-37" tabindex="-1"></a><span class="co">            inputs: tf.Tensor of shape `(batch_size, input_seq_len, num_nodes, in_feat)`</span></span>
<span id="cb11-38"><a href="#cb11-38" tabindex="-1"></a></span>
<span id="cb11-39"><a href="#cb11-39" tabindex="-1"></a><span class="co">        Returns:</span></span>
<span id="cb11-40"><a href="#cb11-40" tabindex="-1"></a><span class="co">            A tensor of shape `(batch_size, output_seq_len, num_nodes)`.</span></span>
<span id="cb11-41"><a href="#cb11-41" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb11-42"><a href="#cb11-42" tabindex="-1"></a></span>
<span id="cb11-43"><a href="#cb11-43" tabindex="-1"></a>        <span class="co"># convert shape to  (num_nodes, batch_size, input_seq_len, in_feat)</span></span>
<span id="cb11-44"><a href="#cb11-44" tabindex="-1"></a>        inputs <span class="op">=</span> tf.transpose(inputs, [<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">3</span>])</span>
<span id="cb11-45"><a href="#cb11-45" tabindex="-1"></a></span>
<span id="cb11-46"><a href="#cb11-46" tabindex="-1"></a>        gcn_out <span class="op">=</span> <span class="va">self</span>.graph_conv(</span>
<span id="cb11-47"><a href="#cb11-47" tabindex="-1"></a>            inputs</span>
<span id="cb11-48"><a href="#cb11-48" tabindex="-1"></a>        )  <span class="co"># gcn_out has shape: (num_nodes, batch_size, input_seq_len, out_feat)</span></span>
<span id="cb11-49"><a href="#cb11-49" tabindex="-1"></a>        shape <span class="op">=</span> tf.shape(gcn_out)</span>
<span id="cb11-50"><a href="#cb11-50" tabindex="-1"></a>        num_nodes, batch_size, input_seq_len, out_feat <span class="op">=</span> (</span>
<span id="cb11-51"><a href="#cb11-51" tabindex="-1"></a>            shape[<span class="dv">0</span>],</span>
<span id="cb11-52"><a href="#cb11-52" tabindex="-1"></a>            shape[<span class="dv">1</span>],</span>
<span id="cb11-53"><a href="#cb11-53" tabindex="-1"></a>            shape[<span class="dv">2</span>],</span>
<span id="cb11-54"><a href="#cb11-54" tabindex="-1"></a>            shape[<span class="dv">3</span>],</span>
<span id="cb11-55"><a href="#cb11-55" tabindex="-1"></a>        )</span>
<span id="cb11-56"><a href="#cb11-56" tabindex="-1"></a></span>
<span id="cb11-57"><a href="#cb11-57" tabindex="-1"></a>        <span class="co"># LSTM takes only 3D tensors as input</span></span>
<span id="cb11-58"><a href="#cb11-58" tabindex="-1"></a>        gcn_out <span class="op">=</span> tf.reshape(</span>
<span id="cb11-59"><a href="#cb11-59" tabindex="-1"></a>            gcn_out, (batch_size <span class="op">*</span> num_nodes, input_seq_len, out_feat)</span>
<span id="cb11-60"><a href="#cb11-60" tabindex="-1"></a>        )</span>
<span id="cb11-61"><a href="#cb11-61" tabindex="-1"></a>        lstm_out <span class="op">=</span> <span class="va">self</span>.lstm(</span>
<span id="cb11-62"><a href="#cb11-62" tabindex="-1"></a>            gcn_out</span>
<span id="cb11-63"><a href="#cb11-63" tabindex="-1"></a>        )  <span class="co"># lstm_out has shape: (batch_size * num_nodes, lstm_units)</span></span>
<span id="cb11-64"><a href="#cb11-64" tabindex="-1"></a></span>
<span id="cb11-65"><a href="#cb11-65" tabindex="-1"></a>        dense_output <span class="op">=</span> <span class="va">self</span>.dense(</span>
<span id="cb11-66"><a href="#cb11-66" tabindex="-1"></a>            lstm_out</span>
<span id="cb11-67"><a href="#cb11-67" tabindex="-1"></a>        )  <span class="co"># dense_output has shape: (batch_size * num_nodes, output_seq_len)</span></span>
<span id="cb11-68"><a href="#cb11-68" tabindex="-1"></a>        output <span class="op">=</span> tf.reshape(</span>
<span id="cb11-69"><a href="#cb11-69" tabindex="-1"></a>            dense_output, (num_nodes, batch_size, <span class="va">self</span>.output_seq_len)</span>
<span id="cb11-70"><a href="#cb11-70" tabindex="-1"></a>        )</span>
<span id="cb11-71"><a href="#cb11-71" tabindex="-1"></a>        <span class="cf">return</span> tf.transpose(</span>
<span id="cb11-72"><a href="#cb11-72" tabindex="-1"></a>            output, [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>]</span>
<span id="cb11-73"><a href="#cb11-73" tabindex="-1"></a>        )  <span class="co"># returns Tensor of shape (batch_size, output_seq_len, num_nodes)</span></span></code></pre></div>
</div>
</div>
<div class="section level2">
<h2 id="model-training">Model training<a class="anchor" aria-label="anchor" href="#model-training"></a>
</h2>
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a>in_feat <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a>input_sequence_length <span class="op">=</span> <span class="dv">12</span></span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a>forecast_horizon <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a>multi_horizon <span class="op">=</span> <span class="va">False</span></span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a>out_feat <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb12-8"><a href="#cb12-8" tabindex="-1"></a>lstm_units <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb12-9"><a href="#cb12-9" tabindex="-1"></a>graph_conv_params <span class="op">=</span> {</span>
<span id="cb12-10"><a href="#cb12-10" tabindex="-1"></a>    <span class="st">"aggregation_type"</span>: <span class="st">"mean"</span>,</span>
<span id="cb12-11"><a href="#cb12-11" tabindex="-1"></a>    <span class="st">"combination_type"</span>: <span class="st">"concat"</span>,</span>
<span id="cb12-12"><a href="#cb12-12" tabindex="-1"></a>    <span class="st">"activation"</span>: <span class="va">None</span>,</span>
<span id="cb12-13"><a href="#cb12-13" tabindex="-1"></a>}</span>
<span id="cb12-14"><a href="#cb12-14" tabindex="-1"></a></span>
<span id="cb12-15"><a href="#cb12-15" tabindex="-1"></a>st_gcn <span class="op">=</span> LSTMGC(</span>
<span id="cb12-16"><a href="#cb12-16" tabindex="-1"></a>    in_feat,</span>
<span id="cb12-17"><a href="#cb12-17" tabindex="-1"></a>    out_feat,</span>
<span id="cb12-18"><a href="#cb12-18" tabindex="-1"></a>    lstm_units,</span>
<span id="cb12-19"><a href="#cb12-19" tabindex="-1"></a>    input_sequence_length,</span>
<span id="cb12-20"><a href="#cb12-20" tabindex="-1"></a>    forecast_horizon,</span>
<span id="cb12-21"><a href="#cb12-21" tabindex="-1"></a>    graph,</span>
<span id="cb12-22"><a href="#cb12-22" tabindex="-1"></a>    graph_conv_params,</span>
<span id="cb12-23"><a href="#cb12-23" tabindex="-1"></a>)</span>
<span id="cb12-24"><a href="#cb12-24" tabindex="-1"></a>inputs <span class="op">=</span> layers.Input((input_sequence_length, graph.num_nodes, in_feat))</span>
<span id="cb12-25"><a href="#cb12-25" tabindex="-1"></a>outputs <span class="op">=</span> st_gcn(inputs)</span>
<span id="cb12-26"><a href="#cb12-26" tabindex="-1"></a></span>
<span id="cb12-27"><a href="#cb12-27" tabindex="-1"></a>model <span class="op">=</span> keras.models.Model(inputs, outputs)</span>
<span id="cb12-28"><a href="#cb12-28" tabindex="-1"></a>model.<span class="bu">compile</span>(</span>
<span id="cb12-29"><a href="#cb12-29" tabindex="-1"></a>    optimizer<span class="op">=</span>keras.optimizers.RMSprop(learning_rate<span class="op">=</span><span class="fl">0.0002</span>),</span>
<span id="cb12-30"><a href="#cb12-30" tabindex="-1"></a>    loss<span class="op">=</span>keras.losses.MeanSquaredError(),</span>
<span id="cb12-31"><a href="#cb12-31" tabindex="-1"></a>)</span>
<span id="cb12-32"><a href="#cb12-32" tabindex="-1"></a>model.fit(</span>
<span id="cb12-33"><a href="#cb12-33" tabindex="-1"></a>    train_dataset,</span>
<span id="cb12-34"><a href="#cb12-34" tabindex="-1"></a>    validation_data<span class="op">=</span>val_dataset,</span>
<span id="cb12-35"><a href="#cb12-35" tabindex="-1"></a>    epochs<span class="op">=</span>epochs,</span>
<span id="cb12-36"><a href="#cb12-36" tabindex="-1"></a>    callbacks<span class="op">=</span>[keras.callbacks.EarlyStopping(patience<span class="op">=</span><span class="dv">10</span>)],</span>
<span id="cb12-37"><a href="#cb12-37" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="making-forecasts-on-test-set">Making forecasts on test set<a class="anchor" aria-label="anchor" href="#making-forecasts-on-test-set"></a>
</h2>
<p>Now we can use the trained model to make forecasts for the test set.
Below, we compute the MAE of the model and compare it to the MAE of
naive forecasts. The naive forecasts are the last value of the speed for
each node.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a>x_test, y <span class="op">=</span> <span class="bu">next</span>(test_dataset.as_numpy_iterator())</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a>y_pred <span class="op">=</span> model.predict(x_test)</span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">18</span>, <span class="dv">6</span>))</span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a>plt.plot(y[:, <span class="dv">0</span>, <span class="dv">0</span>])</span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a>plt.plot(y_pred[:, <span class="dv">0</span>, <span class="dv">0</span>])</span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a>plt.legend([<span class="st">"actual"</span>, <span class="st">"forecast"</span>])</span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a></span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a>naive_mse, model_mse <span class="op">=</span> (</span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a>    np.square(x_test[:, <span class="op">-</span><span class="dv">1</span>, :, <span class="dv">0</span>] <span class="op">-</span> y[:, <span class="dv">0</span>, :]).mean(),</span>
<span id="cb13-10"><a href="#cb13-10" tabindex="-1"></a>    np.square(y_pred[:, <span class="dv">0</span>, :] <span class="op">-</span> y[:, <span class="dv">0</span>, :]).mean(),</span>
<span id="cb13-11"><a href="#cb13-11" tabindex="-1"></a>)</span>
<span id="cb13-12"><a href="#cb13-12" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"naive MAE: </span><span class="sc">{</span>naive_mse<span class="sc">}</span><span class="ss">, model MAE: </span><span class="sc">{</span>model_mse<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div>
<p>Of course, the goal here is to demonstrate the method, not to achieve
the best performance. To improve the model’s accuracy, all model
hyperparameters should be tuned carefully. In addition, several of the
<code>LSTMGC</code> blocks can be stacked to increase the representation
power of the model.</p>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Tomasz Kalinowski, JJ Allaire, François Chollet, RStudio, Google.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
