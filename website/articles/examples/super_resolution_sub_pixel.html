<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="Implementing Super-Resolution using Efficient sub-pixel model on BSDS500.">
<title>Image Super-Resolution using an Efficient Sub-Pixel CNN • keras3</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../../apple-touch-icon-60x60.png">
<script src="../../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../../deps/Fira_Mono-0.4.7/font.css" rel="stylesheet">
<!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../../pkgdown.js"></script><meta property="og:title" content="Image Super-Resolution using an Efficient Sub-Pixel CNN">
<meta property="og:description" content="Implementing Super-Resolution using Efficient sub-pixel model on BSDS500.">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-inverse navbar-expand-lg bg-primary"><div class="container">
    
    <a class="navbar-brand me-2" href="../../index.html">keras3</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">2.13.0.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../../index.html">Home</a>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-getting-started">Getting Started</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-getting-started">
    <a class="dropdown-item" href="../../articles/intro_to_keras_for_engineers.html">Introduction to Keras for engineers</a>
    <h6 class="dropdown-header" data-toc-skip>Tutorials</h6>
    <a class="dropdown-item" href="../../articles/getting_started.html">Getting Started</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_classification.html">Basic Classification</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_text_classification.html">Text Classification</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_regression.html">Basic Regression</a>
    <a class="dropdown-item" href="../../articles/tutorial_overfit_underfit.html">Overfitting and Underfitting</a>
    <a class="dropdown-item" href="../../articles/tutorial_save_and_restore.html">Save and Restore Models</a>
  </div>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-guides">Guides</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-guides">
    <h6 class="dropdown-header" data-toc-skip>Model definition</h6>
    <a class="dropdown-item" href="../../articles/functional_api.html">Functional API</a>
    <a class="dropdown-item" href="../../articles/sequential_model.html">Sequential Model</a>
    <h6 class="dropdown-header" data-toc-skip>Extending and customizing</h6>
    <a class="dropdown-item" href="../../articles/making_new_layers_and_models_via_subclassing.html">Making new layers and models via subclassing</a>
    <a class="dropdown-item" href="../../articles/training_with_built_in_methods.html">Training &amp; evaluation with the built-in methods</a>
    <a class="dropdown-item" href="../../articles/writing_a_custom_training_loop_in_tensorflow.html">Writing a training loop from scratch in TensorFlow</a>
    <a class="dropdown-item" href="../../articles/writing_your_own_callbacks.html">Writing Your Own Callbacks</a>
    <h6 class="dropdown-header" data-toc-skip>Other topics</h6>
    <a class="dropdown-item" href="../../articles/transfer_learning.html">Transfer learning and fine tuning</a>
    <a class="dropdown-item" href="../../articles/distributed_training_with_tensorflow.html">Distributed training with TensorFlow</a>
  </div>
</li>
<li class="active nav-item">
  <a class="nav-link" href="../../articles/examples/index.html">Examples</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../reference/index.html">Reference</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../news/index.html">News</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/rstudio/keras/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Image Super-Resolution using an Efficient Sub-Pixel CNN</h1>
                        <h4 data-toc-skip class="author"><a href="https://github.com/xingyu-long" class="external-link">Xingyu Long</a></h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/rstudio/keras/blob/HEAD/vignettes/examples/super_resolution_sub_pixel.Rmd" class="external-link"><code>vignettes/examples/super_resolution_sub_pixel.Rmd</code></a></small>
      <div class="d-none name"><code>super_resolution_sub_pixel.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>ESPCN (Efficient Sub-Pixel CNN), proposed by <a href="https://arxiv.org/abs/1609.05158" class="external-link">Shi, 2016</a> is a model that
reconstructs a high-resolution version of an image given a
low-resolution version. It leverages efficient “sub-pixel convolution”
layers, which learns an array of image upscaling filters.</p>
<p>In this code example, we will implement the model from the paper and
train it on a small dataset, <a href="https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/resources.html" class="external-link">BSDS500</a>.
<a href="https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/resources.html" class="external-link">BSDS500</a>.</p>
</div>
<div class="section level2">
<h2 id="setup">Setup<a class="anchor" aria-label="anchor" href="#setup"></a>
</h2>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> keras <span class="im">as</span> keras</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">from</span> keras <span class="im">import</span> layers</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">from</span> keras <span class="im">import</span> ops</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">from</span> keras.utils <span class="im">import</span> load_img</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="im">from</span> keras.utils <span class="im">import</span> array_to_img</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="im">from</span> keras.utils <span class="im">import</span> img_to_array</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="im">from</span> keras.preprocessing <span class="im">import</span> image_dataset_from_directory</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf  <span class="co">#  only for data preprocessing</span></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> display</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="load-data-bsds500-dataset">Load data: BSDS500 dataset<a class="anchor" aria-label="anchor" href="#load-data-bsds500-dataset"></a>
</h2>
<div class="section level3">
<h3 id="download-dataset">Download dataset<a class="anchor" aria-label="anchor" href="#download-dataset"></a>
</h3>
<p>We use the built-in <code>keras.utils.get_file</code> utility to
retrieve the dataset.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>dataset_url <span class="op">=</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="co">"http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/BSR/BSR_bsds500.tgz"</span></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>data_dir <span class="op">=</span> keras.utils.get_file(origin<span class="op">=</span>dataset_url, fname<span class="op">=</span><span class="st">"BSR"</span>, untar<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>root_dir <span class="op">=</span> os.path.join(data_dir, <span class="st">"BSDS500/data"</span>)</span></code></pre></div>
<p>We create training and validation datasets via
<code>image_dataset_from_directory</code>.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>crop_size <span class="op">=</span> <span class="dv">300</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>upscale_factor <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>input_size <span class="op">=</span> crop_size <span class="op">//</span> upscale_factor</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a>train_ds <span class="op">=</span> image_dataset_from_directory(</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a>    root_dir,</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>    batch_size<span class="op">=</span>batch_size,</span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a>    image_size<span class="op">=</span>(crop_size, crop_size),</span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a>    validation_split<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a>    subset<span class="op">=</span><span class="st">"training"</span>,</span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a>    seed<span class="op">=</span><span class="dv">1337</span>,</span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a>    label_mode<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a>)</span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a>valid_ds <span class="op">=</span> image_dataset_from_directory(</span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a>    root_dir,</span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a>    batch_size<span class="op">=</span>batch_size,</span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a>    image_size<span class="op">=</span>(crop_size, crop_size),</span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a>    validation_split<span class="op">=</span><span class="fl">0.2</span>,</span>
<span id="cb3-21"><a href="#cb3-21" tabindex="-1"></a>    subset<span class="op">=</span><span class="st">"validation"</span>,</span>
<span id="cb3-22"><a href="#cb3-22" tabindex="-1"></a>    seed<span class="op">=</span><span class="dv">1337</span>,</span>
<span id="cb3-23"><a href="#cb3-23" tabindex="-1"></a>    label_mode<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb3-24"><a href="#cb3-24" tabindex="-1"></a>)</span></code></pre></div>
<p>We rescale the images to take values in the range [0, 1].</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="kw">def</span> scaling(input_image):</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>    input_image <span class="op">=</span> input_image <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>    <span class="cf">return</span> input_image</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a><span class="co"># Scale from (0, 255) to (0, 1)</span></span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>train_ds <span class="op">=</span> train_ds.<span class="bu">map</span>(scaling)</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a>valid_ds <span class="op">=</span> valid_ds.<span class="bu">map</span>(scaling)</span></code></pre></div>
<p>Let’s visualize a few sample images:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="cf">for</span> batch <span class="kw">in</span> train_ds.take(<span class="dv">1</span>):</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>    <span class="cf">for</span> img <span class="kw">in</span> batch:</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>        display(array_to_img(img))</span></code></pre></div>
<p>We prepare a dataset of test image paths that we will use for visual
evaluation at the end of this example.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>dataset <span class="op">=</span> os.path.join(root_dir, <span class="st">"images"</span>)</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>test_path <span class="op">=</span> os.path.join(dataset, <span class="st">"test"</span>)</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a>test_img_paths <span class="op">=</span> <span class="bu">sorted</span>(</span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a>    [</span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>        os.path.join(test_path, fname)</span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a>        <span class="cf">for</span> fname <span class="kw">in</span> os.listdir(test_path)</span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a>        <span class="cf">if</span> fname.endswith(<span class="st">".jpg"</span>)</span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a>    ]</span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a>)</span></code></pre></div>
</div>
</div>
<div class="section level2">
<h2 id="crop-and-resize-images">Crop and resize images<a class="anchor" aria-label="anchor" href="#crop-and-resize-images"></a>
</h2>
<p>Let’s process image data. First, we convert our images from the RGB
color space to the <a href="https://en.wikipedia.org/wiki/YUV" class="external-link">YUV
colour space</a>.</p>
<p>For the input data (low-resolution images), we crop the image,
retrieve the <code>y</code> channel (luninance), and resize it with the
<code>area</code> method (use <code>BICUBIC</code> if you use PIL). We
only consider the luminance channel in the YUV color space because
humans are more sensitive to luminance change.</p>
<p>For the target data (high-resolution images), we just crop the image
and retrieve the <code>y</code> channel.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="co"># Use TF Ops to process.</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a><span class="kw">def</span> process_input(<span class="bu">input</span>, input_size, upscale_factor):</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>    <span class="bu">input</span> <span class="op">=</span> tf.image.rgb_to_yuv(<span class="bu">input</span>)</span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>    last_dimension_axis <span class="op">=</span> <span class="bu">len</span>(<span class="bu">input</span>.shape) <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>    y, u, v <span class="op">=</span> tf.split(<span class="bu">input</span>, <span class="dv">3</span>, axis<span class="op">=</span>last_dimension_axis)</span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a>    <span class="cf">return</span> tf.image.resize(y, [input_size, input_size], method<span class="op">=</span><span class="st">"area"</span>)</span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a><span class="kw">def</span> process_target(<span class="bu">input</span>):</span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a>    <span class="bu">input</span> <span class="op">=</span> tf.image.rgb_to_yuv(<span class="bu">input</span>)</span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a>    last_dimension_axis <span class="op">=</span> <span class="bu">len</span>(<span class="bu">input</span>.shape) <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a>    y, u, v <span class="op">=</span> tf.split(<span class="bu">input</span>, <span class="dv">3</span>, axis<span class="op">=</span>last_dimension_axis)</span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a>    <span class="cf">return</span> y</span>
<span id="cb7-14"><a href="#cb7-14" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" tabindex="-1"></a></span>
<span id="cb7-16"><a href="#cb7-16" tabindex="-1"></a>train_ds <span class="op">=</span> train_ds.<span class="bu">map</span>(</span>
<span id="cb7-17"><a href="#cb7-17" tabindex="-1"></a>    <span class="kw">lambda</span> x: (process_input(x, input_size, upscale_factor), process_target(x))</span>
<span id="cb7-18"><a href="#cb7-18" tabindex="-1"></a>)</span>
<span id="cb7-19"><a href="#cb7-19" tabindex="-1"></a>train_ds <span class="op">=</span> train_ds.prefetch(buffer_size<span class="op">=</span><span class="dv">32</span>)</span>
<span id="cb7-20"><a href="#cb7-20" tabindex="-1"></a></span>
<span id="cb7-21"><a href="#cb7-21" tabindex="-1"></a>valid_ds <span class="op">=</span> valid_ds.<span class="bu">map</span>(</span>
<span id="cb7-22"><a href="#cb7-22" tabindex="-1"></a>    <span class="kw">lambda</span> x: (process_input(x, input_size, upscale_factor), process_target(x))</span>
<span id="cb7-23"><a href="#cb7-23" tabindex="-1"></a>)</span>
<span id="cb7-24"><a href="#cb7-24" tabindex="-1"></a>valid_ds <span class="op">=</span> valid_ds.prefetch(buffer_size<span class="op">=</span><span class="dv">32</span>)</span></code></pre></div>
<p>Let’s take a look at the input and target data.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="cf">for</span> batch <span class="kw">in</span> train_ds.take(<span class="dv">1</span>):</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>    <span class="cf">for</span> img <span class="kw">in</span> batch[<span class="dv">0</span>]:</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>        display(array_to_img(img))</span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>    <span class="cf">for</span> img <span class="kw">in</span> batch[<span class="dv">1</span>]:</span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a>        display(array_to_img(img))</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="build-a-model">Build a model<a class="anchor" aria-label="anchor" href="#build-a-model"></a>
</h2>
<p>Compared to the paper, we add one more layer and we use the
<code>relu</code> activation function instead of <code>tanh</code>. It
achieves better performance even though we train the model for fewer
epochs.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="kw">class</span> DepthToSpace(layers.Layer):</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, block_size):</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>        <span class="va">self</span>.block_size <span class="op">=</span> block_size</span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a>    <span class="kw">def</span> call(<span class="va">self</span>, <span class="bu">input</span>):</span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a>        batch, height, width, depth <span class="op">=</span> ops.shape(<span class="bu">input</span>)</span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a>        depth <span class="op">=</span> depth <span class="op">//</span> (<span class="va">self</span>.block_size<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a></span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a>        x <span class="op">=</span> ops.reshape(</span>
<span id="cb9-11"><a href="#cb9-11" tabindex="-1"></a>            <span class="bu">input</span>, [batch, height, width, <span class="va">self</span>.block_size, <span class="va">self</span>.block_size, depth]</span>
<span id="cb9-12"><a href="#cb9-12" tabindex="-1"></a>        )</span>
<span id="cb9-13"><a href="#cb9-13" tabindex="-1"></a>        x <span class="op">=</span> ops.transpose(x, [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">5</span>])</span>
<span id="cb9-14"><a href="#cb9-14" tabindex="-1"></a>        x <span class="op">=</span> ops.reshape(</span>
<span id="cb9-15"><a href="#cb9-15" tabindex="-1"></a>            x, [batch, height <span class="op">*</span> <span class="va">self</span>.block_size, width <span class="op">*</span> <span class="va">self</span>.block_size, depth]</span>
<span id="cb9-16"><a href="#cb9-16" tabindex="-1"></a>        )</span>
<span id="cb9-17"><a href="#cb9-17" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb9-18"><a href="#cb9-18" tabindex="-1"></a></span>
<span id="cb9-19"><a href="#cb9-19" tabindex="-1"></a></span>
<span id="cb9-20"><a href="#cb9-20" tabindex="-1"></a><span class="kw">def</span> get_model(upscale_factor<span class="op">=</span><span class="dv">3</span>, channels<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb9-21"><a href="#cb9-21" tabindex="-1"></a>    conv_args <span class="op">=</span> {</span>
<span id="cb9-22"><a href="#cb9-22" tabindex="-1"></a>        <span class="st">"activation"</span>: <span class="st">"relu"</span>,</span>
<span id="cb9-23"><a href="#cb9-23" tabindex="-1"></a>        <span class="st">"kernel_initializer"</span>: <span class="st">"orthogonal"</span>,</span>
<span id="cb9-24"><a href="#cb9-24" tabindex="-1"></a>        <span class="st">"padding"</span>: <span class="st">"same"</span>,</span>
<span id="cb9-25"><a href="#cb9-25" tabindex="-1"></a>    }</span>
<span id="cb9-26"><a href="#cb9-26" tabindex="-1"></a>    inputs <span class="op">=</span> keras.Input(shape<span class="op">=</span>(<span class="va">None</span>, <span class="va">None</span>, channels))</span>
<span id="cb9-27"><a href="#cb9-27" tabindex="-1"></a>    x <span class="op">=</span> layers.Conv2D(<span class="dv">64</span>, <span class="dv">5</span>, <span class="op">**</span>conv_args)(inputs)</span>
<span id="cb9-28"><a href="#cb9-28" tabindex="-1"></a>    x <span class="op">=</span> layers.Conv2D(<span class="dv">64</span>, <span class="dv">3</span>, <span class="op">**</span>conv_args)(x)</span>
<span id="cb9-29"><a href="#cb9-29" tabindex="-1"></a>    x <span class="op">=</span> layers.Conv2D(<span class="dv">32</span>, <span class="dv">3</span>, <span class="op">**</span>conv_args)(x)</span>
<span id="cb9-30"><a href="#cb9-30" tabindex="-1"></a>    x <span class="op">=</span> layers.Conv2D(channels <span class="op">*</span> (upscale_factor<span class="op">**</span><span class="dv">2</span>), <span class="dv">3</span>, <span class="op">**</span>conv_args)(x)</span>
<span id="cb9-31"><a href="#cb9-31" tabindex="-1"></a>    outputs <span class="op">=</span> DepthToSpace(upscale_factor)(x)</span>
<span id="cb9-32"><a href="#cb9-32" tabindex="-1"></a></span>
<span id="cb9-33"><a href="#cb9-33" tabindex="-1"></a>    <span class="cf">return</span> keras.Model(inputs, outputs)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="define-utility-functions">Define utility functions<a class="anchor" aria-label="anchor" href="#define-utility-functions"></a>
</h2>
<p>We need to define several utility functions to monitor our
results:</p>
<ul>
<li>
<code>plot_results</code> to plot an save an image.</li>
<li>
<code>get_lowres_image</code> to convert an image to its
low-resolution version.</li>
<li>
<code>upscale_image</code> to turn a low-resolution image to a
high-resolution version reconstructed by the model. In this function, we
use the <code>y</code> channel from the YUV color space as input to the
model and then combine the output with the other channels to obtain an
RGB image.</li>
</ul>
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a><span class="im">from</span> mpl_toolkits.axes_grid1.inset_locator <span class="im">import</span> zoomed_inset_axes</span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a><span class="im">from</span> mpl_toolkits.axes_grid1.inset_locator <span class="im">import</span> mark_inset</span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a><span class="im">import</span> PIL</span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a><span class="kw">def</span> plot_results(img, prefix, title):</span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a>    <span class="co">"""Plot the result with zoom-in area."""</span></span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a>    img_array <span class="op">=</span> img_to_array(img)</span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a>    img_array <span class="op">=</span> img_array.astype(<span class="st">"float32"</span>) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a></span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a>    <span class="co"># Create a new figure with a default 111 subplot.</span></span>
<span id="cb10-13"><a href="#cb10-13" tabindex="-1"></a>    fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb10-14"><a href="#cb10-14" tabindex="-1"></a>    im <span class="op">=</span> ax.imshow(img_array[::<span class="op">-</span><span class="dv">1</span>], origin<span class="op">=</span><span class="st">"lower"</span>)</span>
<span id="cb10-15"><a href="#cb10-15" tabindex="-1"></a></span>
<span id="cb10-16"><a href="#cb10-16" tabindex="-1"></a>    plt.title(title)</span>
<span id="cb10-17"><a href="#cb10-17" tabindex="-1"></a>    <span class="co"># zoom-factor: 2.0, location: upper-left</span></span>
<span id="cb10-18"><a href="#cb10-18" tabindex="-1"></a>    axins <span class="op">=</span> zoomed_inset_axes(ax, <span class="dv">2</span>, loc<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb10-19"><a href="#cb10-19" tabindex="-1"></a>    axins.imshow(img_array[::<span class="op">-</span><span class="dv">1</span>], origin<span class="op">=</span><span class="st">"lower"</span>)</span>
<span id="cb10-20"><a href="#cb10-20" tabindex="-1"></a></span>
<span id="cb10-21"><a href="#cb10-21" tabindex="-1"></a>    <span class="co"># Specify the limits.</span></span>
<span id="cb10-22"><a href="#cb10-22" tabindex="-1"></a>    x1, x2, y1, y2 <span class="op">=</span> <span class="dv">200</span>, <span class="dv">300</span>, <span class="dv">100</span>, <span class="dv">200</span></span>
<span id="cb10-23"><a href="#cb10-23" tabindex="-1"></a>    <span class="co"># Apply the x-limits.</span></span>
<span id="cb10-24"><a href="#cb10-24" tabindex="-1"></a>    axins.set_xlim(x1, x2)</span>
<span id="cb10-25"><a href="#cb10-25" tabindex="-1"></a>    <span class="co"># Apply the y-limits.</span></span>
<span id="cb10-26"><a href="#cb10-26" tabindex="-1"></a>    axins.set_ylim(y1, y2)</span>
<span id="cb10-27"><a href="#cb10-27" tabindex="-1"></a></span>
<span id="cb10-28"><a href="#cb10-28" tabindex="-1"></a>    plt.yticks(visible<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb10-29"><a href="#cb10-29" tabindex="-1"></a>    plt.xticks(visible<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb10-30"><a href="#cb10-30" tabindex="-1"></a></span>
<span id="cb10-31"><a href="#cb10-31" tabindex="-1"></a>    <span class="co"># Make the line.</span></span>
<span id="cb10-32"><a href="#cb10-32" tabindex="-1"></a>    mark_inset(ax, axins, loc1<span class="op">=</span><span class="dv">1</span>, loc2<span class="op">=</span><span class="dv">3</span>, fc<span class="op">=</span><span class="st">"none"</span>, ec<span class="op">=</span><span class="st">"blue"</span>)</span>
<span id="cb10-33"><a href="#cb10-33" tabindex="-1"></a>    plt.savefig(<span class="bu">str</span>(prefix) <span class="op">+</span> <span class="st">"-"</span> <span class="op">+</span> title <span class="op">+</span> <span class="st">".png"</span>)</span>
<span id="cb10-34"><a href="#cb10-34" tabindex="-1"></a>    plt.show()</span>
<span id="cb10-35"><a href="#cb10-35" tabindex="-1"></a></span>
<span id="cb10-36"><a href="#cb10-36" tabindex="-1"></a></span>
<span id="cb10-37"><a href="#cb10-37" tabindex="-1"></a><span class="kw">def</span> get_lowres_image(img, upscale_factor):</span>
<span id="cb10-38"><a href="#cb10-38" tabindex="-1"></a>    <span class="co">"""Return low-resolution image to use as model input."""</span></span>
<span id="cb10-39"><a href="#cb10-39" tabindex="-1"></a>    <span class="cf">return</span> img.resize(</span>
<span id="cb10-40"><a href="#cb10-40" tabindex="-1"></a>        (img.size[<span class="dv">0</span>] <span class="op">//</span> upscale_factor, img.size[<span class="dv">1</span>] <span class="op">//</span> upscale_factor),</span>
<span id="cb10-41"><a href="#cb10-41" tabindex="-1"></a>        PIL.Image.BICUBIC,</span>
<span id="cb10-42"><a href="#cb10-42" tabindex="-1"></a>    )</span>
<span id="cb10-43"><a href="#cb10-43" tabindex="-1"></a></span>
<span id="cb10-44"><a href="#cb10-44" tabindex="-1"></a></span>
<span id="cb10-45"><a href="#cb10-45" tabindex="-1"></a><span class="kw">def</span> upscale_image(model, img):</span>
<span id="cb10-46"><a href="#cb10-46" tabindex="-1"></a>    <span class="co">"""Predict the result based on input image and restore the image as RGB."""</span></span>
<span id="cb10-47"><a href="#cb10-47" tabindex="-1"></a>    ycbcr <span class="op">=</span> img.convert(<span class="st">"YCbCr"</span>)</span>
<span id="cb10-48"><a href="#cb10-48" tabindex="-1"></a>    y, cb, cr <span class="op">=</span> ycbcr.split()</span>
<span id="cb10-49"><a href="#cb10-49" tabindex="-1"></a>    y <span class="op">=</span> img_to_array(y)</span>
<span id="cb10-50"><a href="#cb10-50" tabindex="-1"></a>    y <span class="op">=</span> y.astype(<span class="st">"float32"</span>) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb10-51"><a href="#cb10-51" tabindex="-1"></a></span>
<span id="cb10-52"><a href="#cb10-52" tabindex="-1"></a>    <span class="bu">input</span> <span class="op">=</span> np.expand_dims(y, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb10-53"><a href="#cb10-53" tabindex="-1"></a>    out <span class="op">=</span> model.predict(<span class="bu">input</span>)</span>
<span id="cb10-54"><a href="#cb10-54" tabindex="-1"></a></span>
<span id="cb10-55"><a href="#cb10-55" tabindex="-1"></a>    out_img_y <span class="op">=</span> out[<span class="dv">0</span>]</span>
<span id="cb10-56"><a href="#cb10-56" tabindex="-1"></a>    out_img_y <span class="op">*=</span> <span class="fl">255.0</span></span>
<span id="cb10-57"><a href="#cb10-57" tabindex="-1"></a></span>
<span id="cb10-58"><a href="#cb10-58" tabindex="-1"></a>    <span class="co"># Restore the image in RGB color space.</span></span>
<span id="cb10-59"><a href="#cb10-59" tabindex="-1"></a>    out_img_y <span class="op">=</span> out_img_y.clip(<span class="dv">0</span>, <span class="dv">255</span>)</span>
<span id="cb10-60"><a href="#cb10-60" tabindex="-1"></a>    out_img_y <span class="op">=</span> out_img_y.reshape((np.shape(out_img_y)[<span class="dv">0</span>], np.shape(out_img_y)[<span class="dv">1</span>]))</span>
<span id="cb10-61"><a href="#cb10-61" tabindex="-1"></a>    out_img_y <span class="op">=</span> PIL.Image.fromarray(np.uint8(out_img_y), mode<span class="op">=</span><span class="st">"L"</span>)</span>
<span id="cb10-62"><a href="#cb10-62" tabindex="-1"></a>    out_img_cb <span class="op">=</span> cb.resize(out_img_y.size, PIL.Image.BICUBIC)</span>
<span id="cb10-63"><a href="#cb10-63" tabindex="-1"></a>    out_img_cr <span class="op">=</span> cr.resize(out_img_y.size, PIL.Image.BICUBIC)</span>
<span id="cb10-64"><a href="#cb10-64" tabindex="-1"></a>    out_img <span class="op">=</span> PIL.Image.merge(<span class="st">"YCbCr"</span>, (out_img_y, out_img_cb, out_img_cr)).convert(</span>
<span id="cb10-65"><a href="#cb10-65" tabindex="-1"></a>        <span class="st">"RGB"</span></span>
<span id="cb10-66"><a href="#cb10-66" tabindex="-1"></a>    )</span>
<span id="cb10-67"><a href="#cb10-67" tabindex="-1"></a>    <span class="cf">return</span> out_img</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="define-callbacks-to-monitor-training">Define callbacks to monitor training<a class="anchor" aria-label="anchor" href="#define-callbacks-to-monitor-training"></a>
</h2>
<p>The <code>ESPCNCallback</code> object will compute and display the <a href="https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio" class="external-link">PSNR</a>
metric. This is the main metric we use to evaluate super-resolution
performance.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="kw">class</span> ESPCNCallback(keras.callbacks.Callback):</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a>        <span class="va">self</span>.test_img <span class="op">=</span> get_lowres_image(load_img(test_img_paths[<span class="dv">0</span>]), upscale_factor)</span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a></span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a>    <span class="co"># Store PSNR value in each epoch.</span></span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a>    <span class="kw">def</span> on_epoch_begin(<span class="va">self</span>, epoch, logs<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a>        <span class="va">self</span>.psnr <span class="op">=</span> []</span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a></span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a>    <span class="kw">def</span> on_epoch_end(<span class="va">self</span>, epoch, logs<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb11-11"><a href="#cb11-11" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Mean PSNR for epoch: </span><span class="sc">%.2f</span><span class="st">"</span> <span class="op">%</span> (np.mean(<span class="va">self</span>.psnr)))</span>
<span id="cb11-12"><a href="#cb11-12" tabindex="-1"></a>        <span class="cf">if</span> epoch <span class="op">%</span> <span class="dv">20</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb11-13"><a href="#cb11-13" tabindex="-1"></a>            prediction <span class="op">=</span> upscale_image(<span class="va">self</span>.model, <span class="va">self</span>.test_img)</span>
<span id="cb11-14"><a href="#cb11-14" tabindex="-1"></a>            plot_results(prediction, <span class="st">"epoch-"</span> <span class="op">+</span> <span class="bu">str</span>(epoch), <span class="st">"prediction"</span>)</span>
<span id="cb11-15"><a href="#cb11-15" tabindex="-1"></a></span>
<span id="cb11-16"><a href="#cb11-16" tabindex="-1"></a>    <span class="kw">def</span> on_test_batch_end(<span class="va">self</span>, batch, logs<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb11-17"><a href="#cb11-17" tabindex="-1"></a>        <span class="va">self</span>.psnr.append(<span class="dv">10</span> <span class="op">*</span> math.log10(<span class="dv">1</span> <span class="op">/</span> logs[<span class="st">"loss"</span>]))</span></code></pre></div>
<p>Define <code>ModelCheckpoint</code> and <code>EarlyStopping</code>
callbacks.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a>early_stopping_callback <span class="op">=</span> keras.callbacks.EarlyStopping(monitor<span class="op">=</span><span class="st">"loss"</span>, patience<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>checkpoint_filepath <span class="op">=</span> <span class="st">"/tmp/checkpoint.keras"</span></span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a>model_checkpoint_callback <span class="op">=</span> keras.callbacks.ModelCheckpoint(</span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a>    filepath<span class="op">=</span>checkpoint_filepath,</span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a>    save_weights_only<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb12-8"><a href="#cb12-8" tabindex="-1"></a>    monitor<span class="op">=</span><span class="st">"loss"</span>,</span>
<span id="cb12-9"><a href="#cb12-9" tabindex="-1"></a>    mode<span class="op">=</span><span class="st">"min"</span>,</span>
<span id="cb12-10"><a href="#cb12-10" tabindex="-1"></a>    save_best_only<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb12-11"><a href="#cb12-11" tabindex="-1"></a>)</span>
<span id="cb12-12"><a href="#cb12-12" tabindex="-1"></a></span>
<span id="cb12-13"><a href="#cb12-13" tabindex="-1"></a>model <span class="op">=</span> get_model(upscale_factor<span class="op">=</span>upscale_factor, channels<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb12-14"><a href="#cb12-14" tabindex="-1"></a>model.summary()</span>
<span id="cb12-15"><a href="#cb12-15" tabindex="-1"></a></span>
<span id="cb12-16"><a href="#cb12-16" tabindex="-1"></a>callbacks <span class="op">=</span> [ESPCNCallback(), early_stopping_callback, model_checkpoint_callback]</span>
<span id="cb12-17"><a href="#cb12-17" tabindex="-1"></a>loss_fn <span class="op">=</span> keras.losses.MeanSquaredError()</span>
<span id="cb12-18"><a href="#cb12-18" tabindex="-1"></a>optimizer <span class="op">=</span> keras.optimizers.Adam(learning_rate<span class="op">=</span><span class="fl">0.001</span>)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="train-the-model">Train the model<a class="anchor" aria-label="anchor" href="#train-the-model"></a>
</h2>
<div class="sourceCode" id="cb13"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a>model.<span class="bu">compile</span>(</span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a>    optimizer<span class="op">=</span>optimizer,</span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a>    loss<span class="op">=</span>loss_fn,</span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a>)</span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a></span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a>model.fit(</span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a>    train_ds, epochs<span class="op">=</span>epochs, callbacks<span class="op">=</span>callbacks, validation_data<span class="op">=</span>valid_ds, verbose<span class="op">=</span><span class="dv">2</span></span>
<span id="cb13-10"><a href="#cb13-10" tabindex="-1"></a>)</span>
<span id="cb13-11"><a href="#cb13-11" tabindex="-1"></a></span>
<span id="cb13-12"><a href="#cb13-12" tabindex="-1"></a><span class="co"># The model weights (that are considered the best) are loaded into the model.</span></span>
<span id="cb13-13"><a href="#cb13-13" tabindex="-1"></a>model.load_weights(checkpoint_filepath)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="run-model-prediction-and-plot-the-results">Run model prediction and plot the results<a class="anchor" aria-label="anchor" href="#run-model-prediction-and-plot-the-results"></a>
</h2>
<p>Let’s compute the reconstructed version of a few images and save the
results.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a>total_bicubic_psnr <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a>total_test_psnr <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a><span class="cf">for</span> index, test_img_path <span class="kw">in</span> <span class="bu">enumerate</span>(test_img_paths[<span class="dv">50</span>:<span class="dv">60</span>]):</span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a>    img <span class="op">=</span> load_img(test_img_path)</span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a>    lowres_input <span class="op">=</span> get_lowres_image(img, upscale_factor)</span>
<span id="cb14-7"><a href="#cb14-7" tabindex="-1"></a>    w <span class="op">=</span> lowres_input.size[<span class="dv">0</span>] <span class="op">*</span> upscale_factor</span>
<span id="cb14-8"><a href="#cb14-8" tabindex="-1"></a>    h <span class="op">=</span> lowres_input.size[<span class="dv">1</span>] <span class="op">*</span> upscale_factor</span>
<span id="cb14-9"><a href="#cb14-9" tabindex="-1"></a>    highres_img <span class="op">=</span> img.resize((w, h))</span>
<span id="cb14-10"><a href="#cb14-10" tabindex="-1"></a>    prediction <span class="op">=</span> upscale_image(model, lowres_input)</span>
<span id="cb14-11"><a href="#cb14-11" tabindex="-1"></a>    lowres_img <span class="op">=</span> lowres_input.resize((w, h))</span>
<span id="cb14-12"><a href="#cb14-12" tabindex="-1"></a>    lowres_img_arr <span class="op">=</span> img_to_array(lowres_img)</span>
<span id="cb14-13"><a href="#cb14-13" tabindex="-1"></a>    highres_img_arr <span class="op">=</span> img_to_array(highres_img)</span>
<span id="cb14-14"><a href="#cb14-14" tabindex="-1"></a>    predict_img_arr <span class="op">=</span> img_to_array(prediction)</span>
<span id="cb14-15"><a href="#cb14-15" tabindex="-1"></a>    bicubic_psnr <span class="op">=</span> tf.image.psnr(lowres_img_arr, highres_img_arr, max_val<span class="op">=</span><span class="dv">255</span>)</span>
<span id="cb14-16"><a href="#cb14-16" tabindex="-1"></a>    test_psnr <span class="op">=</span> tf.image.psnr(predict_img_arr, highres_img_arr, max_val<span class="op">=</span><span class="dv">255</span>)</span>
<span id="cb14-17"><a href="#cb14-17" tabindex="-1"></a></span>
<span id="cb14-18"><a href="#cb14-18" tabindex="-1"></a>    total_bicubic_psnr <span class="op">+=</span> bicubic_psnr</span>
<span id="cb14-19"><a href="#cb14-19" tabindex="-1"></a>    total_test_psnr <span class="op">+=</span> test_psnr</span>
<span id="cb14-20"><a href="#cb14-20" tabindex="-1"></a></span>
<span id="cb14-21"><a href="#cb14-21" tabindex="-1"></a>    <span class="bu">print</span>(</span>
<span id="cb14-22"><a href="#cb14-22" tabindex="-1"></a>        <span class="st">"PSNR of low resolution image and high resolution image is </span><span class="sc">%.4f</span><span class="st">"</span> <span class="op">%</span> bicubic_psnr</span>
<span id="cb14-23"><a href="#cb14-23" tabindex="-1"></a>    )</span>
<span id="cb14-24"><a href="#cb14-24" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"PSNR of predict and high resolution is </span><span class="sc">%.4f</span><span class="st">"</span> <span class="op">%</span> test_psnr)</span>
<span id="cb14-25"><a href="#cb14-25" tabindex="-1"></a>    plot_results(lowres_img, index, <span class="st">"lowres"</span>)</span>
<span id="cb14-26"><a href="#cb14-26" tabindex="-1"></a>    plot_results(highres_img, index, <span class="st">"highres"</span>)</span>
<span id="cb14-27"><a href="#cb14-27" tabindex="-1"></a>    plot_results(prediction, index, <span class="st">"prediction"</span>)</span>
<span id="cb14-28"><a href="#cb14-28" tabindex="-1"></a></span>
<span id="cb14-29"><a href="#cb14-29" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Avg. PSNR of lowres images is </span><span class="sc">%.4f</span><span class="st">"</span> <span class="op">%</span> (total_bicubic_psnr <span class="op">/</span> <span class="dv">10</span>))</span>
<span id="cb14-30"><a href="#cb14-30" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Avg. PSNR of reconstructions is </span><span class="sc">%.4f</span><span class="st">"</span> <span class="op">%</span> (total_test_psnr <span class="op">/</span> <span class="dv">10</span>))</span></code></pre></div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Tomasz Kalinowski, JJ Allaire, François Chollet, Posit Software, PBC, Google.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
