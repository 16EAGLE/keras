<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="How to implement an OCR model using CNNs, RNNs and CTC loss.">
<title>OCR model for reading Captchas • keras</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../../apple-touch-icon-60x60.png">
<script src="../../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../../pkgdown.js"></script><link href="../../extra.css" rel="stylesheet">
<script src="../../extra.js"></script><meta property="og:title" content="OCR model for reading Captchas">
<meta property="og:description" content="How to implement an OCR model using CNNs, RNNs and CTC loss.">
<meta property="og:image" content="/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-inverse navbar-expand-lg bg-primary"><div class="container">
    
    <a class="navbar-brand me-2" href="../../index.html">keras</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">2.13.0.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../../index.html">Home</a>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-tutorials">Tutorials</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-tutorials">
    <a class="dropdown-item" href="../../articles/getting_started.html">Getting Started</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_classification.html">Basic Classification</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_text_classification.html">Text Classification</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_regression.html">Basic Regression</a>
    <a class="dropdown-item" href="../../articles/tutorial_overfit_underfit.html">Overfitting and Underfitting</a>
    <a class="dropdown-item" href="../../articles/tutorial_save_and_restore.html">Save and Restore Models</a>
  </div>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-guides">Guides</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-guides">
    <a class="dropdown-item" href="../../writing_your_own_callbacks.html">Writing Your Own Callbacks</a>
  </div>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <h6 class="dropdown-header" data-toc-skip>Guides (New for TF 2.6)</h6>
    <a class="dropdown-item" href="../../articles/new-guides/python_subclasses.html">Python Subclasses</a>
    <a class="dropdown-item" href="../../articles/new-guides/making_new_layers_and_models_via_subclassing.html">Making New Layers and Models via Subclassing</a>
    <a class="dropdown-item" href="../../articles/new-guides/customizing_what_happens_in_fit.html">Customizing What Happens in Fit</a>
    <a class="dropdown-item" href="../../articles/new-guides/writing_your_own_callbacks.html">Writing Your Own Callbacks</a>
    <a class="dropdown-item" href="../../articles/new-guides/preprocessing_layers.html">Working with Preprocessing Layers</a>
    <a class="dropdown-item" href="../../argicles/new-guides/working_with_rnns.html">Working with RNNs</a>
    <div class="dropdown-divider"></div>
    <h6 class="dropdown-header" data-toc-skip>Using Keras</h6>
    <a class="dropdown-item" href="../../articles/guide_keras.html">Guide to Keras Basics</a>
    <a class="dropdown-item" href="../../articles/sequential_model.html">Sequential Model in Depth</a>
    <a class="dropdown-item" href="../../articles/functional_api.html">Functional API in Depth</a>
    <a class="dropdown-item" href="../../articles/about_keras_models.html">About Keras Models</a>
    <a class="dropdown-item" href="../../articles/about_keras_layers.html">About Keras Layers</a>
    <a class="dropdown-item" href="../../articles/training_visualization.html">Training Visualization</a>
    <a class="dropdown-item" href="../../articles/applications.html">Pre-Trained Models</a>
    <a class="dropdown-item" href="../../articles/faq.html">Frequently Asked Questions</a>
    <a class="dropdown-item" href="../../articles/why_use_keras.html">Why Use Keras?</a>
    <div class="dropdown-divider"></div>
    <h6 class="dropdown-header" data-toc-skip>Advanced</h6>
    <a class="dropdown-item" href="../../articles/eager_guide.html">Eager Execution</a>
    <a class="dropdown-item" href="../../articles/training_callbacks.html">Training Callbacks</a>
    <a class="dropdown-item" href="../../articles/backend.html">Keras Backend</a>
    <a class="dropdown-item" href="../../articles/custom_layers.html">Custom Layers</a>
    <a class="dropdown-item" href="../../articles/custom_models.html">Custom Models</a>
    <a class="dropdown-item" href="../../articles/saving_serializing.html">Saving and serializing</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../articles/learn.html">Learn</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../articles/tools.html">Tools</a>
</li>
<li class="active nav-item">
  <a class="nav-link" href="../../articles/examples/index.html">Examples</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../reference/index.html">Reference</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../news/index.html">News</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/rstudio/keras/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../../logo.png" class="logo" alt=""><h1>OCR model for reading Captchas</h1>
                        <h4 data-toc-skip class="author"><a href="https://twitter.com/A_K_Nain" class="external-link">A_K_Nain</a></h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/rstudio/keras/blob/HEAD/vignettes/examples/captcha_ocr.Rmd" class="external-link"><code>vignettes/examples/captcha_ocr.Rmd</code></a></small>
      <div class="d-none name"><code>captcha_ocr.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>This example demonstrates a simple OCR model built with the
Functional API. Apart from combining CNN and RNN, it also illustrates
how you can instantiate a new layer and use it as an “Endpoint layer”
for implementing CTC loss. For a detailed guide to layer subclassing,
please check out <a href="https://keras.io/guides/making_new_layers_and_models_via_subclassing/" class="external-link">this
page</a> in the developer guides.</p>
</div>
<div class="section level2">
<h2 id="setup">Setup<a class="anchor" aria-label="anchor" href="#setup"></a>
</h2>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="im">from</span> tensorflow <span class="im">import</span> keras</span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a><span class="im">from</span> tensorflow.keras <span class="im">import</span> layers</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="load-the-data-captcha-images">Load the data: <a href="https://www.kaggle.com/fournierp/captcha-version-2-images" class="external-link">Captcha
Images</a><a class="anchor" aria-label="anchor" href="#load-the-data-captcha-images"></a>
</h2>
<p>Let’s download the data.</p>
<p>curl -LO <a href="https://github.com/AakashKumarNain/CaptchaCracker/raw/master/captcha_images_v2.zip" class="external-link uri">https://github.com/AakashKumarNain/CaptchaCracker/raw/master/captcha_images_v2.zip</a>
unzip -qq captcha_images_v2.zip</p>
<p>The dataset contains 1040 captcha files as <code>png</code> images.
The label for each sample is a string, the name of the file (minus the
file extension). We will map each character in the string to an integer
for training the model. Similary, we will need to map the predictions of
the model back to strings. For this purpose we will maintain two
dictionaries, mapping characters to integers, and integers to
characters, respectively.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="co"># Path to the data directory</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>data_dir <span class="op">=</span> Path(<span class="st">"./captcha_images_v2/"</span>)</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a><span class="co"># Get list of all the images</span></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>images <span class="op">=</span> <span class="bu">sorted</span>(<span class="bu">list</span>(<span class="bu">map</span>(<span class="bu">str</span>, <span class="bu">list</span>(data_dir.glob(<span class="st">"*.png"</span>)))))</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a>labels <span class="op">=</span> [img.split(os.path.sep)[<span class="op">-</span><span class="dv">1</span>].split(<span class="st">".png"</span>)[<span class="dv">0</span>] <span class="cf">for</span> img <span class="kw">in</span> images]</span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>characters <span class="op">=</span> <span class="bu">set</span>(char <span class="cf">for</span> label <span class="kw">in</span> labels <span class="cf">for</span> char <span class="kw">in</span> label)</span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>characters <span class="op">=</span> <span class="bu">sorted</span>(<span class="bu">list</span>(characters))</span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of images found: "</span>, <span class="bu">len</span>(images))</span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of labels found: "</span>, <span class="bu">len</span>(labels))</span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Number of unique characters: "</span>, <span class="bu">len</span>(characters))</span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Characters present: "</span>, characters)</span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" tabindex="-1"></a><span class="co"># Batch size for training and validation</span></span>
<span id="cb2-16"><a href="#cb2-16" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">16</span></span>
<span id="cb2-17"><a href="#cb2-17" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" tabindex="-1"></a><span class="co"># Desired image dimensions</span></span>
<span id="cb2-19"><a href="#cb2-19" tabindex="-1"></a>img_width <span class="op">=</span> <span class="dv">200</span></span>
<span id="cb2-20"><a href="#cb2-20" tabindex="-1"></a>img_height <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb2-21"><a href="#cb2-21" tabindex="-1"></a></span>
<span id="cb2-22"><a href="#cb2-22" tabindex="-1"></a><span class="co"># Factor by which the image is going to be downsampled</span></span>
<span id="cb2-23"><a href="#cb2-23" tabindex="-1"></a><span class="co"># by the convolutional blocks. We will be using two</span></span>
<span id="cb2-24"><a href="#cb2-24" tabindex="-1"></a><span class="co"># convolution blocks and each block will have</span></span>
<span id="cb2-25"><a href="#cb2-25" tabindex="-1"></a><span class="co"># a pooling layer which downsample the features by a factor of 2.</span></span>
<span id="cb2-26"><a href="#cb2-26" tabindex="-1"></a><span class="co"># Hence total downsampling factor would be 4.</span></span>
<span id="cb2-27"><a href="#cb2-27" tabindex="-1"></a>downsample_factor <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb2-28"><a href="#cb2-28" tabindex="-1"></a></span>
<span id="cb2-29"><a href="#cb2-29" tabindex="-1"></a><span class="co"># Maximum length of any captcha in the dataset</span></span>
<span id="cb2-30"><a href="#cb2-30" tabindex="-1"></a>max_length <span class="op">=</span> <span class="bu">max</span>([<span class="bu">len</span>(label) <span class="cf">for</span> label <span class="kw">in</span> labels])</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="preprocessing">Preprocessing<a class="anchor" aria-label="anchor" href="#preprocessing"></a>
</h2>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="co"># Mapping characters to integers</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>char_to_num <span class="op">=</span> layers.StringLookup(vocabulary<span class="op">=</span><span class="bu">list</span>(characters), mask_token<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a><span class="co"># Mapping integers back to original characters</span></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>num_to_char <span class="op">=</span> layers.StringLookup(</span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a>    vocabulary<span class="op">=</span>char_to_num.get_vocabulary(), mask_token<span class="op">=</span><span class="va">None</span>, invert<span class="op">=</span><span class="va">True</span></span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a>)</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a><span class="kw">def</span> split_data(images, labels, train_size<span class="op">=</span><span class="fl">0.9</span>, shuffle<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a>    <span class="co"># 1. Get the total size of the dataset</span></span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a>    size <span class="op">=</span> <span class="bu">len</span>(images)</span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a>    <span class="co"># 2. Make an indices array and shuffle it, if required</span></span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a>    indices <span class="op">=</span> np.arange(size)</span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a>    <span class="cf">if</span> shuffle:</span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a>        np.random.shuffle(indices)</span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a>    <span class="co"># 3. Get the size of training samples</span></span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a>    train_samples <span class="op">=</span> <span class="bu">int</span>(size <span class="op">*</span> train_size)</span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a>    <span class="co"># 4. Split data into training and validation sets</span></span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a>    x_train, y_train <span class="op">=</span> (</span>
<span id="cb3-21"><a href="#cb3-21" tabindex="-1"></a>        images[indices[:train_samples]],</span>
<span id="cb3-22"><a href="#cb3-22" tabindex="-1"></a>        labels[indices[:train_samples]],</span>
<span id="cb3-23"><a href="#cb3-23" tabindex="-1"></a>    )</span>
<span id="cb3-24"><a href="#cb3-24" tabindex="-1"></a>    x_valid, y_valid <span class="op">=</span> (</span>
<span id="cb3-25"><a href="#cb3-25" tabindex="-1"></a>        images[indices[train_samples:]],</span>
<span id="cb3-26"><a href="#cb3-26" tabindex="-1"></a>        labels[indices[train_samples:]],</span>
<span id="cb3-27"><a href="#cb3-27" tabindex="-1"></a>    )</span>
<span id="cb3-28"><a href="#cb3-28" tabindex="-1"></a>    <span class="cf">return</span> x_train, x_valid, y_train, y_valid</span>
<span id="cb3-29"><a href="#cb3-29" tabindex="-1"></a></span>
<span id="cb3-30"><a href="#cb3-30" tabindex="-1"></a></span>
<span id="cb3-31"><a href="#cb3-31" tabindex="-1"></a><span class="co"># Splitting data into training and validation sets</span></span>
<span id="cb3-32"><a href="#cb3-32" tabindex="-1"></a>x_train, x_valid, y_train, y_valid <span class="op">=</span> split_data(</span>
<span id="cb3-33"><a href="#cb3-33" tabindex="-1"></a>    np.array(images), np.array(labels)</span>
<span id="cb3-34"><a href="#cb3-34" tabindex="-1"></a>)</span>
<span id="cb3-35"><a href="#cb3-35" tabindex="-1"></a></span>
<span id="cb3-36"><a href="#cb3-36" tabindex="-1"></a></span>
<span id="cb3-37"><a href="#cb3-37" tabindex="-1"></a><span class="kw">def</span> encode_single_sample(img_path, label):</span>
<span id="cb3-38"><a href="#cb3-38" tabindex="-1"></a>    <span class="co"># 1. Read image</span></span>
<span id="cb3-39"><a href="#cb3-39" tabindex="-1"></a>    img <span class="op">=</span> tf.io.read_file(img_path)</span>
<span id="cb3-40"><a href="#cb3-40" tabindex="-1"></a>    <span class="co"># 2. Decode and convert to grayscale</span></span>
<span id="cb3-41"><a href="#cb3-41" tabindex="-1"></a>    img <span class="op">=</span> tf.io.decode_png(img, channels<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb3-42"><a href="#cb3-42" tabindex="-1"></a>    <span class="co"># 3. Convert to float32 in [0, 1] range</span></span>
<span id="cb3-43"><a href="#cb3-43" tabindex="-1"></a>    img <span class="op">=</span> tf.image.convert_image_dtype(img, tf.float32)</span>
<span id="cb3-44"><a href="#cb3-44" tabindex="-1"></a>    <span class="co"># 4. Resize to the desired size</span></span>
<span id="cb3-45"><a href="#cb3-45" tabindex="-1"></a>    img <span class="op">=</span> tf.image.resize(img, [img_height, img_width])</span>
<span id="cb3-46"><a href="#cb3-46" tabindex="-1"></a>    <span class="co"># 5. Transpose the image because we want the time</span></span>
<span id="cb3-47"><a href="#cb3-47" tabindex="-1"></a>    <span class="co"># dimension to correspond to the width of the image.</span></span>
<span id="cb3-48"><a href="#cb3-48" tabindex="-1"></a>    img <span class="op">=</span> tf.transpose(img, perm<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">2</span>])</span>
<span id="cb3-49"><a href="#cb3-49" tabindex="-1"></a>    <span class="co"># 6. Map the characters in label to numbers</span></span>
<span id="cb3-50"><a href="#cb3-50" tabindex="-1"></a>    label <span class="op">=</span> char_to_num(tf.strings.unicode_split(label, input_encoding<span class="op">=</span><span class="st">"UTF-8"</span>))</span>
<span id="cb3-51"><a href="#cb3-51" tabindex="-1"></a>    <span class="co"># 7. Return a dict as our model is expecting two inputs</span></span>
<span id="cb3-52"><a href="#cb3-52" tabindex="-1"></a>    <span class="cf">return</span> {<span class="st">"image"</span>: img, <span class="st">"label"</span>: label}</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="create-dataset-objects">Create <code>Dataset</code> objects<a class="anchor" aria-label="anchor" href="#create-dataset-objects"></a>
</h2>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>train_dataset <span class="op">=</span> tf.data.Dataset.from_tensor_slices((x_train, y_train))</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>train_dataset <span class="op">=</span> (</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>    train_dataset.<span class="bu">map</span>(encode_single_sample, num_parallel_calls<span class="op">=</span>tf.data.AUTOTUNE)</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>    .batch(batch_size)</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a>    .prefetch(buffer_size<span class="op">=</span>tf.data.AUTOTUNE)</span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a>)</span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a>validation_dataset <span class="op">=</span> tf.data.Dataset.from_tensor_slices((x_valid, y_valid))</span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a>validation_dataset <span class="op">=</span> (</span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a>    validation_dataset.<span class="bu">map</span>(</span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a>        encode_single_sample, num_parallel_calls<span class="op">=</span>tf.data.AUTOTUNE</span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a>    )</span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a>    .batch(batch_size)</span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a>    .prefetch(buffer_size<span class="op">=</span>tf.data.AUTOTUNE)</span>
<span id="cb4-15"><a href="#cb4-15" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="visualize-the-data">Visualize the data<a class="anchor" aria-label="anchor" href="#visualize-the-data"></a>
</h2>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>_, ax <span class="op">=</span> plt.subplots(<span class="dv">4</span>, <span class="dv">4</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="cf">for</span> batch <span class="kw">in</span> train_dataset.take(<span class="dv">1</span>):</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>    images <span class="op">=</span> batch[<span class="st">"image"</span>]</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>    labels <span class="op">=</span> batch[<span class="st">"label"</span>]</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">16</span>):</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>        img <span class="op">=</span> (images[i] <span class="op">*</span> <span class="dv">255</span>).numpy().astype(<span class="st">"uint8"</span>)</span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a>        label <span class="op">=</span> (</span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a>            tf.strings.reduce_join(num_to_char(labels[i]))</span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a>            .numpy()</span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a>            .decode(<span class="st">"utf-8"</span>)</span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a>        )</span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a>        ax[i <span class="op">//</span> <span class="dv">4</span>, i <span class="op">%</span> <span class="dv">4</span>].imshow(img[:, :, <span class="dv">0</span>].T, cmap<span class="op">=</span><span class="st">"gray"</span>)</span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a>        ax[i <span class="op">//</span> <span class="dv">4</span>, i <span class="op">%</span> <span class="dv">4</span>].set_title(label)</span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a>        ax[i <span class="op">//</span> <span class="dv">4</span>, i <span class="op">%</span> <span class="dv">4</span>].axis(<span class="st">"off"</span>)</span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a>plt.show()</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="model">Model<a class="anchor" aria-label="anchor" href="#model"></a>
</h2>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="kw">class</span> CTCLayer(layers.Layer):</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, name<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(name<span class="op">=</span>name)</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a>        <span class="va">self</span>.loss_fn <span class="op">=</span> keras.backend.ctc_batch_cost</span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>    <span class="kw">def</span> call(<span class="va">self</span>, y_true, y_pred):</span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a>        <span class="co"># Compute the training-time loss value and add it</span></span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a>        <span class="co"># to the layer using `self.add_loss()`.</span></span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a>        batch_len <span class="op">=</span> tf.cast(tf.shape(y_true)[<span class="dv">0</span>], dtype<span class="op">=</span><span class="st">"int64"</span>)</span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a>        input_length <span class="op">=</span> tf.cast(tf.shape(y_pred)[<span class="dv">1</span>], dtype<span class="op">=</span><span class="st">"int64"</span>)</span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a>        label_length <span class="op">=</span> tf.cast(tf.shape(y_true)[<span class="dv">1</span>], dtype<span class="op">=</span><span class="st">"int64"</span>)</span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" tabindex="-1"></a>        input_length <span class="op">=</span> input_length <span class="op">*</span> tf.ones(</span>
<span id="cb6-14"><a href="#cb6-14" tabindex="-1"></a>            shape<span class="op">=</span>(batch_len, <span class="dv">1</span>), dtype<span class="op">=</span><span class="st">"int64"</span></span>
<span id="cb6-15"><a href="#cb6-15" tabindex="-1"></a>        )</span>
<span id="cb6-16"><a href="#cb6-16" tabindex="-1"></a>        label_length <span class="op">=</span> label_length <span class="op">*</span> tf.ones(</span>
<span id="cb6-17"><a href="#cb6-17" tabindex="-1"></a>            shape<span class="op">=</span>(batch_len, <span class="dv">1</span>), dtype<span class="op">=</span><span class="st">"int64"</span></span>
<span id="cb6-18"><a href="#cb6-18" tabindex="-1"></a>        )</span>
<span id="cb6-19"><a href="#cb6-19" tabindex="-1"></a></span>
<span id="cb6-20"><a href="#cb6-20" tabindex="-1"></a>        loss <span class="op">=</span> <span class="va">self</span>.loss_fn(y_true, y_pred, input_length, label_length)</span>
<span id="cb6-21"><a href="#cb6-21" tabindex="-1"></a>        <span class="va">self</span>.add_loss(loss)</span>
<span id="cb6-22"><a href="#cb6-22" tabindex="-1"></a></span>
<span id="cb6-23"><a href="#cb6-23" tabindex="-1"></a>        <span class="co"># At test time, just return the computed predictions</span></span>
<span id="cb6-24"><a href="#cb6-24" tabindex="-1"></a>        <span class="cf">return</span> y_pred</span>
<span id="cb6-25"><a href="#cb6-25" tabindex="-1"></a></span>
<span id="cb6-26"><a href="#cb6-26" tabindex="-1"></a></span>
<span id="cb6-27"><a href="#cb6-27" tabindex="-1"></a><span class="kw">def</span> build_model():</span>
<span id="cb6-28"><a href="#cb6-28" tabindex="-1"></a>    <span class="co"># Inputs to the model</span></span>
<span id="cb6-29"><a href="#cb6-29" tabindex="-1"></a>    input_img <span class="op">=</span> layers.Input(</span>
<span id="cb6-30"><a href="#cb6-30" tabindex="-1"></a>        shape<span class="op">=</span>(img_width, img_height, <span class="dv">1</span>), name<span class="op">=</span><span class="st">"image"</span>, dtype<span class="op">=</span><span class="st">"float32"</span></span>
<span id="cb6-31"><a href="#cb6-31" tabindex="-1"></a>    )</span>
<span id="cb6-32"><a href="#cb6-32" tabindex="-1"></a>    labels <span class="op">=</span> layers.Input(name<span class="op">=</span><span class="st">"label"</span>, shape<span class="op">=</span>(<span class="va">None</span>,), dtype<span class="op">=</span><span class="st">"float32"</span>)</span>
<span id="cb6-33"><a href="#cb6-33" tabindex="-1"></a></span>
<span id="cb6-34"><a href="#cb6-34" tabindex="-1"></a>    <span class="co"># First conv block</span></span>
<span id="cb6-35"><a href="#cb6-35" tabindex="-1"></a>    x <span class="op">=</span> layers.Conv2D(</span>
<span id="cb6-36"><a href="#cb6-36" tabindex="-1"></a>        <span class="dv">32</span>,</span>
<span id="cb6-37"><a href="#cb6-37" tabindex="-1"></a>        (<span class="dv">3</span>, <span class="dv">3</span>),</span>
<span id="cb6-38"><a href="#cb6-38" tabindex="-1"></a>        activation<span class="op">=</span><span class="st">"relu"</span>,</span>
<span id="cb6-39"><a href="#cb6-39" tabindex="-1"></a>        kernel_initializer<span class="op">=</span><span class="st">"he_normal"</span>,</span>
<span id="cb6-40"><a href="#cb6-40" tabindex="-1"></a>        padding<span class="op">=</span><span class="st">"same"</span>,</span>
<span id="cb6-41"><a href="#cb6-41" tabindex="-1"></a>        name<span class="op">=</span><span class="st">"Conv1"</span>,</span>
<span id="cb6-42"><a href="#cb6-42" tabindex="-1"></a>    )(input_img)</span>
<span id="cb6-43"><a href="#cb6-43" tabindex="-1"></a>    x <span class="op">=</span> layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>), name<span class="op">=</span><span class="st">"pool1"</span>)(x)</span>
<span id="cb6-44"><a href="#cb6-44" tabindex="-1"></a></span>
<span id="cb6-45"><a href="#cb6-45" tabindex="-1"></a>    <span class="co"># Second conv block</span></span>
<span id="cb6-46"><a href="#cb6-46" tabindex="-1"></a>    x <span class="op">=</span> layers.Conv2D(</span>
<span id="cb6-47"><a href="#cb6-47" tabindex="-1"></a>        <span class="dv">64</span>,</span>
<span id="cb6-48"><a href="#cb6-48" tabindex="-1"></a>        (<span class="dv">3</span>, <span class="dv">3</span>),</span>
<span id="cb6-49"><a href="#cb6-49" tabindex="-1"></a>        activation<span class="op">=</span><span class="st">"relu"</span>,</span>
<span id="cb6-50"><a href="#cb6-50" tabindex="-1"></a>        kernel_initializer<span class="op">=</span><span class="st">"he_normal"</span>,</span>
<span id="cb6-51"><a href="#cb6-51" tabindex="-1"></a>        padding<span class="op">=</span><span class="st">"same"</span>,</span>
<span id="cb6-52"><a href="#cb6-52" tabindex="-1"></a>        name<span class="op">=</span><span class="st">"Conv2"</span>,</span>
<span id="cb6-53"><a href="#cb6-53" tabindex="-1"></a>    )(x)</span>
<span id="cb6-54"><a href="#cb6-54" tabindex="-1"></a>    x <span class="op">=</span> layers.MaxPooling2D((<span class="dv">2</span>, <span class="dv">2</span>), name<span class="op">=</span><span class="st">"pool2"</span>)(x)</span>
<span id="cb6-55"><a href="#cb6-55" tabindex="-1"></a></span>
<span id="cb6-56"><a href="#cb6-56" tabindex="-1"></a>    <span class="co"># We have used two max pool with pool size and strides 2.</span></span>
<span id="cb6-57"><a href="#cb6-57" tabindex="-1"></a>    <span class="co"># Hence, downsampled feature maps are 4x smaller. The number of</span></span>
<span id="cb6-58"><a href="#cb6-58" tabindex="-1"></a>    <span class="co"># filters in the last layer is 64. Reshape accordingly before</span></span>
<span id="cb6-59"><a href="#cb6-59" tabindex="-1"></a>    <span class="co"># passing the output to the RNN part of the model</span></span>
<span id="cb6-60"><a href="#cb6-60" tabindex="-1"></a>    new_shape <span class="op">=</span> ((img_width <span class="op">//</span> <span class="dv">4</span>), (img_height <span class="op">//</span> <span class="dv">4</span>) <span class="op">*</span> <span class="dv">64</span>)</span>
<span id="cb6-61"><a href="#cb6-61" tabindex="-1"></a>    x <span class="op">=</span> layers.Reshape(target_shape<span class="op">=</span>new_shape, name<span class="op">=</span><span class="st">"reshape"</span>)(x)</span>
<span id="cb6-62"><a href="#cb6-62" tabindex="-1"></a>    x <span class="op">=</span> layers.Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">"relu"</span>, name<span class="op">=</span><span class="st">"dense1"</span>)(x)</span>
<span id="cb6-63"><a href="#cb6-63" tabindex="-1"></a>    x <span class="op">=</span> layers.Dropout(<span class="fl">0.2</span>)(x)</span>
<span id="cb6-64"><a href="#cb6-64" tabindex="-1"></a></span>
<span id="cb6-65"><a href="#cb6-65" tabindex="-1"></a>    <span class="co"># RNNs</span></span>
<span id="cb6-66"><a href="#cb6-66" tabindex="-1"></a>    x <span class="op">=</span> layers.Bidirectional(</span>
<span id="cb6-67"><a href="#cb6-67" tabindex="-1"></a>        layers.LSTM(<span class="dv">128</span>, return_sequences<span class="op">=</span><span class="va">True</span>, dropout<span class="op">=</span><span class="fl">0.25</span>)</span>
<span id="cb6-68"><a href="#cb6-68" tabindex="-1"></a>    )(x)</span>
<span id="cb6-69"><a href="#cb6-69" tabindex="-1"></a>    x <span class="op">=</span> layers.Bidirectional(</span>
<span id="cb6-70"><a href="#cb6-70" tabindex="-1"></a>        layers.LSTM(<span class="dv">64</span>, return_sequences<span class="op">=</span><span class="va">True</span>, dropout<span class="op">=</span><span class="fl">0.25</span>)</span>
<span id="cb6-71"><a href="#cb6-71" tabindex="-1"></a>    )(x)</span>
<span id="cb6-72"><a href="#cb6-72" tabindex="-1"></a></span>
<span id="cb6-73"><a href="#cb6-73" tabindex="-1"></a>    <span class="co"># Output layer</span></span>
<span id="cb6-74"><a href="#cb6-74" tabindex="-1"></a>    x <span class="op">=</span> layers.Dense(</span>
<span id="cb6-75"><a href="#cb6-75" tabindex="-1"></a>        <span class="bu">len</span>(char_to_num.get_vocabulary()) <span class="op">+</span> <span class="dv">1</span>,</span>
<span id="cb6-76"><a href="#cb6-76" tabindex="-1"></a>        activation<span class="op">=</span><span class="st">"softmax"</span>,</span>
<span id="cb6-77"><a href="#cb6-77" tabindex="-1"></a>        name<span class="op">=</span><span class="st">"dense2"</span>,</span>
<span id="cb6-78"><a href="#cb6-78" tabindex="-1"></a>    )(x)</span>
<span id="cb6-79"><a href="#cb6-79" tabindex="-1"></a></span>
<span id="cb6-80"><a href="#cb6-80" tabindex="-1"></a>    <span class="co"># Add CTC layer for calculating CTC loss at each step</span></span>
<span id="cb6-81"><a href="#cb6-81" tabindex="-1"></a>    output <span class="op">=</span> CTCLayer(name<span class="op">=</span><span class="st">"ctc_loss"</span>)(labels, x)</span>
<span id="cb6-82"><a href="#cb6-82" tabindex="-1"></a></span>
<span id="cb6-83"><a href="#cb6-83" tabindex="-1"></a>    <span class="co"># Define the model</span></span>
<span id="cb6-84"><a href="#cb6-84" tabindex="-1"></a>    model <span class="op">=</span> keras.models.Model(</span>
<span id="cb6-85"><a href="#cb6-85" tabindex="-1"></a>        inputs<span class="op">=</span>[input_img, labels], outputs<span class="op">=</span>output, name<span class="op">=</span><span class="st">"ocr_model_v1"</span></span>
<span id="cb6-86"><a href="#cb6-86" tabindex="-1"></a>    )</span>
<span id="cb6-87"><a href="#cb6-87" tabindex="-1"></a>    <span class="co"># Optimizer</span></span>
<span id="cb6-88"><a href="#cb6-88" tabindex="-1"></a>    opt <span class="op">=</span> keras.optimizers.Adam()</span>
<span id="cb6-89"><a href="#cb6-89" tabindex="-1"></a>    <span class="co"># Compile the model and return</span></span>
<span id="cb6-90"><a href="#cb6-90" tabindex="-1"></a>    model.<span class="bu">compile</span>(optimizer<span class="op">=</span>opt)</span>
<span id="cb6-91"><a href="#cb6-91" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb6-92"><a href="#cb6-92" tabindex="-1"></a></span>
<span id="cb6-93"><a href="#cb6-93" tabindex="-1"></a></span>
<span id="cb6-94"><a href="#cb6-94" tabindex="-1"></a><span class="co"># Get the model</span></span>
<span id="cb6-95"><a href="#cb6-95" tabindex="-1"></a>model <span class="op">=</span> build_model()</span>
<span id="cb6-96"><a href="#cb6-96" tabindex="-1"></a>model.summary()</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="training">Training<a class="anchor" aria-label="anchor" href="#training"></a>
</h2>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>early_stopping_patience <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a><span class="co"># Add early stopping</span></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>early_stopping <span class="op">=</span> keras.callbacks.EarlyStopping(</span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>    monitor<span class="op">=</span><span class="st">"val_loss"</span>,</span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a>    patience<span class="op">=</span>early_stopping_patience,</span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a>    restore_best_weights<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a>)</span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a></span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a>history <span class="op">=</span> model.fit(</span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a>    train_dataset,</span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a>    validation_data<span class="op">=</span>validation_dataset,</span>
<span id="cb7-14"><a href="#cb7-14" tabindex="-1"></a>    epochs<span class="op">=</span>epochs,</span>
<span id="cb7-15"><a href="#cb7-15" tabindex="-1"></a>    callbacks<span class="op">=</span>[early_stopping],</span>
<span id="cb7-16"><a href="#cb7-16" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="inference">Inference<a class="anchor" aria-label="anchor" href="#inference"></a>
</h2>
<p>You can use the trained model hosted on <a href="https://huggingface.co/keras-io/ocr-for-captcha" class="external-link">Hugging Face
Hub</a> and try the demo on <a href="https://huggingface.co/spaces/keras-io/ocr-for-captcha" class="external-link">Hugging
Face Spaces</a>.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="co"># Get the prediction model by extracting layers till the output layer</span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>prediction_model <span class="op">=</span> keras.models.Model(</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>    model.get_layer(name<span class="op">=</span><span class="st">"image"</span>).<span class="bu">input</span>, model.get_layer(name<span class="op">=</span><span class="st">"dense2"</span>).output</span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>)</span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a>prediction_model.summary()</span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a><span class="co"># A utility function to decode the output of the network</span></span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a><span class="kw">def</span> decode_batch_predictions(pred):</span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a>    input_len <span class="op">=</span> np.ones(pred.shape[<span class="dv">0</span>]) <span class="op">*</span> pred.shape[<span class="dv">1</span>]</span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a>    <span class="co"># Use greedy search. For complex tasks, you can use beam search</span></span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a>    results <span class="op">=</span> keras.backend.ctc_decode(</span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a>        pred, input_length<span class="op">=</span>input_len, greedy<span class="op">=</span><span class="va">True</span></span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a>    )[<span class="dv">0</span>][<span class="dv">0</span>][:, :max_length]</span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a>    <span class="co"># Iterate over the results and get back the text</span></span>
<span id="cb8-16"><a href="#cb8-16" tabindex="-1"></a>    output_text <span class="op">=</span> []</span>
<span id="cb8-17"><a href="#cb8-17" tabindex="-1"></a>    <span class="cf">for</span> res <span class="kw">in</span> results:</span>
<span id="cb8-18"><a href="#cb8-18" tabindex="-1"></a>        res <span class="op">=</span> tf.strings.reduce_join(num_to_char(res)).numpy().decode(<span class="st">"utf-8"</span>)</span>
<span id="cb8-19"><a href="#cb8-19" tabindex="-1"></a>        output_text.append(res)</span>
<span id="cb8-20"><a href="#cb8-20" tabindex="-1"></a>    <span class="cf">return</span> output_text</span>
<span id="cb8-21"><a href="#cb8-21" tabindex="-1"></a></span>
<span id="cb8-22"><a href="#cb8-22" tabindex="-1"></a></span>
<span id="cb8-23"><a href="#cb8-23" tabindex="-1"></a><span class="co">#  Let's check results on some validation samples</span></span>
<span id="cb8-24"><a href="#cb8-24" tabindex="-1"></a><span class="cf">for</span> batch <span class="kw">in</span> validation_dataset.take(<span class="dv">1</span>):</span>
<span id="cb8-25"><a href="#cb8-25" tabindex="-1"></a>    batch_images <span class="op">=</span> batch[<span class="st">"image"</span>]</span>
<span id="cb8-26"><a href="#cb8-26" tabindex="-1"></a>    batch_labels <span class="op">=</span> batch[<span class="st">"label"</span>]</span>
<span id="cb8-27"><a href="#cb8-27" tabindex="-1"></a></span>
<span id="cb8-28"><a href="#cb8-28" tabindex="-1"></a>    preds <span class="op">=</span> prediction_model.predict(batch_images)</span>
<span id="cb8-29"><a href="#cb8-29" tabindex="-1"></a>    pred_texts <span class="op">=</span> decode_batch_predictions(preds)</span>
<span id="cb8-30"><a href="#cb8-30" tabindex="-1"></a></span>
<span id="cb8-31"><a href="#cb8-31" tabindex="-1"></a>    orig_texts <span class="op">=</span> []</span>
<span id="cb8-32"><a href="#cb8-32" tabindex="-1"></a>    <span class="cf">for</span> label <span class="kw">in</span> batch_labels:</span>
<span id="cb8-33"><a href="#cb8-33" tabindex="-1"></a>        label <span class="op">=</span> (</span>
<span id="cb8-34"><a href="#cb8-34" tabindex="-1"></a>            tf.strings.reduce_join(num_to_char(label)).numpy().decode(<span class="st">"utf-8"</span>)</span>
<span id="cb8-35"><a href="#cb8-35" tabindex="-1"></a>        )</span>
<span id="cb8-36"><a href="#cb8-36" tabindex="-1"></a>        orig_texts.append(label)</span>
<span id="cb8-37"><a href="#cb8-37" tabindex="-1"></a></span>
<span id="cb8-38"><a href="#cb8-38" tabindex="-1"></a>    _, ax <span class="op">=</span> plt.subplots(<span class="dv">4</span>, <span class="dv">4</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb8-39"><a href="#cb8-39" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(pred_texts)):</span>
<span id="cb8-40"><a href="#cb8-40" tabindex="-1"></a>        img <span class="op">=</span> (batch_images[i, :, :, <span class="dv">0</span>] <span class="op">*</span> <span class="dv">255</span>).numpy().astype(np.uint8)</span>
<span id="cb8-41"><a href="#cb8-41" tabindex="-1"></a>        img <span class="op">=</span> img.T</span>
<span id="cb8-42"><a href="#cb8-42" tabindex="-1"></a>        title <span class="op">=</span> <span class="ss">f"Prediction: </span><span class="sc">{</span>pred_texts[i]<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb8-43"><a href="#cb8-43" tabindex="-1"></a>        ax[i <span class="op">//</span> <span class="dv">4</span>, i <span class="op">%</span> <span class="dv">4</span>].imshow(img, cmap<span class="op">=</span><span class="st">"gray"</span>)</span>
<span id="cb8-44"><a href="#cb8-44" tabindex="-1"></a>        ax[i <span class="op">//</span> <span class="dv">4</span>, i <span class="op">%</span> <span class="dv">4</span>].set_title(title)</span>
<span id="cb8-45"><a href="#cb8-45" tabindex="-1"></a>        ax[i <span class="op">//</span> <span class="dv">4</span>, i <span class="op">%</span> <span class="dv">4</span>].axis(<span class="st">"off"</span>)</span>
<span id="cb8-46"><a href="#cb8-46" tabindex="-1"></a>plt.show()</span></code></pre></div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Tomasz Kalinowski, JJ Allaire, François Chollet, RStudio, Google.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
