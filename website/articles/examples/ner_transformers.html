<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="NER using the Transformers and data from CoNLL 2003 shared task.">
<title>Named Entity Recognition using Transformers • keras</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../../apple-touch-icon-60x60.png">
<script src="../../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../../pkgdown.js"></script><link href="../../extra.css" rel="stylesheet">
<script src="../../extra.js"></script><meta property="og:title" content="Named Entity Recognition using Transformers">
<meta property="og:description" content="NER using the Transformers and data from CoNLL 2003 shared task.">
<meta property="og:image" content="https://keras.posit.co/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-inverse navbar-expand-lg bg-primary"><div class="container">
    
    <a class="navbar-brand me-2" href="../../index.html">keras</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">2.13.0.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../../index.html">Home</a>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-tutorials">Tutorials</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-tutorials">
    <a class="dropdown-item" href="../../articles/getting_started.html">Getting Started</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_classification.html">Basic Classification</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_text_classification.html">Text Classification</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_regression.html">Basic Regression</a>
    <a class="dropdown-item" href="../../articles/tutorial_overfit_underfit.html">Overfitting and Underfitting</a>
    <a class="dropdown-item" href="../../articles/tutorial_save_and_restore.html">Save and Restore Models</a>
  </div>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-guides">Guides</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-guides">
    <a class="dropdown-item" href="../../articles/writing_your_own_callbacks.html">Writing Your Own Callbacks</a>
  </div>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <h6 class="dropdown-header" data-toc-skip>Guides (New for TF 2.6)</h6>
    <a class="dropdown-item" href="../../articles/new-guides/python_subclasses.html">Python Subclasses</a>
    <a class="dropdown-item" href="../../articles/new-guides/making_new_layers_and_models_via_subclassing.html">Making New Layers and Models via Subclassing</a>
    <a class="dropdown-item" href="../../articles/new-guides/customizing_what_happens_in_fit.html">Customizing What Happens in Fit</a>
    <a class="dropdown-item" href="../../articles/new-guides/writing_your_own_callbacks.html">Writing Your Own Callbacks</a>
    <a class="dropdown-item" href="../../articles/new-guides/preprocessing_layers.html">Working with Preprocessing Layers</a>
    <a class="dropdown-item" href="../../argicles/new-guides/working_with_rnns.html">Working with RNNs</a>
    <div class="dropdown-divider"></div>
    <h6 class="dropdown-header" data-toc-skip>Using Keras</h6>
    <a class="dropdown-item" href="../../articles/guide_keras.html">Guide to Keras Basics</a>
    <a class="dropdown-item" href="../../articles/sequential_model.html">Sequential Model in Depth</a>
    <a class="dropdown-item" href="../../articles/functional_api.html">Functional API in Depth</a>
    <a class="dropdown-item" href="../../articles/about_keras_models.html">About Keras Models</a>
    <a class="dropdown-item" href="../../articles/about_keras_layers.html">About Keras Layers</a>
    <a class="dropdown-item" href="../../articles/training_visualization.html">Training Visualization</a>
    <a class="dropdown-item" href="../../articles/applications.html">Pre-Trained Models</a>
    <a class="dropdown-item" href="../../articles/faq.html">Frequently Asked Questions</a>
    <a class="dropdown-item" href="../../articles/why_use_keras.html">Why Use Keras?</a>
    <div class="dropdown-divider"></div>
    <h6 class="dropdown-header" data-toc-skip>Advanced</h6>
    <a class="dropdown-item" href="../../articles/eager_guide.html">Eager Execution</a>
    <a class="dropdown-item" href="../../articles/training_callbacks.html">Training Callbacks</a>
    <a class="dropdown-item" href="../../articles/backend.html">Keras Backend</a>
    <a class="dropdown-item" href="../../articles/custom_layers.html">Custom Layers</a>
    <a class="dropdown-item" href="../../articles/custom_models.html">Custom Models</a>
    <a class="dropdown-item" href="../../articles/saving_serializing.html">Saving and serializing</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../articles/learn.html">Learn</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../articles/tools.html">Tools</a>
</li>
<li class="active nav-item">
  <a class="nav-link" href="../../articles/examples/index.html">Examples</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../reference/index.html">Reference</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../news/index.html">News</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/rstudio/keras/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../../logo.png" class="logo" alt=""><h1>Named Entity Recognition using Transformers</h1>
                        <h4 data-toc-skip class="author"><a href="https://www.linkedin.com/in/varunsingh2/" class="external-link">Varun Singh</a></h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/rstudio/keras/blob/HEAD/vignettes/examples/ner_transformers.Rmd" class="external-link"><code>vignettes/examples/ner_transformers.Rmd</code></a></small>
      <div class="d-none name"><code>ner_transformers.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>Named Entity Recognition (NER) is the process of identifying named
entities in text. Example of named entities are: “Person”, “Location”,
“Organization”, “Dates” etc. NER is essentially a token classification
task where every token is classified into one or more predetermined
categories.</p>
<p>In this exercise, we will train a simple Transformer based model to
perform NER. We will be using the data from CoNLL 2003 shared task. For
more information about the dataset, please visit <a href="https://www.clips.uantwerpen.be/conll2003/ner/" class="external-link">the dataset
website</a>. However, since obtaining this data requires an additional
step of getting a free license, we will be using HuggingFace’s datasets
library which contains a processed version of this dataset.</p>
</div>
<div class="section level2">
<h2 id="install-the-open-source-datasets-library-from-huggingface">Install the open source datasets library from HuggingFace<a class="anchor" aria-label="anchor" href="#install-the-open-source-datasets-library-from-huggingface"></a>
</h2>
<p>We also download the script used to evaluate NER models.</p>
<p>pip3 install datasets wget <a href="https://raw.githubusercontent.com/sighsmile/conlleval/master/conlleval.py" class="external-link uri">https://raw.githubusercontent.com/sighsmile/conlleval/master/conlleval.py</a></p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">import</span> keras <span class="im">as</span> keras</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">from</span> keras <span class="im">import</span> layers</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> load_dataset</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="im">from</span> conlleval <span class="im">import</span> evaluate</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="co"># imports for data preprocessing</span></span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a><span class="im">from</span> tensorflow <span class="im">import</span> data <span class="im">as</span> tf_data</span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="im">from</span> tensorflow <span class="im">import</span> strings <span class="im">as</span> tf_strings</span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a><span class="kw">class</span> TransformerBlock(layers.Layer):</span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, embed_dim, num_heads, ff_dim, rate<span class="op">=</span><span class="fl">0.1</span>):</span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a>        <span class="va">self</span>.att <span class="op">=</span> keras.layers.MultiHeadAttention(</span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a>            num_heads<span class="op">=</span>num_heads, key_dim<span class="op">=</span>embed_dim</span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a>        )</span>
<span id="cb1-20"><a href="#cb1-20" tabindex="-1"></a>        <span class="va">self</span>.ffn <span class="op">=</span> keras.Sequential(</span>
<span id="cb1-21"><a href="#cb1-21" tabindex="-1"></a>            [</span>
<span id="cb1-22"><a href="#cb1-22" tabindex="-1"></a>                keras.layers.Dense(ff_dim, activation<span class="op">=</span><span class="st">"relu"</span>),</span>
<span id="cb1-23"><a href="#cb1-23" tabindex="-1"></a>                keras.layers.Dense(embed_dim),</span>
<span id="cb1-24"><a href="#cb1-24" tabindex="-1"></a>            ]</span>
<span id="cb1-25"><a href="#cb1-25" tabindex="-1"></a>        )</span>
<span id="cb1-26"><a href="#cb1-26" tabindex="-1"></a>        <span class="va">self</span>.layernorm1 <span class="op">=</span> keras.layers.LayerNormalization(epsilon<span class="op">=</span><span class="fl">1e-6</span>)</span>
<span id="cb1-27"><a href="#cb1-27" tabindex="-1"></a>        <span class="va">self</span>.layernorm2 <span class="op">=</span> keras.layers.LayerNormalization(epsilon<span class="op">=</span><span class="fl">1e-6</span>)</span>
<span id="cb1-28"><a href="#cb1-28" tabindex="-1"></a>        <span class="va">self</span>.dropout1 <span class="op">=</span> keras.layers.Dropout(rate)</span>
<span id="cb1-29"><a href="#cb1-29" tabindex="-1"></a>        <span class="va">self</span>.dropout2 <span class="op">=</span> keras.layers.Dropout(rate)</span>
<span id="cb1-30"><a href="#cb1-30" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" tabindex="-1"></a>    <span class="kw">def</span> call(<span class="va">self</span>, inputs, training<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb1-32"><a href="#cb1-32" tabindex="-1"></a>        attn_output <span class="op">=</span> <span class="va">self</span>.att(inputs, inputs)</span>
<span id="cb1-33"><a href="#cb1-33" tabindex="-1"></a>        attn_output <span class="op">=</span> <span class="va">self</span>.dropout1(attn_output, training<span class="op">=</span>training)</span>
<span id="cb1-34"><a href="#cb1-34" tabindex="-1"></a>        out1 <span class="op">=</span> <span class="va">self</span>.layernorm1(inputs <span class="op">+</span> attn_output)</span>
<span id="cb1-35"><a href="#cb1-35" tabindex="-1"></a>        ffn_output <span class="op">=</span> <span class="va">self</span>.ffn(out1)</span>
<span id="cb1-36"><a href="#cb1-36" tabindex="-1"></a>        ffn_output <span class="op">=</span> <span class="va">self</span>.dropout2(ffn_output, training<span class="op">=</span>training)</span>
<span id="cb1-37"><a href="#cb1-37" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.layernorm2(out1 <span class="op">+</span> ffn_output)</span></code></pre></div>
<p>Next, let’s define a <code>TokenAndPositionEmbedding</code>
layer:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="kw">class</span> TokenAndPositionEmbedding(layers.Layer):</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, maxlen, vocab_size, embed_dim):</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>        <span class="va">self</span>.token_emb <span class="op">=</span> keras.layers.Embedding(</span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>            input_dim<span class="op">=</span>vocab_size, output_dim<span class="op">=</span>embed_dim</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a>        )</span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>        <span class="va">self</span>.pos_emb <span class="op">=</span> keras.layers.Embedding(</span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>            input_dim<span class="op">=</span>maxlen, output_dim<span class="op">=</span>embed_dim</span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a>        )</span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a>    <span class="kw">def</span> call(<span class="va">self</span>, inputs):</span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a>        maxlen <span class="op">=</span> keras.ops.backend.shape(inputs)[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a>        positions <span class="op">=</span> keras.ops.arange(start<span class="op">=</span><span class="dv">0</span>, stop<span class="op">=</span>maxlen, step<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a>        position_embeddings <span class="op">=</span> <span class="va">self</span>.pos_emb(positions)</span>
<span id="cb2-15"><a href="#cb2-15" tabindex="-1"></a>        token_embeddings <span class="op">=</span> <span class="va">self</span>.token_emb(inputs)</span>
<span id="cb2-16"><a href="#cb2-16" tabindex="-1"></a>        <span class="cf">return</span> token_embeddings <span class="op">+</span> position_embeddings</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="build-the-ner-model-class-as-a-keras-model-subclass">Build the NER model class as a <code>keras.Model</code>
subclass<a class="anchor" aria-label="anchor" href="#build-the-ner-model-class-as-a-keras-model-subclass"></a>
</h2>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="kw">class</span> NERModel(keras.Model):</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>        <span class="va">self</span>,</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>        num_tags,</span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>        vocab_size,</span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a>        maxlen<span class="op">=</span><span class="dv">128</span>,</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a>        embed_dim<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>        num_heads<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a>        ff_dim<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a>    ):</span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a>        <span class="va">self</span>.embedding_layer <span class="op">=</span> TokenAndPositionEmbedding(</span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a>            maxlen, vocab_size, embed_dim</span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a>        )</span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a>        <span class="va">self</span>.transformer_block <span class="op">=</span> TransformerBlock(embed_dim, num_heads, ff_dim)</span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a>        <span class="va">self</span>.dropout1 <span class="op">=</span> layers.Dropout(<span class="fl">0.1</span>)</span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a>        <span class="va">self</span>.ff <span class="op">=</span> layers.Dense(ff_dim, activation<span class="op">=</span><span class="st">"relu"</span>)</span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a>        <span class="va">self</span>.dropout2 <span class="op">=</span> layers.Dropout(<span class="fl">0.1</span>)</span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a>        <span class="va">self</span>.ff_final <span class="op">=</span> layers.Dense(num_tags, activation<span class="op">=</span><span class="st">"softmax"</span>)</span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a></span>
<span id="cb3-21"><a href="#cb3-21" tabindex="-1"></a>    <span class="kw">def</span> call(<span class="va">self</span>, inputs, training<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb3-22"><a href="#cb3-22" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.embedding_layer(inputs)</span>
<span id="cb3-23"><a href="#cb3-23" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.transformer_block(x)</span>
<span id="cb3-24"><a href="#cb3-24" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.dropout1(x, training<span class="op">=</span>training)</span>
<span id="cb3-25"><a href="#cb3-25" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.ff(x)</span>
<span id="cb3-26"><a href="#cb3-26" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.dropout2(x, training<span class="op">=</span>training)</span>
<span id="cb3-27"><a href="#cb3-27" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.ff_final(x)</span>
<span id="cb3-28"><a href="#cb3-28" tabindex="-1"></a>        <span class="cf">return</span> x</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="load-the-conll-2003-dataset-from-the-datasets-library-and-process-it">Load the CoNLL 2003 dataset from the datasets library and process
it<a class="anchor" aria-label="anchor" href="#load-the-conll-2003-dataset-from-the-datasets-library-and-process-it"></a>
</h2>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>conll_data <span class="op">=</span> load_dataset(<span class="st">"conll2003"</span>)</span></code></pre></div>
<p>We will export this data to a tab-separated file format which will be
easy to read as a <code>tf.data.Dataset</code> object.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="kw">def</span> export_to_file(export_file_path, data):</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>    <span class="cf">with</span> <span class="bu">open</span>(export_file_path, <span class="st">"w"</span>) <span class="im">as</span> f:</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>        <span class="cf">for</span> record <span class="kw">in</span> data:</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>            ner_tags <span class="op">=</span> record[<span class="st">"ner_tags"</span>]</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>            tokens <span class="op">=</span> record[<span class="st">"tokens"</span>]</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">len</span>(tokens) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a>                f.write(</span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a>                    <span class="bu">str</span>(<span class="bu">len</span>(tokens))</span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a>                    <span class="op">+</span> <span class="st">"</span><span class="ch">\t</span><span class="st">"</span></span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a>                    <span class="op">+</span> <span class="st">"</span><span class="ch">\t</span><span class="st">"</span>.join(tokens)</span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a>                    <span class="op">+</span> <span class="st">"</span><span class="ch">\t</span><span class="st">"</span></span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a>                    <span class="op">+</span> <span class="st">"</span><span class="ch">\t</span><span class="st">"</span>.join(<span class="bu">map</span>(<span class="bu">str</span>, ner_tags))</span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a>                    <span class="op">+</span> <span class="st">"</span><span class="ch">\n</span><span class="st">"</span></span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a>                )</span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a></span>
<span id="cb5-16"><a href="#cb5-16" tabindex="-1"></a></span>
<span id="cb5-17"><a href="#cb5-17" tabindex="-1"></a>os.mkdir(<span class="st">"data"</span>)</span>
<span id="cb5-18"><a href="#cb5-18" tabindex="-1"></a>export_to_file(<span class="st">"./data/conll_train.txt"</span>, conll_data[<span class="st">"train"</span>])</span>
<span id="cb5-19"><a href="#cb5-19" tabindex="-1"></a>export_to_file(<span class="st">"./data/conll_val.txt"</span>, conll_data[<span class="st">"validation"</span>])</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="make-the-ner-label-lookup-table">Make the NER label lookup table<a class="anchor" aria-label="anchor" href="#make-the-ner-label-lookup-table"></a>
</h2>
<p>NER labels are usually provided in IOB, IOB2 or IOBES formats.
Checkout this link for more information: <a href="https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)" class="external-link">Wikipedia</a></p>
<p>Note that we start our label numbering from 1 since 0 will be
reserved for padding. We have a total of 10 labels: 9 from the NER
dataset and one for padding.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="kw">def</span> make_tag_lookup_table():</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>    iob_labels <span class="op">=</span> [<span class="st">"B"</span>, <span class="st">"I"</span>]</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>    ner_labels <span class="op">=</span> [<span class="st">"PER"</span>, <span class="st">"ORG"</span>, <span class="st">"LOC"</span>, <span class="st">"MISC"</span>]</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a>    all_labels <span class="op">=</span> [</span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a>        (label1, label2) <span class="cf">for</span> label2 <span class="kw">in</span> ner_labels <span class="cf">for</span> label1 <span class="kw">in</span> iob_labels</span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>    ]</span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a>    all_labels <span class="op">=</span> [<span class="st">"-"</span>.join([a, b]) <span class="cf">for</span> a, b <span class="kw">in</span> all_labels]</span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a>    all_labels <span class="op">=</span> [<span class="st">"[PAD]"</span>, <span class="st">"O"</span>] <span class="op">+</span> all_labels</span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">dict</span>(<span class="bu">zip</span>(<span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(all_labels) <span class="op">+</span> <span class="dv">1</span>), all_labels))</span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a></span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a>mapping <span class="op">=</span> make_tag_lookup_table()</span>
<span id="cb6-13"><a href="#cb6-13" tabindex="-1"></a><span class="bu">print</span>(mapping)</span></code></pre></div>
<p>Get a list of all tokens in the training dataset. This will be used
to create the vocabulary.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>all_tokens <span class="op">=</span> <span class="bu">sum</span>(conll_data[<span class="st">"train"</span>][<span class="st">"tokens"</span>], [])</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>all_tokens_array <span class="op">=</span> np.array(<span class="bu">list</span>(<span class="bu">map</span>(<span class="bu">str</span>.lower, all_tokens)))</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>counter <span class="op">=</span> Counter(all_tokens_array)</span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(counter))</span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a>num_tags <span class="op">=</span> <span class="bu">len</span>(mapping)</span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a>vocab_size <span class="op">=</span> <span class="dv">20000</span></span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a></span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a><span class="co"># We only take (vocab_size - 2) most commons words from the training data since</span></span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a><span class="co"># the `StringLookup` class uses 2 additional tokens - one denoting an unknown</span></span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a><span class="co"># token and another one denoting a masking token</span></span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a>vocabulary <span class="op">=</span> [token <span class="cf">for</span> token, count <span class="kw">in</span> counter.most_common(vocab_size <span class="op">-</span> <span class="dv">2</span>)]</span>
<span id="cb7-14"><a href="#cb7-14" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" tabindex="-1"></a><span class="co"># The StringLook class will convert tokens to token IDs</span></span>
<span id="cb7-16"><a href="#cb7-16" tabindex="-1"></a>lookup_layer <span class="op">=</span> keras.layers.StringLookup(vocabulary<span class="op">=</span>vocabulary)</span></code></pre></div>
<p>Create 2 new <code>Dataset</code> objects from the training and
validation data</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a>train_data <span class="op">=</span> tf_data.TextLineDataset(<span class="st">"./data/conll_train.txt"</span>)</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>val_data <span class="op">=</span> tf_data.TextLineDataset(<span class="st">"./data/conll_val.txt"</span>)</span></code></pre></div>
<p>Print out one line to make sure it looks good. The first record in
the line is the number of tokens. After that we will have all the tokens
followed by all the ner tags.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">list</span>(train_data.take(<span class="dv">1</span>).as_numpy_iterator()))</span></code></pre></div>
<p>We will be using the following map function to transform the data in
the dataset:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="co"># Data preprocessing using Tensorflow</span></span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a><span class="kw">def</span> map_record_to_training_data(record):</span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a>    record <span class="op">=</span> tf_strings.split(record, sep<span class="op">=</span><span class="st">"</span><span class="ch">\t</span><span class="st">"</span>)</span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a>    length <span class="op">=</span> tf_strings.to_number(record[<span class="dv">0</span>], out_type<span class="op">=</span><span class="st">"int32"</span>)</span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a>    tokens <span class="op">=</span> record[<span class="dv">1</span> : length <span class="op">+</span> <span class="dv">1</span>]</span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a>    tags <span class="op">=</span> record[length <span class="op">+</span> <span class="dv">1</span> :]</span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a>    tags <span class="op">=</span> tf_strings.to_number(tags, out_type<span class="op">=</span><span class="st">"int64"</span>)</span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a>    tags <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a>    <span class="cf">return</span> tokens, tags</span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a></span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a><span class="kw">def</span> lowercase_and_convert_to_ids(tokens):</span>
<span id="cb10-13"><a href="#cb10-13" tabindex="-1"></a>    tokens <span class="op">=</span> tf_strings.lower(tokens)</span>
<span id="cb10-14"><a href="#cb10-14" tabindex="-1"></a>    <span class="cf">return</span> lookup_layer(tokens)</span>
<span id="cb10-15"><a href="#cb10-15" tabindex="-1"></a></span>
<span id="cb10-16"><a href="#cb10-16" tabindex="-1"></a></span>
<span id="cb10-17"><a href="#cb10-17" tabindex="-1"></a><span class="co"># We use `padded_batch` here because each record in the dataset has a</span></span>
<span id="cb10-18"><a href="#cb10-18" tabindex="-1"></a><span class="co"># different length.</span></span>
<span id="cb10-19"><a href="#cb10-19" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">32</span></span>
<span id="cb10-20"><a href="#cb10-20" tabindex="-1"></a>train_dataset <span class="op">=</span> (</span>
<span id="cb10-21"><a href="#cb10-21" tabindex="-1"></a>    train_data.<span class="bu">map</span>(map_record_to_training_data)</span>
<span id="cb10-22"><a href="#cb10-22" tabindex="-1"></a>    .<span class="bu">map</span>(<span class="kw">lambda</span> x, y: (lowercase_and_convert_to_ids(x), y))</span>
<span id="cb10-23"><a href="#cb10-23" tabindex="-1"></a>    .padded_batch(batch_size)</span>
<span id="cb10-24"><a href="#cb10-24" tabindex="-1"></a>)</span>
<span id="cb10-25"><a href="#cb10-25" tabindex="-1"></a>val_dataset <span class="op">=</span> (</span>
<span id="cb10-26"><a href="#cb10-26" tabindex="-1"></a>    val_data.<span class="bu">map</span>(map_record_to_training_data)</span>
<span id="cb10-27"><a href="#cb10-27" tabindex="-1"></a>    .<span class="bu">map</span>(<span class="kw">lambda</span> x, y: (lowercase_and_convert_to_ids(x), y))</span>
<span id="cb10-28"><a href="#cb10-28" tabindex="-1"></a>    .padded_batch(batch_size)</span>
<span id="cb10-29"><a href="#cb10-29" tabindex="-1"></a>)</span>
<span id="cb10-30"><a href="#cb10-30" tabindex="-1"></a></span>
<span id="cb10-31"><a href="#cb10-31" tabindex="-1"></a>ner_model <span class="op">=</span> NERModel(num_tags, vocab_size, embed_dim<span class="op">=</span><span class="dv">32</span>, num_heads<span class="op">=</span><span class="dv">4</span>, ff_dim<span class="op">=</span><span class="dv">64</span>)</span></code></pre></div>
<p>We will be using a custom loss function that will ignore the loss
from padded tokens.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="kw">class</span> CustomNonPaddingTokenLoss(keras.losses.Loss):</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, name<span class="op">=</span><span class="st">"custom_ner_loss"</span>):</span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(name<span class="op">=</span>name)</span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a>    <span class="kw">def</span> call(<span class="va">self</span>, y_true, y_pred):</span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a>        loss_fn <span class="op">=</span> keras.losses.SparseCategoricalCrossentropy(</span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a>            from_logits<span class="op">=</span><span class="va">True</span>, reduction<span class="op">=</span><span class="va">None</span></span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a>        )</span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a>        loss <span class="op">=</span> loss_fn(y_true, y_pred)</span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a>        mask <span class="op">=</span> keras.backend.cast((y_true <span class="op">&gt;</span> <span class="dv">0</span>), dtype<span class="op">=</span><span class="st">"float32"</span>)</span>
<span id="cb11-11"><a href="#cb11-11" tabindex="-1"></a>        loss <span class="op">=</span> loss <span class="op">*</span> mask</span>
<span id="cb11-12"><a href="#cb11-12" tabindex="-1"></a>        <span class="cf">return</span> keras.ops.<span class="bu">sum</span>(loss) <span class="op">/</span> keras.ops.<span class="bu">sum</span>(mask)</span>
<span id="cb11-13"><a href="#cb11-13" tabindex="-1"></a></span>
<span id="cb11-14"><a href="#cb11-14" tabindex="-1"></a></span>
<span id="cb11-15"><a href="#cb11-15" tabindex="-1"></a>loss <span class="op">=</span> CustomNonPaddingTokenLoss()</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="compile-and-fit-the-model">Compile and fit the model<a class="anchor" aria-label="anchor" href="#compile-and-fit-the-model"></a>
</h2>
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a>ner_model.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">"adam"</span>, loss<span class="op">=</span>loss)</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a>ner_model.fit(train_dataset, epochs<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a><span class="kw">def</span> tokenize_and_convert_to_ids(text):</span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a>    tokens <span class="op">=</span> text.split()</span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a>    <span class="cf">return</span> lowercase_and_convert_to_ids(tokens)</span>
<span id="cb12-8"><a href="#cb12-8" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" tabindex="-1"></a></span>
<span id="cb12-10"><a href="#cb12-10" tabindex="-1"></a><span class="co"># Sample inference using the trained model</span></span>
<span id="cb12-11"><a href="#cb12-11" tabindex="-1"></a>sample_input <span class="op">=</span> tokenize_and_convert_to_ids(</span>
<span id="cb12-12"><a href="#cb12-12" tabindex="-1"></a>    <span class="st">"eu rejects german call to boycott british lamb"</span></span>
<span id="cb12-13"><a href="#cb12-13" tabindex="-1"></a>)</span>
<span id="cb12-14"><a href="#cb12-14" tabindex="-1"></a>sample_input <span class="op">=</span> keras.ops.reshape(sample_input, new_shape<span class="op">=</span>[<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb12-15"><a href="#cb12-15" tabindex="-1"></a><span class="bu">print</span>(sample_input)</span>
<span id="cb12-16"><a href="#cb12-16" tabindex="-1"></a></span>
<span id="cb12-17"><a href="#cb12-17" tabindex="-1"></a>output <span class="op">=</span> ner_model.predict(sample_input)</span>
<span id="cb12-18"><a href="#cb12-18" tabindex="-1"></a>prediction <span class="op">=</span> np.argmax(output, axis<span class="op">=-</span><span class="dv">1</span>)[<span class="dv">0</span>]</span>
<span id="cb12-19"><a href="#cb12-19" tabindex="-1"></a>prediction <span class="op">=</span> [mapping[i] <span class="cf">for</span> i <span class="kw">in</span> prediction]</span>
<span id="cb12-20"><a href="#cb12-20" tabindex="-1"></a></span>
<span id="cb12-21"><a href="#cb12-21" tabindex="-1"></a><span class="co"># eu -&gt; B-ORG, german -&gt; B-MISC, british -&gt; B-MISC</span></span>
<span id="cb12-22"><a href="#cb12-22" tabindex="-1"></a><span class="bu">print</span>(prediction)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="metrics-calculation">Metrics calculation<a class="anchor" aria-label="anchor" href="#metrics-calculation"></a>
</h2>
<p>Here is a function to calculate the metrics. The function calculates
F1 score for the overall NER dataset as well as individual scores for
each NER tag.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="kw">def</span> calculate_metrics(dataset):</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a>    all_true_tag_ids, all_predicted_tag_ids <span class="op">=</span> [], []</span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a>    <span class="cf">for</span> x, y <span class="kw">in</span> dataset:</span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a>        output <span class="op">=</span> ner_model.predict(x)</span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a>        predictions <span class="op">=</span> np.argmax(output, axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a>        predictions <span class="op">=</span> np.reshape(predictions, [<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a>        true_tag_ids <span class="op">=</span> np.reshape(y, [<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb13-10"><a href="#cb13-10" tabindex="-1"></a></span>
<span id="cb13-11"><a href="#cb13-11" tabindex="-1"></a>        mask <span class="op">=</span> (true_tag_ids <span class="op">&gt;</span> <span class="dv">0</span>) <span class="op">&amp;</span> (predictions <span class="op">&gt;</span> <span class="dv">0</span>)</span>
<span id="cb13-12"><a href="#cb13-12" tabindex="-1"></a>        true_tag_ids <span class="op">=</span> true_tag_ids[mask]</span>
<span id="cb13-13"><a href="#cb13-13" tabindex="-1"></a>        predicted_tag_ids <span class="op">=</span> predictions[mask]</span>
<span id="cb13-14"><a href="#cb13-14" tabindex="-1"></a></span>
<span id="cb13-15"><a href="#cb13-15" tabindex="-1"></a>        all_true_tag_ids.append(true_tag_ids)</span>
<span id="cb13-16"><a href="#cb13-16" tabindex="-1"></a>        all_predicted_tag_ids.append(predicted_tag_ids)</span>
<span id="cb13-17"><a href="#cb13-17" tabindex="-1"></a></span>
<span id="cb13-18"><a href="#cb13-18" tabindex="-1"></a>    all_true_tag_ids <span class="op">=</span> np.concatenate(all_true_tag_ids)</span>
<span id="cb13-19"><a href="#cb13-19" tabindex="-1"></a>    all_predicted_tag_ids <span class="op">=</span> np.concatenate(all_predicted_tag_ids)</span>
<span id="cb13-20"><a href="#cb13-20" tabindex="-1"></a></span>
<span id="cb13-21"><a href="#cb13-21" tabindex="-1"></a>    predicted_tags <span class="op">=</span> [mapping[tag] <span class="cf">for</span> tag <span class="kw">in</span> all_predicted_tag_ids]</span>
<span id="cb13-22"><a href="#cb13-22" tabindex="-1"></a>    real_tags <span class="op">=</span> [mapping[tag] <span class="cf">for</span> tag <span class="kw">in</span> all_true_tag_ids]</span>
<span id="cb13-23"><a href="#cb13-23" tabindex="-1"></a></span>
<span id="cb13-24"><a href="#cb13-24" tabindex="-1"></a>    evaluate(real_tags, predicted_tags)</span>
<span id="cb13-25"><a href="#cb13-25" tabindex="-1"></a></span>
<span id="cb13-26"><a href="#cb13-26" tabindex="-1"></a></span>
<span id="cb13-27"><a href="#cb13-27" tabindex="-1"></a>calculate_metrics(val_dataset)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="conclusions">Conclusions<a class="anchor" aria-label="anchor" href="#conclusions"></a>
</h2>
<p>In this exercise, we created a simple transformer based named entity
recognition model. We trained it on the CoNLL 2003 shared task data and
got an overall F1 score of around 70%. State of the art NER models
fine-tuned on pretrained models such as BERT or ELECTRA can easily get
much higher F1 score -between 90-95% on this dataset owing to the
inherent knowledge of words as part of the pretraining process and the
usage of subword tokenization.</p>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Tomasz Kalinowski, JJ Allaire, François Chollet, RStudio, Google.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
