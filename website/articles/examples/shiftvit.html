<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="A minimal implementation of ShiftViT.">
<title>A Vision Transformer without Attention â€¢ keras3</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../../apple-touch-icon-60x60.png">
<script src="../../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../../pkgdown.js"></script><meta property="og:title" content="A Vision Transformer without Attention">
<meta property="og:description" content="A minimal implementation of ShiftViT.">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-inverse navbar-expand-lg bg-primary"><div class="container">
    
    <a class="navbar-brand me-2" href="../../index.html">keras3</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">2.13.0.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../../index.html">Home</a>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-getting-started">Getting Started</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-getting-started">
    <a class="dropdown-item" href="../../articles/intro_to_keras_for_engineers.html">Introduction to Keras for engineers</a>
    <h6 class="dropdown-header" data-toc-skip>Tutorials</h6>
    <a class="dropdown-item" href="../../articles/getting_started.html">Getting Started</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_classification.html">Basic Classification</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_text_classification.html">Text Classification</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_regression.html">Basic Regression</a>
    <a class="dropdown-item" href="../../articles/tutorial_overfit_underfit.html">Overfitting and Underfitting</a>
    <a class="dropdown-item" href="../../articles/tutorial_save_and_restore.html">Save and Restore Models</a>
  </div>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-guides">Guides</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-guides">
    <h6 class="dropdown-header" data-toc-skip>Model definition</h6>
    <a class="dropdown-item" href="../../articles/functional_api.html">Functional API</a>
    <a class="dropdown-item" href="../../articles/sequential_model.html">Sequential Model</a>
    <h6 class="dropdown-header" data-toc-skip>Extending and customizing</h6>
    <a class="dropdown-item" href="../../articles/making_new_layers_and_models_via_subclassing.html">Making new layers and models via subclassing</a>
    <a class="dropdown-item" href="../../articles/training_with_built_in_methods.html">Training &amp; evaluation with the built-in methods</a>
    <a class="dropdown-item" href="../../articles/writing_a_custom_training_loop_in_tensorflow.html">Writing a training loop from scratch in TensorFlow</a>
    <a class="dropdown-item" href="../../articles/writing_your_own_callbacks.html">Writing Your Own Callbacks</a>
    <h6 class="dropdown-header" data-toc-skip>Other topics</h6>
    <a class="dropdown-item" href="../../articles/transfer_learning.html">Transfer learning and fine tuning</a>
    <a class="dropdown-item" href="../../articles/distributed_training_with_tensorflow.html">Distributed training with TensorFlow</a>
  </div>
</li>
<li class="active nav-item">
  <a class="nav-link" href="../../articles/examples/index.html">Examples</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../reference/index.html">Reference</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../news/index.html">News</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/rstudio/keras/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>A Vision Transformer without Attention</h1>
                        <h4 data-toc-skip class="author">
<a href="https://twitter.com/ariG23498" class="external-link">Aritra Roy Gosthipaty</a>, <a href="https://twitter.com/ritwik_raha" class="external-link">Ritwik Raha</a>
</h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/rstudio/keras/blob/HEAD/vignettes/examples/shiftvit.Rmd" class="external-link"><code>vignettes/examples/shiftvit.Rmd</code></a></small>
      <div class="d-none name"><code>shiftvit.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p><a href="https://arxiv.org/abs/2010.11929" class="external-link">Vision Transformers</a>
(ViTs) have sparked a wave of research at the intersection of
Transformers and Computer Vision (CV).</p>
<p>ViTs can simultaneously model long- and short-range dependencies,
thanks to the Multi-Head Self-Attention mechanism in the Transformer
block. Many researchers believe that the success of ViTs are purely due
to the attention layer, and they seldom think about other parts of the
ViT model.</p>
<p>In the academic paper <a href="https://arxiv.org/abs/2201.10801" class="external-link">When
Shift Operation Meets Vision Transformer: An Extremely Simple
Alternative to Attention Mechanism</a> the authors propose to demystify
the success of ViTs with the introduction of a <strong>NO
PARAMETER</strong> operation in place of the attention operation. They
swap the attention operation with a shifting operation.</p>
<p>In this example, we minimally implement the paper with close
alignement to the authorâ€™s <a href="https://github.com/microsoft/SPACH/blob/main/models/shiftvit.py" class="external-link">official
implementation</a>.</p>
</div>
<div class="section level2">
<h2 id="setup-and-imports">Setup and imports<a class="anchor" aria-label="anchor" href="#setup-and-imports"></a>
</h2>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a>os.environ[<span class="st">"KERAS_BACKEND"</span>] <span class="op">=</span> <span class="st">"tensorflow"</span></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="im">import</span> keras <span class="im">as</span> keras</span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a><span class="im">from</span> keras <span class="im">import</span> layers</span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a><span class="co"># Setting seed for reproducibiltiy</span></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a>SEED <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a>keras.utils.set_random_seed(SEED)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="hyperparameters">Hyperparameters<a class="anchor" aria-label="anchor" href="#hyperparameters"></a>
</h2>
<p>These are the hyperparameters that we have chosen for the experiment.
Please feel free to tune them.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="kw">class</span> Config(<span class="bu">object</span>):</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>    <span class="co"># DATA</span></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>    batch_size <span class="op">=</span> <span class="dv">256</span></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>    buffer_size <span class="op">=</span> batch_size <span class="op">*</span> <span class="dv">2</span></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>    input_shape <span class="op">=</span> (<span class="dv">32</span>, <span class="dv">32</span>, <span class="dv">3</span>)</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a>    num_classes <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>    <span class="co"># AUGMENTATION</span></span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a>    image_size <span class="op">=</span> <span class="dv">48</span></span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a>    <span class="co"># ARCHITECTURE</span></span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a>    patch_size <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a>    projected_dim <span class="op">=</span> <span class="dv">96</span></span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a>    num_shift_blocks_per_stages <span class="op">=</span> [<span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">8</span>, <span class="dv">2</span>]</span>
<span id="cb2-15"><a href="#cb2-15" tabindex="-1"></a>    epsilon <span class="op">=</span> <span class="fl">1e-5</span></span>
<span id="cb2-16"><a href="#cb2-16" tabindex="-1"></a>    stochastic_depth_rate <span class="op">=</span> <span class="fl">0.2</span></span>
<span id="cb2-17"><a href="#cb2-17" tabindex="-1"></a>    mlp_dropout_rate <span class="op">=</span> <span class="fl">0.2</span></span>
<span id="cb2-18"><a href="#cb2-18" tabindex="-1"></a>    num_div <span class="op">=</span> <span class="dv">12</span></span>
<span id="cb2-19"><a href="#cb2-19" tabindex="-1"></a>    shift_pixel <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb2-20"><a href="#cb2-20" tabindex="-1"></a>    mlp_expand_ratio <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb2-21"><a href="#cb2-21" tabindex="-1"></a></span>
<span id="cb2-22"><a href="#cb2-22" tabindex="-1"></a>    <span class="co"># OPTIMIZER</span></span>
<span id="cb2-23"><a href="#cb2-23" tabindex="-1"></a>    lr_start <span class="op">=</span> <span class="fl">1e-5</span></span>
<span id="cb2-24"><a href="#cb2-24" tabindex="-1"></a>    lr_max <span class="op">=</span> <span class="fl">1e-3</span></span>
<span id="cb2-25"><a href="#cb2-25" tabindex="-1"></a>    weight_decay <span class="op">=</span> <span class="fl">1e-4</span></span>
<span id="cb2-26"><a href="#cb2-26" tabindex="-1"></a></span>
<span id="cb2-27"><a href="#cb2-27" tabindex="-1"></a>    <span class="co"># TRAINING</span></span>
<span id="cb2-28"><a href="#cb2-28" tabindex="-1"></a>    epochs <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb2-29"><a href="#cb2-29" tabindex="-1"></a></span>
<span id="cb2-30"><a href="#cb2-30" tabindex="-1"></a></span>
<span id="cb2-31"><a href="#cb2-31" tabindex="-1"></a>config <span class="op">=</span> Config()</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="load-the-cifar-10-dataset">Load the CIFAR-10 dataset<a class="anchor" aria-label="anchor" href="#load-the-cifar-10-dataset"></a>
</h2>
<p>We use the CIFAR-10 dataset for our experiments.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>(x_train, y_train), (x_test, y_test) <span class="op">=</span> keras.datasets.cifar10.load_data()</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>(x_train, y_train), (x_val, y_val) <span class="op">=</span> (</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>    (x_train[:<span class="dv">40000</span>], y_train[:<span class="dv">40000</span>]),</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>    (x_train[<span class="dv">40000</span>:], y_train[<span class="dv">40000</span>:]),</span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>)</span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Training samples: </span><span class="sc">{</span><span class="bu">len</span>(x_train)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Validation samples: </span><span class="sc">{</span><span class="bu">len</span>(x_val)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Testing samples: </span><span class="sc">{</span><span class="bu">len</span>(x_test)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a>AUTO <span class="op">=</span> tf.data.AUTOTUNE</span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a>train_ds <span class="op">=</span> tf.data.Dataset.from_tensor_slices((x_train, y_train))</span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a>train_ds <span class="op">=</span> (</span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a>    train_ds.shuffle(config.buffer_size).batch(config.batch_size).prefetch(AUTO)</span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a>)</span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a>val_ds <span class="op">=</span> tf.data.Dataset.from_tensor_slices((x_val, y_val))</span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a>val_ds <span class="op">=</span> val_ds.batch(config.batch_size).prefetch(AUTO)</span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a></span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a>test_ds <span class="op">=</span> tf.data.Dataset.from_tensor_slices((x_test, y_test))</span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a>test_ds <span class="op">=</span> test_ds.batch(config.batch_size).prefetch(AUTO)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="data-augmentation">Data Augmentation<a class="anchor" aria-label="anchor" href="#data-augmentation"></a>
</h2>
<p>The augmentation pipeline consists of:</p>
<ul>
<li>Rescaling</li>
<li>Resizing</li>
<li>Random cropping</li>
<li>Random horizontal flipping</li>
</ul>
<p><em>Note</em>: The image data augmentation layers do not apply data
transformations at inference time. This means that when these layers are
called with <code>training=False</code> they behave differently. Refer
to the <a href="https://keras.io/api/layers/preprocessing_layers/image_augmentation/" class="external-link">documentation</a>
for more details.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="kw">def</span> get_augmentation_model():</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>    <span class="co">"""Build the data augmentation model."""</span></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>    data_augmentation <span class="op">=</span> keras.Sequential(</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>        [</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a>            layers.Resizing(</span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a>                config.input_shape[<span class="dv">0</span>] <span class="op">+</span> <span class="dv">20</span>, config.input_shape[<span class="dv">0</span>] <span class="op">+</span> <span class="dv">20</span></span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>            ),</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a>            layers.RandomCrop(config.image_size, config.image_size),</span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a>            layers.RandomFlip(<span class="st">"horizontal"</span>),</span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a>            layers.Rescaling(<span class="dv">1</span> <span class="op">/</span> <span class="fl">255.0</span>),</span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a>        ]</span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a>    )</span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a>    <span class="cf">return</span> data_augmentation</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="the-shiftvit-architecture">The ShiftViT architecture<a class="anchor" aria-label="anchor" href="#the-shiftvit-architecture"></a>
</h2>
<p>In this section, we build the architecture proposed in <a href="https://arxiv.org/abs/2201.10801" class="external-link">the ShiftViT paper</a>.</p>
<table class="table">
<thead><tr class="header">
<th align="center"><img src="https://i.imgur.com/CHU40HX.png" alt="ShiftViT Architecture"></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="center">Figure 1: The entire architecutre of ShiftViT.</td>
</tr>
<tr class="even">
<td align="center"><a href="https://arxiv.org/abs/2201.10801" class="external-link">Source</a></td>
</tr>
</tbody>
</table>
<p>The architecture as shown in Fig. 1, is inspired by <a href="https://arxiv.org/abs/2103.14030" class="external-link">Swin Transformer: Hierarchical
Vision Transformer using Shifted Windows</a>. Here the authors propose a
modular architecture with 4 stages. Each stage works on its own spatial
size, creating a hierarchical architecture.</p>
<p>An input image of size <code>HxWx3</code> is split into
non-overlapping patches of size <code>4x4</code>. This is done via the
patchify layer which results in individual tokens of feature size
<code>48</code> (<code>4x4x3</code>). Each stage comprises two
parts:</p>
<ol style="list-style-type: decimal">
<li>Embedding Generation</li>
<li>Stacked Shift Blocks</li>
</ol>
<p>We discuss the stages and the modules in detail in what follows.</p>
<p><em>Note</em>: Compared to the <a href="https://github.com/microsoft/SPACH/blob/main/models/shiftvit.py" class="external-link">official
implementation</a> we restructure some key components to better fit the
Keras API.</p>
<div class="section level3">
<h3 id="the-shiftvit-block">The ShiftViT Block<a class="anchor" aria-label="anchor" href="#the-shiftvit-block"></a>
</h3>
<table class="table">
<thead><tr class="header">
<th align="center"><img src="https://i.imgur.com/IDe35vo.gif" alt="ShiftViT block"></th>
</tr></thead>
<tbody><tr class="odd">
<td align="center">Figure 2: From the Model to a Shift Block.</td>
</tr></tbody>
</table>
<p>Each stage in the ShiftViT architecture comprises of a Shift Block as
shown in Fig 2.</p>
<table class="table">
<colgroup><col width="100%"></colgroup>
<thead><tr class="header">
<th align="center"><img src="https://i.imgur.com/0q13pLu.png" alt="Shift Vit Block"></th>
</tr></thead>
<tbody><tr class="odd">
<td align="center">Figure 3: The Shift ViT Block. <a href="https://arxiv.org/abs/2201.10801" class="external-link">Source</a>
</td>
</tr></tbody>
</table>
<p>The Shift Block as shown in Fig. 3, comprises of the following:</p>
<ol style="list-style-type: decimal">
<li>Shift Operation</li>
<li>Linear Normalization</li>
<li>MLP Layer</li>
</ol>
<div class="section level4">
<h4 id="the-mlp-block">The MLP block<a class="anchor" aria-label="anchor" href="#the-mlp-block"></a>
</h4>
<p>The MLP block is intended to be a stack of densely-connected
layers.s</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="kw">class</span> MLP(layers.Layer):</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>    <span class="co">"""Get the MLP layer for each shift block.</span></span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a><span class="co">        mlp_expand_ratio (int): The ratio with which the first feature map is expanded.</span></span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a><span class="co">        mlp_dropout_rate (float): The rate for dropout.</span></span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, mlp_expand_ratio, mlp_dropout_rate, <span class="op">**</span>kwargs):</span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(<span class="op">**</span>kwargs)</span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a>        <span class="va">self</span>.mlp_expand_ratio <span class="op">=</span> mlp_expand_ratio</span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a>        <span class="va">self</span>.mlp_dropout_rate <span class="op">=</span> mlp_dropout_rate</span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a></span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a>    <span class="kw">def</span> build(<span class="va">self</span>, input_shape):</span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a>        input_channels <span class="op">=</span> input_shape[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb5-16"><a href="#cb5-16" tabindex="-1"></a>        initial_filters <span class="op">=</span> <span class="bu">int</span>(<span class="va">self</span>.mlp_expand_ratio <span class="op">*</span> input_channels)</span>
<span id="cb5-17"><a href="#cb5-17" tabindex="-1"></a></span>
<span id="cb5-18"><a href="#cb5-18" tabindex="-1"></a>        <span class="va">self</span>.mlp <span class="op">=</span> keras.Sequential(</span>
<span id="cb5-19"><a href="#cb5-19" tabindex="-1"></a>            [</span>
<span id="cb5-20"><a href="#cb5-20" tabindex="-1"></a>                layers.Dense(</span>
<span id="cb5-21"><a href="#cb5-21" tabindex="-1"></a>                    units<span class="op">=</span>initial_filters,</span>
<span id="cb5-22"><a href="#cb5-22" tabindex="-1"></a>                    activation<span class="op">=</span>tf.nn.gelu,</span>
<span id="cb5-23"><a href="#cb5-23" tabindex="-1"></a>                ),</span>
<span id="cb5-24"><a href="#cb5-24" tabindex="-1"></a>                layers.Dropout(rate<span class="op">=</span><span class="va">self</span>.mlp_dropout_rate),</span>
<span id="cb5-25"><a href="#cb5-25" tabindex="-1"></a>                layers.Dense(units<span class="op">=</span>input_channels),</span>
<span id="cb5-26"><a href="#cb5-26" tabindex="-1"></a>                layers.Dropout(rate<span class="op">=</span><span class="va">self</span>.mlp_dropout_rate),</span>
<span id="cb5-27"><a href="#cb5-27" tabindex="-1"></a>            ]</span>
<span id="cb5-28"><a href="#cb5-28" tabindex="-1"></a>        )</span>
<span id="cb5-29"><a href="#cb5-29" tabindex="-1"></a></span>
<span id="cb5-30"><a href="#cb5-30" tabindex="-1"></a>    <span class="kw">def</span> call(<span class="va">self</span>, x):</span>
<span id="cb5-31"><a href="#cb5-31" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.mlp(x)</span>
<span id="cb5-32"><a href="#cb5-32" tabindex="-1"></a>        <span class="cf">return</span> x</span></code></pre></div>
</div>
<div class="section level4">
<h4 id="the-droppath-layer">The DropPath layer<a class="anchor" aria-label="anchor" href="#the-droppath-layer"></a>
</h4>
<p>Stochastic depth is a regularization technique that randomly drops a
set of layers. During inference, the layers are kept as they are. It is
very similar to Dropout, but it operates on a block of layers rather
than on individual nodes present inside a layer.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="kw">class</span> DropPath(layers.Layer):</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>    <span class="co">"""Drop Path also known as the Stochastic Depth layer.</span></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a><span class="co">    Refernece:</span></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a><span class="co">        - https://keras.io/examples/vision/cct/#stochastic-depth-for-regularization</span></span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a><span class="co">        - github.com:rwightman/pytorch-image-models</span></span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, drop_path_prob, <span class="op">**</span>kwargs):</span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(<span class="op">**</span>kwargs)</span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a>        <span class="va">self</span>.drop_path_prob <span class="op">=</span> drop_path_prob</span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" tabindex="-1"></a>    <span class="kw">def</span> call(<span class="va">self</span>, x, training<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb6-14"><a href="#cb6-14" tabindex="-1"></a>        <span class="cf">if</span> training:</span>
<span id="cb6-15"><a href="#cb6-15" tabindex="-1"></a>            keep_prob <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> <span class="va">self</span>.drop_path_prob</span>
<span id="cb6-16"><a href="#cb6-16" tabindex="-1"></a>            shape <span class="op">=</span> (tf.shape(x)[<span class="dv">0</span>],) <span class="op">+</span> (<span class="dv">1</span>,) <span class="op">*</span> (<span class="bu">len</span>(x.shape) <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb6-17"><a href="#cb6-17" tabindex="-1"></a>            random_tensor <span class="op">=</span> keep_prob <span class="op">+</span> tf.random.uniform(shape, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb6-18"><a href="#cb6-18" tabindex="-1"></a>            random_tensor <span class="op">=</span> tf.floor(random_tensor)</span>
<span id="cb6-19"><a href="#cb6-19" tabindex="-1"></a>            <span class="cf">return</span> (x <span class="op">/</span> keep_prob) <span class="op">*</span> random_tensor</span>
<span id="cb6-20"><a href="#cb6-20" tabindex="-1"></a>        <span class="cf">return</span> x</span></code></pre></div>
</div>
<div class="section level4">
<h4 id="block">Block<a class="anchor" aria-label="anchor" href="#block"></a>
</h4>
<p>The most important operation in this paper is the <strong>shift
opperation</strong>. In this section, we describe the shift operation
and compare it with its original implementation provided by the
authors.</p>
<p>A generic feature map is assumed to have the shape
<code>[N, H, W, C]</code>. Here we choose a <code>num_div</code>
parameter that decides the division size of the channels. The first 4
divisions are shifted (1 pixel) in the left, right, up, and down
direction. The remaining splits are kept as is. After partial shifting
the shifted channels are padded and the overflown pixels are chopped
off. This completes the partial shifting operation.</p>
<p>In the original implementation, the code is approximately:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>out[:, g <span class="op">*</span> <span class="dv">0</span>:g <span class="op">*</span> <span class="dv">1</span>, :, :<span class="op">-</span><span class="dv">1</span>] <span class="op">=</span> x[:, g <span class="op">*</span> <span class="dv">0</span>:g <span class="op">*</span> <span class="dv">1</span>, :, <span class="dv">1</span>:]  <span class="co"># shift left</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>out[:, g <span class="op">*</span> <span class="dv">1</span>:g <span class="op">*</span> <span class="dv">2</span>, :, <span class="dv">1</span>:] <span class="op">=</span> x[:, g <span class="op">*</span> <span class="dv">1</span>:g <span class="op">*</span> <span class="dv">2</span>, :, :<span class="op">-</span><span class="dv">1</span>]  <span class="co"># shift right</span></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>out[:, g <span class="op">*</span> <span class="dv">2</span>:g <span class="op">*</span> <span class="dv">3</span>, :<span class="op">-</span><span class="dv">1</span>, :] <span class="op">=</span> x[:, g <span class="op">*</span> <span class="dv">2</span>:g <span class="op">*</span> <span class="dv">3</span>, <span class="dv">1</span>:, :]  <span class="co"># shift up</span></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>out[:, g <span class="op">*</span> <span class="dv">3</span>:g <span class="op">*</span> <span class="dv">4</span>, <span class="dv">1</span>:, :] <span class="op">=</span> x[:, g <span class="op">*</span> <span class="dv">3</span>:g <span class="op">*</span> <span class="dv">4</span>, :<span class="op">-</span><span class="dv">1</span>, :]  <span class="co"># shift down</span></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a>out[:, g <span class="op">*</span> <span class="dv">4</span>:, :, :] <span class="op">=</span> x[:, g <span class="op">*</span> <span class="dv">4</span>:, :, :]  <span class="co"># no shift</span></span></code></pre></div>
<p>In TensorFlow it would be infeasible for us to assign shifted
channels to a tensor in the middle of the training process. This is why
we have resorted to the following procedure:</p>
<ol style="list-style-type: decimal">
<li>Split the channels with the <code>num_div</code> parameter.</li>
<li>Select each of the first four spilts and shift and pad them in the
respective directions.</li>
<li>After shifting and padding, we concatenate the channel back.</li>
</ol>
<table class="table">
<colgroup><col width="100%"></colgroup>
<thead><tr class="header">
<th align="center"><img src="https://i.imgur.com/PReeULP.gif" alt="Manim rendered animation for shift operation"></th>
</tr></thead>
<tbody><tr class="odd">
<td align="center">Figure 4: The TensorFlow style shifting</td>
</tr></tbody>
</table>
<p>The entire procedure is explained in the Fig. 4.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="kw">class</span> ShiftViTBlock(layers.Layer):</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>    <span class="co">"""A unit ShiftViT Block</span></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a><span class="co">        shift_pixel (int): The number of pixels to shift. Defaults to `1`.</span></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a><span class="co">        mlp_expand_ratio (int): The ratio with which MLP features are</span></span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a><span class="co">            expanded. Defaults to `2`.</span></span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a><span class="co">        mlp_dropout_rate (float): The dropout rate used in MLP.</span></span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a><span class="co">        num_div (int): The number of divisions of the feature map's channel.</span></span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a><span class="co">            Totally, 4/num_div of channels will be shifted. Defaults to 12.</span></span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a><span class="co">        epsilon (float): Epsilon constant.</span></span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a><span class="co">        drop_path_prob (float): The drop probability for drop path.</span></span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a></span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb8-16"><a href="#cb8-16" tabindex="-1"></a>        <span class="va">self</span>,</span>
<span id="cb8-17"><a href="#cb8-17" tabindex="-1"></a>        epsilon,</span>
<span id="cb8-18"><a href="#cb8-18" tabindex="-1"></a>        drop_path_prob,</span>
<span id="cb8-19"><a href="#cb8-19" tabindex="-1"></a>        mlp_dropout_rate,</span>
<span id="cb8-20"><a href="#cb8-20" tabindex="-1"></a>        num_div<span class="op">=</span><span class="dv">12</span>,</span>
<span id="cb8-21"><a href="#cb8-21" tabindex="-1"></a>        shift_pixel<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb8-22"><a href="#cb8-22" tabindex="-1"></a>        mlp_expand_ratio<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb8-23"><a href="#cb8-23" tabindex="-1"></a>        <span class="op">**</span>kwargs,</span>
<span id="cb8-24"><a href="#cb8-24" tabindex="-1"></a>    ):</span>
<span id="cb8-25"><a href="#cb8-25" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(<span class="op">**</span>kwargs)</span>
<span id="cb8-26"><a href="#cb8-26" tabindex="-1"></a>        <span class="va">self</span>.shift_pixel <span class="op">=</span> shift_pixel</span>
<span id="cb8-27"><a href="#cb8-27" tabindex="-1"></a>        <span class="va">self</span>.mlp_expand_ratio <span class="op">=</span> mlp_expand_ratio</span>
<span id="cb8-28"><a href="#cb8-28" tabindex="-1"></a>        <span class="va">self</span>.mlp_dropout_rate <span class="op">=</span> mlp_dropout_rate</span>
<span id="cb8-29"><a href="#cb8-29" tabindex="-1"></a>        <span class="va">self</span>.num_div <span class="op">=</span> num_div</span>
<span id="cb8-30"><a href="#cb8-30" tabindex="-1"></a>        <span class="va">self</span>.epsilon <span class="op">=</span> epsilon</span>
<span id="cb8-31"><a href="#cb8-31" tabindex="-1"></a>        <span class="va">self</span>.drop_path_prob <span class="op">=</span> drop_path_prob</span>
<span id="cb8-32"><a href="#cb8-32" tabindex="-1"></a></span>
<span id="cb8-33"><a href="#cb8-33" tabindex="-1"></a>    <span class="kw">def</span> build(<span class="va">self</span>, input_shape):</span>
<span id="cb8-34"><a href="#cb8-34" tabindex="-1"></a>        <span class="va">self</span>.H <span class="op">=</span> input_shape[<span class="dv">1</span>]</span>
<span id="cb8-35"><a href="#cb8-35" tabindex="-1"></a>        <span class="va">self</span>.W <span class="op">=</span> input_shape[<span class="dv">2</span>]</span>
<span id="cb8-36"><a href="#cb8-36" tabindex="-1"></a>        <span class="va">self</span>.C <span class="op">=</span> input_shape[<span class="dv">3</span>]</span>
<span id="cb8-37"><a href="#cb8-37" tabindex="-1"></a>        <span class="va">self</span>.layer_norm <span class="op">=</span> layers.LayerNormalization(epsilon<span class="op">=</span><span class="va">self</span>.epsilon)</span>
<span id="cb8-38"><a href="#cb8-38" tabindex="-1"></a>        <span class="va">self</span>.drop_path <span class="op">=</span> (</span>
<span id="cb8-39"><a href="#cb8-39" tabindex="-1"></a>            DropPath(drop_path_prob<span class="op">=</span><span class="va">self</span>.drop_path_prob)</span>
<span id="cb8-40"><a href="#cb8-40" tabindex="-1"></a>            <span class="cf">if</span> <span class="va">self</span>.drop_path_prob <span class="op">&gt;</span> <span class="fl">0.0</span></span>
<span id="cb8-41"><a href="#cb8-41" tabindex="-1"></a>            <span class="cf">else</span> layers.Activation(<span class="st">"linear"</span>)</span>
<span id="cb8-42"><a href="#cb8-42" tabindex="-1"></a>        )</span>
<span id="cb8-43"><a href="#cb8-43" tabindex="-1"></a>        <span class="va">self</span>.mlp <span class="op">=</span> MLP(</span>
<span id="cb8-44"><a href="#cb8-44" tabindex="-1"></a>            mlp_expand_ratio<span class="op">=</span><span class="va">self</span>.mlp_expand_ratio,</span>
<span id="cb8-45"><a href="#cb8-45" tabindex="-1"></a>            mlp_dropout_rate<span class="op">=</span><span class="va">self</span>.mlp_dropout_rate,</span>
<span id="cb8-46"><a href="#cb8-46" tabindex="-1"></a>        )</span>
<span id="cb8-47"><a href="#cb8-47" tabindex="-1"></a></span>
<span id="cb8-48"><a href="#cb8-48" tabindex="-1"></a>    <span class="kw">def</span> get_shift_pad(<span class="va">self</span>, x, mode):</span>
<span id="cb8-49"><a href="#cb8-49" tabindex="-1"></a>        <span class="co">"""Shifts the channels according to the mode chosen."""</span></span>
<span id="cb8-50"><a href="#cb8-50" tabindex="-1"></a>        <span class="cf">if</span> mode <span class="op">==</span> <span class="st">"left"</span>:</span>
<span id="cb8-51"><a href="#cb8-51" tabindex="-1"></a>            offset_height <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-52"><a href="#cb8-52" tabindex="-1"></a>            offset_width <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-53"><a href="#cb8-53" tabindex="-1"></a>            target_height <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-54"><a href="#cb8-54" tabindex="-1"></a>            target_width <span class="op">=</span> <span class="va">self</span>.shift_pixel</span>
<span id="cb8-55"><a href="#cb8-55" tabindex="-1"></a>        <span class="cf">elif</span> mode <span class="op">==</span> <span class="st">"right"</span>:</span>
<span id="cb8-56"><a href="#cb8-56" tabindex="-1"></a>            offset_height <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-57"><a href="#cb8-57" tabindex="-1"></a>            offset_width <span class="op">=</span> <span class="va">self</span>.shift_pixel</span>
<span id="cb8-58"><a href="#cb8-58" tabindex="-1"></a>            target_height <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-59"><a href="#cb8-59" tabindex="-1"></a>            target_width <span class="op">=</span> <span class="va">self</span>.shift_pixel</span>
<span id="cb8-60"><a href="#cb8-60" tabindex="-1"></a>        <span class="cf">elif</span> mode <span class="op">==</span> <span class="st">"up"</span>:</span>
<span id="cb8-61"><a href="#cb8-61" tabindex="-1"></a>            offset_height <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-62"><a href="#cb8-62" tabindex="-1"></a>            offset_width <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-63"><a href="#cb8-63" tabindex="-1"></a>            target_height <span class="op">=</span> <span class="va">self</span>.shift_pixel</span>
<span id="cb8-64"><a href="#cb8-64" tabindex="-1"></a>            target_width <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-65"><a href="#cb8-65" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb8-66"><a href="#cb8-66" tabindex="-1"></a>            offset_height <span class="op">=</span> <span class="va">self</span>.shift_pixel</span>
<span id="cb8-67"><a href="#cb8-67" tabindex="-1"></a>            offset_width <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-68"><a href="#cb8-68" tabindex="-1"></a>            target_height <span class="op">=</span> <span class="va">self</span>.shift_pixel</span>
<span id="cb8-69"><a href="#cb8-69" tabindex="-1"></a>            target_width <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-70"><a href="#cb8-70" tabindex="-1"></a>        crop <span class="op">=</span> tf.image.crop_to_bounding_box(</span>
<span id="cb8-71"><a href="#cb8-71" tabindex="-1"></a>            x,</span>
<span id="cb8-72"><a href="#cb8-72" tabindex="-1"></a>            offset_height<span class="op">=</span>offset_height,</span>
<span id="cb8-73"><a href="#cb8-73" tabindex="-1"></a>            offset_width<span class="op">=</span>offset_width,</span>
<span id="cb8-74"><a href="#cb8-74" tabindex="-1"></a>            target_height<span class="op">=</span><span class="va">self</span>.H <span class="op">-</span> target_height,</span>
<span id="cb8-75"><a href="#cb8-75" tabindex="-1"></a>            target_width<span class="op">=</span><span class="va">self</span>.W <span class="op">-</span> target_width,</span>
<span id="cb8-76"><a href="#cb8-76" tabindex="-1"></a>        )</span>
<span id="cb8-77"><a href="#cb8-77" tabindex="-1"></a>        shift_pad <span class="op">=</span> tf.image.pad_to_bounding_box(</span>
<span id="cb8-78"><a href="#cb8-78" tabindex="-1"></a>            crop,</span>
<span id="cb8-79"><a href="#cb8-79" tabindex="-1"></a>            offset_height<span class="op">=</span>offset_height,</span>
<span id="cb8-80"><a href="#cb8-80" tabindex="-1"></a>            offset_width<span class="op">=</span>offset_width,</span>
<span id="cb8-81"><a href="#cb8-81" tabindex="-1"></a>            target_height<span class="op">=</span><span class="va">self</span>.H,</span>
<span id="cb8-82"><a href="#cb8-82" tabindex="-1"></a>            target_width<span class="op">=</span><span class="va">self</span>.W,</span>
<span id="cb8-83"><a href="#cb8-83" tabindex="-1"></a>        )</span>
<span id="cb8-84"><a href="#cb8-84" tabindex="-1"></a>        <span class="cf">return</span> shift_pad</span>
<span id="cb8-85"><a href="#cb8-85" tabindex="-1"></a></span>
<span id="cb8-86"><a href="#cb8-86" tabindex="-1"></a>    <span class="kw">def</span> call(<span class="va">self</span>, x, training<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb8-87"><a href="#cb8-87" tabindex="-1"></a>        <span class="co"># Split the feature maps</span></span>
<span id="cb8-88"><a href="#cb8-88" tabindex="-1"></a>        x_splits <span class="op">=</span> tf.split(</span>
<span id="cb8-89"><a href="#cb8-89" tabindex="-1"></a>            x, num_or_size_splits<span class="op">=</span><span class="va">self</span>.C <span class="op">//</span> <span class="va">self</span>.num_div, axis<span class="op">=-</span><span class="dv">1</span></span>
<span id="cb8-90"><a href="#cb8-90" tabindex="-1"></a>        )</span>
<span id="cb8-91"><a href="#cb8-91" tabindex="-1"></a></span>
<span id="cb8-92"><a href="#cb8-92" tabindex="-1"></a>        <span class="co"># Shift the feature maps</span></span>
<span id="cb8-93"><a href="#cb8-93" tabindex="-1"></a>        x_splits[<span class="dv">0</span>] <span class="op">=</span> <span class="va">self</span>.get_shift_pad(x_splits[<span class="dv">0</span>], mode<span class="op">=</span><span class="st">"left"</span>)</span>
<span id="cb8-94"><a href="#cb8-94" tabindex="-1"></a>        x_splits[<span class="dv">1</span>] <span class="op">=</span> <span class="va">self</span>.get_shift_pad(x_splits[<span class="dv">1</span>], mode<span class="op">=</span><span class="st">"right"</span>)</span>
<span id="cb8-95"><a href="#cb8-95" tabindex="-1"></a>        x_splits[<span class="dv">2</span>] <span class="op">=</span> <span class="va">self</span>.get_shift_pad(x_splits[<span class="dv">2</span>], mode<span class="op">=</span><span class="st">"up"</span>)</span>
<span id="cb8-96"><a href="#cb8-96" tabindex="-1"></a>        x_splits[<span class="dv">3</span>] <span class="op">=</span> <span class="va">self</span>.get_shift_pad(x_splits[<span class="dv">3</span>], mode<span class="op">=</span><span class="st">"down"</span>)</span>
<span id="cb8-97"><a href="#cb8-97" tabindex="-1"></a></span>
<span id="cb8-98"><a href="#cb8-98" tabindex="-1"></a>        <span class="co"># Concatenate the shifted and unshifted feature maps</span></span>
<span id="cb8-99"><a href="#cb8-99" tabindex="-1"></a>        x <span class="op">=</span> tf.concat(x_splits, axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb8-100"><a href="#cb8-100" tabindex="-1"></a></span>
<span id="cb8-101"><a href="#cb8-101" tabindex="-1"></a>        <span class="co"># Add the residual connection</span></span>
<span id="cb8-102"><a href="#cb8-102" tabindex="-1"></a>        shortcut <span class="op">=</span> x</span>
<span id="cb8-103"><a href="#cb8-103" tabindex="-1"></a>        x <span class="op">=</span> shortcut <span class="op">+</span> <span class="va">self</span>.drop_path(</span>
<span id="cb8-104"><a href="#cb8-104" tabindex="-1"></a>            <span class="va">self</span>.mlp(<span class="va">self</span>.layer_norm(x)), training<span class="op">=</span>training</span>
<span id="cb8-105"><a href="#cb8-105" tabindex="-1"></a>        )</span>
<span id="cb8-106"><a href="#cb8-106" tabindex="-1"></a>        <span class="cf">return</span> x</span></code></pre></div>
</div>
</div>
<div class="section level3">
<h3 id="the-shiftvit-blocks">The ShiftViT blocks<a class="anchor" aria-label="anchor" href="#the-shiftvit-blocks"></a>
</h3>
<table class="table">
<colgroup><col width="100%"></colgroup>
<thead><tr class="header">
<th align="center"><img src="https://i.imgur.com/FKy5NnD.png" alt="Shift Blokcs"></th>
</tr></thead>
<tbody><tr class="odd">
<td align="center">Figure 5: Shift Blocks in the architecture. <a href="https://arxiv.org/abs/2201.10801" class="external-link">Source</a>
</td>
</tr></tbody>
</table>
<p>Each stage of the architecture has shift blocks as shown in Fig.5.
Each of these blocks contain a variable number of stacked ShiftViT block
(as built in the earlier section).</p>
<p>Shift blocks are followed by a PatchMerging layer that scales down
feature inputs. The PatchMerging layer helps in the pyramidal structure
of the model.</p>
<div class="section level4">
<h4 id="the-patchmerging-layer">The PatchMerging layer<a class="anchor" aria-label="anchor" href="#the-patchmerging-layer"></a>
</h4>
<p>This layer merges the two adjacent tokens. This layer helps in
scaling the features down spatially and increasing the features up
channel wise. We use a Conv2D layer to merge the patches.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="kw">class</span> PatchMerging(layers.Layer):</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>    <span class="co">"""The Patch Merging layer.</span></span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a><span class="co">        epsilon (float): The epsilon constant.</span></span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, epsilon, <span class="op">**</span>kwargs):</span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(<span class="op">**</span>kwargs)</span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a>        <span class="va">self</span>.epsilon <span class="op">=</span> epsilon</span>
<span id="cb9-11"><a href="#cb9-11" tabindex="-1"></a></span>
<span id="cb9-12"><a href="#cb9-12" tabindex="-1"></a>    <span class="kw">def</span> build(<span class="va">self</span>, input_shape):</span>
<span id="cb9-13"><a href="#cb9-13" tabindex="-1"></a>        filters <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> input_shape[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb9-14"><a href="#cb9-14" tabindex="-1"></a>        <span class="va">self</span>.reduction <span class="op">=</span> layers.Conv2D(</span>
<span id="cb9-15"><a href="#cb9-15" tabindex="-1"></a>            filters<span class="op">=</span>filters,</span>
<span id="cb9-16"><a href="#cb9-16" tabindex="-1"></a>            kernel_size<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb9-17"><a href="#cb9-17" tabindex="-1"></a>            strides<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb9-18"><a href="#cb9-18" tabindex="-1"></a>            padding<span class="op">=</span><span class="st">"same"</span>,</span>
<span id="cb9-19"><a href="#cb9-19" tabindex="-1"></a>            use_bias<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb9-20"><a href="#cb9-20" tabindex="-1"></a>        )</span>
<span id="cb9-21"><a href="#cb9-21" tabindex="-1"></a>        <span class="va">self</span>.layer_norm <span class="op">=</span> layers.LayerNormalization(epsilon<span class="op">=</span><span class="va">self</span>.epsilon)</span>
<span id="cb9-22"><a href="#cb9-22" tabindex="-1"></a></span>
<span id="cb9-23"><a href="#cb9-23" tabindex="-1"></a>    <span class="kw">def</span> call(<span class="va">self</span>, x):</span>
<span id="cb9-24"><a href="#cb9-24" tabindex="-1"></a>        <span class="co"># Apply the patch merging algorithm on the feature maps</span></span>
<span id="cb9-25"><a href="#cb9-25" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.layer_norm(x)</span>
<span id="cb9-26"><a href="#cb9-26" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.reduction(x)</span>
<span id="cb9-27"><a href="#cb9-27" tabindex="-1"></a>        <span class="cf">return</span> x</span></code></pre></div>
</div>
<div class="section level4">
<h4 id="stacked-shift-blocks">Stacked Shift Blocks<a class="anchor" aria-label="anchor" href="#stacked-shift-blocks"></a>
</h4>
<p>Each stage will have a variable number of stacked ShiftViT Blocks, as
suggested in the paper. This is a generic layer that will contain the
stacked shift vit blocks with the patch merging layer as well. Combining
the two operations (shift ViT block and patch merging) is a design
choice we picked for better code reusability.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="co"># Note: This layer will have a different depth of stacking</span></span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a><span class="co"># for different stages on the model.</span></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a><span class="kw">class</span> StackedShiftBlocks(layers.Layer):</span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a>    <span class="co">"""The layer containing stacked ShiftViTBlocks.</span></span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a><span class="co">        epsilon (float): The epsilon constant.</span></span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a><span class="co">        mlp_dropout_rate (float): The dropout rate used in the MLP block.</span></span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a><span class="co">        num_shift_blocks (int): The number of shift vit blocks for this stage.</span></span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a><span class="co">        stochastic_depth_rate (float): The maximum drop path rate chosen.</span></span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a><span class="co">        is_merge (boolean): A flag that determines the use of the Patch Merge</span></span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a><span class="co">            layer after the shift vit blocks.</span></span>
<span id="cb10-13"><a href="#cb10-13" tabindex="-1"></a><span class="co">        num_div (int): The division of channels of the feature map. Defaults to `12`.</span></span>
<span id="cb10-14"><a href="#cb10-14" tabindex="-1"></a><span class="co">        shift_pixel (int): The number of pixels to shift. Defaults to `1`.</span></span>
<span id="cb10-15"><a href="#cb10-15" tabindex="-1"></a><span class="co">        mlp_expand_ratio (int): The ratio with which the initial dense layer of</span></span>
<span id="cb10-16"><a href="#cb10-16" tabindex="-1"></a><span class="co">            the MLP is expanded Defaults to `2`.</span></span>
<span id="cb10-17"><a href="#cb10-17" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb10-18"><a href="#cb10-18" tabindex="-1"></a></span>
<span id="cb10-19"><a href="#cb10-19" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb10-20"><a href="#cb10-20" tabindex="-1"></a>        <span class="va">self</span>,</span>
<span id="cb10-21"><a href="#cb10-21" tabindex="-1"></a>        epsilon,</span>
<span id="cb10-22"><a href="#cb10-22" tabindex="-1"></a>        mlp_dropout_rate,</span>
<span id="cb10-23"><a href="#cb10-23" tabindex="-1"></a>        num_shift_blocks,</span>
<span id="cb10-24"><a href="#cb10-24" tabindex="-1"></a>        stochastic_depth_rate,</span>
<span id="cb10-25"><a href="#cb10-25" tabindex="-1"></a>        is_merge,</span>
<span id="cb10-26"><a href="#cb10-26" tabindex="-1"></a>        num_div<span class="op">=</span><span class="dv">12</span>,</span>
<span id="cb10-27"><a href="#cb10-27" tabindex="-1"></a>        shift_pixel<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb10-28"><a href="#cb10-28" tabindex="-1"></a>        mlp_expand_ratio<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb10-29"><a href="#cb10-29" tabindex="-1"></a>        <span class="op">**</span>kwargs,</span>
<span id="cb10-30"><a href="#cb10-30" tabindex="-1"></a>    ):</span>
<span id="cb10-31"><a href="#cb10-31" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(<span class="op">**</span>kwargs)</span>
<span id="cb10-32"><a href="#cb10-32" tabindex="-1"></a>        <span class="va">self</span>.epsilon <span class="op">=</span> epsilon</span>
<span id="cb10-33"><a href="#cb10-33" tabindex="-1"></a>        <span class="va">self</span>.mlp_dropout_rate <span class="op">=</span> mlp_dropout_rate</span>
<span id="cb10-34"><a href="#cb10-34" tabindex="-1"></a>        <span class="va">self</span>.num_shift_blocks <span class="op">=</span> num_shift_blocks</span>
<span id="cb10-35"><a href="#cb10-35" tabindex="-1"></a>        <span class="va">self</span>.stochastic_depth_rate <span class="op">=</span> stochastic_depth_rate</span>
<span id="cb10-36"><a href="#cb10-36" tabindex="-1"></a>        <span class="va">self</span>.is_merge <span class="op">=</span> is_merge</span>
<span id="cb10-37"><a href="#cb10-37" tabindex="-1"></a>        <span class="va">self</span>.num_div <span class="op">=</span> num_div</span>
<span id="cb10-38"><a href="#cb10-38" tabindex="-1"></a>        <span class="va">self</span>.shift_pixel <span class="op">=</span> shift_pixel</span>
<span id="cb10-39"><a href="#cb10-39" tabindex="-1"></a>        <span class="va">self</span>.mlp_expand_ratio <span class="op">=</span> mlp_expand_ratio</span>
<span id="cb10-40"><a href="#cb10-40" tabindex="-1"></a></span>
<span id="cb10-41"><a href="#cb10-41" tabindex="-1"></a>    <span class="kw">def</span> build(<span class="va">self</span>, input_shapes):</span>
<span id="cb10-42"><a href="#cb10-42" tabindex="-1"></a>        <span class="co"># Calculate stochastic depth probabilities.</span></span>
<span id="cb10-43"><a href="#cb10-43" tabindex="-1"></a>        <span class="co"># Reference: https://keras.io/examples/vision/cct/#the-final-cct-model</span></span>
<span id="cb10-44"><a href="#cb10-44" tabindex="-1"></a>        dpr <span class="op">=</span> [</span>
<span id="cb10-45"><a href="#cb10-45" tabindex="-1"></a>            x</span>
<span id="cb10-46"><a href="#cb10-46" tabindex="-1"></a>            <span class="cf">for</span> x <span class="kw">in</span> np.linspace(</span>
<span id="cb10-47"><a href="#cb10-47" tabindex="-1"></a>                start<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb10-48"><a href="#cb10-48" tabindex="-1"></a>                stop<span class="op">=</span><span class="va">self</span>.stochastic_depth_rate,</span>
<span id="cb10-49"><a href="#cb10-49" tabindex="-1"></a>                num<span class="op">=</span><span class="va">self</span>.num_shift_blocks,</span>
<span id="cb10-50"><a href="#cb10-50" tabindex="-1"></a>            )</span>
<span id="cb10-51"><a href="#cb10-51" tabindex="-1"></a>        ]</span>
<span id="cb10-52"><a href="#cb10-52" tabindex="-1"></a></span>
<span id="cb10-53"><a href="#cb10-53" tabindex="-1"></a>        <span class="co"># Build the shift blocks as a list of ShiftViT Blocks</span></span>
<span id="cb10-54"><a href="#cb10-54" tabindex="-1"></a>        <span class="va">self</span>.shift_blocks <span class="op">=</span> <span class="bu">list</span>()</span>
<span id="cb10-55"><a href="#cb10-55" tabindex="-1"></a>        <span class="cf">for</span> num <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.num_shift_blocks):</span>
<span id="cb10-56"><a href="#cb10-56" tabindex="-1"></a>            <span class="va">self</span>.shift_blocks.append(</span>
<span id="cb10-57"><a href="#cb10-57" tabindex="-1"></a>                ShiftViTBlock(</span>
<span id="cb10-58"><a href="#cb10-58" tabindex="-1"></a>                    num_div<span class="op">=</span><span class="va">self</span>.num_div,</span>
<span id="cb10-59"><a href="#cb10-59" tabindex="-1"></a>                    epsilon<span class="op">=</span><span class="va">self</span>.epsilon,</span>
<span id="cb10-60"><a href="#cb10-60" tabindex="-1"></a>                    drop_path_prob<span class="op">=</span>dpr[num],</span>
<span id="cb10-61"><a href="#cb10-61" tabindex="-1"></a>                    mlp_dropout_rate<span class="op">=</span><span class="va">self</span>.mlp_dropout_rate,</span>
<span id="cb10-62"><a href="#cb10-62" tabindex="-1"></a>                    shift_pixel<span class="op">=</span><span class="va">self</span>.shift_pixel,</span>
<span id="cb10-63"><a href="#cb10-63" tabindex="-1"></a>                    mlp_expand_ratio<span class="op">=</span><span class="va">self</span>.mlp_expand_ratio,</span>
<span id="cb10-64"><a href="#cb10-64" tabindex="-1"></a>                )</span>
<span id="cb10-65"><a href="#cb10-65" tabindex="-1"></a>            )</span>
<span id="cb10-66"><a href="#cb10-66" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.is_merge:</span>
<span id="cb10-67"><a href="#cb10-67" tabindex="-1"></a>            <span class="va">self</span>.patch_merge <span class="op">=</span> PatchMerging(epsilon<span class="op">=</span><span class="va">self</span>.epsilon)</span>
<span id="cb10-68"><a href="#cb10-68" tabindex="-1"></a></span>
<span id="cb10-69"><a href="#cb10-69" tabindex="-1"></a>    <span class="kw">def</span> call(<span class="va">self</span>, x, training<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb10-70"><a href="#cb10-70" tabindex="-1"></a>        <span class="cf">for</span> shift_block <span class="kw">in</span> <span class="va">self</span>.shift_blocks:</span>
<span id="cb10-71"><a href="#cb10-71" tabindex="-1"></a>            x <span class="op">=</span> shift_block(x, training<span class="op">=</span>training)</span>
<span id="cb10-72"><a href="#cb10-72" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.is_merge:</span>
<span id="cb10-73"><a href="#cb10-73" tabindex="-1"></a>            x <span class="op">=</span> <span class="va">self</span>.patch_merge(x)</span>
<span id="cb10-74"><a href="#cb10-74" tabindex="-1"></a>        <span class="cf">return</span> x</span></code></pre></div>
</div>
</div>
</div>
<div class="section level2">
<h2 id="the-shiftvit-model">The ShiftViT model<a class="anchor" aria-label="anchor" href="#the-shiftvit-model"></a>
</h2>
<p>Build the ShiftViT custom model.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="kw">class</span> ShiftViTModel(keras.Model):</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>    <span class="co">"""The ShiftViT Model.</span></span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a><span class="co">        data_augmentation (keras.Model): A data augmentation model.</span></span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a><span class="co">        projected_dim (int): The dimension to which the patches of the image are</span></span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a><span class="co">            projected.</span></span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a><span class="co">        patch_size (int): The patch size of the images.</span></span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a><span class="co">        num_shift_blocks_per_stages (list[int]): A list of all the number of shit</span></span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a><span class="co">            blocks per stage.</span></span>
<span id="cb11-11"><a href="#cb11-11" tabindex="-1"></a><span class="co">        epsilon (float): The epsilon constant.</span></span>
<span id="cb11-12"><a href="#cb11-12" tabindex="-1"></a><span class="co">        mlp_dropout_rate (float): The dropout rate used in the MLP block.</span></span>
<span id="cb11-13"><a href="#cb11-13" tabindex="-1"></a><span class="co">        stochastic_depth_rate (float): The maximum drop rate probability.</span></span>
<span id="cb11-14"><a href="#cb11-14" tabindex="-1"></a><span class="co">        num_div (int): The number of divisions of the channesl of the feature</span></span>
<span id="cb11-15"><a href="#cb11-15" tabindex="-1"></a><span class="co">            map. Defaults to `12`.</span></span>
<span id="cb11-16"><a href="#cb11-16" tabindex="-1"></a><span class="co">        shift_pixel (int): The number of pixel to shift. Defaults to `1`.</span></span>
<span id="cb11-17"><a href="#cb11-17" tabindex="-1"></a><span class="co">        mlp_expand_ratio (int): The ratio with which the initial mlp dense layer</span></span>
<span id="cb11-18"><a href="#cb11-18" tabindex="-1"></a><span class="co">            is expanded to. Defaults to `2`.</span></span>
<span id="cb11-19"><a href="#cb11-19" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb11-20"><a href="#cb11-20" tabindex="-1"></a></span>
<span id="cb11-21"><a href="#cb11-21" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb11-22"><a href="#cb11-22" tabindex="-1"></a>        <span class="va">self</span>,</span>
<span id="cb11-23"><a href="#cb11-23" tabindex="-1"></a>        data_augmentation,</span>
<span id="cb11-24"><a href="#cb11-24" tabindex="-1"></a>        projected_dim,</span>
<span id="cb11-25"><a href="#cb11-25" tabindex="-1"></a>        patch_size,</span>
<span id="cb11-26"><a href="#cb11-26" tabindex="-1"></a>        num_shift_blocks_per_stages,</span>
<span id="cb11-27"><a href="#cb11-27" tabindex="-1"></a>        epsilon,</span>
<span id="cb11-28"><a href="#cb11-28" tabindex="-1"></a>        mlp_dropout_rate,</span>
<span id="cb11-29"><a href="#cb11-29" tabindex="-1"></a>        stochastic_depth_rate,</span>
<span id="cb11-30"><a href="#cb11-30" tabindex="-1"></a>        num_div<span class="op">=</span><span class="dv">12</span>,</span>
<span id="cb11-31"><a href="#cb11-31" tabindex="-1"></a>        shift_pixel<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb11-32"><a href="#cb11-32" tabindex="-1"></a>        mlp_expand_ratio<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb11-33"><a href="#cb11-33" tabindex="-1"></a>        <span class="op">**</span>kwargs,</span>
<span id="cb11-34"><a href="#cb11-34" tabindex="-1"></a>    ):</span>
<span id="cb11-35"><a href="#cb11-35" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(<span class="op">**</span>kwargs)</span>
<span id="cb11-36"><a href="#cb11-36" tabindex="-1"></a>        <span class="va">self</span>.data_augmentation <span class="op">=</span> data_augmentation</span>
<span id="cb11-37"><a href="#cb11-37" tabindex="-1"></a>        <span class="va">self</span>.patch_projection <span class="op">=</span> layers.Conv2D(</span>
<span id="cb11-38"><a href="#cb11-38" tabindex="-1"></a>            filters<span class="op">=</span>projected_dim,</span>
<span id="cb11-39"><a href="#cb11-39" tabindex="-1"></a>            kernel_size<span class="op">=</span>patch_size,</span>
<span id="cb11-40"><a href="#cb11-40" tabindex="-1"></a>            strides<span class="op">=</span>patch_size,</span>
<span id="cb11-41"><a href="#cb11-41" tabindex="-1"></a>            padding<span class="op">=</span><span class="st">"same"</span>,</span>
<span id="cb11-42"><a href="#cb11-42" tabindex="-1"></a>        )</span>
<span id="cb11-43"><a href="#cb11-43" tabindex="-1"></a>        <span class="va">self</span>.stages <span class="op">=</span> <span class="bu">list</span>()</span>
<span id="cb11-44"><a href="#cb11-44" tabindex="-1"></a>        <span class="cf">for</span> index, num_shift_blocks <span class="kw">in</span> <span class="bu">enumerate</span>(num_shift_blocks_per_stages):</span>
<span id="cb11-45"><a href="#cb11-45" tabindex="-1"></a>            <span class="cf">if</span> index <span class="op">==</span> <span class="bu">len</span>(num_shift_blocks_per_stages) <span class="op">-</span> <span class="dv">1</span>:</span>
<span id="cb11-46"><a href="#cb11-46" tabindex="-1"></a>                <span class="co"># This is the last stage, do not use the patch merge here.</span></span>
<span id="cb11-47"><a href="#cb11-47" tabindex="-1"></a>                is_merge <span class="op">=</span> <span class="va">False</span></span>
<span id="cb11-48"><a href="#cb11-48" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb11-49"><a href="#cb11-49" tabindex="-1"></a>                is_merge <span class="op">=</span> <span class="va">True</span></span>
<span id="cb11-50"><a href="#cb11-50" tabindex="-1"></a>            <span class="co"># Build the stages.</span></span>
<span id="cb11-51"><a href="#cb11-51" tabindex="-1"></a>            <span class="va">self</span>.stages.append(</span>
<span id="cb11-52"><a href="#cb11-52" tabindex="-1"></a>                StackedShiftBlocks(</span>
<span id="cb11-53"><a href="#cb11-53" tabindex="-1"></a>                    epsilon<span class="op">=</span>epsilon,</span>
<span id="cb11-54"><a href="#cb11-54" tabindex="-1"></a>                    mlp_dropout_rate<span class="op">=</span>mlp_dropout_rate,</span>
<span id="cb11-55"><a href="#cb11-55" tabindex="-1"></a>                    num_shift_blocks<span class="op">=</span>num_shift_blocks,</span>
<span id="cb11-56"><a href="#cb11-56" tabindex="-1"></a>                    stochastic_depth_rate<span class="op">=</span>stochastic_depth_rate,</span>
<span id="cb11-57"><a href="#cb11-57" tabindex="-1"></a>                    is_merge<span class="op">=</span>is_merge,</span>
<span id="cb11-58"><a href="#cb11-58" tabindex="-1"></a>                    num_div<span class="op">=</span>num_div,</span>
<span id="cb11-59"><a href="#cb11-59" tabindex="-1"></a>                    shift_pixel<span class="op">=</span>shift_pixel,</span>
<span id="cb11-60"><a href="#cb11-60" tabindex="-1"></a>                    mlp_expand_ratio<span class="op">=</span>mlp_expand_ratio,</span>
<span id="cb11-61"><a href="#cb11-61" tabindex="-1"></a>                )</span>
<span id="cb11-62"><a href="#cb11-62" tabindex="-1"></a>            )</span>
<span id="cb11-63"><a href="#cb11-63" tabindex="-1"></a>        <span class="va">self</span>.global_avg_pool <span class="op">=</span> layers.GlobalAveragePooling2D()</span>
<span id="cb11-64"><a href="#cb11-64" tabindex="-1"></a></span>
<span id="cb11-65"><a href="#cb11-65" tabindex="-1"></a>    <span class="kw">def</span> get_config(<span class="va">self</span>):</span>
<span id="cb11-66"><a href="#cb11-66" tabindex="-1"></a>        config <span class="op">=</span> <span class="bu">super</span>().get_config()</span>
<span id="cb11-67"><a href="#cb11-67" tabindex="-1"></a>        config.update(</span>
<span id="cb11-68"><a href="#cb11-68" tabindex="-1"></a>            {</span>
<span id="cb11-69"><a href="#cb11-69" tabindex="-1"></a>                <span class="st">"data_augmentation"</span>: <span class="va">self</span>.data_augmentation,</span>
<span id="cb11-70"><a href="#cb11-70" tabindex="-1"></a>                <span class="st">"patch_projection"</span>: <span class="va">self</span>.patch_projection,</span>
<span id="cb11-71"><a href="#cb11-71" tabindex="-1"></a>                <span class="st">"stages"</span>: <span class="va">self</span>.stages,</span>
<span id="cb11-72"><a href="#cb11-72" tabindex="-1"></a>                <span class="st">"global_avg_pool"</span>: <span class="va">self</span>.global_avg_pool,</span>
<span id="cb11-73"><a href="#cb11-73" tabindex="-1"></a>            }</span>
<span id="cb11-74"><a href="#cb11-74" tabindex="-1"></a>        )</span>
<span id="cb11-75"><a href="#cb11-75" tabindex="-1"></a>        <span class="cf">return</span> config</span>
<span id="cb11-76"><a href="#cb11-76" tabindex="-1"></a></span>
<span id="cb11-77"><a href="#cb11-77" tabindex="-1"></a>    <span class="kw">def</span> _calculate_loss(<span class="va">self</span>, data, training<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb11-78"><a href="#cb11-78" tabindex="-1"></a>        (images, labels) <span class="op">=</span> data</span>
<span id="cb11-79"><a href="#cb11-79" tabindex="-1"></a></span>
<span id="cb11-80"><a href="#cb11-80" tabindex="-1"></a>        <span class="co"># Augment the images</span></span>
<span id="cb11-81"><a href="#cb11-81" tabindex="-1"></a>        augmented_images <span class="op">=</span> <span class="va">self</span>.data_augmentation(images, training<span class="op">=</span>training)</span>
<span id="cb11-82"><a href="#cb11-82" tabindex="-1"></a></span>
<span id="cb11-83"><a href="#cb11-83" tabindex="-1"></a>        <span class="co"># Create patches and project the pathces.</span></span>
<span id="cb11-84"><a href="#cb11-84" tabindex="-1"></a>        projected_patches <span class="op">=</span> <span class="va">self</span>.patch_projection(augmented_images)</span>
<span id="cb11-85"><a href="#cb11-85" tabindex="-1"></a></span>
<span id="cb11-86"><a href="#cb11-86" tabindex="-1"></a>        <span class="co"># Pass through the stages</span></span>
<span id="cb11-87"><a href="#cb11-87" tabindex="-1"></a>        x <span class="op">=</span> projected_patches</span>
<span id="cb11-88"><a href="#cb11-88" tabindex="-1"></a>        <span class="cf">for</span> stage <span class="kw">in</span> <span class="va">self</span>.stages:</span>
<span id="cb11-89"><a href="#cb11-89" tabindex="-1"></a>            x <span class="op">=</span> stage(x, training<span class="op">=</span>training)</span>
<span id="cb11-90"><a href="#cb11-90" tabindex="-1"></a></span>
<span id="cb11-91"><a href="#cb11-91" tabindex="-1"></a>        <span class="co"># Get the logits.</span></span>
<span id="cb11-92"><a href="#cb11-92" tabindex="-1"></a>        logits <span class="op">=</span> <span class="va">self</span>.global_avg_pool(x)</span>
<span id="cb11-93"><a href="#cb11-93" tabindex="-1"></a></span>
<span id="cb11-94"><a href="#cb11-94" tabindex="-1"></a>        <span class="co"># Calculate the loss and return it.</span></span>
<span id="cb11-95"><a href="#cb11-95" tabindex="-1"></a>        total_loss <span class="op">=</span> <span class="va">self</span>.compute_loss(data, labels, logits)</span>
<span id="cb11-96"><a href="#cb11-96" tabindex="-1"></a>        <span class="cf">return</span> total_loss, labels, logits</span>
<span id="cb11-97"><a href="#cb11-97" tabindex="-1"></a></span>
<span id="cb11-98"><a href="#cb11-98" tabindex="-1"></a>    <span class="kw">def</span> train_step(<span class="va">self</span>, inputs):</span>
<span id="cb11-99"><a href="#cb11-99" tabindex="-1"></a>        <span class="cf">with</span> tf.GradientTape() <span class="im">as</span> tape:</span>
<span id="cb11-100"><a href="#cb11-100" tabindex="-1"></a>            total_loss, labels, logits <span class="op">=</span> <span class="va">self</span>._calculate_loss(</span>
<span id="cb11-101"><a href="#cb11-101" tabindex="-1"></a>                data<span class="op">=</span>inputs, training<span class="op">=</span><span class="va">True</span></span>
<span id="cb11-102"><a href="#cb11-102" tabindex="-1"></a>            )</span>
<span id="cb11-103"><a href="#cb11-103" tabindex="-1"></a></span>
<span id="cb11-104"><a href="#cb11-104" tabindex="-1"></a>        <span class="co"># Apply gradients.</span></span>
<span id="cb11-105"><a href="#cb11-105" tabindex="-1"></a>        train_vars <span class="op">=</span> [</span>
<span id="cb11-106"><a href="#cb11-106" tabindex="-1"></a>            <span class="va">self</span>.data_augmentation.trainable_variables,</span>
<span id="cb11-107"><a href="#cb11-107" tabindex="-1"></a>            <span class="va">self</span>.patch_projection.trainable_variables,</span>
<span id="cb11-108"><a href="#cb11-108" tabindex="-1"></a>            <span class="va">self</span>.global_avg_pool.trainable_variables,</span>
<span id="cb11-109"><a href="#cb11-109" tabindex="-1"></a>        ]</span>
<span id="cb11-110"><a href="#cb11-110" tabindex="-1"></a>        train_vars <span class="op">=</span> train_vars <span class="op">+</span> [</span>
<span id="cb11-111"><a href="#cb11-111" tabindex="-1"></a>            stage.trainable_variables <span class="cf">for</span> stage <span class="kw">in</span> <span class="va">self</span>.stages</span>
<span id="cb11-112"><a href="#cb11-112" tabindex="-1"></a>        ]</span>
<span id="cb11-113"><a href="#cb11-113" tabindex="-1"></a></span>
<span id="cb11-114"><a href="#cb11-114" tabindex="-1"></a>        <span class="co"># Optimize the gradients.</span></span>
<span id="cb11-115"><a href="#cb11-115" tabindex="-1"></a>        grads <span class="op">=</span> tape.gradient(total_loss, train_vars)</span>
<span id="cb11-116"><a href="#cb11-116" tabindex="-1"></a>        trainable_variable_list <span class="op">=</span> []</span>
<span id="cb11-117"><a href="#cb11-117" tabindex="-1"></a>        <span class="cf">for</span> grad, var <span class="kw">in</span> <span class="bu">zip</span>(grads, train_vars):</span>
<span id="cb11-118"><a href="#cb11-118" tabindex="-1"></a>            <span class="cf">for</span> g, v <span class="kw">in</span> <span class="bu">zip</span>(grad, var):</span>
<span id="cb11-119"><a href="#cb11-119" tabindex="-1"></a>                trainable_variable_list.append((g, v))</span>
<span id="cb11-120"><a href="#cb11-120" tabindex="-1"></a>        <span class="va">self</span>.optimizer.apply_gradients(trainable_variable_list)</span>
<span id="cb11-121"><a href="#cb11-121" tabindex="-1"></a></span>
<span id="cb11-122"><a href="#cb11-122" tabindex="-1"></a>        <span class="co"># Update the metrics</span></span>
<span id="cb11-123"><a href="#cb11-123" tabindex="-1"></a>        <span class="cf">for</span> metric <span class="kw">in</span> <span class="va">self</span>.metrics:</span>
<span id="cb11-124"><a href="#cb11-124" tabindex="-1"></a>            <span class="cf">if</span> metric.name <span class="op">==</span> <span class="st">"loss"</span>:</span>
<span id="cb11-125"><a href="#cb11-125" tabindex="-1"></a>                metric.update_state(total_loss)</span>
<span id="cb11-126"><a href="#cb11-126" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb11-127"><a href="#cb11-127" tabindex="-1"></a>                metric.update_state(labels, logits)</span>
<span id="cb11-128"><a href="#cb11-128" tabindex="-1"></a></span>
<span id="cb11-129"><a href="#cb11-129" tabindex="-1"></a>        <span class="co"># Return a dict mapping metric names to current value</span></span>
<span id="cb11-130"><a href="#cb11-130" tabindex="-1"></a>        <span class="cf">return</span> {m.name: m.result() <span class="cf">for</span> m <span class="kw">in</span> <span class="va">self</span>.metrics}</span>
<span id="cb11-131"><a href="#cb11-131" tabindex="-1"></a></span>
<span id="cb11-132"><a href="#cb11-132" tabindex="-1"></a>    <span class="kw">def</span> test_step(<span class="va">self</span>, data):</span>
<span id="cb11-133"><a href="#cb11-133" tabindex="-1"></a>        loss, labels, logits <span class="op">=</span> <span class="va">self</span>._calculate_loss(data<span class="op">=</span>data, training<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb11-134"><a href="#cb11-134" tabindex="-1"></a></span>
<span id="cb11-135"><a href="#cb11-135" tabindex="-1"></a>        <span class="co"># Update the metrics</span></span>
<span id="cb11-136"><a href="#cb11-136" tabindex="-1"></a>        <span class="cf">for</span> metric <span class="kw">in</span> <span class="va">self</span>.metrics:</span>
<span id="cb11-137"><a href="#cb11-137" tabindex="-1"></a>            <span class="cf">if</span> metric.name <span class="op">==</span> <span class="st">"loss"</span>:</span>
<span id="cb11-138"><a href="#cb11-138" tabindex="-1"></a>                metric.update_state(loss)</span>
<span id="cb11-139"><a href="#cb11-139" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb11-140"><a href="#cb11-140" tabindex="-1"></a>                metric.update_state(labels, logits)</span>
<span id="cb11-141"><a href="#cb11-141" tabindex="-1"></a></span>
<span id="cb11-142"><a href="#cb11-142" tabindex="-1"></a>        <span class="co"># Return a dict mapping metric names to current value</span></span>
<span id="cb11-143"><a href="#cb11-143" tabindex="-1"></a>        <span class="cf">return</span> {m.name: m.result() <span class="cf">for</span> m <span class="kw">in</span> <span class="va">self</span>.metrics}</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="instantiate-the-model">Instantiate the model<a class="anchor" aria-label="anchor" href="#instantiate-the-model"></a>
</h2>
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a>model <span class="op">=</span> ShiftViTModel(</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a>    data_augmentation<span class="op">=</span>get_augmentation_model(),</span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>    projected_dim<span class="op">=</span>config.projected_dim,</span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a>    patch_size<span class="op">=</span>config.patch_size,</span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a>    num_shift_blocks_per_stages<span class="op">=</span>config.num_shift_blocks_per_stages,</span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a>    epsilon<span class="op">=</span>config.epsilon,</span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a>    mlp_dropout_rate<span class="op">=</span>config.mlp_dropout_rate,</span>
<span id="cb12-8"><a href="#cb12-8" tabindex="-1"></a>    stochastic_depth_rate<span class="op">=</span>config.stochastic_depth_rate,</span>
<span id="cb12-9"><a href="#cb12-9" tabindex="-1"></a>    num_div<span class="op">=</span>config.num_div,</span>
<span id="cb12-10"><a href="#cb12-10" tabindex="-1"></a>    shift_pixel<span class="op">=</span>config.shift_pixel,</span>
<span id="cb12-11"><a href="#cb12-11" tabindex="-1"></a>    mlp_expand_ratio<span class="op">=</span>config.mlp_expand_ratio,</span>
<span id="cb12-12"><a href="#cb12-12" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="learning-rate-schedule">Learning rate schedule<a class="anchor" aria-label="anchor" href="#learning-rate-schedule"></a>
</h2>
<p>In many experiments, we want to warm up the model with a slowly
increasing learning rate and then cool down the model with a slowly
decaying learning rate. In the warmup cosine decay, the learning rate
linearly increases for the warmup steps and then decays with a cosine
decay.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="co"># Some code is taken from:</span></span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a><span class="co"># https://www.kaggle.com/ashusma/training-rfcx-tensorflow-tpu-effnet-b2.</span></span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a><span class="kw">class</span> WarmUpCosine(keras.optimizers.schedules.LearningRateSchedule):</span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a>    <span class="co">"""A LearningRateSchedule that uses a warmup cosine decay schedule."""</span></span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, lr_start, lr_max, warmup_steps, total_steps):</span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a><span class="co">            lr_start: The initial learning rate</span></span>
<span id="cb13-10"><a href="#cb13-10" tabindex="-1"></a><span class="co">            lr_max: The maximum learning rate to which lr should increase to in</span></span>
<span id="cb13-11"><a href="#cb13-11" tabindex="-1"></a><span class="co">                the warmup steps</span></span>
<span id="cb13-12"><a href="#cb13-12" tabindex="-1"></a><span class="co">            warmup_steps: The number of steps for which the model warms up</span></span>
<span id="cb13-13"><a href="#cb13-13" tabindex="-1"></a><span class="co">            total_steps: The total number of steps for the model training</span></span>
<span id="cb13-14"><a href="#cb13-14" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb13-15"><a href="#cb13-15" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb13-16"><a href="#cb13-16" tabindex="-1"></a>        <span class="va">self</span>.lr_start <span class="op">=</span> lr_start</span>
<span id="cb13-17"><a href="#cb13-17" tabindex="-1"></a>        <span class="va">self</span>.lr_max <span class="op">=</span> lr_max</span>
<span id="cb13-18"><a href="#cb13-18" tabindex="-1"></a>        <span class="va">self</span>.warmup_steps <span class="op">=</span> warmup_steps</span>
<span id="cb13-19"><a href="#cb13-19" tabindex="-1"></a>        <span class="va">self</span>.total_steps <span class="op">=</span> total_steps</span>
<span id="cb13-20"><a href="#cb13-20" tabindex="-1"></a>        <span class="va">self</span>.pi <span class="op">=</span> tf.constant(np.pi)</span>
<span id="cb13-21"><a href="#cb13-21" tabindex="-1"></a></span>
<span id="cb13-22"><a href="#cb13-22" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, step):</span>
<span id="cb13-23"><a href="#cb13-23" tabindex="-1"></a>        <span class="co"># Check whether the total number of steps is larger than the warmup</span></span>
<span id="cb13-24"><a href="#cb13-24" tabindex="-1"></a>        <span class="co"># steps. If not, then throw a value error.</span></span>
<span id="cb13-25"><a href="#cb13-25" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.total_steps <span class="op">&lt;</span> <span class="va">self</span>.warmup_steps:</span>
<span id="cb13-26"><a href="#cb13-26" tabindex="-1"></a>            <span class="cf">raise</span> <span class="pp">ValueError</span>(</span>
<span id="cb13-27"><a href="#cb13-27" tabindex="-1"></a>                <span class="ss">f"Total number of steps </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>total_steps<span class="sc">}</span><span class="ss"> must be"</span></span>
<span id="cb13-28"><a href="#cb13-28" tabindex="-1"></a>                <span class="op">+</span> <span class="ss">f"larger or equal to warmup steps </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>warmup_steps<span class="sc">}</span><span class="ss">."</span></span>
<span id="cb13-29"><a href="#cb13-29" tabindex="-1"></a>            )</span>
<span id="cb13-30"><a href="#cb13-30" tabindex="-1"></a></span>
<span id="cb13-31"><a href="#cb13-31" tabindex="-1"></a>        <span class="co"># `cos_annealed_lr` is a graph that increases to 1 from the initial</span></span>
<span id="cb13-32"><a href="#cb13-32" tabindex="-1"></a>        <span class="co"># step to the warmup step. After that this graph decays to -1 at the</span></span>
<span id="cb13-33"><a href="#cb13-33" tabindex="-1"></a>        <span class="co"># final step mark.</span></span>
<span id="cb13-34"><a href="#cb13-34" tabindex="-1"></a>        cos_annealed_lr <span class="op">=</span> tf.cos(</span>
<span id="cb13-35"><a href="#cb13-35" tabindex="-1"></a>            <span class="va">self</span>.pi</span>
<span id="cb13-36"><a href="#cb13-36" tabindex="-1"></a>            <span class="op">*</span> (tf.cast(step, tf.float32) <span class="op">-</span> <span class="va">self</span>.warmup_steps)</span>
<span id="cb13-37"><a href="#cb13-37" tabindex="-1"></a>            <span class="op">/</span> tf.cast(<span class="va">self</span>.total_steps <span class="op">-</span> <span class="va">self</span>.warmup_steps, tf.float32)</span>
<span id="cb13-38"><a href="#cb13-38" tabindex="-1"></a>        )</span>
<span id="cb13-39"><a href="#cb13-39" tabindex="-1"></a></span>
<span id="cb13-40"><a href="#cb13-40" tabindex="-1"></a>        <span class="co"># Shift the mean of the `cos_annealed_lr` graph to 1. Now the grpah goes</span></span>
<span id="cb13-41"><a href="#cb13-41" tabindex="-1"></a>        <span class="co"># from 0 to 2. Normalize the graph with 0.5 so that now it goes from 0</span></span>
<span id="cb13-42"><a href="#cb13-42" tabindex="-1"></a>        <span class="co"># to 1. With the normalized graph we scale it with `lr_max` such that</span></span>
<span id="cb13-43"><a href="#cb13-43" tabindex="-1"></a>        <span class="co"># it goes from 0 to `lr_max`</span></span>
<span id="cb13-44"><a href="#cb13-44" tabindex="-1"></a>        learning_rate <span class="op">=</span> <span class="fl">0.5</span> <span class="op">*</span> <span class="va">self</span>.lr_max <span class="op">*</span> (<span class="dv">1</span> <span class="op">+</span> cos_annealed_lr)</span>
<span id="cb13-45"><a href="#cb13-45" tabindex="-1"></a></span>
<span id="cb13-46"><a href="#cb13-46" tabindex="-1"></a>        <span class="co"># Check whether warmup_steps is more than 0.</span></span>
<span id="cb13-47"><a href="#cb13-47" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.warmup_steps <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb13-48"><a href="#cb13-48" tabindex="-1"></a>            <span class="co"># Check whether lr_max is larger that lr_start. If not, throw a value</span></span>
<span id="cb13-49"><a href="#cb13-49" tabindex="-1"></a>            <span class="co"># error.</span></span>
<span id="cb13-50"><a href="#cb13-50" tabindex="-1"></a>            <span class="cf">if</span> <span class="va">self</span>.lr_max <span class="op">&lt;</span> <span class="va">self</span>.lr_start:</span>
<span id="cb13-51"><a href="#cb13-51" tabindex="-1"></a>                <span class="cf">raise</span> <span class="pp">ValueError</span>(</span>
<span id="cb13-52"><a href="#cb13-52" tabindex="-1"></a>                    <span class="ss">f"lr_start </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>lr_start<span class="sc">}</span><span class="ss"> must be smaller or"</span></span>
<span id="cb13-53"><a href="#cb13-53" tabindex="-1"></a>                    <span class="op">+</span> <span class="ss">f"equal to lr_max </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>lr_max<span class="sc">}</span><span class="ss">."</span></span>
<span id="cb13-54"><a href="#cb13-54" tabindex="-1"></a>                )</span>
<span id="cb13-55"><a href="#cb13-55" tabindex="-1"></a></span>
<span id="cb13-56"><a href="#cb13-56" tabindex="-1"></a>            <span class="co"># Calculate the slope with which the learning rate should increase</span></span>
<span id="cb13-57"><a href="#cb13-57" tabindex="-1"></a>            <span class="co"># in the warumup schedule. The formula for slope is m = ((b-a)/steps)</span></span>
<span id="cb13-58"><a href="#cb13-58" tabindex="-1"></a>            slope <span class="op">=</span> (<span class="va">self</span>.lr_max <span class="op">-</span> <span class="va">self</span>.lr_start) <span class="op">/</span> <span class="va">self</span>.warmup_steps</span>
<span id="cb13-59"><a href="#cb13-59" tabindex="-1"></a></span>
<span id="cb13-60"><a href="#cb13-60" tabindex="-1"></a>            <span class="co"># With the formula for a straight line (y = mx+c) build the warmup</span></span>
<span id="cb13-61"><a href="#cb13-61" tabindex="-1"></a>            <span class="co"># schedule</span></span>
<span id="cb13-62"><a href="#cb13-62" tabindex="-1"></a>            warmup_rate <span class="op">=</span> slope <span class="op">*</span> tf.cast(step, tf.float32) <span class="op">+</span> <span class="va">self</span>.lr_start</span>
<span id="cb13-63"><a href="#cb13-63" tabindex="-1"></a></span>
<span id="cb13-64"><a href="#cb13-64" tabindex="-1"></a>            <span class="co"># When the current step is lesser that warmup steps, get the line</span></span>
<span id="cb13-65"><a href="#cb13-65" tabindex="-1"></a>            <span class="co"># graph. When the current step is greater than the warmup steps, get</span></span>
<span id="cb13-66"><a href="#cb13-66" tabindex="-1"></a>            <span class="co"># the scaled cos graph.</span></span>
<span id="cb13-67"><a href="#cb13-67" tabindex="-1"></a>            learning_rate <span class="op">=</span> tf.where(</span>
<span id="cb13-68"><a href="#cb13-68" tabindex="-1"></a>                step <span class="op">&lt;</span> <span class="va">self</span>.warmup_steps, warmup_rate, learning_rate</span>
<span id="cb13-69"><a href="#cb13-69" tabindex="-1"></a>            )</span>
<span id="cb13-70"><a href="#cb13-70" tabindex="-1"></a></span>
<span id="cb13-71"><a href="#cb13-71" tabindex="-1"></a>        <span class="co"># When the current step is more that the total steps, return 0 else return</span></span>
<span id="cb13-72"><a href="#cb13-72" tabindex="-1"></a>        <span class="co"># the calculated graph.</span></span>
<span id="cb13-73"><a href="#cb13-73" tabindex="-1"></a>        <span class="cf">return</span> tf.where(</span>
<span id="cb13-74"><a href="#cb13-74" tabindex="-1"></a>            step <span class="op">&gt;</span> <span class="va">self</span>.total_steps, <span class="fl">0.0</span>, learning_rate, name<span class="op">=</span><span class="st">"learning_rate"</span></span>
<span id="cb13-75"><a href="#cb13-75" tabindex="-1"></a>        )</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="compile-and-train-the-model">Compile and train the model<a class="anchor" aria-label="anchor" href="#compile-and-train-the-model"></a>
</h2>
<div class="sourceCode" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="co"># Get the total number of steps for training.</span></span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a>total_steps <span class="op">=</span> <span class="bu">int</span>((<span class="bu">len</span>(x_train) <span class="op">/</span> config.batch_size) <span class="op">*</span> config.epochs)</span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a><span class="co"># Calculate the number of steps for warmup.</span></span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a>warmup_epoch_percentage <span class="op">=</span> <span class="fl">0.15</span></span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a>warmup_steps <span class="op">=</span> <span class="bu">int</span>(total_steps <span class="op">*</span> warmup_epoch_percentage)</span>
<span id="cb14-7"><a href="#cb14-7" tabindex="-1"></a></span>
<span id="cb14-8"><a href="#cb14-8" tabindex="-1"></a><span class="co"># Initialize the warmupcosine schedule.</span></span>
<span id="cb14-9"><a href="#cb14-9" tabindex="-1"></a>scheduled_lrs <span class="op">=</span> WarmUpCosine(</span>
<span id="cb14-10"><a href="#cb14-10" tabindex="-1"></a>    lr_start<span class="op">=</span><span class="fl">1e-5</span>,</span>
<span id="cb14-11"><a href="#cb14-11" tabindex="-1"></a>    lr_max<span class="op">=</span><span class="fl">1e-3</span>,</span>
<span id="cb14-12"><a href="#cb14-12" tabindex="-1"></a>    warmup_steps<span class="op">=</span>warmup_steps,</span>
<span id="cb14-13"><a href="#cb14-13" tabindex="-1"></a>    total_steps<span class="op">=</span>total_steps,</span>
<span id="cb14-14"><a href="#cb14-14" tabindex="-1"></a>)</span>
<span id="cb14-15"><a href="#cb14-15" tabindex="-1"></a></span>
<span id="cb14-16"><a href="#cb14-16" tabindex="-1"></a><span class="co"># Get the optimizer.</span></span>
<span id="cb14-17"><a href="#cb14-17" tabindex="-1"></a>optimizer <span class="op">=</span> keras.optimizers.AdamW(</span>
<span id="cb14-18"><a href="#cb14-18" tabindex="-1"></a>    learning_rate<span class="op">=</span>scheduled_lrs, weight_decay<span class="op">=</span>config.weight_decay</span>
<span id="cb14-19"><a href="#cb14-19" tabindex="-1"></a>)</span>
<span id="cb14-20"><a href="#cb14-20" tabindex="-1"></a></span>
<span id="cb14-21"><a href="#cb14-21" tabindex="-1"></a><span class="co"># Compile and pretrain the model.</span></span>
<span id="cb14-22"><a href="#cb14-22" tabindex="-1"></a>model.<span class="bu">compile</span>(</span>
<span id="cb14-23"><a href="#cb14-23" tabindex="-1"></a>    optimizer<span class="op">=</span>optimizer,</span>
<span id="cb14-24"><a href="#cb14-24" tabindex="-1"></a>    loss<span class="op">=</span>keras.losses.SparseCategoricalCrossentropy(from_logits<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb14-25"><a href="#cb14-25" tabindex="-1"></a>    metrics<span class="op">=</span>[</span>
<span id="cb14-26"><a href="#cb14-26" tabindex="-1"></a>        keras.metrics.SparseCategoricalAccuracy(name<span class="op">=</span><span class="st">"accuracy"</span>),</span>
<span id="cb14-27"><a href="#cb14-27" tabindex="-1"></a>        keras.metrics.SparseTopKCategoricalAccuracy(<span class="dv">5</span>, name<span class="op">=</span><span class="st">"top-5-accuracy"</span>),</span>
<span id="cb14-28"><a href="#cb14-28" tabindex="-1"></a>    ],</span>
<span id="cb14-29"><a href="#cb14-29" tabindex="-1"></a>)</span>
<span id="cb14-30"><a href="#cb14-30" tabindex="-1"></a></span>
<span id="cb14-31"><a href="#cb14-31" tabindex="-1"></a><span class="co"># Train the model</span></span>
<span id="cb14-32"><a href="#cb14-32" tabindex="-1"></a>history <span class="op">=</span> model.fit(</span>
<span id="cb14-33"><a href="#cb14-33" tabindex="-1"></a>    train_ds,</span>
<span id="cb14-34"><a href="#cb14-34" tabindex="-1"></a>    epochs<span class="op">=</span>config.epochs,</span>
<span id="cb14-35"><a href="#cb14-35" tabindex="-1"></a>    validation_data<span class="op">=</span>val_ds,</span>
<span id="cb14-36"><a href="#cb14-36" tabindex="-1"></a>    callbacks<span class="op">=</span>[</span>
<span id="cb14-37"><a href="#cb14-37" tabindex="-1"></a>        keras.callbacks.EarlyStopping(</span>
<span id="cb14-38"><a href="#cb14-38" tabindex="-1"></a>            monitor<span class="op">=</span><span class="st">"val_accuracy"</span>,</span>
<span id="cb14-39"><a href="#cb14-39" tabindex="-1"></a>            patience<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb14-40"><a href="#cb14-40" tabindex="-1"></a>            mode<span class="op">=</span><span class="st">"auto"</span>,</span>
<span id="cb14-41"><a href="#cb14-41" tabindex="-1"></a>        )</span>
<span id="cb14-42"><a href="#cb14-42" tabindex="-1"></a>    ],</span>
<span id="cb14-43"><a href="#cb14-43" tabindex="-1"></a>)</span>
<span id="cb14-44"><a href="#cb14-44" tabindex="-1"></a></span>
<span id="cb14-45"><a href="#cb14-45" tabindex="-1"></a><span class="co"># Evaluate the model with the test dataset.</span></span>
<span id="cb14-46"><a href="#cb14-46" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"TESTING"</span>)</span>
<span id="cb14-47"><a href="#cb14-47" tabindex="-1"></a>loss, acc_top1, acc_top5 <span class="op">=</span> model.evaluate(test_ds)</span>
<span id="cb14-48"><a href="#cb14-48" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Loss: </span><span class="sc">{</span>loss<span class="sc">:0.2f}</span><span class="ss">"</span>)</span>
<span id="cb14-49"><a href="#cb14-49" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Top 1 test accuracy: </span><span class="sc">{</span>acc_top1<span class="op">*</span><span class="dv">100</span><span class="sc">:0.2f}</span><span class="ss">%"</span>)</span>
<span id="cb14-50"><a href="#cb14-50" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Top 5 test accuracy: </span><span class="sc">{</span>acc_top5<span class="op">*</span><span class="dv">100</span><span class="sc">:0.2f}</span><span class="ss">%"</span>)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="conclusion">Conclusion<a class="anchor" aria-label="anchor" href="#conclusion"></a>
</h2>
<p>The most impactful contribution of the paper is not the novel
architecture, but the idea that hierarchical ViTs trained with no
attention can perform quite well. This opens up the question of how
essential attention is to the performance of ViTs.</p>
<p>For curious minds, we would suggest reading the <a href="https://arxiv.org/abs/2201.03545" class="external-link">ConvNexT</a> paper which attends
more to the training paradigms and architectural details of ViTs rather
than providing a novel architecture based on attention.</p>
<p>Acknowledgements:</p>
<ul>
<li>We would like to thank <a href="https://pyimagesearch.com" class="external-link">PyImageSearch</a> for providing us with
resources that helped in the completion of this project.</li>
<li>We would like to thank <a href="https://jarvislabs.ai/" class="external-link">JarvisLabs.ai</a> for providing with the
GPU credits.</li>
<li>We would like to thank <a href="https://www.manim.community/" class="external-link">Manim
Community</a> for the manim library.</li>
<li>A personal note of thanks to <a href="https://twitter.com/pleb_talks" class="external-link">Puja Roychowdhury</a> for helping
us with the Learning Rate Schedule.</li>
</ul>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Tomasz Kalinowski, JJ Allaire, FranÃ§ois Chollet, Posit Software, PBC, Google.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.9000.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
