<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="Implementing Zero-Reference Deep Curve Estimation for low-light image enhancement.">
<title>Zero-DCE for low-light image enhancement â€¢ keras3</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../../apple-touch-icon-60x60.png">
<script src="../../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../../pkgdown.js"></script><meta property="og:title" content="Zero-DCE for low-light image enhancement">
<meta property="og:description" content="Implementing Zero-Reference Deep Curve Estimation for low-light image enhancement.">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-inverse navbar-expand-lg bg-primary"><div class="container">
    
    <a class="navbar-brand me-2" href="../../index.html">keras3</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">2.13.0.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../../index.html">Home</a>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-getting-started">Getting Started</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-getting-started">
    <a class="dropdown-item" href="../../articles/intro_to_keras_for_engineers.html">Introduction to Keras for engineers</a>
    <h6 class="dropdown-header" data-toc-skip>Tutorials</h6>
    <a class="dropdown-item" href="../../articles/getting_started.html">Getting Started</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_classification.html">Basic Classification</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_text_classification.html">Text Classification</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_regression.html">Basic Regression</a>
    <a class="dropdown-item" href="../../articles/tutorial_overfit_underfit.html">Overfitting and Underfitting</a>
    <a class="dropdown-item" href="../../articles/tutorial_save_and_restore.html">Save and Restore Models</a>
  </div>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-guides">Guides</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-guides">
    <h6 class="dropdown-header" data-toc-skip>Model definition</h6>
    <a class="dropdown-item" href="../../articles/functional_api.html">Functional API</a>
    <a class="dropdown-item" href="../../articles/sequential_model.html">Sequential Model</a>
    <h6 class="dropdown-header" data-toc-skip>Extending and customizing</h6>
    <a class="dropdown-item" href="../../articles/making_new_layers_and_models_via_subclassing.html">Making new layers and models via subclassing</a>
    <a class="dropdown-item" href="../../articles/training_with_built_in_methods.html">Training &amp; evaluation with the built-in methods</a>
    <a class="dropdown-item" href="../../articles/writing_a_custom_training_loop_in_tensorflow.html">Writing a training loop from scratch in TensorFlow</a>
    <a class="dropdown-item" href="../../articles/writing_your_own_callbacks.html">Writing Your Own Callbacks</a>
    <h6 class="dropdown-header" data-toc-skip>Other topics</h6>
    <a class="dropdown-item" href="../../articles/transfer_learning.html">Transfer learning and fine tuning</a>
    <a class="dropdown-item" href="../../articles/distributed_training_with_tensorflow.html">Distributed training with TensorFlow</a>
  </div>
</li>
<li class="active nav-item">
  <a class="nav-link" href="../../articles/examples/index.html">Examples</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../reference/index.html">Reference</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../news/index.html">News</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/rstudio/keras/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Zero-DCE for low-light image enhancement</h1>
                        <h4 data-toc-skip class="author"><a href="http://github.com/soumik12345" class="external-link">Soumik Rakshit</a></h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/rstudio/keras/blob/HEAD/vignettes/examples/zero_dce.Rmd" class="external-link"><code>vignettes/examples/zero_dce.Rmd</code></a></small>
      <div class="d-none name"><code>zero_dce.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p><strong>Zero-Reference Deep Curve Estimation</strong> or
<strong>Zero-DCE</strong> formulates low-light image enhancement as the
task of estimating an image-specific <a href="https://en.wikipedia.org/wiki/Curve_(tonality)" class="external-link"><em>tonal
curve</em></a> with a deep neural network. In this example, we train a
lightweight deep network, <strong>DCE-Net</strong>, to estimate
pixel-wise and high-order tonal curves for dynamic range adjustment of a
given image.</p>
<p>Zero-DCE takes a low-light image as input and produces high-order
tonal curves as its output. These curves are then used for pixel-wise
adjustment on the dynamic range of the input to obtain an enhanced
image. The curve estimation process is done in such a way that it
maintains the range of the enhanced image and preserves the contrast of
neighboring pixels. This curve estimation is inspired by curves
adjustment used in photo editing software such as Adobe Photoshop where
users can adjust points throughout an imageâ€™s tonal range.</p>
<p>Zero-DCE is appealing because of its relaxed assumptions with regard
to reference images: it does not require any input/output image pairs
during training. This is achieved through a set of carefully formulated
non-reference loss functions, which implicitly measure the enhancement
quality and guide the training of the network.</p>
<div class="section level3">
<h3 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h3>
<ul>
<li><a href="https://arxiv.org/pdf/2001.06826.pdf" class="external-link">Zero-Reference Deep
Curve Estimation for Low-Light Image Enhancement</a></li>
<li><a href="https://helpx.adobe.com/photoshop/using/curves-adjustment.html" class="external-link">Curves
adjustment in Adobe Photoshop</a></li>
</ul>
</div>
</div>
<div class="section level2">
<h2 id="downloading-loldataset">Downloading LOLDataset<a class="anchor" aria-label="anchor" href="#downloading-loldataset"></a>
</h2>
<p>The <strong>LoL Dataset</strong> has been created for low-light image
enhancement. It provides 485 images for training and 15 for testing.
Each image pair in the dataset consists of a low-light input image and
its corresponding well-exposed reference image.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">from</span> glob <span class="im">import</span> glob</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image, ImageOps</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="im">import</span> keras <span class="im">as</span> keras</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="im">from</span> keras <span class="im">import</span> layers</span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span></code></pre></div>
<p>wget <a href="https://huggingface.co/datasets/geekyrakshit/LoL-Dataset/resolve/main/lol_dataset.zip" class="external-link uri">https://huggingface.co/datasets/geekyrakshit/LoL-Dataset/resolve/main/lol_dataset.zip</a>
unzip -q lol_dataset.zip &amp;&amp; rm lol_dataset.zip</p>
</div>
<div class="section level2">
<h2 id="creating-a-tensorflow-dataset">Creating a TensorFlow Dataset<a class="anchor" aria-label="anchor" href="#creating-a-tensorflow-dataset"></a>
</h2>
<p>We use 300 low-light images from the LoL Dataset training set for
training, and we use the remaining 185 low-light images for validation.
We resize the images to size <code>256 x 256</code> to be used for both
training and validation. Note that in order to train the DCE-Net, we
will not require the corresponding enhanced images.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>IMAGE_SIZE <span class="op">=</span> <span class="dv">256</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>BATCH_SIZE <span class="op">=</span> <span class="dv">16</span></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>MAX_TRAIN_IMAGES <span class="op">=</span> <span class="dv">400</span></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a><span class="kw">def</span> load_data(image_path):</span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>    image <span class="op">=</span> tf.io.read_file(image_path)</span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a>    image <span class="op">=</span> tf.image.decode_png(image, channels<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a>    image <span class="op">=</span> tf.image.resize(images<span class="op">=</span>image, size<span class="op">=</span>[IMAGE_SIZE, IMAGE_SIZE])</span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a>    image <span class="op">=</span> image <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a>    <span class="cf">return</span> image</span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a><span class="kw">def</span> data_generator(low_light_images):</span>
<span id="cb2-15"><a href="#cb2-15" tabindex="-1"></a>    dataset <span class="op">=</span> tf.data.Dataset.from_tensor_slices((low_light_images))</span>
<span id="cb2-16"><a href="#cb2-16" tabindex="-1"></a>    dataset <span class="op">=</span> dataset.<span class="bu">map</span>(load_data, num_parallel_calls<span class="op">=</span>tf.data.AUTOTUNE)</span>
<span id="cb2-17"><a href="#cb2-17" tabindex="-1"></a>    dataset <span class="op">=</span> dataset.batch(BATCH_SIZE, drop_remainder<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-18"><a href="#cb2-18" tabindex="-1"></a>    <span class="cf">return</span> dataset</span>
<span id="cb2-19"><a href="#cb2-19" tabindex="-1"></a></span>
<span id="cb2-20"><a href="#cb2-20" tabindex="-1"></a></span>
<span id="cb2-21"><a href="#cb2-21" tabindex="-1"></a>train_low_light_images <span class="op">=</span> <span class="bu">sorted</span>(glob(<span class="st">"./lol_dataset/our485/low/*"</span>))[</span>
<span id="cb2-22"><a href="#cb2-22" tabindex="-1"></a>    :MAX_TRAIN_IMAGES</span>
<span id="cb2-23"><a href="#cb2-23" tabindex="-1"></a>]</span>
<span id="cb2-24"><a href="#cb2-24" tabindex="-1"></a>val_low_light_images <span class="op">=</span> <span class="bu">sorted</span>(glob(<span class="st">"./lol_dataset/our485/low/*"</span>))[</span>
<span id="cb2-25"><a href="#cb2-25" tabindex="-1"></a>    MAX_TRAIN_IMAGES:</span>
<span id="cb2-26"><a href="#cb2-26" tabindex="-1"></a>]</span>
<span id="cb2-27"><a href="#cb2-27" tabindex="-1"></a>test_low_light_images <span class="op">=</span> <span class="bu">sorted</span>(glob(<span class="st">"./lol_dataset/eval15/low/*"</span>))</span>
<span id="cb2-28"><a href="#cb2-28" tabindex="-1"></a></span>
<span id="cb2-29"><a href="#cb2-29" tabindex="-1"></a></span>
<span id="cb2-30"><a href="#cb2-30" tabindex="-1"></a>train_dataset <span class="op">=</span> data_generator(train_low_light_images)</span>
<span id="cb2-31"><a href="#cb2-31" tabindex="-1"></a>val_dataset <span class="op">=</span> data_generator(val_low_light_images)</span>
<span id="cb2-32"><a href="#cb2-32" tabindex="-1"></a></span>
<span id="cb2-33"><a href="#cb2-33" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Train Dataset:"</span>, train_dataset)</span>
<span id="cb2-34"><a href="#cb2-34" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Validation Dataset:"</span>, val_dataset)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="the-zero-dce-framework">The Zero-DCE Framework<a class="anchor" aria-label="anchor" href="#the-zero-dce-framework"></a>
</h2>
<p>The goal of DCE-Net is to estimate a set of best-fitting
light-enhancement curves (LE-curves) given an input image. The framework
then maps all pixels of the inputâ€™s RGB channels by applying the curves
iteratively to obtain the final enhanced image.</p>
<div class="section level3">
<h3 id="understanding-light-enhancement-curves">Understanding light-enhancement curves<a class="anchor" aria-label="anchor" href="#understanding-light-enhancement-curves"></a>
</h3>
<p>A ligh-enhancement curve is a kind of curve that can map a low-light
image to its enhanced version automatically, where the self-adaptive
curve parameters are solely dependent on the input image. When designing
such a curve, three objectives should be taken into account:</p>
<ul>
<li>Each pixel value of the enhanced image should be in the normalized
range <code>[0,1]</code>, in order to avoid information loss induced by
overflow truncation.</li>
<li>It should be monotonous, to preserve the contrast between
neighboring pixels.</li>
<li>The shape of this curve should be as simple as possible, and the
curve should be differentiable to allow backpropagation.</li>
</ul>
<p>The light-enhancement curve is separately applied to three RGB
channels instead of solely on the illumination channel. The
three-channel adjustment can better preserve the inherent color and
reduce the risk of over-saturation.</p>
<p><img src="https://li-chongyi.github.io/Zero-DCE_files/framework.png"></p>
</div>
<div class="section level3">
<h3 id="dce-net">DCE-Net<a class="anchor" aria-label="anchor" href="#dce-net"></a>
</h3>
<p>The DCE-Net is a lightweight deep neural network that learns the
mapping between an input image and its best-fitting curve parameter
maps. The input to the DCE-Net is a low-light image while the outputs
are a set of pixel-wise curve parameter maps for corresponding
higher-order curves. It is a plain CNN of seven convolutional layers
with symmetrical concatenation. Each layer consists of 32 convolutional
kernels of size 3Ã—3 and stride 1 followed by the ReLU activation
function. The last convolutional layer is followed by the Tanh
activation function, which produces 24 parameter maps for 8 iterations,
where each iteration requires three curve parameter maps for the three
channels.</p>
<p><img src="https://i.imgur.com/HtIg34W.png"></p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="kw">def</span> build_dce_net():</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>    input_img <span class="op">=</span> keras.Input(shape<span class="op">=</span>[<span class="va">None</span>, <span class="va">None</span>, <span class="dv">3</span>])</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>    conv1 <span class="op">=</span> layers.Conv2D(</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>        <span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), strides<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), activation<span class="op">=</span><span class="st">"relu"</span>, padding<span class="op">=</span><span class="st">"same"</span></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>    )(input_img)</span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a>    conv2 <span class="op">=</span> layers.Conv2D(</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a>        <span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), strides<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), activation<span class="op">=</span><span class="st">"relu"</span>, padding<span class="op">=</span><span class="st">"same"</span></span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>    )(conv1)</span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a>    conv3 <span class="op">=</span> layers.Conv2D(</span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a>        <span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), strides<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), activation<span class="op">=</span><span class="st">"relu"</span>, padding<span class="op">=</span><span class="st">"same"</span></span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a>    )(conv2)</span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a>    conv4 <span class="op">=</span> layers.Conv2D(</span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a>        <span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), strides<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), activation<span class="op">=</span><span class="st">"relu"</span>, padding<span class="op">=</span><span class="st">"same"</span></span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a>    )(conv3)</span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a>    int_con1 <span class="op">=</span> layers.Concatenate(axis<span class="op">=-</span><span class="dv">1</span>)([conv4, conv3])</span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a>    conv5 <span class="op">=</span> layers.Conv2D(</span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a>        <span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), strides<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), activation<span class="op">=</span><span class="st">"relu"</span>, padding<span class="op">=</span><span class="st">"same"</span></span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a>    )(int_con1)</span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a>    int_con2 <span class="op">=</span> layers.Concatenate(axis<span class="op">=-</span><span class="dv">1</span>)([conv5, conv2])</span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a>    conv6 <span class="op">=</span> layers.Conv2D(</span>
<span id="cb3-21"><a href="#cb3-21" tabindex="-1"></a>        <span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), strides<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), activation<span class="op">=</span><span class="st">"relu"</span>, padding<span class="op">=</span><span class="st">"same"</span></span>
<span id="cb3-22"><a href="#cb3-22" tabindex="-1"></a>    )(int_con2)</span>
<span id="cb3-23"><a href="#cb3-23" tabindex="-1"></a>    int_con3 <span class="op">=</span> layers.Concatenate(axis<span class="op">=-</span><span class="dv">1</span>)([conv6, conv1])</span>
<span id="cb3-24"><a href="#cb3-24" tabindex="-1"></a>    x_r <span class="op">=</span> layers.Conv2D(</span>
<span id="cb3-25"><a href="#cb3-25" tabindex="-1"></a>        <span class="dv">24</span>, (<span class="dv">3</span>, <span class="dv">3</span>), strides<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>), activation<span class="op">=</span><span class="st">"tanh"</span>, padding<span class="op">=</span><span class="st">"same"</span></span>
<span id="cb3-26"><a href="#cb3-26" tabindex="-1"></a>    )(int_con3)</span>
<span id="cb3-27"><a href="#cb3-27" tabindex="-1"></a>    <span class="cf">return</span> keras.Model(inputs<span class="op">=</span>input_img, outputs<span class="op">=</span>x_r)</span></code></pre></div>
</div>
</div>
<div class="section level2">
<h2 id="loss-functions">Loss functions<a class="anchor" aria-label="anchor" href="#loss-functions"></a>
</h2>
<p>To enable zero-reference learning in DCE-Net, we use a set of
differentiable zero-reference losses that allow us to evaluate the
quality of enhanced images.</p>
<div class="section level3">
<h3 id="color-constancy-loss">Color constancy loss<a class="anchor" aria-label="anchor" href="#color-constancy-loss"></a>
</h3>
<p>The <em>color constancy loss</em> is used to correct the potential
color deviations in the enhanced image.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="kw">def</span> color_constancy_loss(x):</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>    mean_rgb <span class="op">=</span> tf.reduce_mean(x, axis<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">2</span>), keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>    mr, mg, mb <span class="op">=</span> (</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>        mean_rgb[:, :, :, <span class="dv">0</span>],</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a>        mean_rgb[:, :, :, <span class="dv">1</span>],</span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a>        mean_rgb[:, :, :, <span class="dv">2</span>],</span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>    )</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a>    d_rg <span class="op">=</span> tf.square(mr <span class="op">-</span> mg)</span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a>    d_rb <span class="op">=</span> tf.square(mr <span class="op">-</span> mb)</span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a>    d_gb <span class="op">=</span> tf.square(mb <span class="op">-</span> mg)</span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a>    <span class="cf">return</span> tf.sqrt(tf.square(d_rg) <span class="op">+</span> tf.square(d_rb) <span class="op">+</span> tf.square(d_gb))</span></code></pre></div>
</div>
<div class="section level3">
<h3 id="exposure-loss">Exposure loss<a class="anchor" aria-label="anchor" href="#exposure-loss"></a>
</h3>
<p>To restrain under-/over-exposed regions, we use the <em>exposure
control loss</em>. It measures the distance between the average
intensity value of a local region and a preset well-exposedness level
(set to <code>0.6</code>).</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="kw">def</span> exposure_loss(x, mean_val<span class="op">=</span><span class="fl">0.6</span>):</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>    x <span class="op">=</span> tf.reduce_mean(x, axis<span class="op">=</span><span class="dv">3</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>    mean <span class="op">=</span> tf.nn.avg_pool2d(x, ksize<span class="op">=</span><span class="dv">16</span>, strides<span class="op">=</span><span class="dv">16</span>, padding<span class="op">=</span><span class="st">"VALID"</span>)</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>    <span class="cf">return</span> tf.reduce_mean(tf.square(mean <span class="op">-</span> mean_val))</span></code></pre></div>
</div>
<div class="section level3">
<h3 id="illumination-smoothness-loss">Illumination smoothness loss<a class="anchor" aria-label="anchor" href="#illumination-smoothness-loss"></a>
</h3>
<p>To preserve the monotonicity relations between neighboring pixels,
the <em>illumination smoothness loss</em> is added to each curve
parameter map.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="kw">def</span> illumination_smoothness_loss(x):</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>    batch_size <span class="op">=</span> tf.shape(x)[<span class="dv">0</span>]</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>    h_x <span class="op">=</span> tf.shape(x)[<span class="dv">1</span>]</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a>    w_x <span class="op">=</span> tf.shape(x)[<span class="dv">2</span>]</span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a>    count_h <span class="op">=</span> (tf.shape(x)[<span class="dv">2</span>] <span class="op">-</span> <span class="dv">1</span>) <span class="op">*</span> tf.shape(x)[<span class="dv">3</span>]</span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>    count_w <span class="op">=</span> tf.shape(x)[<span class="dv">2</span>] <span class="op">*</span> (tf.shape(x)[<span class="dv">3</span>] <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a>    h_tv <span class="op">=</span> tf.reduce_sum(tf.square((x[:, <span class="dv">1</span>:, :, :] <span class="op">-</span> x[:, : h_x <span class="op">-</span> <span class="dv">1</span>, :, :])))</span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a>    w_tv <span class="op">=</span> tf.reduce_sum(tf.square((x[:, :, <span class="dv">1</span>:, :] <span class="op">-</span> x[:, :, : w_x <span class="op">-</span> <span class="dv">1</span>, :])))</span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a>    batch_size <span class="op">=</span> tf.cast(batch_size, dtype<span class="op">=</span>tf.float32)</span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a>    count_h <span class="op">=</span> tf.cast(count_h, dtype<span class="op">=</span>tf.float32)</span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a>    count_w <span class="op">=</span> tf.cast(count_w, dtype<span class="op">=</span>tf.float32)</span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">2</span> <span class="op">*</span> (h_tv <span class="op">/</span> count_h <span class="op">+</span> w_tv <span class="op">/</span> count_w) <span class="op">/</span> batch_size</span></code></pre></div>
</div>
<div class="section level3">
<h3 id="spatial-consistency-loss">Spatial consistency loss<a class="anchor" aria-label="anchor" href="#spatial-consistency-loss"></a>
</h3>
<p>The <em>spatial consistency loss</em> encourages spatial coherence of
the enhanced image by preserving the contrast between neighboring
regions across the input image and its enhanced version.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="kw">class</span> SpatialConsistencyLoss(keras.losses.Loss):</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, <span class="op">**</span>kwargs):</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(reduction<span class="op">=</span><span class="st">"none"</span>)</span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>        <span class="va">self</span>.left_kernel <span class="op">=</span> tf.constant(</span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a>            [[[[<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>]], [[<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>]], [[<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>]]]], dtype<span class="op">=</span>tf.float32</span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a>        )</span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a>        <span class="va">self</span>.right_kernel <span class="op">=</span> tf.constant(</span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a>            [[[[<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>]], [[<span class="dv">0</span>, <span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>]], [[<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>]]]], dtype<span class="op">=</span>tf.float32</span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a>        )</span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a>        <span class="va">self</span>.up_kernel <span class="op">=</span> tf.constant(</span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a>            [[[[<span class="dv">0</span>, <span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>]], [[<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>]], [[<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>]]]], dtype<span class="op">=</span>tf.float32</span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a>        )</span>
<span id="cb7-14"><a href="#cb7-14" tabindex="-1"></a>        <span class="va">self</span>.down_kernel <span class="op">=</span> tf.constant(</span>
<span id="cb7-15"><a href="#cb7-15" tabindex="-1"></a>            [[[[<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>]], [[<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>]], [[<span class="dv">0</span>, <span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>]]]], dtype<span class="op">=</span>tf.float32</span>
<span id="cb7-16"><a href="#cb7-16" tabindex="-1"></a>        )</span>
<span id="cb7-17"><a href="#cb7-17" tabindex="-1"></a></span>
<span id="cb7-18"><a href="#cb7-18" tabindex="-1"></a>    <span class="kw">def</span> call(<span class="va">self</span>, y_true, y_pred):</span>
<span id="cb7-19"><a href="#cb7-19" tabindex="-1"></a>        original_mean <span class="op">=</span> tf.reduce_mean(y_true, <span class="dv">3</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-20"><a href="#cb7-20" tabindex="-1"></a>        enhanced_mean <span class="op">=</span> tf.reduce_mean(y_pred, <span class="dv">3</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-21"><a href="#cb7-21" tabindex="-1"></a>        original_pool <span class="op">=</span> tf.nn.avg_pool2d(</span>
<span id="cb7-22"><a href="#cb7-22" tabindex="-1"></a>            original_mean, ksize<span class="op">=</span><span class="dv">4</span>, strides<span class="op">=</span><span class="dv">4</span>, padding<span class="op">=</span><span class="st">"VALID"</span></span>
<span id="cb7-23"><a href="#cb7-23" tabindex="-1"></a>        )</span>
<span id="cb7-24"><a href="#cb7-24" tabindex="-1"></a>        enhanced_pool <span class="op">=</span> tf.nn.avg_pool2d(</span>
<span id="cb7-25"><a href="#cb7-25" tabindex="-1"></a>            enhanced_mean, ksize<span class="op">=</span><span class="dv">4</span>, strides<span class="op">=</span><span class="dv">4</span>, padding<span class="op">=</span><span class="st">"VALID"</span></span>
<span id="cb7-26"><a href="#cb7-26" tabindex="-1"></a>        )</span>
<span id="cb7-27"><a href="#cb7-27" tabindex="-1"></a></span>
<span id="cb7-28"><a href="#cb7-28" tabindex="-1"></a>        d_original_left <span class="op">=</span> tf.nn.conv2d(</span>
<span id="cb7-29"><a href="#cb7-29" tabindex="-1"></a>            original_pool,</span>
<span id="cb7-30"><a href="#cb7-30" tabindex="-1"></a>            <span class="va">self</span>.left_kernel,</span>
<span id="cb7-31"><a href="#cb7-31" tabindex="-1"></a>            strides<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>],</span>
<span id="cb7-32"><a href="#cb7-32" tabindex="-1"></a>            padding<span class="op">=</span><span class="st">"SAME"</span>,</span>
<span id="cb7-33"><a href="#cb7-33" tabindex="-1"></a>        )</span>
<span id="cb7-34"><a href="#cb7-34" tabindex="-1"></a>        d_original_right <span class="op">=</span> tf.nn.conv2d(</span>
<span id="cb7-35"><a href="#cb7-35" tabindex="-1"></a>            original_pool,</span>
<span id="cb7-36"><a href="#cb7-36" tabindex="-1"></a>            <span class="va">self</span>.right_kernel,</span>
<span id="cb7-37"><a href="#cb7-37" tabindex="-1"></a>            strides<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>],</span>
<span id="cb7-38"><a href="#cb7-38" tabindex="-1"></a>            padding<span class="op">=</span><span class="st">"SAME"</span>,</span>
<span id="cb7-39"><a href="#cb7-39" tabindex="-1"></a>        )</span>
<span id="cb7-40"><a href="#cb7-40" tabindex="-1"></a>        d_original_up <span class="op">=</span> tf.nn.conv2d(</span>
<span id="cb7-41"><a href="#cb7-41" tabindex="-1"></a>            original_pool, <span class="va">self</span>.up_kernel, strides<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>], padding<span class="op">=</span><span class="st">"SAME"</span></span>
<span id="cb7-42"><a href="#cb7-42" tabindex="-1"></a>        )</span>
<span id="cb7-43"><a href="#cb7-43" tabindex="-1"></a>        d_original_down <span class="op">=</span> tf.nn.conv2d(</span>
<span id="cb7-44"><a href="#cb7-44" tabindex="-1"></a>            original_pool,</span>
<span id="cb7-45"><a href="#cb7-45" tabindex="-1"></a>            <span class="va">self</span>.down_kernel,</span>
<span id="cb7-46"><a href="#cb7-46" tabindex="-1"></a>            strides<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>],</span>
<span id="cb7-47"><a href="#cb7-47" tabindex="-1"></a>            padding<span class="op">=</span><span class="st">"SAME"</span>,</span>
<span id="cb7-48"><a href="#cb7-48" tabindex="-1"></a>        )</span>
<span id="cb7-49"><a href="#cb7-49" tabindex="-1"></a></span>
<span id="cb7-50"><a href="#cb7-50" tabindex="-1"></a>        d_enhanced_left <span class="op">=</span> tf.nn.conv2d(</span>
<span id="cb7-51"><a href="#cb7-51" tabindex="-1"></a>            enhanced_pool,</span>
<span id="cb7-52"><a href="#cb7-52" tabindex="-1"></a>            <span class="va">self</span>.left_kernel,</span>
<span id="cb7-53"><a href="#cb7-53" tabindex="-1"></a>            strides<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>],</span>
<span id="cb7-54"><a href="#cb7-54" tabindex="-1"></a>            padding<span class="op">=</span><span class="st">"SAME"</span>,</span>
<span id="cb7-55"><a href="#cb7-55" tabindex="-1"></a>        )</span>
<span id="cb7-56"><a href="#cb7-56" tabindex="-1"></a>        d_enhanced_right <span class="op">=</span> tf.nn.conv2d(</span>
<span id="cb7-57"><a href="#cb7-57" tabindex="-1"></a>            enhanced_pool,</span>
<span id="cb7-58"><a href="#cb7-58" tabindex="-1"></a>            <span class="va">self</span>.right_kernel,</span>
<span id="cb7-59"><a href="#cb7-59" tabindex="-1"></a>            strides<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>],</span>
<span id="cb7-60"><a href="#cb7-60" tabindex="-1"></a>            padding<span class="op">=</span><span class="st">"SAME"</span>,</span>
<span id="cb7-61"><a href="#cb7-61" tabindex="-1"></a>        )</span>
<span id="cb7-62"><a href="#cb7-62" tabindex="-1"></a>        d_enhanced_up <span class="op">=</span> tf.nn.conv2d(</span>
<span id="cb7-63"><a href="#cb7-63" tabindex="-1"></a>            enhanced_pool, <span class="va">self</span>.up_kernel, strides<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>], padding<span class="op">=</span><span class="st">"SAME"</span></span>
<span id="cb7-64"><a href="#cb7-64" tabindex="-1"></a>        )</span>
<span id="cb7-65"><a href="#cb7-65" tabindex="-1"></a>        d_enhanced_down <span class="op">=</span> tf.nn.conv2d(</span>
<span id="cb7-66"><a href="#cb7-66" tabindex="-1"></a>            enhanced_pool,</span>
<span id="cb7-67"><a href="#cb7-67" tabindex="-1"></a>            <span class="va">self</span>.down_kernel,</span>
<span id="cb7-68"><a href="#cb7-68" tabindex="-1"></a>            strides<span class="op">=</span>[<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>],</span>
<span id="cb7-69"><a href="#cb7-69" tabindex="-1"></a>            padding<span class="op">=</span><span class="st">"SAME"</span>,</span>
<span id="cb7-70"><a href="#cb7-70" tabindex="-1"></a>        )</span>
<span id="cb7-71"><a href="#cb7-71" tabindex="-1"></a></span>
<span id="cb7-72"><a href="#cb7-72" tabindex="-1"></a>        d_left <span class="op">=</span> tf.square(d_original_left <span class="op">-</span> d_enhanced_left)</span>
<span id="cb7-73"><a href="#cb7-73" tabindex="-1"></a>        d_right <span class="op">=</span> tf.square(d_original_right <span class="op">-</span> d_enhanced_right)</span>
<span id="cb7-74"><a href="#cb7-74" tabindex="-1"></a>        d_up <span class="op">=</span> tf.square(d_original_up <span class="op">-</span> d_enhanced_up)</span>
<span id="cb7-75"><a href="#cb7-75" tabindex="-1"></a>        d_down <span class="op">=</span> tf.square(d_original_down <span class="op">-</span> d_enhanced_down)</span>
<span id="cb7-76"><a href="#cb7-76" tabindex="-1"></a>        <span class="cf">return</span> d_left <span class="op">+</span> d_right <span class="op">+</span> d_up <span class="op">+</span> d_down</span></code></pre></div>
</div>
<div class="section level3">
<h3 id="deep-curve-estimation-model">Deep curve estimation model<a class="anchor" aria-label="anchor" href="#deep-curve-estimation-model"></a>
</h3>
<p>We implement the Zero-DCE framework as a Keras subclassed model.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="kw">class</span> ZeroDCE(keras.Model):</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, <span class="op">**</span>kwargs):</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(<span class="op">**</span>kwargs)</span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>        <span class="va">self</span>.dce_model <span class="op">=</span> build_dce_net()</span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a>    <span class="kw">def</span> <span class="bu">compile</span>(<span class="va">self</span>, learning_rate, <span class="op">**</span>kwargs):</span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a>        <span class="bu">super</span>().<span class="bu">compile</span>(<span class="op">**</span>kwargs)</span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a>        <span class="va">self</span>.optimizer <span class="op">=</span> keras.optimizers.Adam(learning_rate<span class="op">=</span>learning_rate)</span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a>        <span class="va">self</span>.spatial_constancy_loss <span class="op">=</span> SpatialConsistencyLoss(reduction<span class="op">=</span><span class="st">"none"</span>)</span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a>        <span class="va">self</span>.total_loss_tracker <span class="op">=</span> keras.metrics.Mean(name<span class="op">=</span><span class="st">"total_loss"</span>)</span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a>        <span class="va">self</span>.illumination_smoothness_loss_tracker <span class="op">=</span> keras.metrics.Mean(</span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a>            name<span class="op">=</span><span class="st">"illumination_smoothness_loss"</span></span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a>        )</span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a>        <span class="va">self</span>.spatial_constancy_loss_tracker <span class="op">=</span> keras.metrics.Mean(</span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a>            name<span class="op">=</span><span class="st">"spatial_constancy_loss"</span></span>
<span id="cb8-16"><a href="#cb8-16" tabindex="-1"></a>        )</span>
<span id="cb8-17"><a href="#cb8-17" tabindex="-1"></a>        <span class="va">self</span>.color_constancy_loss_tracker <span class="op">=</span> keras.metrics.Mean(</span>
<span id="cb8-18"><a href="#cb8-18" tabindex="-1"></a>            name<span class="op">=</span><span class="st">"color_constancy_loss"</span></span>
<span id="cb8-19"><a href="#cb8-19" tabindex="-1"></a>        )</span>
<span id="cb8-20"><a href="#cb8-20" tabindex="-1"></a>        <span class="va">self</span>.exposure_loss_tracker <span class="op">=</span> keras.metrics.Mean(name<span class="op">=</span><span class="st">"exposure_loss"</span>)</span>
<span id="cb8-21"><a href="#cb8-21" tabindex="-1"></a></span>
<span id="cb8-22"><a href="#cb8-22" tabindex="-1"></a>    <span class="at">@property</span></span>
<span id="cb8-23"><a href="#cb8-23" tabindex="-1"></a>    <span class="kw">def</span> metrics(<span class="va">self</span>):</span>
<span id="cb8-24"><a href="#cb8-24" tabindex="-1"></a>        <span class="cf">return</span> [</span>
<span id="cb8-25"><a href="#cb8-25" tabindex="-1"></a>            <span class="va">self</span>.total_loss_tracker,</span>
<span id="cb8-26"><a href="#cb8-26" tabindex="-1"></a>            <span class="va">self</span>.illumination_smoothness_loss_tracker,</span>
<span id="cb8-27"><a href="#cb8-27" tabindex="-1"></a>            <span class="va">self</span>.spatial_constancy_loss_tracker,</span>
<span id="cb8-28"><a href="#cb8-28" tabindex="-1"></a>            <span class="va">self</span>.color_constancy_loss_tracker,</span>
<span id="cb8-29"><a href="#cb8-29" tabindex="-1"></a>            <span class="va">self</span>.exposure_loss_tracker,</span>
<span id="cb8-30"><a href="#cb8-30" tabindex="-1"></a>        ]</span>
<span id="cb8-31"><a href="#cb8-31" tabindex="-1"></a></span>
<span id="cb8-32"><a href="#cb8-32" tabindex="-1"></a>    <span class="kw">def</span> get_enhanced_image(<span class="va">self</span>, data, output):</span>
<span id="cb8-33"><a href="#cb8-33" tabindex="-1"></a>        r1 <span class="op">=</span> output[:, :, :, :<span class="dv">3</span>]</span>
<span id="cb8-34"><a href="#cb8-34" tabindex="-1"></a>        r2 <span class="op">=</span> output[:, :, :, <span class="dv">3</span>:<span class="dv">6</span>]</span>
<span id="cb8-35"><a href="#cb8-35" tabindex="-1"></a>        r3 <span class="op">=</span> output[:, :, :, <span class="dv">6</span>:<span class="dv">9</span>]</span>
<span id="cb8-36"><a href="#cb8-36" tabindex="-1"></a>        r4 <span class="op">=</span> output[:, :, :, <span class="dv">9</span>:<span class="dv">12</span>]</span>
<span id="cb8-37"><a href="#cb8-37" tabindex="-1"></a>        r5 <span class="op">=</span> output[:, :, :, <span class="dv">12</span>:<span class="dv">15</span>]</span>
<span id="cb8-38"><a href="#cb8-38" tabindex="-1"></a>        r6 <span class="op">=</span> output[:, :, :, <span class="dv">15</span>:<span class="dv">18</span>]</span>
<span id="cb8-39"><a href="#cb8-39" tabindex="-1"></a>        r7 <span class="op">=</span> output[:, :, :, <span class="dv">18</span>:<span class="dv">21</span>]</span>
<span id="cb8-40"><a href="#cb8-40" tabindex="-1"></a>        r8 <span class="op">=</span> output[:, :, :, <span class="dv">21</span>:<span class="dv">24</span>]</span>
<span id="cb8-41"><a href="#cb8-41" tabindex="-1"></a>        x <span class="op">=</span> data <span class="op">+</span> r1 <span class="op">*</span> (tf.square(data) <span class="op">-</span> data)</span>
<span id="cb8-42"><a href="#cb8-42" tabindex="-1"></a>        x <span class="op">=</span> x <span class="op">+</span> r2 <span class="op">*</span> (tf.square(x) <span class="op">-</span> x)</span>
<span id="cb8-43"><a href="#cb8-43" tabindex="-1"></a>        x <span class="op">=</span> x <span class="op">+</span> r3 <span class="op">*</span> (tf.square(x) <span class="op">-</span> x)</span>
<span id="cb8-44"><a href="#cb8-44" tabindex="-1"></a>        enhanced_image <span class="op">=</span> x <span class="op">+</span> r4 <span class="op">*</span> (tf.square(x) <span class="op">-</span> x)</span>
<span id="cb8-45"><a href="#cb8-45" tabindex="-1"></a>        x <span class="op">=</span> enhanced_image <span class="op">+</span> r5 <span class="op">*</span> (tf.square(enhanced_image) <span class="op">-</span> enhanced_image)</span>
<span id="cb8-46"><a href="#cb8-46" tabindex="-1"></a>        x <span class="op">=</span> x <span class="op">+</span> r6 <span class="op">*</span> (tf.square(x) <span class="op">-</span> x)</span>
<span id="cb8-47"><a href="#cb8-47" tabindex="-1"></a>        x <span class="op">=</span> x <span class="op">+</span> r7 <span class="op">*</span> (tf.square(x) <span class="op">-</span> x)</span>
<span id="cb8-48"><a href="#cb8-48" tabindex="-1"></a>        enhanced_image <span class="op">=</span> x <span class="op">+</span> r8 <span class="op">*</span> (tf.square(x) <span class="op">-</span> x)</span>
<span id="cb8-49"><a href="#cb8-49" tabindex="-1"></a>        <span class="cf">return</span> enhanced_image</span>
<span id="cb8-50"><a href="#cb8-50" tabindex="-1"></a></span>
<span id="cb8-51"><a href="#cb8-51" tabindex="-1"></a>    <span class="kw">def</span> call(<span class="va">self</span>, data):</span>
<span id="cb8-52"><a href="#cb8-52" tabindex="-1"></a>        dce_net_output <span class="op">=</span> <span class="va">self</span>.dce_model(data)</span>
<span id="cb8-53"><a href="#cb8-53" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.get_enhanced_image(data, dce_net_output)</span>
<span id="cb8-54"><a href="#cb8-54" tabindex="-1"></a></span>
<span id="cb8-55"><a href="#cb8-55" tabindex="-1"></a>    <span class="kw">def</span> compute_losses(<span class="va">self</span>, data, output):</span>
<span id="cb8-56"><a href="#cb8-56" tabindex="-1"></a>        enhanced_image <span class="op">=</span> <span class="va">self</span>.get_enhanced_image(data, output)</span>
<span id="cb8-57"><a href="#cb8-57" tabindex="-1"></a>        loss_illumination <span class="op">=</span> <span class="dv">200</span> <span class="op">*</span> illumination_smoothness_loss(output)</span>
<span id="cb8-58"><a href="#cb8-58" tabindex="-1"></a>        loss_spatial_constancy <span class="op">=</span> tf.reduce_mean(</span>
<span id="cb8-59"><a href="#cb8-59" tabindex="-1"></a>            <span class="va">self</span>.spatial_constancy_loss(enhanced_image, data)</span>
<span id="cb8-60"><a href="#cb8-60" tabindex="-1"></a>        )</span>
<span id="cb8-61"><a href="#cb8-61" tabindex="-1"></a>        loss_color_constancy <span class="op">=</span> <span class="dv">5</span> <span class="op">*</span> tf.reduce_mean(</span>
<span id="cb8-62"><a href="#cb8-62" tabindex="-1"></a>            color_constancy_loss(enhanced_image)</span>
<span id="cb8-63"><a href="#cb8-63" tabindex="-1"></a>        )</span>
<span id="cb8-64"><a href="#cb8-64" tabindex="-1"></a>        loss_exposure <span class="op">=</span> <span class="dv">10</span> <span class="op">*</span> tf.reduce_mean(exposure_loss(enhanced_image))</span>
<span id="cb8-65"><a href="#cb8-65" tabindex="-1"></a>        total_loss <span class="op">=</span> (</span>
<span id="cb8-66"><a href="#cb8-66" tabindex="-1"></a>            loss_illumination</span>
<span id="cb8-67"><a href="#cb8-67" tabindex="-1"></a>            <span class="op">+</span> loss_spatial_constancy</span>
<span id="cb8-68"><a href="#cb8-68" tabindex="-1"></a>            <span class="op">+</span> loss_color_constancy</span>
<span id="cb8-69"><a href="#cb8-69" tabindex="-1"></a>            <span class="op">+</span> loss_exposure</span>
<span id="cb8-70"><a href="#cb8-70" tabindex="-1"></a>        )</span>
<span id="cb8-71"><a href="#cb8-71" tabindex="-1"></a></span>
<span id="cb8-72"><a href="#cb8-72" tabindex="-1"></a>        <span class="cf">return</span> {</span>
<span id="cb8-73"><a href="#cb8-73" tabindex="-1"></a>            <span class="st">"total_loss"</span>: total_loss,</span>
<span id="cb8-74"><a href="#cb8-74" tabindex="-1"></a>            <span class="st">"illumination_smoothness_loss"</span>: loss_illumination,</span>
<span id="cb8-75"><a href="#cb8-75" tabindex="-1"></a>            <span class="st">"spatial_constancy_loss"</span>: loss_spatial_constancy,</span>
<span id="cb8-76"><a href="#cb8-76" tabindex="-1"></a>            <span class="st">"color_constancy_loss"</span>: loss_color_constancy,</span>
<span id="cb8-77"><a href="#cb8-77" tabindex="-1"></a>            <span class="st">"exposure_loss"</span>: loss_exposure,</span>
<span id="cb8-78"><a href="#cb8-78" tabindex="-1"></a>        }</span>
<span id="cb8-79"><a href="#cb8-79" tabindex="-1"></a></span>
<span id="cb8-80"><a href="#cb8-80" tabindex="-1"></a>    <span class="kw">def</span> train_step(<span class="va">self</span>, data):</span>
<span id="cb8-81"><a href="#cb8-81" tabindex="-1"></a>        <span class="cf">with</span> tf.GradientTape() <span class="im">as</span> tape:</span>
<span id="cb8-82"><a href="#cb8-82" tabindex="-1"></a>            output <span class="op">=</span> <span class="va">self</span>.dce_model(data)</span>
<span id="cb8-83"><a href="#cb8-83" tabindex="-1"></a>            losses <span class="op">=</span> <span class="va">self</span>.compute_losses(data, output)</span>
<span id="cb8-84"><a href="#cb8-84" tabindex="-1"></a></span>
<span id="cb8-85"><a href="#cb8-85" tabindex="-1"></a>        gradients <span class="op">=</span> tape.gradient(</span>
<span id="cb8-86"><a href="#cb8-86" tabindex="-1"></a>            losses[<span class="st">"total_loss"</span>], <span class="va">self</span>.dce_model.trainable_weights</span>
<span id="cb8-87"><a href="#cb8-87" tabindex="-1"></a>        )</span>
<span id="cb8-88"><a href="#cb8-88" tabindex="-1"></a>        <span class="va">self</span>.optimizer.apply_gradients(</span>
<span id="cb8-89"><a href="#cb8-89" tabindex="-1"></a>            <span class="bu">zip</span>(gradients, <span class="va">self</span>.dce_model.trainable_weights)</span>
<span id="cb8-90"><a href="#cb8-90" tabindex="-1"></a>        )</span>
<span id="cb8-91"><a href="#cb8-91" tabindex="-1"></a></span>
<span id="cb8-92"><a href="#cb8-92" tabindex="-1"></a>        <span class="va">self</span>.total_loss_tracker.update_state(losses[<span class="st">"total_loss"</span>])</span>
<span id="cb8-93"><a href="#cb8-93" tabindex="-1"></a>        <span class="va">self</span>.illumination_smoothness_loss_tracker.update_state(</span>
<span id="cb8-94"><a href="#cb8-94" tabindex="-1"></a>            losses[<span class="st">"illumination_smoothness_loss"</span>]</span>
<span id="cb8-95"><a href="#cb8-95" tabindex="-1"></a>        )</span>
<span id="cb8-96"><a href="#cb8-96" tabindex="-1"></a>        <span class="va">self</span>.spatial_constancy_loss_tracker.update_state(</span>
<span id="cb8-97"><a href="#cb8-97" tabindex="-1"></a>            losses[<span class="st">"spatial_constancy_loss"</span>]</span>
<span id="cb8-98"><a href="#cb8-98" tabindex="-1"></a>        )</span>
<span id="cb8-99"><a href="#cb8-99" tabindex="-1"></a>        <span class="va">self</span>.color_constancy_loss_tracker.update_state(</span>
<span id="cb8-100"><a href="#cb8-100" tabindex="-1"></a>            losses[<span class="st">"color_constancy_loss"</span>]</span>
<span id="cb8-101"><a href="#cb8-101" tabindex="-1"></a>        )</span>
<span id="cb8-102"><a href="#cb8-102" tabindex="-1"></a>        <span class="va">self</span>.exposure_loss_tracker.update_state(losses[<span class="st">"exposure_loss"</span>])</span>
<span id="cb8-103"><a href="#cb8-103" tabindex="-1"></a></span>
<span id="cb8-104"><a href="#cb8-104" tabindex="-1"></a>        <span class="cf">return</span> {metric.name: metric.result() <span class="cf">for</span> metric <span class="kw">in</span> <span class="va">self</span>.metrics}</span>
<span id="cb8-105"><a href="#cb8-105" tabindex="-1"></a></span>
<span id="cb8-106"><a href="#cb8-106" tabindex="-1"></a>    <span class="kw">def</span> test_step(<span class="va">self</span>, data):</span>
<span id="cb8-107"><a href="#cb8-107" tabindex="-1"></a>        output <span class="op">=</span> <span class="va">self</span>.dce_model(data)</span>
<span id="cb8-108"><a href="#cb8-108" tabindex="-1"></a>        losses <span class="op">=</span> <span class="va">self</span>.compute_losses(data, output)</span>
<span id="cb8-109"><a href="#cb8-109" tabindex="-1"></a></span>
<span id="cb8-110"><a href="#cb8-110" tabindex="-1"></a>        <span class="va">self</span>.total_loss_tracker.update_state(losses[<span class="st">"total_loss"</span>])</span>
<span id="cb8-111"><a href="#cb8-111" tabindex="-1"></a>        <span class="va">self</span>.illumination_smoothness_loss_tracker.update_state(</span>
<span id="cb8-112"><a href="#cb8-112" tabindex="-1"></a>            losses[<span class="st">"illumination_smoothness_loss"</span>]</span>
<span id="cb8-113"><a href="#cb8-113" tabindex="-1"></a>        )</span>
<span id="cb8-114"><a href="#cb8-114" tabindex="-1"></a>        <span class="va">self</span>.spatial_constancy_loss_tracker.update_state(</span>
<span id="cb8-115"><a href="#cb8-115" tabindex="-1"></a>            losses[<span class="st">"spatial_constancy_loss"</span>]</span>
<span id="cb8-116"><a href="#cb8-116" tabindex="-1"></a>        )</span>
<span id="cb8-117"><a href="#cb8-117" tabindex="-1"></a>        <span class="va">self</span>.color_constancy_loss_tracker.update_state(</span>
<span id="cb8-118"><a href="#cb8-118" tabindex="-1"></a>            losses[<span class="st">"color_constancy_loss"</span>]</span>
<span id="cb8-119"><a href="#cb8-119" tabindex="-1"></a>        )</span>
<span id="cb8-120"><a href="#cb8-120" tabindex="-1"></a>        <span class="va">self</span>.exposure_loss_tracker.update_state(losses[<span class="st">"exposure_loss"</span>])</span>
<span id="cb8-121"><a href="#cb8-121" tabindex="-1"></a></span>
<span id="cb8-122"><a href="#cb8-122" tabindex="-1"></a>        <span class="cf">return</span> {metric.name: metric.result() <span class="cf">for</span> metric <span class="kw">in</span> <span class="va">self</span>.metrics}</span>
<span id="cb8-123"><a href="#cb8-123" tabindex="-1"></a></span>
<span id="cb8-124"><a href="#cb8-124" tabindex="-1"></a>    <span class="kw">def</span> save_weights(</span>
<span id="cb8-125"><a href="#cb8-125" tabindex="-1"></a>        <span class="va">self</span>, filepath, overwrite<span class="op">=</span><span class="va">True</span>, save_format<span class="op">=</span><span class="va">None</span>, options<span class="op">=</span><span class="va">None</span></span>
<span id="cb8-126"><a href="#cb8-126" tabindex="-1"></a>    ):</span>
<span id="cb8-127"><a href="#cb8-127" tabindex="-1"></a>        <span class="co">"""While saving the weights, we simply save the weights of the DCE-Net"""</span></span>
<span id="cb8-128"><a href="#cb8-128" tabindex="-1"></a>        <span class="va">self</span>.dce_model.save_weights(</span>
<span id="cb8-129"><a href="#cb8-129" tabindex="-1"></a>            filepath,</span>
<span id="cb8-130"><a href="#cb8-130" tabindex="-1"></a>            overwrite<span class="op">=</span>overwrite,</span>
<span id="cb8-131"><a href="#cb8-131" tabindex="-1"></a>            save_format<span class="op">=</span>save_format,</span>
<span id="cb8-132"><a href="#cb8-132" tabindex="-1"></a>            options<span class="op">=</span>options,</span>
<span id="cb8-133"><a href="#cb8-133" tabindex="-1"></a>        )</span>
<span id="cb8-134"><a href="#cb8-134" tabindex="-1"></a></span>
<span id="cb8-135"><a href="#cb8-135" tabindex="-1"></a>    <span class="kw">def</span> load_weights(</span>
<span id="cb8-136"><a href="#cb8-136" tabindex="-1"></a>        <span class="va">self</span>, filepath, by_name<span class="op">=</span><span class="va">False</span>, skip_mismatch<span class="op">=</span><span class="va">False</span>, options<span class="op">=</span><span class="va">None</span></span>
<span id="cb8-137"><a href="#cb8-137" tabindex="-1"></a>    ):</span>
<span id="cb8-138"><a href="#cb8-138" tabindex="-1"></a>        <span class="co">"""While loading the weights, we simply load the weights of the DCE-Net"""</span></span>
<span id="cb8-139"><a href="#cb8-139" tabindex="-1"></a>        <span class="va">self</span>.dce_model.load_weights(</span>
<span id="cb8-140"><a href="#cb8-140" tabindex="-1"></a>            filepath<span class="op">=</span>filepath,</span>
<span id="cb8-141"><a href="#cb8-141" tabindex="-1"></a>            by_name<span class="op">=</span>by_name,</span>
<span id="cb8-142"><a href="#cb8-142" tabindex="-1"></a>            skip_mismatch<span class="op">=</span>skip_mismatch,</span>
<span id="cb8-143"><a href="#cb8-143" tabindex="-1"></a>            options<span class="op">=</span>options,</span>
<span id="cb8-144"><a href="#cb8-144" tabindex="-1"></a>        )</span></code></pre></div>
</div>
</div>
<div class="section level2">
<h2 id="training">Training<a class="anchor" aria-label="anchor" href="#training"></a>
</h2>
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>zero_dce_model <span class="op">=</span> ZeroDCE()</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>zero_dce_model.<span class="bu">compile</span>(learning_rate<span class="op">=</span><span class="fl">1e-4</span>)</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a>history <span class="op">=</span> zero_dce_model.fit(</span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>    train_dataset, validation_data<span class="op">=</span>val_dataset, epochs<span class="op">=</span><span class="dv">100</span></span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a>)</span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a><span class="kw">def</span> plot_result(item):</span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a>    plt.plot(history.history[item], label<span class="op">=</span>item)</span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a>    plt.plot(history.history[<span class="st">"val_"</span> <span class="op">+</span> item], label<span class="op">=</span><span class="st">"val_"</span> <span class="op">+</span> item)</span>
<span id="cb9-11"><a href="#cb9-11" tabindex="-1"></a>    plt.xlabel(<span class="st">"Epochs"</span>)</span>
<span id="cb9-12"><a href="#cb9-12" tabindex="-1"></a>    plt.ylabel(item)</span>
<span id="cb9-13"><a href="#cb9-13" tabindex="-1"></a>    plt.title(<span class="st">"Train and Validation </span><span class="sc">{}</span><span class="st"> Over Epochs"</span>.<span class="bu">format</span>(item), fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb9-14"><a href="#cb9-14" tabindex="-1"></a>    plt.legend()</span>
<span id="cb9-15"><a href="#cb9-15" tabindex="-1"></a>    plt.grid()</span>
<span id="cb9-16"><a href="#cb9-16" tabindex="-1"></a>    plt.show()</span>
<span id="cb9-17"><a href="#cb9-17" tabindex="-1"></a></span>
<span id="cb9-18"><a href="#cb9-18" tabindex="-1"></a></span>
<span id="cb9-19"><a href="#cb9-19" tabindex="-1"></a>plot_result(<span class="st">"total_loss"</span>)</span>
<span id="cb9-20"><a href="#cb9-20" tabindex="-1"></a>plot_result(<span class="st">"illumination_smoothness_loss"</span>)</span>
<span id="cb9-21"><a href="#cb9-21" tabindex="-1"></a>plot_result(<span class="st">"spatial_constancy_loss"</span>)</span>
<span id="cb9-22"><a href="#cb9-22" tabindex="-1"></a>plot_result(<span class="st">"color_constancy_loss"</span>)</span>
<span id="cb9-23"><a href="#cb9-23" tabindex="-1"></a>plot_result(<span class="st">"exposure_loss"</span>)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="inference">Inference<a class="anchor" aria-label="anchor" href="#inference"></a>
</h2>
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="kw">def</span> plot_results(images, titles, figure_size<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">12</span>)):</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>    fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>figure_size)</span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(images)):</span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a>        fig.add_subplot(<span class="dv">1</span>, <span class="bu">len</span>(images), i <span class="op">+</span> <span class="dv">1</span>).set_title(titles[i])</span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a>        _ <span class="op">=</span> plt.imshow(images[i])</span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a>        plt.axis(<span class="st">"off"</span>)</span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a>    plt.show()</span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a></span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a><span class="kw">def</span> infer(original_image):</span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a>    image <span class="op">=</span> keras.utils.img_to_array(original_image)</span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a>    image <span class="op">=</span> image.astype(<span class="st">"float32"</span>) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb10-13"><a href="#cb10-13" tabindex="-1"></a>    image <span class="op">=</span> np.expand_dims(image, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb10-14"><a href="#cb10-14" tabindex="-1"></a>    output_image <span class="op">=</span> zero_dce_model(image)</span>
<span id="cb10-15"><a href="#cb10-15" tabindex="-1"></a>    output_image <span class="op">=</span> tf.cast((output_image[<span class="dv">0</span>, :, :, :] <span class="op">*</span> <span class="dv">255</span>), dtype<span class="op">=</span>np.uint8)</span>
<span id="cb10-16"><a href="#cb10-16" tabindex="-1"></a>    output_image <span class="op">=</span> Image.fromarray(output_image.numpy())</span>
<span id="cb10-17"><a href="#cb10-17" tabindex="-1"></a>    <span class="cf">return</span> output_image</span></code></pre></div>
<div class="section level3">
<h3 id="inference-on-test-images">Inference on test images<a class="anchor" aria-label="anchor" href="#inference-on-test-images"></a>
</h3>
<p>We compare the test images from LOLDataset enhanced by MIRNet with
images enhanced via the <code>PIL.ImageOps.autocontrast()</code>
function.</p>
<p>You can use the trained model hosted on <a href="https://huggingface.co/keras-io/low-light-image-enhancement" class="external-link">Hugging
Face Hub</a> and try the demo on <a href="https://huggingface.co/spaces/keras-io/low-light-image-enhancement" class="external-link">Hugging
Face Spaces</a>.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="cf">for</span> val_image_file <span class="kw">in</span> test_low_light_images:</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>    original_image <span class="op">=</span> Image.<span class="bu">open</span>(val_image_file)</span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>    enhanced_image <span class="op">=</span> infer(original_image)</span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a>    plot_results(</span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a>        [original_image, ImageOps.autocontrast(original_image), enhanced_image],</span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a>        [<span class="st">"Original"</span>, <span class="st">"PIL Autocontrast"</span>, <span class="st">"Enhanced"</span>],</span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a>        (<span class="dv">20</span>, <span class="dv">12</span>),</span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a>    )</span></code></pre></div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Tomasz Kalinowski, JJ Allaire, FranÃ§ois Chollet, Posit Software, PBC, Google.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
