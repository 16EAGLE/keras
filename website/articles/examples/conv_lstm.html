<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="How to build and train a convolutional LSTM model for next-frame video prediction.">
<title>Next-Frame Video Prediction with Convolutional LSTMs • keras3</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../../apple-touch-icon-60x60.png">
<script src="../../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../../pkgdown.js"></script><meta property="og:title" content="Next-Frame Video Prediction with Convolutional LSTMs">
<meta property="og:description" content="How to build and train a convolutional LSTM model for next-frame video prediction.">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-inverse navbar-expand-lg bg-primary"><div class="container">
    
    <a class="navbar-brand me-2" href="../../index.html">keras3</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">2.13.0.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../../index.html">Home</a>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-getting-started">Getting Started</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-getting-started">
    <a class="dropdown-item" href="../../articles/intro_to_keras_for_engineers.html">Introduction to Keras for engineers</a>
    <h6 class="dropdown-header" data-toc-skip>Tutorials</h6>
    <a class="dropdown-item" href="../../articles/getting_started.html">Getting Started</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_classification.html">Basic Classification</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_text_classification.html">Text Classification</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_regression.html">Basic Regression</a>
    <a class="dropdown-item" href="../../articles/tutorial_overfit_underfit.html">Overfitting and Underfitting</a>
    <a class="dropdown-item" href="../../articles/tutorial_save_and_restore.html">Save and Restore Models</a>
  </div>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-guides">Guides</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-guides">
    <h6 class="dropdown-header" data-toc-skip>Model definition</h6>
    <a class="dropdown-item" href="../../articles/functional_api.html">Functional API</a>
    <a class="dropdown-item" href="../../articles/sequential_model.html">Sequential Model</a>
    <h6 class="dropdown-header" data-toc-skip>Extending and customizing</h6>
    <a class="dropdown-item" href="../../articles/making_new_layers_and_models_via_subclassing.html">Making new layers and models via subclassing</a>
    <a class="dropdown-item" href="../../articles/training_with_built_in_methods.html">Training &amp; evaluation with the built-in methods</a>
    <a class="dropdown-item" href="../../articles/writing_a_custom_training_loop_in_tensorflow.html">Writing a training loop from scratch in TensorFlow</a>
    <a class="dropdown-item" href="../../articles/writing_your_own_callbacks.html">Writing Your Own Callbacks</a>
    <h6 class="dropdown-header" data-toc-skip>Other topics</h6>
    <a class="dropdown-item" href="../../articles/transfer_learning.html">Transfer learning and fine tuning</a>
    <a class="dropdown-item" href="../../articles/distributed_training_with_tensorflow.html">Distributed training with TensorFlow</a>
  </div>
</li>
<li class="active nav-item">
  <a class="nav-link" href="../../articles/examples/index.html">Examples</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../reference/index.html">Reference</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../news/index.html">News</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/rstudio/keras/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Next-Frame Video Prediction with Convolutional LSTMs</h1>
                        <h4 data-toc-skip class="author"><a href="https://github.com/amogh7joshi" class="external-link">Amogh Joshi</a></h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/rstudio/keras/blob/HEAD/vignettes/examples/conv_lstm.Rmd" class="external-link"><code>vignettes/examples/conv_lstm.Rmd</code></a></small>
      <div class="d-none name"><code>conv_lstm.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>The <a href="https://papers.nips.cc/paper/2015/file/07563a3fe3bbe7e3ba84431ad9d055af-Paper.pdf" class="external-link">Convolutional
LSTM</a> architectures bring together time series processing and
computer vision by introducing a convolutional recurrent cell in a LSTM
layer. In this example, we will explore the Convolutional LSTM model in
an application to next-frame prediction, the process of predicting what
video frames come next given a series of past frames.</p>
</div>
<div class="section level2">
<h2 id="setup">Setup<a class="anchor" aria-label="anchor" href="#setup"></a>
</h2>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">import</span> keras <span class="im">as</span> keras</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="im">from</span> keras <span class="im">import</span> layers</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="im">import</span> io</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="im">import</span> imageio</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> Image, display</span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a><span class="im">from</span> ipywidgets <span class="im">import</span> widgets, Layout, HBox</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="dataset-construction">Dataset Construction<a class="anchor" aria-label="anchor" href="#dataset-construction"></a>
</h2>
<p>For this example, we will be using the <a href="http://www.cs.toronto.edu/~nitish/unsupervised_video/" class="external-link">Moving
MNIST</a> dataset.</p>
<p>We will download the dataset and then construct and preprocess
training and validation sets.</p>
<p>For next-frame prediction, our model will be using a previous frame,
which we’ll call <code>f_n</code>, to predict a new frame, called
<code>f_(n + 1)</code>. To allow the model to create these predictions,
we’ll need to process the data such that we have “shifted” inputs and
outputs, where the input data is frame <code>x_n</code>, being used to
predict frame <code>y_(n + 1)</code>.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="co"># Download and load the dataset.</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>fpath <span class="op">=</span> keras.utils.get_file(</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>    <span class="st">"moving_mnist.npy"</span>,</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>    <span class="st">"http://www.cs.toronto.edu/~nitish/unsupervised_video/mnist_test_seq.npy"</span>,</span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>)</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a>dataset <span class="op">=</span> np.load(fpath)</span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a><span class="co"># Swap the axes representing the number of frames and number of data samples.</span></span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a>dataset <span class="op">=</span> np.swapaxes(dataset, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a><span class="co"># We'll pick out 1000 of the 10000 total examples and use those.</span></span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a>dataset <span class="op">=</span> dataset[:<span class="dv">1000</span>, ...]</span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a><span class="co"># Add a channel dimension since the images are grayscale.</span></span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a>dataset <span class="op">=</span> np.expand_dims(dataset, axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" tabindex="-1"></a><span class="co"># Split into train and validation sets using indexing to optimize memory.</span></span>
<span id="cb2-16"><a href="#cb2-16" tabindex="-1"></a>indexes <span class="op">=</span> np.arange(dataset.shape[<span class="dv">0</span>])</span>
<span id="cb2-17"><a href="#cb2-17" tabindex="-1"></a>np.random.shuffle(indexes)</span>
<span id="cb2-18"><a href="#cb2-18" tabindex="-1"></a>train_index <span class="op">=</span> indexes[: <span class="bu">int</span>(<span class="fl">0.9</span> <span class="op">*</span> dataset.shape[<span class="dv">0</span>])]</span>
<span id="cb2-19"><a href="#cb2-19" tabindex="-1"></a>val_index <span class="op">=</span> indexes[<span class="bu">int</span>(<span class="fl">0.9</span> <span class="op">*</span> dataset.shape[<span class="dv">0</span>]) :]</span>
<span id="cb2-20"><a href="#cb2-20" tabindex="-1"></a>train_dataset <span class="op">=</span> dataset[train_index]</span>
<span id="cb2-21"><a href="#cb2-21" tabindex="-1"></a>val_dataset <span class="op">=</span> dataset[val_index]</span>
<span id="cb2-22"><a href="#cb2-22" tabindex="-1"></a></span>
<span id="cb2-23"><a href="#cb2-23" tabindex="-1"></a><span class="co"># Normalize the data to the 0-1 range.</span></span>
<span id="cb2-24"><a href="#cb2-24" tabindex="-1"></a>train_dataset <span class="op">=</span> train_dataset <span class="op">/</span> <span class="dv">255</span></span>
<span id="cb2-25"><a href="#cb2-25" tabindex="-1"></a>val_dataset <span class="op">=</span> val_dataset <span class="op">/</span> <span class="dv">255</span></span>
<span id="cb2-26"><a href="#cb2-26" tabindex="-1"></a></span>
<span id="cb2-27"><a href="#cb2-27" tabindex="-1"></a></span>
<span id="cb2-28"><a href="#cb2-28" tabindex="-1"></a><span class="co"># We'll define a helper function to shift the frames, where</span></span>
<span id="cb2-29"><a href="#cb2-29" tabindex="-1"></a><span class="co"># `x` is frames 0 to n - 1, and `y` is frames 1 to n.</span></span>
<span id="cb2-30"><a href="#cb2-30" tabindex="-1"></a><span class="kw">def</span> create_shifted_frames(data):</span>
<span id="cb2-31"><a href="#cb2-31" tabindex="-1"></a>    x <span class="op">=</span> data[:, <span class="dv">0</span> : data.shape[<span class="dv">1</span>] <span class="op">-</span> <span class="dv">1</span>, :, :]</span>
<span id="cb2-32"><a href="#cb2-32" tabindex="-1"></a>    y <span class="op">=</span> data[:, <span class="dv">1</span> : data.shape[<span class="dv">1</span>], :, :]</span>
<span id="cb2-33"><a href="#cb2-33" tabindex="-1"></a>    <span class="cf">return</span> x, y</span>
<span id="cb2-34"><a href="#cb2-34" tabindex="-1"></a></span>
<span id="cb2-35"><a href="#cb2-35" tabindex="-1"></a></span>
<span id="cb2-36"><a href="#cb2-36" tabindex="-1"></a><span class="co"># Apply the processing function to the datasets.</span></span>
<span id="cb2-37"><a href="#cb2-37" tabindex="-1"></a>x_train, y_train <span class="op">=</span> create_shifted_frames(train_dataset)</span>
<span id="cb2-38"><a href="#cb2-38" tabindex="-1"></a>x_val, y_val <span class="op">=</span> create_shifted_frames(val_dataset)</span>
<span id="cb2-39"><a href="#cb2-39" tabindex="-1"></a></span>
<span id="cb2-40"><a href="#cb2-40" tabindex="-1"></a><span class="co"># Inspect the dataset.</span></span>
<span id="cb2-41"><a href="#cb2-41" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb2-42"><a href="#cb2-42" tabindex="-1"></a>    <span class="st">"Training Dataset Shapes: "</span> <span class="op">+</span> <span class="bu">str</span>(x_train.shape) <span class="op">+</span> <span class="st">", "</span> <span class="op">+</span> <span class="bu">str</span>(y_train.shape)</span>
<span id="cb2-43"><a href="#cb2-43" tabindex="-1"></a>)</span>
<span id="cb2-44"><a href="#cb2-44" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb2-45"><a href="#cb2-45" tabindex="-1"></a>    <span class="st">"Validation Dataset Shapes: "</span> <span class="op">+</span> <span class="bu">str</span>(x_val.shape) <span class="op">+</span> <span class="st">", "</span> <span class="op">+</span> <span class="bu">str</span>(y_val.shape)</span>
<span id="cb2-46"><a href="#cb2-46" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="data-visualization">Data Visualization<a class="anchor" aria-label="anchor" href="#data-visualization"></a>
</h2>
<p>Our data consists of sequences of frames, each of which are used to
predict the upcoming frame. Let’s take a look at some of these
sequential frames.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="co"># Construct a figure on which we will visualize the images.</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">4</span>, <span class="dv">5</span>, figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a><span class="co"># Plot each of the sequential images for one random data example.</span></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>data_choice <span class="op">=</span> np.random.choice(<span class="bu">range</span>(<span class="bu">len</span>(train_dataset)), size<span class="op">=</span><span class="dv">1</span>)[<span class="dv">0</span>]</span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a><span class="cf">for</span> idx, ax <span class="kw">in</span> <span class="bu">enumerate</span>(axes.flat):</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a>    ax.imshow(np.squeeze(train_dataset[data_choice][idx]), cmap<span class="op">=</span><span class="st">"gray"</span>)</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>    ax.set_title(<span class="ss">f"Frame </span><span class="sc">{</span>idx <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a>    ax.axis(<span class="st">"off"</span>)</span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a><span class="co"># Print information and display the figure.</span></span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Displaying frames for example </span><span class="sc">{</span>data_choice<span class="sc">}</span><span class="ss">."</span>)</span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a>plt.show()</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="model-construction">Model Construction<a class="anchor" aria-label="anchor" href="#model-construction"></a>
</h2>
<p>To build a Convolutional LSTM model, we will use the
<code>ConvLSTM2D</code> layer, which will accept inputs of shape
<code>(batch_size, num_frames, width, height, channels)</code>, and
return a prediction movie of the same shape.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co"># Construct the input layer with no definite frame size.</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>inp <span class="op">=</span> layers.Input(shape<span class="op">=</span>(<span class="va">None</span>, <span class="op">*</span>x_train.shape[<span class="dv">2</span>:]))</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a><span class="co"># We will construct 3 `ConvLSTM2D` layers with batch normalization,</span></span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a><span class="co"># followed by a `Conv3D` layer for the spatiotemporal outputs.</span></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a>x <span class="op">=</span> layers.ConvLSTM2D(</span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>    filters<span class="op">=</span><span class="dv">64</span>,</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a>    kernel_size<span class="op">=</span>(<span class="dv">5</span>, <span class="dv">5</span>),</span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a>    padding<span class="op">=</span><span class="st">"same"</span>,</span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a>    return_sequences<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a>    activation<span class="op">=</span><span class="st">"relu"</span>,</span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a>)(inp)</span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a>x <span class="op">=</span> layers.BatchNormalization()(x)</span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a>x <span class="op">=</span> layers.ConvLSTM2D(</span>
<span id="cb4-15"><a href="#cb4-15" tabindex="-1"></a>    filters<span class="op">=</span><span class="dv">64</span>,</span>
<span id="cb4-16"><a href="#cb4-16" tabindex="-1"></a>    kernel_size<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">3</span>),</span>
<span id="cb4-17"><a href="#cb4-17" tabindex="-1"></a>    padding<span class="op">=</span><span class="st">"same"</span>,</span>
<span id="cb4-18"><a href="#cb4-18" tabindex="-1"></a>    return_sequences<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb4-19"><a href="#cb4-19" tabindex="-1"></a>    activation<span class="op">=</span><span class="st">"relu"</span>,</span>
<span id="cb4-20"><a href="#cb4-20" tabindex="-1"></a>)(x)</span>
<span id="cb4-21"><a href="#cb4-21" tabindex="-1"></a>x <span class="op">=</span> layers.BatchNormalization()(x)</span>
<span id="cb4-22"><a href="#cb4-22" tabindex="-1"></a>x <span class="op">=</span> layers.ConvLSTM2D(</span>
<span id="cb4-23"><a href="#cb4-23" tabindex="-1"></a>    filters<span class="op">=</span><span class="dv">64</span>,</span>
<span id="cb4-24"><a href="#cb4-24" tabindex="-1"></a>    kernel_size<span class="op">=</span>(<span class="dv">1</span>, <span class="dv">1</span>),</span>
<span id="cb4-25"><a href="#cb4-25" tabindex="-1"></a>    padding<span class="op">=</span><span class="st">"same"</span>,</span>
<span id="cb4-26"><a href="#cb4-26" tabindex="-1"></a>    return_sequences<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb4-27"><a href="#cb4-27" tabindex="-1"></a>    activation<span class="op">=</span><span class="st">"relu"</span>,</span>
<span id="cb4-28"><a href="#cb4-28" tabindex="-1"></a>)(x)</span>
<span id="cb4-29"><a href="#cb4-29" tabindex="-1"></a>x <span class="op">=</span> layers.Conv3D(</span>
<span id="cb4-30"><a href="#cb4-30" tabindex="-1"></a>    filters<span class="op">=</span><span class="dv">1</span>, kernel_size<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">3</span>), activation<span class="op">=</span><span class="st">"sigmoid"</span>, padding<span class="op">=</span><span class="st">"same"</span></span>
<span id="cb4-31"><a href="#cb4-31" tabindex="-1"></a>)(x)</span>
<span id="cb4-32"><a href="#cb4-32" tabindex="-1"></a></span>
<span id="cb4-33"><a href="#cb4-33" tabindex="-1"></a><span class="co"># Next, we will build the complete model and compile it.</span></span>
<span id="cb4-34"><a href="#cb4-34" tabindex="-1"></a>model <span class="op">=</span> keras.models.Model(inp, x)</span>
<span id="cb4-35"><a href="#cb4-35" tabindex="-1"></a>model.<span class="bu">compile</span>(</span>
<span id="cb4-36"><a href="#cb4-36" tabindex="-1"></a>    loss<span class="op">=</span>keras.losses.binary_crossentropy,</span>
<span id="cb4-37"><a href="#cb4-37" tabindex="-1"></a>    optimizer<span class="op">=</span>keras.optimizers.Adam(),</span>
<span id="cb4-38"><a href="#cb4-38" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="model-training">Model Training<a class="anchor" aria-label="anchor" href="#model-training"></a>
</h2>
<p>With our model and data constructed, we can now train the model.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="co"># Define some callbacks to improve training.</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>early_stopping <span class="op">=</span> keras.callbacks.EarlyStopping(monitor<span class="op">=</span><span class="st">"val_loss"</span>, patience<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>reduce_lr <span class="op">=</span> keras.callbacks.ReduceLROnPlateau(monitor<span class="op">=</span><span class="st">"val_loss"</span>, patience<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a><span class="co"># Define modifiable training hyperparameters.</span></span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a><span class="co"># Fit the model to the training data.</span></span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a>model.fit(</span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a>    x_train,</span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a>    y_train,</span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a>    batch_size<span class="op">=</span>batch_size,</span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a>    epochs<span class="op">=</span>epochs,</span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a>    validation_data<span class="op">=</span>(x_val, y_val),</span>
<span id="cb5-16"><a href="#cb5-16" tabindex="-1"></a>    callbacks<span class="op">=</span>[early_stopping, reduce_lr],</span>
<span id="cb5-17"><a href="#cb5-17" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="frame-prediction-visualizations">Frame Prediction Visualizations<a class="anchor" aria-label="anchor" href="#frame-prediction-visualizations"></a>
</h2>
<p>With our model now constructed and trained, we can generate some
example frame predictions based on a new video.</p>
<p>We’ll pick a random example from the validation set and then choose
the first ten frames from them. From there, we can allow the model to
predict 10 new frames, which we can compare to the ground truth frame
predictions.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="co"># Select a random example from the validation dataset.</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>example <span class="op">=</span> val_dataset[np.random.choice(<span class="bu">range</span>(<span class="bu">len</span>(val_dataset)), size<span class="op">=</span><span class="dv">1</span>)[<span class="dv">0</span>]]</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a><span class="co"># Pick the first/last ten frames from the example.</span></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a>frames <span class="op">=</span> example[:<span class="dv">10</span>, ...]</span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>original_frames <span class="op">=</span> example[<span class="dv">10</span>:, ...]</span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a><span class="co"># Predict a new set of 10 frames.</span></span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a><span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a>    <span class="co"># Extract the model's prediction and post-process it.</span></span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a>    new_prediction <span class="op">=</span> model.predict(np.expand_dims(frames, axis<span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a>    new_prediction <span class="op">=</span> np.squeeze(new_prediction, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb6-13"><a href="#cb6-13" tabindex="-1"></a>    predicted_frame <span class="op">=</span> np.expand_dims(new_prediction[<span class="op">-</span><span class="dv">1</span>, ...], axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb6-14"><a href="#cb6-14" tabindex="-1"></a></span>
<span id="cb6-15"><a href="#cb6-15" tabindex="-1"></a>    <span class="co"># Extend the set of prediction frames.</span></span>
<span id="cb6-16"><a href="#cb6-16" tabindex="-1"></a>    frames <span class="op">=</span> np.concatenate((frames, predicted_frame), axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb6-17"><a href="#cb6-17" tabindex="-1"></a></span>
<span id="cb6-18"><a href="#cb6-18" tabindex="-1"></a><span class="co"># Construct a figure for the original and new frames.</span></span>
<span id="cb6-19"><a href="#cb6-19" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">10</span>, figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">4</span>))</span>
<span id="cb6-20"><a href="#cb6-20" tabindex="-1"></a></span>
<span id="cb6-21"><a href="#cb6-21" tabindex="-1"></a><span class="co"># Plot the original frames.</span></span>
<span id="cb6-22"><a href="#cb6-22" tabindex="-1"></a><span class="cf">for</span> idx, ax <span class="kw">in</span> <span class="bu">enumerate</span>(axes[<span class="dv">0</span>]):</span>
<span id="cb6-23"><a href="#cb6-23" tabindex="-1"></a>    ax.imshow(np.squeeze(original_frames[idx]), cmap<span class="op">=</span><span class="st">"gray"</span>)</span>
<span id="cb6-24"><a href="#cb6-24" tabindex="-1"></a>    ax.set_title(<span class="ss">f"Frame </span><span class="sc">{</span>idx <span class="op">+</span> <span class="dv">11</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-25"><a href="#cb6-25" tabindex="-1"></a>    ax.axis(<span class="st">"off"</span>)</span>
<span id="cb6-26"><a href="#cb6-26" tabindex="-1"></a></span>
<span id="cb6-27"><a href="#cb6-27" tabindex="-1"></a><span class="co"># Plot the new frames.</span></span>
<span id="cb6-28"><a href="#cb6-28" tabindex="-1"></a>new_frames <span class="op">=</span> frames[<span class="dv">10</span>:, ...]</span>
<span id="cb6-29"><a href="#cb6-29" tabindex="-1"></a><span class="cf">for</span> idx, ax <span class="kw">in</span> <span class="bu">enumerate</span>(axes[<span class="dv">1</span>]):</span>
<span id="cb6-30"><a href="#cb6-30" tabindex="-1"></a>    ax.imshow(np.squeeze(new_frames[idx]), cmap<span class="op">=</span><span class="st">"gray"</span>)</span>
<span id="cb6-31"><a href="#cb6-31" tabindex="-1"></a>    ax.set_title(<span class="ss">f"Frame </span><span class="sc">{</span>idx <span class="op">+</span> <span class="dv">11</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-32"><a href="#cb6-32" tabindex="-1"></a>    ax.axis(<span class="st">"off"</span>)</span>
<span id="cb6-33"><a href="#cb6-33" tabindex="-1"></a></span>
<span id="cb6-34"><a href="#cb6-34" tabindex="-1"></a><span class="co"># Display the figure.</span></span>
<span id="cb6-35"><a href="#cb6-35" tabindex="-1"></a>plt.show()</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="predicted-videos">Predicted Videos<a class="anchor" aria-label="anchor" href="#predicted-videos"></a>
</h2>
<p>Finally, we’ll pick a few examples from the validation set and
construct some GIFs with them to see the model’s predicted videos.</p>
<p>You can use the trained model hosted on <a href="https://huggingface.co/keras-io/conv-lstm" class="external-link">Hugging Face Hub</a>
and try the demo on <a href="https://huggingface.co/spaces/keras-io/conv-lstm" class="external-link">Hugging Face
Spaces</a>.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="co"># Select a few random examples from the dataset.</span></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>examples <span class="op">=</span> val_dataset[np.random.choice(<span class="bu">range</span>(<span class="bu">len</span>(val_dataset)), size<span class="op">=</span><span class="dv">5</span>)]</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a><span class="co"># Iterate over the examples and predict the frames.</span></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>predicted_videos <span class="op">=</span> []</span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a><span class="cf">for</span> example <span class="kw">in</span> examples:</span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a>    <span class="co"># Pick the first/last ten frames from the example.</span></span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a>    frames <span class="op">=</span> example[:<span class="dv">10</span>, ...]</span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a>    original_frames <span class="op">=</span> example[<span class="dv">10</span>:, ...]</span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a>    new_predictions <span class="op">=</span> np.zeros(shape<span class="op">=</span>(<span class="dv">10</span>, <span class="op">*</span>frames[<span class="dv">0</span>].shape))</span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a></span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a>    <span class="co"># Predict a new set of 10 frames.</span></span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb7-14"><a href="#cb7-14" tabindex="-1"></a>        <span class="co"># Extract the model's prediction and post-process it.</span></span>
<span id="cb7-15"><a href="#cb7-15" tabindex="-1"></a>        frames <span class="op">=</span> example[: <span class="dv">10</span> <span class="op">+</span> i <span class="op">+</span> <span class="dv">1</span>, ...]</span>
<span id="cb7-16"><a href="#cb7-16" tabindex="-1"></a>        new_prediction <span class="op">=</span> model.predict(np.expand_dims(frames, axis<span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb7-17"><a href="#cb7-17" tabindex="-1"></a>        new_prediction <span class="op">=</span> np.squeeze(new_prediction, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb7-18"><a href="#cb7-18" tabindex="-1"></a>        predicted_frame <span class="op">=</span> np.expand_dims(new_prediction[<span class="op">-</span><span class="dv">1</span>, ...], axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb7-19"><a href="#cb7-19" tabindex="-1"></a></span>
<span id="cb7-20"><a href="#cb7-20" tabindex="-1"></a>        <span class="co"># Extend the set of prediction frames.</span></span>
<span id="cb7-21"><a href="#cb7-21" tabindex="-1"></a>        new_predictions[i] <span class="op">=</span> predicted_frame</span>
<span id="cb7-22"><a href="#cb7-22" tabindex="-1"></a></span>
<span id="cb7-23"><a href="#cb7-23" tabindex="-1"></a>    <span class="co"># Create and save GIFs for each of the ground truth/prediction images.</span></span>
<span id="cb7-24"><a href="#cb7-24" tabindex="-1"></a>    <span class="cf">for</span> frame_set <span class="kw">in</span> [original_frames, new_predictions]:</span>
<span id="cb7-25"><a href="#cb7-25" tabindex="-1"></a>        <span class="co"># Construct a GIF from the selected video frames.</span></span>
<span id="cb7-26"><a href="#cb7-26" tabindex="-1"></a>        current_frames <span class="op">=</span> np.squeeze(frame_set)</span>
<span id="cb7-27"><a href="#cb7-27" tabindex="-1"></a>        current_frames <span class="op">=</span> current_frames[..., np.newaxis] <span class="op">*</span> np.ones(<span class="dv">3</span>)</span>
<span id="cb7-28"><a href="#cb7-28" tabindex="-1"></a>        current_frames <span class="op">=</span> (current_frames <span class="op">*</span> <span class="dv">255</span>).astype(np.uint8)</span>
<span id="cb7-29"><a href="#cb7-29" tabindex="-1"></a>        current_frames <span class="op">=</span> <span class="bu">list</span>(current_frames)</span>
<span id="cb7-30"><a href="#cb7-30" tabindex="-1"></a></span>
<span id="cb7-31"><a href="#cb7-31" tabindex="-1"></a>        <span class="co"># Construct a GIF from the frames.</span></span>
<span id="cb7-32"><a href="#cb7-32" tabindex="-1"></a>        <span class="cf">with</span> io.BytesIO() <span class="im">as</span> gif:</span>
<span id="cb7-33"><a href="#cb7-33" tabindex="-1"></a>            imageio.mimsave(gif, current_frames, <span class="st">"GIF"</span>, duration<span class="op">=</span><span class="dv">200</span>)</span>
<span id="cb7-34"><a href="#cb7-34" tabindex="-1"></a>            predicted_videos.append(gif.getvalue())</span>
<span id="cb7-35"><a href="#cb7-35" tabindex="-1"></a></span>
<span id="cb7-36"><a href="#cb7-36" tabindex="-1"></a><span class="co"># Display the videos.</span></span>
<span id="cb7-37"><a href="#cb7-37" tabindex="-1"></a><span class="bu">print</span>(<span class="st">" Truth</span><span class="ch">\t</span><span class="st">Prediction"</span>)</span>
<span id="cb7-38"><a href="#cb7-38" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(predicted_videos), <span class="dv">2</span>):</span>
<span id="cb7-39"><a href="#cb7-39" tabindex="-1"></a>    <span class="co"># Construct and display an `HBox` with the ground truth and prediction.</span></span>
<span id="cb7-40"><a href="#cb7-40" tabindex="-1"></a>    box <span class="op">=</span> HBox(</span>
<span id="cb7-41"><a href="#cb7-41" tabindex="-1"></a>        [</span>
<span id="cb7-42"><a href="#cb7-42" tabindex="-1"></a>            widgets.Image(value<span class="op">=</span>predicted_videos[i]),</span>
<span id="cb7-43"><a href="#cb7-43" tabindex="-1"></a>            widgets.Image(value<span class="op">=</span>predicted_videos[i <span class="op">+</span> <span class="dv">1</span>]),</span>
<span id="cb7-44"><a href="#cb7-44" tabindex="-1"></a>        ]</span>
<span id="cb7-45"><a href="#cb7-45" tabindex="-1"></a>    )</span>
<span id="cb7-46"><a href="#cb7-46" tabindex="-1"></a>    display(box)</span></code></pre></div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Tomasz Kalinowski, JJ Allaire, François Chollet, Posit Software, PBC, Google.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
