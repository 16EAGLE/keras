<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="Use pre-trained nlp models for multiplechoice task.">
<title>MultipleChoice Task with Transfer Learning • keras3</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../../apple-touch-icon-60x60.png">
<script src="../../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../../deps/Fira_Code-0.4.7/font.css" rel="stylesheet">
<!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../../pkgdown.js"></script><meta property="og:title" content="MultipleChoice Task with Transfer Learning">
<meta property="og:description" content="Use pre-trained nlp models for multiplechoice task.">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-inverse navbar-expand-lg bg-primary"><div class="container">
    
    <a class="navbar-brand me-2" href="../../index.html">keras3</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">2.13.0.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../../index.html">Home</a>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-getting-started">Getting Started</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-getting-started">
    <a class="dropdown-item" href="../../articles/intro_to_keras_for_engineers.html">Introduction to Keras for engineers</a>
    <h6 class="dropdown-header" data-toc-skip>Tutorials</h6>
    <a class="dropdown-item" href="../../articles/getting_started.html">Getting Started</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_classification.html">Basic Classification</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_text_classification.html">Text Classification</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_regression.html">Basic Regression</a>
    <a class="dropdown-item" href="../../articles/tutorial_overfit_underfit.html">Overfitting and Underfitting</a>
    <a class="dropdown-item" href="../../articles/tutorial_save_and_restore.html">Save and Restore Models</a>
  </div>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-guides">Guides</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-guides">
    <h6 class="dropdown-header" data-toc-skip>Model definition</h6>
    <a class="dropdown-item" href="../../articles/functional_api.html">Functional API</a>
    <a class="dropdown-item" href="../../articles/sequential_model.html">Sequential Model</a>
    <h6 class="dropdown-header" data-toc-skip>Extending and customizing</h6>
    <a class="dropdown-item" href="../../articles/making_new_layers_and_models_via_subclassing.html">Making new layers and models via subclassing</a>
    <a class="dropdown-item" href="../../articles/training_with_built_in_methods.html">Training &amp; evaluation with the built-in methods</a>
    <a class="dropdown-item" href="../../articles/writing_a_custom_training_loop_in_tensorflow.html">Writing a training loop from scratch in TensorFlow</a>
    <a class="dropdown-item" href="../../articles/writing_your_own_callbacks.html">Writing Your Own Callbacks</a>
    <h6 class="dropdown-header" data-toc-skip>Other topics</h6>
    <a class="dropdown-item" href="../../articles/transfer_learning.html">Transfer learning and fine tuning</a>
    <a class="dropdown-item" href="../../articles/distributed_training_with_tensorflow.html">Distributed training with TensorFlow</a>
  </div>
</li>
<li class="active nav-item">
  <a class="nav-link" href="../../articles/examples/index.html">Examples</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../reference/index.html">Reference</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../news/index.html">News</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/rstudio/keras/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>MultipleChoice Task with Transfer Learning</h1>
                        <h4 data-toc-skip class="author">Md Awsafur
Rahman</h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/rstudio/keras/blob/HEAD/vignettes/examples/multiple_choice_task_with_transfer_learning.Rmd" class="external-link"><code>vignettes/examples/multiple_choice_task_with_transfer_learning.Rmd</code></a></small>
      <div class="d-none name"><code>multiple_choice_task_with_transfer_learning.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>In this example, we will demonstrate how to perform the
<strong>MultipleChoice</strong> task by finetuning pre-trained DebertaV3
model. In this task, several candidate answers are provided along with a
context and the model is trained to select the correct answer unlike
question answering. We will use SWAG dataset to demonstrate this
example.</p>
</div>
<div class="section level2">
<h2 id="setup">Setup<a class="anchor" aria-label="anchor" href="#setup"></a>
</h2>
<p>pip install -q keras –upgrade pip install -q keras-nlp –upgrade</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a>os.environ[<span class="st">"KERAS_BACKEND"</span>] <span class="op">=</span> <span class="st">"jax"</span>  <span class="co"># or "tensorflow" or "torch"</span></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">import</span> keras_nlp</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="im">import</span> keras <span class="im">as</span> keras</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="dataset">Dataset<a class="anchor" aria-label="anchor" href="#dataset"></a>
</h2>
<p>In this example we’ll use <strong>SWAG</strong> dataset for
multiplechoice task.</p>
<p>wget “<a href="https://github.com/rowanz/swagaf/archive/refs/heads/master.zip" class="external-link uri">https://github.com/rowanz/swagaf/archive/refs/heads/master.zip</a>”
-O swag.zip unzip -q /content/swag.zip</p>
<p>ls /content/swagaf-master/data</p>
</div>
<div class="section level2">
<h2 id="configuration">Configuration<a class="anchor" aria-label="anchor" href="#configuration"></a>
</h2>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="kw">class</span> CFG:</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>    preset <span class="op">=</span> <span class="st">"deberta_v3_extra_small_en"</span>  <span class="co"># Name of pretrained models</span></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>    sequence_length <span class="op">=</span> <span class="dv">200</span>  <span class="co"># Input sequence length</span></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>    seed <span class="op">=</span> <span class="dv">42</span>  <span class="co"># Random seed</span></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>    epochs <span class="op">=</span> <span class="dv">5</span>  <span class="co"># Training epochs</span></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a>    batch_size <span class="op">=</span> <span class="dv">8</span>  <span class="co"># Batch size</span></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>    augment <span class="op">=</span> <span class="va">True</span>  <span class="co"># Augmentation (Shuffle Options)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="reproducibility">Reproducibility<a class="anchor" aria-label="anchor" href="#reproducibility"></a>
</h2>
<p>Sets value for random seed to produce similar result in each run.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>keras.utils.set_random_seed(CFG.seed)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="meta-data">Meta Data<a class="anchor" aria-label="anchor" href="#meta-data"></a>
</h2>
<ul>
<li>
<strong>train.csv</strong> - will be used for training.</li>
<li>
<code>sent1</code> and <code>sent2</code>: these fields show how a
sentence starts, and if you put the two together, you get the
<code>startphrase</code> field.</li>
<li>
<code>ending_&lt;i&gt;</code>: suggests a possible ending for how a
sentence can end, but only one of them is correct.
<ul>
<li>
<code>label</code>: identifies the correct sentence ending.</li>
</ul>
</li>
<li>
<strong>val.csv</strong> - similar to <code>train.csv</code> but
will be used for validation.</li>
</ul>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co"># Train data</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>train_df <span class="op">=</span> pd.read_csv(</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>    <span class="st">"/content/swagaf-master/data/train.csv"</span>, index_col<span class="op">=</span><span class="dv">0</span></span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>)  <span class="co"># Read CSV file into a DataFrame</span></span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a>train_df <span class="op">=</span> train_df.sample(frac<span class="op">=</span><span class="fl">0.02</span>)</span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"# Train Data: {:,}"</span>.<span class="bu">format</span>(<span class="bu">len</span>(train_df)))</span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a><span class="co"># Valid data</span></span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a>valid_df <span class="op">=</span> pd.read_csv(</span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a>    <span class="st">"/content/swagaf-master/data/val.csv"</span>, index_col<span class="op">=</span><span class="dv">0</span></span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a>)  <span class="co"># Read CSV file into a DataFrame</span></span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a>valid_df <span class="op">=</span> valid_df.sample(frac<span class="op">=</span><span class="fl">0.02</span>)</span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"# Valid Data: {:,}"</span>.<span class="bu">format</span>(<span class="bu">len</span>(valid_df)))</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="contextualize-options">Contextualize Options<a class="anchor" aria-label="anchor" href="#contextualize-options"></a>
</h2>
<p>Our approach entails furnishing the model with question and answer
pairs, as opposed to employing a single question for all five options.
In practice, this signifies that for the five options, we will supply
the model with the same set of five questions combined with each
respective answer choice (e.g., <code>(Q + A)</code>,
<code>(Q + B)</code>, and so on). This analogy draws parallels to the
practice of revisiting a question multiple times during an exam to
promote a deeper understanding of the problem at hand.</p>
<blockquote>
<p>Notably, in the context of SWAG dataset, question is the start of a
sentence and options are possible ending of that sentence.</p>
</blockquote>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="co"># Define a function to create options based on the prompt and choices</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="kw">def</span> make_options(row):</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>    row[<span class="st">"options"</span>] <span class="op">=</span> [</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>        <span class="ss">f"</span><span class="sc">{</span>row<span class="sc">.</span>startphrase<span class="sc">}</span><span class="ch">\n</span><span class="sc">{</span>row<span class="sc">.</span>ending0<span class="sc">}</span><span class="ss">"</span>,  <span class="co"># Option 0</span></span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>        <span class="ss">f"</span><span class="sc">{</span>row<span class="sc">.</span>startphrase<span class="sc">}</span><span class="ch">\n</span><span class="sc">{</span>row<span class="sc">.</span>ending1<span class="sc">}</span><span class="ss">"</span>,  <span class="co"># Option 1</span></span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>        <span class="ss">f"</span><span class="sc">{</span>row<span class="sc">.</span>startphrase<span class="sc">}</span><span class="ch">\n</span><span class="sc">{</span>row<span class="sc">.</span>ending2<span class="sc">}</span><span class="ss">"</span>,  <span class="co"># Option 2</span></span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a>        <span class="ss">f"</span><span class="sc">{</span>row<span class="sc">.</span>startphrase<span class="sc">}</span><span class="ch">\n</span><span class="sc">{</span>row<span class="sc">.</span>ending3<span class="sc">}</span><span class="ss">"</span>,</span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a>    ]  <span class="co"># Option 3</span></span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a>    <span class="cf">return</span> row</span></code></pre></div>
<p>Apply the <code>make_options</code> function to each row of the
dataframe</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>train_df <span class="op">=</span> train_df.<span class="bu">apply</span>(make_options, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>valid_df <span class="op">=</span> valid_df.<span class="bu">apply</span>(make_options, axis<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="preprocessing">Preprocessing<a class="anchor" aria-label="anchor" href="#preprocessing"></a>
</h2>
<p><strong>What it does:</strong> The preprocessor takes input strings
and transforms them into a dictionary (<code>token_ids</code>,
<code>padding_mask</code>) containing preprocessed tensors. This process
starts with tokenization, where input strings are converted into
sequences of token IDs.</p>
<p><strong>Why it’s important:</strong> Initially, raw text data is
complex and challenging for modeling due to its high dimensionality. By
converting text into a compact set of tokens, such as transforming
<code>"The quick brown fox"</code> into
<code>["the", "qu", "##ick", "br", "##own", "fox"]</code>, we simplify
the data. Many models rely on special tokens and additional tensors to
understand input. These tokens help divide input and identify padding,
among other tasks. Making all sequences the same length through padding
boosts computational efficiency, making subsequent steps smoother.</p>
<p>Explore the following pages to access the available preprocessing and
tokenizer layers in <strong>KerasNLP</strong>: - <a href="https://keras.io/api/keras_nlp/preprocessing_layers/" class="external-link">Preprocessing</a>
- <a href="https://keras.io/api/keras_nlp/tokenizers/" class="external-link">Tokenizers</a></p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>preprocessor <span class="op">=</span> keras_nlp.models.DebertaV3Preprocessor.from_preset(</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>    preset<span class="op">=</span>CFG.preset,  <span class="co"># Name of the model</span></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>    sequence_length<span class="op">=</span>CFG.sequence_length,  <span class="co"># Max sequence length, will be padded if shorter</span></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>)</span></code></pre></div>
<p>Now, let’s examine what the output shape of the preprocessing layer
looks like. The output shape of the layer can be represented as <span class="math inline">\((num\_choices, sequence\_length)\)</span>.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a>outs <span class="op">=</span> preprocessor(</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>    train_df.options.iloc[<span class="dv">0</span>]</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>)  <span class="co"># Process options for the first row</span></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a><span class="co"># Display the shape of each processed output</span></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a><span class="cf">for</span> k, v <span class="kw">in</span> outs.items():</span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a>    <span class="bu">print</span>(k, <span class="st">":"</span>, v.shape)</span></code></pre></div>
<p>We’ll use the <code>preprocessing_fn</code> function to transform
each text option using the <code>dataset.map(preprocessing_fn)</code>
method.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="kw">def</span> preprocess_fn(text, label<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>    text <span class="op">=</span> preprocessor(text)  <span class="co"># Preprocess text</span></span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a>    <span class="cf">return</span> (</span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>        (text, label) <span class="cf">if</span> label <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> text</span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a>    )  <span class="co"># Return processed text and label if available</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="augmentation">Augmentation<a class="anchor" aria-label="anchor" href="#augmentation"></a>
</h2>
<p>In this notebook, we’ll experiment with an interesting augmentation
technique, <code>option_shuffle</code>. Since we’re providing the model
with one option at a time, we can introduce a shuffle to the order of
options. For instance, options <code>[A, C, E, D, B]</code> would be
rearranged as <code>[D, B, A, E, C]</code>. This practice will help the
model focus on the content of the options themselves, rather than being
influenced by their positions.</p>
<p><strong>Note:</strong> Even though <code>option_shuffle</code>
function is written in pure tensorflow, it can be used with any backend
(e.g. JAX, PyTorch) as it is only used in <code>tf.data.Dataset</code>
pipeline which is compatible with Keras 3 routines.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="kw">def</span> option_shuffle(options, labels, prob<span class="op">=</span><span class="fl">0.50</span>, seed<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>    <span class="cf">if</span> tf.random.uniform([]) <span class="op">&gt;</span> prob:  <span class="co"># Shuffle probability check</span></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a>        <span class="cf">return</span> options, labels</span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a>    <span class="co"># Shuffle indices of options and labels in the same order</span></span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a>    indices <span class="op">=</span> tf.random.shuffle(tf.<span class="bu">range</span>(tf.shape(options)[<span class="dv">0</span>]), seed<span class="op">=</span>seed)</span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a>    <span class="co"># Shuffle options and labels</span></span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a>    options <span class="op">=</span> tf.gather(options, indices)</span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a>    labels <span class="op">=</span> tf.gather(labels, indices)</span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a>    <span class="cf">return</span> options, labels</span></code></pre></div>
<p>In the following function, we’ll merge all augmentation functions to
apply to the text. These augmentations will be applied to the data using
the <code>dataset.map(augment_fn)</code> approach.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="kw">def</span> augment_fn(text, label<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a>    text, label <span class="op">=</span> option_shuffle(text, label, prob<span class="op">=</span><span class="fl">0.5</span>  <span class="co"># Shuffle the options</span></span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>    <span class="cf">return</span> (text, label) <span class="cf">if</span> label <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="cf">else</span> text</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="dataloader">DataLoader<a class="anchor" aria-label="anchor" href="#dataloader"></a>
</h2>
<p>The code below sets up a robust data flow pipeline using
<code>tf.data.Dataset</code> for data processing. Notable aspects of
<code>tf.data</code> include its ability to simplify pipeline
construction and represent components in sequences.</p>
<p>To learn more about <code>tf.data</code>, refer to this <a href="https://www.tensorflow.org/guide/data" class="external-link">documentation</a>.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="kw">def</span> build_dataset(</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a>    texts,</span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>    labels<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">32</span>,</span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a>    cache<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a>    augment<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a>    repeat<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb12-8"><a href="#cb12-8" tabindex="-1"></a>    shuffle<span class="op">=</span><span class="dv">1024</span>,</span>
<span id="cb12-9"><a href="#cb12-9" tabindex="-1"></a>):</span>
<span id="cb12-10"><a href="#cb12-10" tabindex="-1"></a>    AUTO <span class="op">=</span> tf.data.AUTOTUNE  <span class="co"># AUTOTUNE option</span></span>
<span id="cb12-11"><a href="#cb12-11" tabindex="-1"></a>    slices <span class="op">=</span> (</span>
<span id="cb12-12"><a href="#cb12-12" tabindex="-1"></a>        (texts,)</span>
<span id="cb12-13"><a href="#cb12-13" tabindex="-1"></a>        <span class="cf">if</span> labels <span class="kw">is</span> <span class="va">None</span></span>
<span id="cb12-14"><a href="#cb12-14" tabindex="-1"></a>        <span class="cf">else</span> (texts, keras.utils.to_categorical(labels, num_classes<span class="op">=</span><span class="dv">4</span>))</span>
<span id="cb12-15"><a href="#cb12-15" tabindex="-1"></a>    )  <span class="co"># Create slices</span></span>
<span id="cb12-16"><a href="#cb12-16" tabindex="-1"></a>    ds <span class="op">=</span> tf.data.Dataset.from_tensor_slices(</span>
<span id="cb12-17"><a href="#cb12-17" tabindex="-1"></a>        slices</span>
<span id="cb12-18"><a href="#cb12-18" tabindex="-1"></a>    )  <span class="co"># Create dataset from slices</span></span>
<span id="cb12-19"><a href="#cb12-19" tabindex="-1"></a>    ds <span class="op">=</span> ds.cache() <span class="cf">if</span> cache <span class="cf">else</span> ds  <span class="co"># Cache dataset if enabled</span></span>
<span id="cb12-20"><a href="#cb12-20" tabindex="-1"></a>    <span class="cf">if</span> augment:  <span class="co"># Apply augmentation if enabled</span></span>
<span id="cb12-21"><a href="#cb12-21" tabindex="-1"></a>        ds <span class="op">=</span> ds.<span class="bu">map</span>(augment_fn, num_parallel_calls<span class="op">=</span>AUTO)</span>
<span id="cb12-22"><a href="#cb12-22" tabindex="-1"></a>    ds <span class="op">=</span> ds.<span class="bu">map</span>(</span>
<span id="cb12-23"><a href="#cb12-23" tabindex="-1"></a>        preprocess_fn, num_parallel_calls<span class="op">=</span>AUTO</span>
<span id="cb12-24"><a href="#cb12-24" tabindex="-1"></a>    )  <span class="co"># Map preprocessing function</span></span>
<span id="cb12-25"><a href="#cb12-25" tabindex="-1"></a>    ds <span class="op">=</span> ds.repeat() <span class="cf">if</span> repeat <span class="cf">else</span> ds  <span class="co"># Repeat dataset if enabled</span></span>
<span id="cb12-26"><a href="#cb12-26" tabindex="-1"></a>    opt <span class="op">=</span> tf.data.Options()  <span class="co"># Create dataset options</span></span>
<span id="cb12-27"><a href="#cb12-27" tabindex="-1"></a>    <span class="cf">if</span> shuffle:</span>
<span id="cb12-28"><a href="#cb12-28" tabindex="-1"></a>        ds <span class="op">=</span> ds.shuffle(shuffle, seed<span class="op">=</span>CFG.seed)  <span class="co"># Shuffle dataset if enabled</span></span>
<span id="cb12-29"><a href="#cb12-29" tabindex="-1"></a>        opt.experimental_deterministic <span class="op">=</span> <span class="va">False</span></span>
<span id="cb12-30"><a href="#cb12-30" tabindex="-1"></a>    ds <span class="op">=</span> ds.with_options(opt)  <span class="co"># Set dataset options</span></span>
<span id="cb12-31"><a href="#cb12-31" tabindex="-1"></a>    ds <span class="op">=</span> ds.batch(batch_size, drop_remainder<span class="op">=</span><span class="va">True</span>)  <span class="co"># Batch dataset</span></span>
<span id="cb12-32"><a href="#cb12-32" tabindex="-1"></a>    ds <span class="op">=</span> ds.prefetch(AUTO)  <span class="co"># Prefetch next batch</span></span>
<span id="cb12-33"><a href="#cb12-33" tabindex="-1"></a>    <span class="cf">return</span> ds  <span class="co"># Return the built dataset</span></span></code></pre></div>
<p>Now let’s create train and valid dataloader using above funciton.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="co"># Build train dataloader</span></span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a>train_texts <span class="op">=</span> train_df.options.tolist()  <span class="co"># Extract training texts</span></span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a>train_labels <span class="op">=</span> train_df.label.tolist()  <span class="co"># Extract training labels</span></span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a>train_ds <span class="op">=</span> build_dataset(</span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a>    train_texts,</span>
<span id="cb13-6"><a href="#cb13-6" tabindex="-1"></a>    train_labels,</span>
<span id="cb13-7"><a href="#cb13-7" tabindex="-1"></a>    batch_size<span class="op">=</span>CFG.batch_size,</span>
<span id="cb13-8"><a href="#cb13-8" tabindex="-1"></a>    cache<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb13-9"><a href="#cb13-9" tabindex="-1"></a>    shuffle<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb13-10"><a href="#cb13-10" tabindex="-1"></a>    repeat<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb13-11"><a href="#cb13-11" tabindex="-1"></a>    augment<span class="op">=</span>CFG.augment,</span>
<span id="cb13-12"><a href="#cb13-12" tabindex="-1"></a>)</span>
<span id="cb13-13"><a href="#cb13-13" tabindex="-1"></a></span>
<span id="cb13-14"><a href="#cb13-14" tabindex="-1"></a><span class="co"># Build valid dataloader</span></span>
<span id="cb13-15"><a href="#cb13-15" tabindex="-1"></a>valid_texts <span class="op">=</span> valid_df.options.tolist()  <span class="co"># Extract validation texts</span></span>
<span id="cb13-16"><a href="#cb13-16" tabindex="-1"></a>valid_labels <span class="op">=</span> valid_df.label.tolist()  <span class="co"># Extract validation labels</span></span>
<span id="cb13-17"><a href="#cb13-17" tabindex="-1"></a>valid_ds <span class="op">=</span> build_dataset(</span>
<span id="cb13-18"><a href="#cb13-18" tabindex="-1"></a>    valid_texts,</span>
<span id="cb13-19"><a href="#cb13-19" tabindex="-1"></a>    valid_labels,</span>
<span id="cb13-20"><a href="#cb13-20" tabindex="-1"></a>    batch_size<span class="op">=</span>CFG.batch_size,</span>
<span id="cb13-21"><a href="#cb13-21" tabindex="-1"></a>    cache<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb13-22"><a href="#cb13-22" tabindex="-1"></a>    shuffle<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb13-23"><a href="#cb13-23" tabindex="-1"></a>    repeat<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb13-24"><a href="#cb13-24" tabindex="-1"></a>    augment<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb13-25"><a href="#cb13-25" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="lr-schedule">LR Schedule<a class="anchor" aria-label="anchor" href="#lr-schedule"></a>
</h2>
<p>Implementing a learning rate scheduler is crucial for transfer
learning. The learning rate initiates at <code>lr_start</code> and
gradually tapers down to <code>lr_min</code> using
<strong>cosine</strong> curve.</p>
<p><strong>Importance:</strong> A well-structured learning rate schedule
is essential for efficient model training, ensuring optimal convergence
and avoiding issues such as overshooting or stagnation.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" tabindex="-1"></a><span class="kw">def</span> get_lr_callback(batch_size<span class="op">=</span><span class="dv">8</span>, mode<span class="op">=</span><span class="st">"cos"</span>, epochs<span class="op">=</span><span class="dv">10</span>, plot<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb14-5"><a href="#cb14-5" tabindex="-1"></a>    lr_start, lr_max, lr_min <span class="op">=</span> <span class="fl">1.0e-6</span>, <span class="fl">0.6e-6</span> <span class="op">*</span> batch_size, <span class="fl">1e-6</span></span>
<span id="cb14-6"><a href="#cb14-6" tabindex="-1"></a>    lr_ramp_ep, lr_sus_ep <span class="op">=</span> <span class="dv">2</span>, <span class="dv">0</span></span>
<span id="cb14-7"><a href="#cb14-7" tabindex="-1"></a></span>
<span id="cb14-8"><a href="#cb14-8" tabindex="-1"></a>    <span class="kw">def</span> lrfn(epoch):  <span class="co"># Learning rate update function</span></span>
<span id="cb14-9"><a href="#cb14-9" tabindex="-1"></a>        <span class="cf">if</span> epoch <span class="op">&lt;</span> lr_ramp_ep:</span>
<span id="cb14-10"><a href="#cb14-10" tabindex="-1"></a>            lr <span class="op">=</span> (lr_max <span class="op">-</span> lr_start) <span class="op">/</span> lr_ramp_ep <span class="op">*</span> epoch <span class="op">+</span> lr_start</span>
<span id="cb14-11"><a href="#cb14-11" tabindex="-1"></a>        <span class="cf">elif</span> epoch <span class="op">&lt;</span> lr_ramp_ep <span class="op">+</span> lr_sus_ep:</span>
<span id="cb14-12"><a href="#cb14-12" tabindex="-1"></a>            lr <span class="op">=</span> lr_max</span>
<span id="cb14-13"><a href="#cb14-13" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb14-14"><a href="#cb14-14" tabindex="-1"></a>            decay_total_epochs, decay_epoch_index <span class="op">=</span> (</span>
<span id="cb14-15"><a href="#cb14-15" tabindex="-1"></a>                epochs <span class="op">-</span> lr_ramp_ep <span class="op">-</span> lr_sus_ep <span class="op">+</span> <span class="dv">3</span>,</span>
<span id="cb14-16"><a href="#cb14-16" tabindex="-1"></a>                epoch <span class="op">-</span> lr_ramp_ep <span class="op">-</span> lr_sus_ep,</span>
<span id="cb14-17"><a href="#cb14-17" tabindex="-1"></a>            )</span>
<span id="cb14-18"><a href="#cb14-18" tabindex="-1"></a>            phase <span class="op">=</span> math.pi <span class="op">*</span> decay_epoch_index <span class="op">/</span> decay_total_epochs</span>
<span id="cb14-19"><a href="#cb14-19" tabindex="-1"></a>            lr <span class="op">=</span> (lr_max <span class="op">-</span> lr_min) <span class="op">*</span> <span class="fl">0.5</span> <span class="op">*</span> (<span class="dv">1</span> <span class="op">+</span> math.cos(phase)) <span class="op">+</span> lr_min</span>
<span id="cb14-20"><a href="#cb14-20" tabindex="-1"></a>        <span class="cf">return</span> lr</span>
<span id="cb14-21"><a href="#cb14-21" tabindex="-1"></a></span>
<span id="cb14-22"><a href="#cb14-22" tabindex="-1"></a>    <span class="cf">if</span> plot:  <span class="co"># Plot lr curve if plot is True</span></span>
<span id="cb14-23"><a href="#cb14-23" tabindex="-1"></a>        plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb14-24"><a href="#cb14-24" tabindex="-1"></a>        plt.plot(</span>
<span id="cb14-25"><a href="#cb14-25" tabindex="-1"></a>            np.arange(epochs),</span>
<span id="cb14-26"><a href="#cb14-26" tabindex="-1"></a>            [lrfn(epoch) <span class="cf">for</span> epoch <span class="kw">in</span> np.arange(epochs)],</span>
<span id="cb14-27"><a href="#cb14-27" tabindex="-1"></a>            marker<span class="op">=</span><span class="st">"o"</span>,</span>
<span id="cb14-28"><a href="#cb14-28" tabindex="-1"></a>        )</span>
<span id="cb14-29"><a href="#cb14-29" tabindex="-1"></a>        plt.xlabel(<span class="st">"epoch"</span>)</span>
<span id="cb14-30"><a href="#cb14-30" tabindex="-1"></a>        plt.ylabel(<span class="st">"lr"</span>)</span>
<span id="cb14-31"><a href="#cb14-31" tabindex="-1"></a>        plt.title(<span class="st">"LR Scheduler"</span>)</span>
<span id="cb14-32"><a href="#cb14-32" tabindex="-1"></a>        plt.show()</span>
<span id="cb14-33"><a href="#cb14-33" tabindex="-1"></a></span>
<span id="cb14-34"><a href="#cb14-34" tabindex="-1"></a>    <span class="cf">return</span> keras.callbacks.LearningRateScheduler(</span>
<span id="cb14-35"><a href="#cb14-35" tabindex="-1"></a>        lrfn, verbose<span class="op">=</span><span class="va">False</span></span>
<span id="cb14-36"><a href="#cb14-36" tabindex="-1"></a>    )  <span class="co"># Create lr callback</span></span>
<span id="cb14-37"><a href="#cb14-37" tabindex="-1"></a></span>
<span id="cb14-38"><a href="#cb14-38" tabindex="-1"></a></span>
<span id="cb14-39"><a href="#cb14-39" tabindex="-1"></a>_ <span class="op">=</span> get_lr_callback(CFG.batch_size, plot<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="callbacks">Callbacks<a class="anchor" aria-label="anchor" href="#callbacks"></a>
</h2>
<p>The function below will gather all the training callbacks, such as
<code>lr_scheduler</code>, <code>model_checkpoint</code>.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="kw">def</span> get_callbacks():</span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a>    callbacks <span class="op">=</span> []</span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a>    lr_cb <span class="op">=</span> get_lr_callback(CFG.batch_size)  <span class="co"># Get lr callback</span></span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a>    ckpt_cb <span class="op">=</span> keras.callbacks.ModelCheckpoint(</span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a>        <span class="ss">f"best.keras"</span>,</span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a>        monitor<span class="op">=</span><span class="st">"val_accuracy"</span>,</span>
<span id="cb15-7"><a href="#cb15-7" tabindex="-1"></a>        save_best_only<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb15-8"><a href="#cb15-8" tabindex="-1"></a>        save_weights_only<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb15-9"><a href="#cb15-9" tabindex="-1"></a>        mode<span class="op">=</span><span class="st">"max"</span>,</span>
<span id="cb15-10"><a href="#cb15-10" tabindex="-1"></a>    )  <span class="co"># Get Model checkpoint callback</span></span>
<span id="cb15-11"><a href="#cb15-11" tabindex="-1"></a>    callbacks.extend([lr_cb, ckpt_cb])  <span class="co"># Add lr and checkpoint callbacks</span></span>
<span id="cb15-12"><a href="#cb15-12" tabindex="-1"></a>    <span class="cf">return</span> callbacks  <span class="co"># Return the list of callbacks</span></span>
<span id="cb15-13"><a href="#cb15-13" tabindex="-1"></a></span>
<span id="cb15-14"><a href="#cb15-14" tabindex="-1"></a></span>
<span id="cb15-15"><a href="#cb15-15" tabindex="-1"></a>callbacks <span class="op">=</span> get_callbacks()</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="multiplechoice-model">MultipleChoice Model<a class="anchor" aria-label="anchor" href="#multiplechoice-model"></a>
</h2>
<div class="section level3">
<h3 id="pre-trained-models">Pre-trained Models<a class="anchor" aria-label="anchor" href="#pre-trained-models"></a>
</h3>
<p>The <code>KerasNLP</code> library provides comprehensive,
ready-to-use implementations of popular NLP model architectures. It
features a variety of pre-trained models including <code>Bert</code>,
<code>Roberta</code>, <code>DebertaV3</code>, and more. In this
notebook, we’ll showcase the usage of <code>DistillBert</code>. However,
feel free to explore all available models in the <a href="https://keras.io/api/keras_nlp/models/" class="external-link">KerasNLP
documentation</a>. Also for a deeper understanding of
<code>KerasNLP</code>, refer to the informative <a href="https://keras.io/guides/keras_nlp/getting_started/" class="external-link">getting
started guide</a>.</p>
<p>Our approach involves using
<code>keras_nlp.models.XXClassifier</code> to process each question and
option pari (e.g. (Q+A), (Q+B), etc.), generating logits. These logits
are then combined and passed through a softmax function to produce the
final output.</p>
</div>
<div class="section level3">
<h3 id="classifier-for-multiple-choice-tasks">Classifier for Multiple-Choice Tasks<a class="anchor" aria-label="anchor" href="#classifier-for-multiple-choice-tasks"></a>
</h3>
<p>When dealing with multiple-choice questions, instead of giving the
model the question and all options together
<code>(Q + A + B + C ...)</code>, we provide the model with one option
at a time along with the question. For instance, <code>(Q + A)</code>,
<code>(Q + B)</code>, and so on. Once we have the prediction scores
(logits) for all options, we combine them using the <code>Softmax</code>
function to get the ultimate result. If we had given all options at once
to the model, the text’s length would increase, making it harder for the
model to handle. The picture below illustrates this idea:</p>
<div class="float">
<img src="https://pbs.twimg.com/media/F3NUju_a8AAS8Fq?format=png&amp;name=large" alt="Model Diagram"><div class="figcaption">Model Diagram</div>
</div>
<div align="center">
<b> Picture Credict: </b> <a href="https://twitter.com/johnowhitaker" class="external-link"> <span class="citation">@johnowhitaker</span> </a>
</div>
</div>
<p><br></p>
<p>From a coding perspective, remember that we use the same model for
all five options, with shared weights. Despite the figure suggesting
five separate models, they are, in fact, one model with shared weights.
Another point to consider is the the input shapes of Classifier and
MultipleChoice.</p>
<ul>
<li>Input shape for <strong>Multiple Choice</strong>: <span class="math inline">\((batch\_size, num\_choices,
seq\_length)\)</span>
</li>
<li>Input shape for <strong>Classifier</strong>: <span class="math inline">\((batch\_size, seq\_length)\)</span>
</li>
</ul>
<p>Certainly, it’s clear that we can’t directly give the data for the
multiple-choice task to the model because the input shapes don’t match.
To handle this, we’ll use <strong>slicing</strong>. This means we’ll
separate the features of each option, like <span class="math inline">\(feature_{(Q + A)}\)</span> and <span class="math inline">\(feature_{(Q + B)}\)</span>, and give them one by
one to the NLP classifier. After we get the prediction scores <span class="math inline">\(logits_{(Q + A)}\)</span> and <span class="math inline">\(logits_{(Q + B)}\)</span> for all the options,
we’ll use the Softmax function, like <span class="math inline">\(\operatorname{Softmax}([logits_{(Q + A)},
logits_{(Q + B)}])\)</span>, to combine them. This final step helps us
make the ultimate decision or choice.</p>
<blockquote>
<p>Note that in the classifier, we set <code>num_classes=1</code>
instead of <code>5</code>. This is because the classifier produces a
single output for each option. When dealing with five options, these
individual outputs are joined together and then processed through a
softmax function to generate the final result, which has a dimension of
<code>5</code>.</p>
</blockquote>
<div class="sourceCode" id="cb16"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="co"># Selects one option from five</span></span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a><span class="kw">class</span> SelectOption(keras.layers.Layer):</span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, index, <span class="op">**</span>kwargs):</span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(<span class="op">**</span>kwargs)</span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a>        <span class="va">self</span>.index <span class="op">=</span> index</span>
<span id="cb16-6"><a href="#cb16-6" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" tabindex="-1"></a>    <span class="kw">def</span> call(<span class="va">self</span>, inputs):</span>
<span id="cb16-8"><a href="#cb16-8" tabindex="-1"></a>        <span class="co"># Selects a specific slice from the inputs tensor</span></span>
<span id="cb16-9"><a href="#cb16-9" tabindex="-1"></a>        <span class="cf">return</span> inputs[:, <span class="va">self</span>.index, :]</span>
<span id="cb16-10"><a href="#cb16-10" tabindex="-1"></a></span>
<span id="cb16-11"><a href="#cb16-11" tabindex="-1"></a>    <span class="kw">def</span> get_config(<span class="va">self</span>):</span>
<span id="cb16-12"><a href="#cb16-12" tabindex="-1"></a>        <span class="co"># For serialize the model</span></span>
<span id="cb16-13"><a href="#cb16-13" tabindex="-1"></a>        base_config <span class="op">=</span> <span class="bu">super</span>().get_config()</span>
<span id="cb16-14"><a href="#cb16-14" tabindex="-1"></a>        config <span class="op">=</span> {</span>
<span id="cb16-15"><a href="#cb16-15" tabindex="-1"></a>            <span class="st">"index"</span>: <span class="va">self</span>.index,</span>
<span id="cb16-16"><a href="#cb16-16" tabindex="-1"></a>        }</span>
<span id="cb16-17"><a href="#cb16-17" tabindex="-1"></a>        <span class="cf">return</span> {<span class="op">**</span>base_config, <span class="op">**</span>config}</span>
<span id="cb16-18"><a href="#cb16-18" tabindex="-1"></a></span>
<span id="cb16-19"><a href="#cb16-19" tabindex="-1"></a></span>
<span id="cb16-20"><a href="#cb16-20" tabindex="-1"></a><span class="kw">def</span> build_model():</span>
<span id="cb16-21"><a href="#cb16-21" tabindex="-1"></a>    <span class="co"># Define input layers</span></span>
<span id="cb16-22"><a href="#cb16-22" tabindex="-1"></a>    inputs <span class="op">=</span> {</span>
<span id="cb16-23"><a href="#cb16-23" tabindex="-1"></a>        <span class="st">"token_ids"</span>: keras.Input(</span>
<span id="cb16-24"><a href="#cb16-24" tabindex="-1"></a>            shape<span class="op">=</span>(<span class="dv">4</span>, <span class="va">None</span>), dtype<span class="op">=</span>t<span class="st">"int32"</span>, name<span class="op">=</span><span class="st">"token_ids"</span></span>
<span id="cb16-25"><a href="#cb16-25" tabindex="-1"></a>        ),</span>
<span id="cb16-26"><a href="#cb16-26" tabindex="-1"></a>        <span class="st">"padding_mask"</span>: keras.Input(</span>
<span id="cb16-27"><a href="#cb16-27" tabindex="-1"></a>            shape<span class="op">=</span>(<span class="dv">4</span>, <span class="va">None</span>), dtype<span class="op">=</span><span class="st">"int32"</span>, name<span class="op">=</span><span class="st">"padding_mask"</span></span>
<span id="cb16-28"><a href="#cb16-28" tabindex="-1"></a>        ),</span>
<span id="cb16-29"><a href="#cb16-29" tabindex="-1"></a>    }</span>
<span id="cb16-30"><a href="#cb16-30" tabindex="-1"></a>    <span class="co"># Create a DebertaV3Classifier model</span></span>
<span id="cb16-31"><a href="#cb16-31" tabindex="-1"></a>    classifier <span class="op">=</span> keras_nlp.models.DebertaV3Classifier.from_preset(</span>
<span id="cb16-32"><a href="#cb16-32" tabindex="-1"></a>        CFG.preset,</span>
<span id="cb16-33"><a href="#cb16-33" tabindex="-1"></a>        preprocessor<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb16-34"><a href="#cb16-34" tabindex="-1"></a>        num_classes<span class="op">=</span><span class="dv">1</span>,  <span class="co"># one output per one option, for five options total 5 outputs</span></span>
<span id="cb16-35"><a href="#cb16-35" tabindex="-1"></a>    )</span>
<span id="cb16-36"><a href="#cb16-36" tabindex="-1"></a>    logits <span class="op">=</span> []</span>
<span id="cb16-37"><a href="#cb16-37" tabindex="-1"></a>    <span class="co"># Loop through each option (Q+A), (Q+B) etc and compute associted logits</span></span>
<span id="cb16-38"><a href="#cb16-38" tabindex="-1"></a>    <span class="cf">for</span> option_idx <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">4</span>):</span>
<span id="cb16-39"><a href="#cb16-39" tabindex="-1"></a>        option <span class="op">=</span> {</span>
<span id="cb16-40"><a href="#cb16-40" tabindex="-1"></a>            k: SelectOption(option_idx, name<span class="op">=</span><span class="ss">f"</span><span class="sc">{</span>k<span class="sc">}</span><span class="ss">_</span><span class="sc">{</span>option_idx<span class="sc">}</span><span class="ss">"</span>)(v)</span>
<span id="cb16-41"><a href="#cb16-41" tabindex="-1"></a>            <span class="cf">for</span> k, v <span class="kw">in</span> inputs.items()</span>
<span id="cb16-42"><a href="#cb16-42" tabindex="-1"></a>        }</span>
<span id="cb16-43"><a href="#cb16-43" tabindex="-1"></a>        logit <span class="op">=</span> classifier(option)</span>
<span id="cb16-44"><a href="#cb16-44" tabindex="-1"></a>        logits.append(logit)</span>
<span id="cb16-45"><a href="#cb16-45" tabindex="-1"></a></span>
<span id="cb16-46"><a href="#cb16-46" tabindex="-1"></a>    <span class="co"># Compute final output</span></span>
<span id="cb16-47"><a href="#cb16-47" tabindex="-1"></a>    logits <span class="op">=</span> keras.layers.Concatenate(axis<span class="op">=-</span><span class="dv">1</span>)(logits)</span>
<span id="cb16-48"><a href="#cb16-48" tabindex="-1"></a>    outputs <span class="op">=</span> keras.layers.Softmax(axis<span class="op">=-</span><span class="dv">1</span>)(logits)</span>
<span id="cb16-49"><a href="#cb16-49" tabindex="-1"></a>    model <span class="op">=</span> keras.Model(inputs, outputs)</span>
<span id="cb16-50"><a href="#cb16-50" tabindex="-1"></a></span>
<span id="cb16-51"><a href="#cb16-51" tabindex="-1"></a>    <span class="co"># Compile the model with optimizer, loss, and metrics</span></span>
<span id="cb16-52"><a href="#cb16-52" tabindex="-1"></a>    model.<span class="bu">compile</span>(</span>
<span id="cb16-53"><a href="#cb16-53" tabindex="-1"></a>        optimizer<span class="op">=</span>keras.optimizers.AdamW(<span class="fl">5e-6</span>),</span>
<span id="cb16-54"><a href="#cb16-54" tabindex="-1"></a>        loss<span class="op">=</span>keras.losses.CategoricalCrossentropy(label_smoothing<span class="op">=</span><span class="fl">0.02</span>),</span>
<span id="cb16-55"><a href="#cb16-55" tabindex="-1"></a>        metrics<span class="op">=</span>[</span>
<span id="cb16-56"><a href="#cb16-56" tabindex="-1"></a>            keras.metrics.CategoricalAccuracy(name<span class="op">=</span><span class="st">"accuracy"</span>),</span>
<span id="cb16-57"><a href="#cb16-57" tabindex="-1"></a>        ],</span>
<span id="cb16-58"><a href="#cb16-58" tabindex="-1"></a>        jit_compile<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb16-59"><a href="#cb16-59" tabindex="-1"></a>    )</span>
<span id="cb16-60"><a href="#cb16-60" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb16-61"><a href="#cb16-61" tabindex="-1"></a></span>
<span id="cb16-62"><a href="#cb16-62" tabindex="-1"></a></span>
<span id="cb16-63"><a href="#cb16-63" tabindex="-1"></a><span class="co"># Build the Build</span></span>
<span id="cb16-64"><a href="#cb16-64" tabindex="-1"></a>model <span class="op">=</span> build_model()</span></code></pre></div>
<p>Let’s checkout the model summary to have a better insight on the
model.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a>model.summary()</span></code></pre></div>
<p>Finally, let’s check the model structure visually if everything is in
place.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a>keras.utils.plot_model(model, show_shapes<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
</div>
</main>
</div>
<div class="section level2">
<h2 id="training">Training<a class="anchor" aria-label="anchor" href="#training"></a>
</h2>
<div class="sourceCode" id="cb19"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a><span class="co"># Start training the model</span></span>
<span id="cb19-2"><a href="#cb19-2" tabindex="-1"></a>history <span class="op">=</span> model.fit(</span>
<span id="cb19-3"><a href="#cb19-3" tabindex="-1"></a>    train_ds,</span>
<span id="cb19-4"><a href="#cb19-4" tabindex="-1"></a>    epochs<span class="op">=</span>CFG.epochs,</span>
<span id="cb19-5"><a href="#cb19-5" tabindex="-1"></a>    validation_data<span class="op">=</span>valid_ds,</span>
<span id="cb19-6"><a href="#cb19-6" tabindex="-1"></a>    callbacks<span class="op">=</span>callbacks,</span>
<span id="cb19-7"><a href="#cb19-7" tabindex="-1"></a>    steps_per_epoch<span class="op">=</span><span class="bu">int</span>(<span class="bu">len</span>(train_df) <span class="op">/</span> CFG.batch_size),</span>
<span id="cb19-8"><a href="#cb19-8" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb19-9"><a href="#cb19-9" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="inference">Inference<a class="anchor" aria-label="anchor" href="#inference"></a>
</h2>
<div class="sourceCode" id="cb20"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a><span class="co"># Make predictions using the trained model on last validation data</span></span>
<span id="cb20-2"><a href="#cb20-2" tabindex="-1"></a>predictions <span class="op">=</span> model.predict(</span>
<span id="cb20-3"><a href="#cb20-3" tabindex="-1"></a>    valid_ds,</span>
<span id="cb20-4"><a href="#cb20-4" tabindex="-1"></a>    batch_size<span class="op">=</span>CFG.batch_size,  <span class="co"># max batch size = valid size</span></span>
<span id="cb20-5"><a href="#cb20-5" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb20-6"><a href="#cb20-6" tabindex="-1"></a>)</span>
<span id="cb20-7"><a href="#cb20-7" tabindex="-1"></a></span>
<span id="cb20-8"><a href="#cb20-8" tabindex="-1"></a><span class="co"># Format predictions and true answers</span></span>
<span id="cb20-9"><a href="#cb20-9" tabindex="-1"></a>pred_answers <span class="op">=</span> np.arange(<span class="dv">4</span>)[np.argsort(<span class="op">-</span>predictions)][:, <span class="dv">0</span>]</span>
<span id="cb20-10"><a href="#cb20-10" tabindex="-1"></a>true_answers <span class="op">=</span> valid_df.label.values</span>
<span id="cb20-11"><a href="#cb20-11" tabindex="-1"></a></span>
<span id="cb20-12"><a href="#cb20-12" tabindex="-1"></a><span class="co"># Check 5 Predictions</span></span>
<span id="cb20-13"><a href="#cb20-13" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"# Predictions</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb20-14"><a href="#cb20-14" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="dv">50</span>, <span class="dv">10</span>):</span>
<span id="cb20-15"><a href="#cb20-15" tabindex="-1"></a>    row <span class="op">=</span> valid_df.iloc[i]</span>
<span id="cb20-16"><a href="#cb20-16" tabindex="-1"></a>    question <span class="op">=</span> row.startphrase</span>
<span id="cb20-17"><a href="#cb20-17" tabindex="-1"></a>    pred_answer <span class="op">=</span> <span class="ss">f"ending</span><span class="sc">{</span>pred_answers[i]<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb20-18"><a href="#cb20-18" tabindex="-1"></a>    true_answer <span class="op">=</span> <span class="ss">f"ending</span><span class="sc">{</span>true_answers[i]<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb20-19"><a href="#cb20-19" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"❓ Sentence </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">:</span><span class="ch">\n</span><span class="sc">{</span>question<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb20-20"><a href="#cb20-20" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"✅ True Ending: </span><span class="sc">{</span>true_answer<span class="sc">}</span><span class="ch">\n</span><span class="ss">   &gt;&gt; </span><span class="sc">{</span>row[true_answer]<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb20-21"><a href="#cb20-21" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"🤖 Predicted Ending: </span><span class="sc">{</span>pred_answer<span class="sc">}</span><span class="ch">\n</span><span class="ss">   &gt;&gt; </span><span class="sc">{</span>row[pred_answer]<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb20-22"><a href="#cb20-22" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">90</span>, <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="reference">Reference<a class="anchor" aria-label="anchor" href="#reference"></a>
</h2>
<ul>
<li><a href="https://twitter.com/johnowhitaker/status/1689790373454041089?s=20" class="external-link">Multiple
Choice with HF</a></li>
<li><a href="https://keras.io/api/keras_nlp/" class="external-link">Keras NLP</a></li>
<li>
<a href="https://www.kaggle.com/code/awsaf49/birdclef23-pretraining-is-all-you-need-train" class="external-link">BirdCLEF23:
Pretraining is All you Need [Train]</a> [Train]](<a href="https://www.kaggle.com/code/awsaf49/birdclef23-pretraining-is-all-you-need-train" class="external-link uri">https://www.kaggle.com/code/awsaf49/birdclef23-pretraining-is-all-you-need-train</a>)</li>
<li><a href="https://www.kaggle.com/code/cdeotte/triple-stratified-kfold-with-tfrecords" class="external-link">Triple
Stratified KFold with TFRecords</a></li>
</ul>
</div>
  <aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Tomasz Kalinowski, JJ Allaire, François Chollet, Posit Software, PBC, Google.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</body>
</html>
