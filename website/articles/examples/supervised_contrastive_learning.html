<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Supervised Contrastive Learning â€¢ keras</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../../apple-touch-icon-60x60.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../../bootstrap-toc.css">
<script src="../../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../../pkgdown.css" rel="stylesheet">
<script src="../../pkgdown.js"></script><link href="../../extra.css" rel="stylesheet">
<script src="../../extra.js"></script><meta property="og:title" content="Supervised Contrastive Learning">
<meta property="og:description" content="Using supervised contrastive learning for image classification.">
<meta property="og:image" content="/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    

    <div class="container template-article">
      <header><div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../../index.html">keras</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">2.13.0.9000</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../../index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Tutorials
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/getting_started.html">Getting Started</a>
    </li>
    <li>
      <a href="../../articles/tutorial_basic_classification.html">Basic Classification</a>
    </li>
    <li>
      <a href="../../articles/tutorial_basic_text_classification.html">Text Classification</a>
    </li>
    <li>
      <a href="../../articles/tutorial_basic_regression.html">Basic Regression</a>
    </li>
    <li>
      <a href="../../articles/tutorial_overfit_underfit.html">Overfitting and Underfitting</a>
    </li>
    <li>
      <a href="../../articles/tutorial_save_and_restore.html">Save and Restore Models</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li class="dropdown-header">Guides (New for TF 2.6)</li>
    <li>
      <a href="../../articles/new-guides/python_subclasses.html">Python Subclasses</a>
    </li>
    <li>
      <a href="../../articles/new-guides/making_new_layers_and_models_via_subclassing.html">Making New Layers and Models via Subclassing</a>
    </li>
    <li>
      <a href="../../articles/new-guides/customizing_what_happens_in_fit.html">Customizing What Happens in Fit</a>
    </li>
    <li>
      <a href="../../articles/new-guides/writing_your_own_callbacks.html">Writing Your Own Callbacks</a>
    </li>
    <li>
      <a href="../../articles/new-guides/preprocessing_layers.html">Working with Preprocessing Layers</a>
    </li>
    <li>
      <a href="../../argicles/new-guides/working_with_rnns.html">Working with RNNs</a>
    </li>
    <li class="divider">
    </li>
<li class="dropdown-header">Using Keras</li>
    <li>
      <a href="../../articles/guide_keras.html">Guide to Keras Basics</a>
    </li>
    <li>
      <a href="../../articles/sequential_model.html">Sequential Model in Depth</a>
    </li>
    <li>
      <a href="../../articles/functional_api.html">Functional API in Depth</a>
    </li>
    <li>
      <a href="../../articles/about_keras_models.html">About Keras Models</a>
    </li>
    <li>
      <a href="../../articles/about_keras_layers.html">About Keras Layers</a>
    </li>
    <li>
      <a href="../../articles/training_visualization.html">Training Visualization</a>
    </li>
    <li>
      <a href="../../articles/applications.html">Pre-Trained Models</a>
    </li>
    <li>
      <a href="../../articles/faq.html">Frequently Asked Questions</a>
    </li>
    <li>
      <a href="../../articles/why_use_keras.html">Why Use Keras?</a>
    </li>
    <li class="divider">
    </li>
<li class="dropdown-header">Advanced</li>
    <li>
      <a href="../../articles/eager_guide.html">Eager Execution</a>
    </li>
    <li>
      <a href="../../articles/training_callbacks.html">Training Callbacks</a>
    </li>
    <li>
      <a href="../../articles/backend.html">Keras Backend</a>
    </li>
    <li>
      <a href="../../articles/custom_layers.html">Custom Layers</a>
    </li>
    <li>
      <a href="../../articles/custom_models.html">Custom Models</a>
    </li>
    <li>
      <a href="../../articles/saving_serializing.html">Saving and serializing</a>
    </li>
  </ul>
</li>
<li>
  <a href="../../articles/learn.html">Learn</a>
</li>
<li>
  <a href="../../articles/tools.html">Tools</a>
</li>
<li>
  <a href="../../articles/examples/index.html">Examples</a>
</li>
<li>
  <a href="../../reference/index.html">Reference</a>
</li>
<li>
  <a href="../../news/index.html">News</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/rstudio/keras/" class="external-link">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Supervised Contrastive Learning</h1>
                        <h4 data-toc-skip class="author"><a href="https://www.linkedin.com/in/khalid-salama-24403144/" class="external-link">Khalid
Salama</a></h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/rstudio/keras/blob/HEAD/vignettes/examples/supervised_contrastive_learning.Rmd" class="external-link"><code>vignettes/examples/supervised_contrastive_learning.Rmd</code></a></small>
      <div class="hidden name"><code>supervised_contrastive_learning.Rmd</code></div>

    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p><a href="https://arxiv.org/abs/2004.11362" class="external-link">Supervised Contrastive
Learning</a> (Prannay Khosla et al.) is a training methodology that
outperforms supervised training with crossentropy on classification
tasks.</p>
<p>Essentially, training an image classification model with Supervised
Contrastive Learning is performed in two phases:</p>
<ol style="list-style-type: decimal">
<li>Training an encoder to learn to produce vector representations of
input images such that representations of images in the same class will
be more similar compared to representations of images in different
classes.</li>
<li>Training a classifier on top of the frozen encoder.</li>
</ol>
</div>
<div class="section level2">
<h2 id="setup">Setup<a class="anchor" aria-label="anchor" href="#setup"></a>
</h2>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> keras</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">from</span> keras <span class="im">import</span> ops</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">from</span> keras <span class="im">import</span> layers</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">from</span> keras.applications.resnet_v2 <span class="im">import</span> ResNet50V2</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="prepare-the-data">Prepare the data<a class="anchor" aria-label="anchor" href="#prepare-the-data"></a>
</h2>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>num_classes <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>input_shape <span class="op">=</span> (<span class="dv">32</span>, <span class="dv">32</span>, <span class="dv">3</span>)</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a><span class="co"># Load the train and test data splits</span></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>(x_train, y_train), (x_test, y_test) <span class="op">=</span> keras.datasets.cifar10.load_data()</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a><span class="co"># Display shapes of train and test datasets</span></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"x_train shape: </span><span class="sc">{</span>x_train<span class="sc">.</span>shape<span class="sc">}</span><span class="ss"> - y_train shape: </span><span class="sc">{</span>y_train<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"x_test shape: </span><span class="sc">{</span>x_test<span class="sc">.</span>shape<span class="sc">}</span><span class="ss"> - y_test shape: </span><span class="sc">{</span>y_test<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="using-image-data-augmentation">Using image data augmentation<a class="anchor" aria-label="anchor" href="#using-image-data-augmentation"></a>
</h2>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>data_augmentation <span class="op">=</span> keras.Sequential(</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>    [</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>        layers.Normalization(),</span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>        layers.RandomFlip(<span class="st">"horizontal"</span>),</span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>        layers.RandomRotation(<span class="fl">0.02</span>),</span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a>    ]</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a>)</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a><span class="co"># Setting the state of the normalization layer.</span></span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a>data_augmentation.layers[<span class="dv">0</span>].adapt(x_train)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="build-the-encoder-model">Build the encoder model<a class="anchor" aria-label="anchor" href="#build-the-encoder-model"></a>
</h2>
<p>The encoder model takes the image as input and turns it into a
2048-dimensional feature vector.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="kw">def</span> create_encoder():</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>    resnet <span class="op">=</span> ResNet50V2(</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>        include_top<span class="op">=</span><span class="va">False</span>, weights<span class="op">=</span><span class="va">None</span>, input_shape<span class="op">=</span>input_shape, pooling<span class="op">=</span><span class="st">"avg"</span></span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>    )</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a>    inputs <span class="op">=</span> keras.Input(shape<span class="op">=</span>input_shape)</span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>    augmented <span class="op">=</span> data_augmentation(inputs)</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a>    outputs <span class="op">=</span> resnet(augmented)</span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a>    model <span class="op">=</span> keras.Model(inputs<span class="op">=</span>inputs, outputs<span class="op">=</span>outputs, name<span class="op">=</span><span class="st">"cifar10-encoder"</span>)</span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a>    <span class="cf">return</span> model</span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a>encoder <span class="op">=</span> create_encoder()</span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a>encoder.summary()</span>
<span id="cb4-15"><a href="#cb4-15" tabindex="-1"></a></span>
<span id="cb4-16"><a href="#cb4-16" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.001</span></span>
<span id="cb4-17"><a href="#cb4-17" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">265</span></span>
<span id="cb4-18"><a href="#cb4-18" tabindex="-1"></a>hidden_units <span class="op">=</span> <span class="dv">512</span></span>
<span id="cb4-19"><a href="#cb4-19" tabindex="-1"></a>projection_units <span class="op">=</span> <span class="dv">128</span></span>
<span id="cb4-20"><a href="#cb4-20" tabindex="-1"></a>num_epochs <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb4-21"><a href="#cb4-21" tabindex="-1"></a>dropout_rate <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb4-22"><a href="#cb4-22" tabindex="-1"></a>temperature <span class="op">=</span> <span class="fl">0.05</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="build-the-classification-model">Build the classification model<a class="anchor" aria-label="anchor" href="#build-the-classification-model"></a>
</h2>
<p>The classification model adds a fully-connected layer on top of the
encoder, plus a softmax layer with the target classes.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="kw">def</span> create_classifier(encoder, trainable<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>    <span class="cf">for</span> layer <span class="kw">in</span> encoder.layers:</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>        layer.trainable <span class="op">=</span> trainable</span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>    inputs <span class="op">=</span> keras.Input(shape<span class="op">=</span>input_shape)</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>    features <span class="op">=</span> encoder(inputs)</span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a>    features <span class="op">=</span> layers.Dropout(dropout_rate)(features)</span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a>    features <span class="op">=</span> layers.Dense(hidden_units, activation<span class="op">=</span><span class="st">"relu"</span>)(features)</span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a>    features <span class="op">=</span> layers.Dropout(dropout_rate)(features)</span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a>    outputs <span class="op">=</span> layers.Dense(num_classes, activation<span class="op">=</span><span class="st">"softmax"</span>)(features)</span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a></span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a>    model <span class="op">=</span> keras.Model(inputs<span class="op">=</span>inputs, outputs<span class="op">=</span>outputs, name<span class="op">=</span><span class="st">"cifar10-classifier"</span>)</span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a>    model.<span class="bu">compile</span>(</span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a>        optimizer<span class="op">=</span>keras.optimizers.Adam(learning_rate),</span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a>        loss<span class="op">=</span>keras.losses.SparseCategoricalCrossentropy(),</span>
<span id="cb5-16"><a href="#cb5-16" tabindex="-1"></a>        metrics<span class="op">=</span>[keras.metrics.SparseCategoricalAccuracy()],</span>
<span id="cb5-17"><a href="#cb5-17" tabindex="-1"></a>    )</span>
<span id="cb5-18"><a href="#cb5-18" tabindex="-1"></a>    <span class="cf">return</span> model</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="define-npairs-loss-function">Define npairs loss function<a class="anchor" aria-label="anchor" href="#define-npairs-loss-function"></a>
</h2>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="kw">def</span> npairs_loss(y_true, y_pred):</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a>    <span class="co">"""Computes the npairs loss between `y_true` and `y_pred`.</span></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a><span class="co">    Npairs loss expects paired data where a pair is composed of samples from</span></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a><span class="co">    the same labels and each pairs in the minibatch have different labels.</span></span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a><span class="co">    The loss takes each row of the pair-wise similarity matrix, `y_pred`,</span></span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a><span class="co">    as logits and the remapped multi-class labels, `y_true`, as labels.</span></span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a><span class="co">    See:</span></span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a><span class="co">    http://www.nec-labs.com/uploads/images/Department-Images/MediaAnalytics/papers/nips16_npairmetriclearning.pdf</span></span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb6-14"><a href="#cb6-14" tabindex="-1"></a><span class="co">      y_true: Ground truth values, of shape `[batch_size]` of multi-class</span></span>
<span id="cb6-15"><a href="#cb6-15" tabindex="-1"></a><span class="co">        labels.</span></span>
<span id="cb6-16"><a href="#cb6-16" tabindex="-1"></a><span class="co">      y_pred: Predicted values of shape `[batch_size, batch_size]` of</span></span>
<span id="cb6-17"><a href="#cb6-17" tabindex="-1"></a><span class="co">        similarity matrix between embedding matrices.</span></span>
<span id="cb6-18"><a href="#cb6-18" tabindex="-1"></a></span>
<span id="cb6-19"><a href="#cb6-19" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb6-20"><a href="#cb6-20" tabindex="-1"></a><span class="co">      npairs_loss: float scalar.</span></span>
<span id="cb6-21"><a href="#cb6-21" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-22"><a href="#cb6-22" tabindex="-1"></a>    y_pred <span class="op">=</span> ops.cast(y_pred, <span class="st">"float32"</span>)</span>
<span id="cb6-23"><a href="#cb6-23" tabindex="-1"></a>    y_true <span class="op">=</span> ops.cast(y_true, y_pred.dtype)</span>
<span id="cb6-24"><a href="#cb6-24" tabindex="-1"></a>    y_true <span class="op">=</span> ops.cast(ops.equal(y_true, ops.transpose(y_true)), y_pred.dtype)</span>
<span id="cb6-25"><a href="#cb6-25" tabindex="-1"></a>    y_true <span class="op">/=</span> ops.<span class="bu">sum</span>(y_true, <span class="dv">1</span>, keepdims<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-26"><a href="#cb6-26" tabindex="-1"></a>    loss <span class="op">=</span> ops.categorical_crossentropy(y_true, y_pred, from_logits<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-27"><a href="#cb6-27" tabindex="-1"></a></span>
<span id="cb6-28"><a href="#cb6-28" tabindex="-1"></a>    <span class="cf">return</span> ops.mean(loss)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="experiment-1-train-the-baseline-classification-model">Experiment 1: Train the baseline classification model<a class="anchor" aria-label="anchor" href="#experiment-1-train-the-baseline-classification-model"></a>
</h2>
<p>In this experiment, a baseline classifier is trained as usual, i.e.,
the encoder and the classifier parts are trained together as a single
model to minimize the crossentropy loss.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>encoder <span class="op">=</span> create_encoder()</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>classifier <span class="op">=</span> create_classifier(encoder)</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>classifier.summary()</span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>history <span class="op">=</span> classifier.fit(x<span class="op">=</span>x_train, y<span class="op">=</span>y_train, batch_size<span class="op">=</span>batch_size, epochs<span class="op">=</span>num_epochs)</span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a>accuracy <span class="op">=</span> classifier.evaluate(x_test, y_test)[<span class="dv">1</span>]</span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Test accuracy: </span><span class="sc">{</span><span class="bu">round</span>(accuracy <span class="op">*</span> <span class="dv">100</span>, <span class="dv">2</span>)<span class="sc">}</span><span class="ss">%"</span>)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="experiment-2-use-supervised-contrastive-learning">Experiment 2: Use supervised contrastive learning<a class="anchor" aria-label="anchor" href="#experiment-2-use-supervised-contrastive-learning"></a>
</h2>
<p>In this experiment, the model is trained in two phases. In the first
phase, the encoder is pretrained to optimize the supervised contrastive
loss, described in <a href="https://arxiv.org/abs/2004.11362" class="external-link">Prannay
Khosla et al.</a>.</p>
<p>In the second phase, the classifier is trained using the trained
encoder with its weights freezed; only the weights of fully-connected
layers with the softmax are optimized.</p>
<div class="section level3">
<h3 id="supervised-contrastive-learning-loss-function">1. Supervised contrastive learning loss function<a class="anchor" aria-label="anchor" href="#supervised-contrastive-learning-loss-function"></a>
</h3>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a><span class="kw">class</span> SupervisedContrastiveLoss(keras.losses.Loss):</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, temperature<span class="op">=</span><span class="dv">1</span>, name<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(name<span class="op">=</span>name)</span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>        <span class="va">self</span>.temperature <span class="op">=</span> temperature</span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, labels, feature_vectors, sample_weight<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a>        <span class="co"># Normalize feature vectors</span></span>
<span id="cb8-8"><a href="#cb8-8" tabindex="-1"></a>        feature_vectors_normalized <span class="op">=</span> keras.utils.normalize(feature_vectors, axis<span class="op">=</span><span class="dv">1</span>, order<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb8-9"><a href="#cb8-9" tabindex="-1"></a>        <span class="co"># Compute logits</span></span>
<span id="cb8-10"><a href="#cb8-10" tabindex="-1"></a>        logits <span class="op">=</span> ops.divide(</span>
<span id="cb8-11"><a href="#cb8-11" tabindex="-1"></a>            ops.matmul(</span>
<span id="cb8-12"><a href="#cb8-12" tabindex="-1"></a>                feature_vectors_normalized, ops.transpose(feature_vectors_normalized)</span>
<span id="cb8-13"><a href="#cb8-13" tabindex="-1"></a>            ),</span>
<span id="cb8-14"><a href="#cb8-14" tabindex="-1"></a>            <span class="va">self</span>.temperature,</span>
<span id="cb8-15"><a href="#cb8-15" tabindex="-1"></a>        )</span>
<span id="cb8-16"><a href="#cb8-16" tabindex="-1"></a>        <span class="cf">return</span> npairs_loss(ops.squeeze(labels), logits)</span>
<span id="cb8-17"><a href="#cb8-17" tabindex="-1"></a></span>
<span id="cb8-18"><a href="#cb8-18" tabindex="-1"></a></span>
<span id="cb8-19"><a href="#cb8-19" tabindex="-1"></a><span class="kw">def</span> add_projection_head(encoder):</span>
<span id="cb8-20"><a href="#cb8-20" tabindex="-1"></a>    inputs <span class="op">=</span> keras.Input(shape<span class="op">=</span>input_shape)</span>
<span id="cb8-21"><a href="#cb8-21" tabindex="-1"></a>    features <span class="op">=</span> encoder(inputs)</span>
<span id="cb8-22"><a href="#cb8-22" tabindex="-1"></a>    outputs <span class="op">=</span> layers.Dense(projection_units, activation<span class="op">=</span><span class="st">"relu"</span>)(features)</span>
<span id="cb8-23"><a href="#cb8-23" tabindex="-1"></a>    model <span class="op">=</span> keras.Model(</span>
<span id="cb8-24"><a href="#cb8-24" tabindex="-1"></a>        inputs<span class="op">=</span>inputs, outputs<span class="op">=</span>outputs, name<span class="op">=</span><span class="st">"cifar-encoder_with_projection-head"</span></span>
<span id="cb8-25"><a href="#cb8-25" tabindex="-1"></a>    )</span>
<span id="cb8-26"><a href="#cb8-26" tabindex="-1"></a>    <span class="cf">return</span> model</span></code></pre></div>
</div>
<div class="section level3">
<h3 id="pretrain-the-encoder">2. Pretrain the encoder<a class="anchor" aria-label="anchor" href="#pretrain-the-encoder"></a>
</h3>
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>encoder <span class="op">=</span> create_encoder()</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a>encoder_with_projection_head <span class="op">=</span> add_projection_head(encoder)</span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>encoder_with_projection_head.<span class="bu">compile</span>(</span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a>    optimizer<span class="op">=</span>keras.optimizers.Adam(learning_rate),</span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a>    loss<span class="op">=</span>SupervisedContrastiveLoss(temperature),</span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a>)</span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a></span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a>encoder_with_projection_head.summary()</span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a></span>
<span id="cb9-11"><a href="#cb9-11" tabindex="-1"></a>history <span class="op">=</span> encoder_with_projection_head.fit(</span>
<span id="cb9-12"><a href="#cb9-12" tabindex="-1"></a>    x<span class="op">=</span>x_train, y<span class="op">=</span>y_train, batch_size<span class="op">=</span>batch_size, epochs<span class="op">=</span>num_epochs</span>
<span id="cb9-13"><a href="#cb9-13" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div class="section level3">
<h3 id="train-the-classifier-with-the-frozen-encoder">3. Train the classifier with the frozen encoder<a class="anchor" aria-label="anchor" href="#train-the-classifier-with-the-frozen-encoder"></a>
</h3>
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a>classifier <span class="op">=</span> create_classifier(encoder, trainable<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a>history <span class="op">=</span> classifier.fit(x<span class="op">=</span>x_train, y<span class="op">=</span>y_train, batch_size<span class="op">=</span>batch_size, epochs<span class="op">=</span>num_epochs)</span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a>accuracy <span class="op">=</span> classifier.evaluate(x_test, y_test)[<span class="dv">1</span>]</span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Test accuracy: </span><span class="sc">{</span><span class="bu">round</span>(accuracy <span class="op">*</span> <span class="dv">100</span>, <span class="dv">2</span>)<span class="sc">}</span><span class="ss">%"</span>)</span></code></pre></div>
<p>We get to an improved test accuracy.</p>
</div>
</div>
<div class="section level2">
<h2 id="conclusion">Conclusion<a class="anchor" aria-label="anchor" href="#conclusion"></a>
</h2>
<p>As shown in the experiments, using the supervised contrastive
learning technique outperformed the conventional technique in terms of
the test accuracy. Note that the same training budget (i.e., number of
epochs) was given to each technique. Supervised contrastive learning
pays off when the encoder involves a complex architecture, like ResNet,
and multi-class problems with many labels. In addition, large batch
sizes and multi-layer projection heads improve its effectiveness. See
the <a href="https://arxiv.org/abs/2004.11362" class="external-link">Supervised Contrastive
Learning</a> paper for more details.</p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by Tomasz Kalinowski, JJ Allaire, FranÃ§ois Chollet, RStudio, Google.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

      </footer>
</div>

  


  

  </body>
</html>
