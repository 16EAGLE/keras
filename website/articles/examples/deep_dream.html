<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="Generating Deep Dreams with Keras.">
<title>Deep Dream • keras3</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../../apple-touch-icon-60x60.png">
<script src="../../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../../deps/JetBrains_Mono-0.4.7/font.css" rel="stylesheet">
<!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../../pkgdown.js"></script><meta property="og:title" content="Deep Dream">
<meta property="og:description" content="Generating Deep Dreams with Keras.">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-inverse navbar-expand-lg bg-primary"><div class="container">
    
    <a class="navbar-brand me-2" href="../../index.html">keras3</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">2.13.0.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../../index.html">Home</a>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-getting-started">Getting Started</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-getting-started">
    <a class="dropdown-item" href="../../articles/intro_to_keras_for_engineers.html">Introduction to Keras for engineers</a>
    <h6 class="dropdown-header" data-toc-skip>Tutorials</h6>
    <a class="dropdown-item" href="../../articles/getting_started.html">Getting Started</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_classification.html">Basic Classification</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_text_classification.html">Text Classification</a>
    <a class="dropdown-item" href="../../articles/tutorial_basic_regression.html">Basic Regression</a>
    <a class="dropdown-item" href="../../articles/tutorial_overfit_underfit.html">Overfitting and Underfitting</a>
    <a class="dropdown-item" href="../../articles/tutorial_save_and_restore.html">Save and Restore Models</a>
  </div>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-guides">Guides</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-guides">
    <h6 class="dropdown-header" data-toc-skip>Model definition</h6>
    <a class="dropdown-item" href="../../articles/functional_api.html">Functional API</a>
    <a class="dropdown-item" href="../../articles/sequential_model.html">Sequential Model</a>
    <h6 class="dropdown-header" data-toc-skip>Extending and customizing</h6>
    <a class="dropdown-item" href="../../articles/making_new_layers_and_models_via_subclassing.html">Making new layers and models via subclassing</a>
    <a class="dropdown-item" href="../../articles/training_with_built_in_methods.html">Training &amp; evaluation with the built-in methods</a>
    <a class="dropdown-item" href="../../articles/writing_a_custom_training_loop_in_tensorflow.html">Writing a training loop from scratch in TensorFlow</a>
    <a class="dropdown-item" href="../../articles/writing_your_own_callbacks.html">Writing Your Own Callbacks</a>
    <h6 class="dropdown-header" data-toc-skip>Other topics</h6>
    <a class="dropdown-item" href="../../articles/transfer_learning.html">Transfer learning and fine tuning</a>
    <a class="dropdown-item" href="../../articles/distributed_training_with_tensorflow.html">Distributed training with TensorFlow</a>
  </div>
</li>
<li class="active nav-item">
  <a class="nav-link" href="../../articles/examples/index.html">Examples</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../reference/index.html">Reference</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../news/index.html">News</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/rstudio/keras/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Deep Dream</h1>
                        <h4 data-toc-skip class="author"><a href="https://twitter.com/fchollet" class="external-link">fchollet</a></h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/rstudio/keras/blob/HEAD/vignettes/examples/deep_dream.Rmd" class="external-link"><code>vignettes/examples/deep_dream.Rmd</code></a></small>
      <div class="d-none name"><code>deep_dream.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>“Deep dream” is an image-filtering technique which consists of taking
an image classification model, and running gradient ascent over an input
image to try to maximize the activations of specific layers (and
sometimes, specific units in specific layers) for this input. It
produces hallucination-like visuals.</p>
<p>It was first introduced by Alexander Mordvintsev from Google in July
2015.</p>
<p>Process:</p>
<ul>
<li>Load the original image.</li>
<li>Define a number of processing scales (“octaves”), from smallest to
largest.</li>
<li>Resize the original image to the smallest scale.</li>
<li>For every scale, starting with the smallest (i.e. current one):
<ul>
<li>Run gradient ascent</li>
<li>Upscale image to the next scale</li>
<li>Reinject the detail that was lost at upscaling time</li>
</ul>
</li>
<li>Stop when we are back to the original size. To obtain the detail
lost during upscaling, we simply take the original image, shrink it
down, upscale it, and compare the result to the (resized) original
image.</li>
</ul>
</div>
<div class="section level2">
<h2 id="setup">Setup<a class="anchor" aria-label="anchor" href="#setup"></a>
</h2>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="im">import</span> keras <span class="im">as</span> keras</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="im">from</span> keras.applications <span class="im">import</span> inception_v3</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a>base_image_path <span class="op">=</span> keras.utils.get_file(</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a>    <span class="st">"sky.jpg"</span>, <span class="st">"https://i.imgur.com/aGBdQyK.jpg"</span></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a>)</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a>result_prefix <span class="op">=</span> <span class="st">"sky_dream"</span></span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="co"># These are the names of the layers</span></span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a><span class="co"># for which we try to maximize activation,</span></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a><span class="co"># as well as their weight in the final loss</span></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a><span class="co"># we try to maximize.</span></span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a><span class="co"># You can tweak these setting to obtain new visual effects.</span></span>
<span id="cb1-16"><a href="#cb1-16" tabindex="-1"></a>layer_settings <span class="op">=</span> {</span>
<span id="cb1-17"><a href="#cb1-17" tabindex="-1"></a>    <span class="st">"mixed4"</span>: <span class="fl">1.0</span>,</span>
<span id="cb1-18"><a href="#cb1-18" tabindex="-1"></a>    <span class="st">"mixed5"</span>: <span class="fl">1.5</span>,</span>
<span id="cb1-19"><a href="#cb1-19" tabindex="-1"></a>    <span class="st">"mixed6"</span>: <span class="fl">2.0</span>,</span>
<span id="cb1-20"><a href="#cb1-20" tabindex="-1"></a>    <span class="st">"mixed7"</span>: <span class="fl">2.5</span>,</span>
<span id="cb1-21"><a href="#cb1-21" tabindex="-1"></a>}</span>
<span id="cb1-22"><a href="#cb1-22" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" tabindex="-1"></a><span class="co"># Playing with these hyperparameters will also allow you to achieve new effects</span></span>
<span id="cb1-24"><a href="#cb1-24" tabindex="-1"></a>step <span class="op">=</span> <span class="fl">0.01</span>  <span class="co"># Gradient ascent step size</span></span>
<span id="cb1-25"><a href="#cb1-25" tabindex="-1"></a>num_octave <span class="op">=</span> <span class="dv">3</span>  <span class="co"># Number of scales at which to run gradient ascent</span></span>
<span id="cb1-26"><a href="#cb1-26" tabindex="-1"></a>octave_scale <span class="op">=</span> <span class="fl">1.4</span>  <span class="co"># Size ratio between scales</span></span>
<span id="cb1-27"><a href="#cb1-27" tabindex="-1"></a>iterations <span class="op">=</span> <span class="dv">20</span>  <span class="co"># Number of ascent steps per scale</span></span>
<span id="cb1-28"><a href="#cb1-28" tabindex="-1"></a>max_loss <span class="op">=</span> <span class="fl">15.0</span></span></code></pre></div>
<p>This is our base image:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> Image, display</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>display(Image(base_image_path))</span></code></pre></div>
<p>Let’s set up some image preprocessing/deprocessing utilities:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="kw">def</span> preprocess_image(image_path):</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>    <span class="co"># Util function to open, resize and format pictures</span></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>    <span class="co"># into appropriate arrays.</span></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a>    img <span class="op">=</span> keras.utils.load_img(image_path)</span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a>    img <span class="op">=</span> keras.utils.img_to_array(img)</span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a>    img <span class="op">=</span> np.expand_dims(img, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a>    img <span class="op">=</span> inception_v3.preprocess_input(img)</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>    <span class="cf">return</span> img</span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a><span class="kw">def</span> deprocess_image(x):</span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a>    <span class="co"># Util function to convert a NumPy array into a valid image.</span></span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a>    x <span class="op">=</span> x.reshape((x.shape[<span class="dv">1</span>], x.shape[<span class="dv">2</span>], <span class="dv">3</span>))</span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a>    <span class="co"># Undo inception v3 preprocessing</span></span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a>    x <span class="op">/=</span> <span class="fl">2.0</span></span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a>    x <span class="op">+=</span> <span class="fl">0.5</span></span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a>    x <span class="op">*=</span> <span class="fl">255.0</span></span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a>    <span class="co"># Convert to uint8 and clip to the valid range [0, 255]</span></span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a>    x <span class="op">=</span> np.clip(x, <span class="dv">0</span>, <span class="dv">255</span>).astype(<span class="st">"uint8"</span>)</span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a>    <span class="cf">return</span> x</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="compute-the-deep-dream-loss">Compute the Deep Dream loss<a class="anchor" aria-label="anchor" href="#compute-the-deep-dream-loss"></a>
</h2>
<p>First, build a feature extraction model to retrieve the activations
of our target layers given an input image.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="co"># Build an InceptionV3 model loaded with pre-trained ImageNet weights</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>model <span class="op">=</span> inception_v3.InceptionV3(weights<span class="op">=</span><span class="st">"imagenet"</span>, include_top<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a><span class="co"># Get the symbolic outputs of each "key" layer (we gave them unique names).</span></span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a>outputs_dict <span class="op">=</span> <span class="bu">dict</span>(</span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a>    [</span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>        (layer.name, layer.output)</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a>        <span class="cf">for</span> layer <span class="kw">in</span> [model.get_layer(name) <span class="cf">for</span> name <span class="kw">in</span> layer_settings.keys()]</span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a>    ]</span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a>)</span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a><span class="co"># Set up a model that returns the activation values for every target layer</span></span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a><span class="co"># (as a dict)</span></span>
<span id="cb4-14"><a href="#cb4-14" tabindex="-1"></a>feature_extractor <span class="op">=</span> keras.Model(inputs<span class="op">=</span>model.inputs, outputs<span class="op">=</span>outputs_dict)</span></code></pre></div>
<p>The actual loss computation is very simple:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="kw">def</span> compute_loss(input_image):</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>    features <span class="op">=</span> feature_extractor(input_image)</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>    <span class="co"># Initialize the loss</span></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>    loss <span class="op">=</span> tf.zeros(shape<span class="op">=</span>())</span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>    <span class="cf">for</span> name <span class="kw">in</span> features.keys():</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>        coeff <span class="op">=</span> layer_settings[name]</span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a>        activation <span class="op">=</span> features[name]</span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a>        <span class="co"># We avoid border artifacts by only involving non-border pixels in the loss.</span></span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a>        scaling <span class="op">=</span> tf.reduce_prod(tf.cast(tf.shape(activation), <span class="st">"float32"</span>))</span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a>        loss <span class="op">+=</span> (</span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a>            coeff</span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a>            <span class="op">*</span> tf.reduce_sum(tf.square(activation[:, <span class="dv">2</span>:<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>:<span class="op">-</span><span class="dv">2</span>, :]))</span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a>            <span class="op">/</span> scaling</span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a>        )</span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a>    <span class="cf">return</span> loss</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="set-up-the-gradient-ascent-loop-for-one-octave">Set up the gradient ascent loop for one octave<a class="anchor" aria-label="anchor" href="#set-up-the-gradient-ascent-loop-for-one-octave"></a>
</h2>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="at">@tf.function</span></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a><span class="kw">def</span> gradient_ascent_step(img, learning_rate):</span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a>    <span class="cf">with</span> tf.GradientTape() <span class="im">as</span> tape:</span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a>        tape.watch(img)</span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a>        loss <span class="op">=</span> compute_loss(img)</span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>    <span class="co"># Compute gradients.</span></span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a>    grads <span class="op">=</span> tape.gradient(loss, img)</span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a>    <span class="co"># Normalize gradients.</span></span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a>    grads <span class="op">/=</span> tf.maximum(tf.reduce_mean(tf.<span class="bu">abs</span>(grads)), <span class="fl">1e-6</span>)</span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a>    img <span class="op">+=</span> learning_rate <span class="op">*</span> grads</span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a>    <span class="cf">return</span> loss, img</span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" tabindex="-1"></a></span>
<span id="cb6-14"><a href="#cb6-14" tabindex="-1"></a><span class="kw">def</span> gradient_ascent_loop(img, iterations, learning_rate, max_loss<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb6-15"><a href="#cb6-15" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(iterations):</span>
<span id="cb6-16"><a href="#cb6-16" tabindex="-1"></a>        loss, img <span class="op">=</span> gradient_ascent_step(img, learning_rate)</span>
<span id="cb6-17"><a href="#cb6-17" tabindex="-1"></a>        <span class="cf">if</span> max_loss <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> loss <span class="op">&gt;</span> max_loss:</span>
<span id="cb6-18"><a href="#cb6-18" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb6-19"><a href="#cb6-19" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"... Loss value at step </span><span class="sc">%d</span><span class="st">: </span><span class="sc">%.2f</span><span class="st">"</span> <span class="op">%</span> (i, loss))</span>
<span id="cb6-20"><a href="#cb6-20" tabindex="-1"></a>    <span class="cf">return</span> img</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="run-the-training-loop-iterating-over-different-octaves">Run the training loop, iterating over different octaves<a class="anchor" aria-label="anchor" href="#run-the-training-loop-iterating-over-different-octaves"></a>
</h2>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>original_img <span class="op">=</span> preprocess_image(base_image_path)</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>original_shape <span class="op">=</span> original_img.shape[<span class="dv">1</span>:<span class="dv">3</span>]</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>successive_shapes <span class="op">=</span> [original_shape]</span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, num_octave):</span>
<span id="cb7-6"><a href="#cb7-6" tabindex="-1"></a>    shape <span class="op">=</span> <span class="bu">tuple</span>([<span class="bu">int</span>(dim <span class="op">/</span> (octave_scale<span class="op">**</span>i)) <span class="cf">for</span> dim <span class="kw">in</span> original_shape])</span>
<span id="cb7-7"><a href="#cb7-7" tabindex="-1"></a>    successive_shapes.append(shape)</span>
<span id="cb7-8"><a href="#cb7-8" tabindex="-1"></a>successive_shapes <span class="op">=</span> successive_shapes[::<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb7-9"><a href="#cb7-9" tabindex="-1"></a>shrunk_original_img <span class="op">=</span> tf.image.resize(original_img, successive_shapes[<span class="dv">0</span>])</span>
<span id="cb7-10"><a href="#cb7-10" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" tabindex="-1"></a>img <span class="op">=</span> tf.identity(original_img)  <span class="co"># Make a copy</span></span>
<span id="cb7-12"><a href="#cb7-12" tabindex="-1"></a><span class="cf">for</span> i, shape <span class="kw">in</span> <span class="bu">enumerate</span>(successive_shapes):</span>
<span id="cb7-13"><a href="#cb7-13" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Processing octave </span><span class="sc">%d</span><span class="st"> with shape </span><span class="sc">%s</span><span class="st">"</span> <span class="op">%</span> (i, shape))</span>
<span id="cb7-14"><a href="#cb7-14" tabindex="-1"></a>    img <span class="op">=</span> tf.image.resize(img, shape)</span>
<span id="cb7-15"><a href="#cb7-15" tabindex="-1"></a>    img <span class="op">=</span> gradient_ascent_loop(</span>
<span id="cb7-16"><a href="#cb7-16" tabindex="-1"></a>        img, iterations<span class="op">=</span>iterations, learning_rate<span class="op">=</span>step, max_loss<span class="op">=</span>max_loss</span>
<span id="cb7-17"><a href="#cb7-17" tabindex="-1"></a>    )</span>
<span id="cb7-18"><a href="#cb7-18" tabindex="-1"></a>    upscaled_shrunk_original_img <span class="op">=</span> tf.image.resize(shrunk_original_img, shape)</span>
<span id="cb7-19"><a href="#cb7-19" tabindex="-1"></a>    same_size_original <span class="op">=</span> tf.image.resize(original_img, shape)</span>
<span id="cb7-20"><a href="#cb7-20" tabindex="-1"></a>    lost_detail <span class="op">=</span> same_size_original <span class="op">-</span> upscaled_shrunk_original_img</span>
<span id="cb7-21"><a href="#cb7-21" tabindex="-1"></a></span>
<span id="cb7-22"><a href="#cb7-22" tabindex="-1"></a>    img <span class="op">+=</span> lost_detail</span>
<span id="cb7-23"><a href="#cb7-23" tabindex="-1"></a>    shrunk_original_img <span class="op">=</span> tf.image.resize(original_img, shape)</span>
<span id="cb7-24"><a href="#cb7-24" tabindex="-1"></a></span>
<span id="cb7-25"><a href="#cb7-25" tabindex="-1"></a>keras.utils.save_img(result_prefix <span class="op">+</span> <span class="st">".png"</span>, deprocess_image(img.numpy()))</span></code></pre></div>
<p>Display the result.</p>
<p>You can use the trained model hosted on <a href="https://huggingface.co/keras-io/deep-dream" class="external-link">Hugging Face Hub</a>
and try the demo on <a href="https://huggingface.co/spaces/keras-io/deep-dream" class="external-link">Hugging Face
Spaces</a>.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a>display(Image(result_prefix <span class="op">+</span> <span class="st">".png"</span>))</span></code></pre></div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Tomasz Kalinowski, JJ Allaire, François Chollet, Posit Software, PBC, Google.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
