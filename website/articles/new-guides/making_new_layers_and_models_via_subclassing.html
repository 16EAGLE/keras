<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Writing `Layer` and `Model` objects from scratch. • keras</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../../apple-touch-icon-60x60.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../../bootstrap-toc.css">
<script src="../../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../../pkgdown.css" rel="stylesheet">
<script src="../../pkgdown.js"></script><link href="../../extra.css" rel="stylesheet">
<script src="../../extra.js"></script><meta property="og:title" content="Writing `Layer` and `Model` objects from scratch.">
<meta property="og:description" content="Guide to writing `Layer` and `Model` objects from scratch.">
<meta property="og:image" content="/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    

    <div class="container template-article">
      <header><div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../../index.html">keras</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">2.8.0.9000</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../../index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Tutorials
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../../articles/getting_started.html">Getting Started</a>
    </li>
    <li>
      <a href="../../articles/tutorial_basic_classification.html">Basic Classification</a>
    </li>
    <li>
      <a href="../../articles/tutorial_basic_text_classification.html">Text Classification</a>
    </li>
    <li>
      <a href="../../articles/tutorial_basic_regression.html">Basic Regression</a>
    </li>
    <li>
      <a href="../../articles/tutorial_overfit_underfit.html">Overfitting and Underfitting</a>
    </li>
    <li>
      <a href="../../articles/tutorial_save_and_restore.html">Save and Restore Models</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li class="dropdown-header">Guides (New for TF 2.6)</li>
    <li>
      <a href="../../articles/new-guides/python_subclasses.html">Python Subclasses</a>
    </li>
    <li>
      <a href="../../articles/new-guides/making_new_layers_and_models_via_subclassing.html">Making New Layers and Models via Subclassing</a>
    </li>
    <li>
      <a href="../../articles/new-guides/customizing_what_happens_in_fit.html">Customizing What Happens in Fit</a>
    </li>
    <li>
      <a href="../../articles/new-guides/writing_your_own_callbacks.html">Writing Your Own Callbacks</a>
    </li>
    <li>
      <a href="../../articles/new-guides/preprocessing_layers.html">Working with Preprocessing Layers</a>
    </li>
    <li>
      <a href="../../argicles/new-guides/working_with_rnns.html">Working with RNNs</a>
    </li>
    <li class="divider">
    </li>
<li class="dropdown-header">Using Keras</li>
    <li>
      <a href="../../articles/guide_keras.html">Guide to Keras Basics</a>
    </li>
    <li>
      <a href="../../articles/sequential_model.html">Sequential Model in Depth</a>
    </li>
    <li>
      <a href="../../articles/functional_api.html">Functional API in Depth</a>
    </li>
    <li>
      <a href="../../articles/about_keras_models.html">About Keras Models</a>
    </li>
    <li>
      <a href="../../articles/about_keras_layers.html">About Keras Layers</a>
    </li>
    <li>
      <a href="../../articles/training_visualization.html">Training Visualization</a>
    </li>
    <li>
      <a href="../../articles/applications.html">Pre-Trained Models</a>
    </li>
    <li>
      <a href="../../articles/faq.html">Frequently Asked Questions</a>
    </li>
    <li>
      <a href="../../articles/why_use_keras.html">Why Use Keras?</a>
    </li>
    <li class="divider">
    </li>
<li class="dropdown-header">Advanced</li>
    <li>
      <a href="../../articles/eager_guide.html">Eager Execution</a>
    </li>
    <li>
      <a href="../../articles/training_callbacks.html">Training Callbacks</a>
    </li>
    <li>
      <a href="../../articles/backend.html">Keras Backend</a>
    </li>
    <li>
      <a href="../../articles/custom_layers.html">Custom Layers</a>
    </li>
    <li>
      <a href="../../articles/custom_models.html">Custom Models</a>
    </li>
    <li>
      <a href="../../articles/saving_serializing.html">Saving and serializing</a>
    </li>
  </ul>
</li>
<li>
  <a href="../../articles/learn.html">Learn</a>
</li>
<li>
  <a href="../../articles/tools.html">Tools</a>
</li>
<li>
  <a href="../../articles/examples/index.html">Examples</a>
</li>
<li>
  <a href="../../reference/index.html">Reference</a>
</li>
<li>
  <a href="../../news/index.html">News</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/rstudio/keras/" class="external-link">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Writing <code>Layer</code> and
<code>Model</code> objects from scratch.</h1>
                        <h4 data-toc-skip class="author">
<a href="https://twitter.com/fchollet" class="external-link">fchollet</a>, <a href="https://github.com/t-kalinowski" class="external-link">t-kalinowski</a>
</h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/rstudio/keras/blob/HEAD/vignettes/new-guides/making_new_layers_and_models_via_subclassing.Rmd" class="external-link"><code>vignettes/new-guides/making_new_layers_and_models_via_subclassing.Rmd</code></a></small>
      <div class="hidden name"><code>making_new_layers_and_models_via_subclassing.Rmd</code></div>

    </div>

    
    
<div class="section level2">
<h2 id="setup">Setup<a class="anchor" aria-label="anchor" href="#setup"></a>
</h2>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://magrittr.tidyverse.org" class="external-link">magrittr</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/rstudio/tensorflow" class="external-link">tensorflow</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/rstudio/tfdatasets" class="external-link">tfdatasets</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://keras.rstudio.com" class="external-link">keras</a></span><span class="op">)</span>

<span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/tf_config.html" class="external-link">tf_version</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="the-layer-class-a-combination-of-state-weights-and-some-computation">The <code>Layer</code> class: a combination of state (weights) and
some computation<a class="anchor" aria-label="anchor" href="#the-layer-class-a-combination-of-state-weights-and-some-computation"></a>
</h2>
<p>One of the central abstractions in Keras is the <code>Layer</code>
class. A layer encapsulates both a state (the layer’s “weights”) and a
transformation from inputs to outputs (a “call”, the layer’s forward
pass).</p>
<p>Here’s a densely-connected layer. It has a state: the variables
<code>w</code> and <code>b</code>.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">Linear</span><span class="op">(</span><span class="va">keras</span><span class="op">$</span><span class="va">layers</span><span class="op">$</span><span class="va">Layer</span><span class="op">)</span> <span class="op"><a href="../../reference/grapes-py_class-grapes.html">%py_class%</a></span> <span class="op">{</span>
  <span class="va">initialize</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">units</span> <span class="op">=</span> <span class="fl">32</span>, <span class="va">input_dim</span> <span class="op">=</span> <span class="fl">32</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span><span class="op">)</span>
    <span class="va">w_init</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="fu">random_normal_initializer</span><span class="op">(</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">w</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="fu">Variable</span><span class="op">(</span>
      initial_value <span class="op">=</span> <span class="fu">w_init</span><span class="op">(</span>
        shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html" class="external-link">shape</a></span><span class="op">(</span><span class="va">input_dim</span>, <span class="va">units</span><span class="op">)</span>,
        dtype <span class="op">=</span> <span class="st">"float32"</span>
      <span class="op">)</span>,
      trainable <span class="op">=</span> <span class="cn">TRUE</span>
    <span class="op">)</span>
    <span class="va">b_init</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="fu">zeros_initializer</span><span class="op">(</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">b</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="fu">Variable</span><span class="op">(</span>
      initial_value <span class="op">=</span> <span class="fu">b_init</span><span class="op">(</span>shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html" class="external-link">shape</a></span><span class="op">(</span><span class="va">units</span><span class="op">)</span>, dtype <span class="op">=</span> <span class="st">"float32"</span><span class="op">)</span>,
      trainable <span class="op">=</span> <span class="cn">TRUE</span>
    <span class="op">)</span>
  <span class="op">}</span>

  <span class="va">call</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">tf</span><span class="op">$</span><span class="fu">matmul</span><span class="op">(</span><span class="va">inputs</span>, <span class="va">self</span><span class="op">$</span><span class="va">w</span><span class="op">)</span> <span class="op">+</span> <span class="va">self</span><span class="op">$</span><span class="va">b</span>
  <span class="op">}</span>
<span class="op">}</span></code></pre></div>
<p>You would use a layer by calling it on some tensor input(s), much
like a regular function.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">x</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="fu">ones</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html" class="external-link">shape</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span>
<span class="va">linear_layer</span> <span class="op">&lt;-</span> <span class="fu">Linear</span><span class="op">(</span><span class="fl">4</span>, <span class="fl">2</span><span class="op">)</span>
<span class="va">y</span> <span class="op">&lt;-</span> <span class="fu">linear_layer</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span></code></pre></div>
<p><code>Linear</code> behaves similarly to a layer present in the
Python interface to keras (e.g., <code>keras$layers$Dense</code>).</p>
<p>However, one additional step is needed to make it behave like the
builtin layers present in the keras R package (e.g.,
<code><a href="../../reference/layer_dense.html">layer_dense()</a></code>).</p>
<p>Keras layers in R are designed to compose nicely with the pipe
operator (<code>%&gt;%</code>), so that the layer instance is
conveniently created on demand when an existing model or tensor is piped
in. In order to make a custom layer similarly compose nicely with the
pipe, you can call <code><a href="../../reference/create_layer_wrapper.html">create_layer_wrapper()</a></code> on the layer
class constructor.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">layer_linear</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/create_layer_wrapper.html">create_layer_wrapper</a></span><span class="op">(</span><span class="va">Linear</span><span class="op">)</span></code></pre></div>
<p>Now <code>layer_linear</code> is a layer constructor that composes
nicely with <code>%&gt;%</code>, just like the built-in layers:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/keras_model_sequential.html">keras_model_sequential</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="../../reference/pipe.html">%&gt;%</a></span>
  <span class="fu">layer_linear</span><span class="op">(</span><span class="fl">4</span>, <span class="fl">2</span><span class="op">)</span>

<span class="fu">model</span><span class="op">(</span><span class="fu"><a href="../../reference/k_ones.html">k_ones</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>

<span class="va">model</span></code></pre></div>
<p>Because the pattern above is so common, there is a convenience
function that combines the steps of subclassing
<code>keras$layers$Layer</code> and calling
<code>create_layer_wrapper</code> on the output: the <code>Layer</code>
function. The <code>layer_linear</code> defined below is identical to
the <code>layer_linear</code> defined above.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">layer_linear</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/Layer.html">Layer</a></span><span class="op">(</span>
  <span class="st">"Linear"</span>,
  initialize <span class="op">=</span>  <span class="kw">function</span><span class="op">(</span><span class="va">units</span> <span class="op">=</span> <span class="fl">32</span>, <span class="va">input_dim</span> <span class="op">=</span> <span class="fl">32</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span><span class="op">)</span>
    <span class="va">w_init</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="fu">random_normal_initializer</span><span class="op">(</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">w</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="fu">Variable</span><span class="op">(</span>initial_value <span class="op">=</span> <span class="fu">w_init</span><span class="op">(</span>shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html" class="external-link">shape</a></span><span class="op">(</span><span class="va">input_dim</span>, <span class="va">units</span><span class="op">)</span>,
                                                 dtype <span class="op">=</span> <span class="st">"float32"</span><span class="op">)</span>,
                          trainable <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
    <span class="va">b_init</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="fu">zeros_initializer</span><span class="op">(</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">b</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="fu">Variable</span><span class="op">(</span>initial_value <span class="op">=</span> <span class="fu">b_init</span><span class="op">(</span>shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html" class="external-link">shape</a></span><span class="op">(</span><span class="va">units</span><span class="op">)</span>,
                                                 dtype <span class="op">=</span> <span class="st">"float32"</span><span class="op">)</span>,
                          trainable <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
  <span class="op">}</span>,

  call <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">tf</span><span class="op">$</span><span class="fu">matmul</span><span class="op">(</span><span class="va">inputs</span>, <span class="va">self</span><span class="op">$</span><span class="va">w</span><span class="op">)</span> <span class="op">+</span> <span class="va">self</span><span class="op">$</span><span class="va">b</span>
  <span class="op">}</span>
<span class="op">)</span></code></pre></div>
<p>For the remainder of this vignette we’ll be using the
<code>%py_class%</code> constructor. However, in your own code feel free
to use <code>create_layer_wrapper</code> and/or <code>Layer</code> if
you prefer.</p>
<p>Note that the weights <code>w</code> and <code>b</code> are
automatically tracked by the layer upon being set as layer
attributes:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/stopifnot.html" class="external-link">stopifnot</a></span><span class="op">(</span><span class="fu"><a href="https://Rdatatable.gitlab.io/data.table/reference/all.equal.data.table.html" class="external-link">all.equal</a></span><span class="op">(</span>
  <span class="va">linear_layer</span><span class="op">$</span><span class="va">weights</span>,
  <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">linear_layer</span><span class="op">$</span><span class="va">w</span>, <span class="va">linear_layer</span><span class="op">$</span><span class="va">b</span><span class="op">)</span>
<span class="op">)</span><span class="op">)</span></code></pre></div>
<p>You also have access to a quicker shortcut for adding a weight to a
layer: the <code>add_weight()</code> method:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">Linear</span><span class="op">(</span><span class="va">keras</span><span class="op">$</span><span class="va">layers</span><span class="op">$</span><span class="va">Layer</span><span class="op">)</span> <span class="op"><a href="../../reference/grapes-py_class-grapes.html">%py_class%</a></span> <span class="op">{</span>
  <span class="va">initialize</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">units</span> <span class="op">=</span> <span class="fl">32</span>, <span class="va">input_dim</span> <span class="op">=</span> <span class="fl">32</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span><span class="op">)</span>
    <span class="va">w_init</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="fu">random_normal_initializer</span><span class="op">(</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">w</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">add_weight</span><span class="op">(</span>
      shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html" class="external-link">shape</a></span><span class="op">(</span><span class="va">input_dim</span>, <span class="va">units</span><span class="op">)</span>,
      initializer <span class="op">=</span> <span class="st">"random_normal"</span>,
      trainable <span class="op">=</span> <span class="cn">TRUE</span>
    <span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">b</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">add_weight</span><span class="op">(</span>
      shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html" class="external-link">shape</a></span><span class="op">(</span><span class="va">units</span><span class="op">)</span>,
      initializer <span class="op">=</span> <span class="st">"zeros"</span>,
      trainable <span class="op">=</span> <span class="cn">TRUE</span>
    <span class="op">)</span>
  <span class="op">}</span>

  <span class="va">call</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">tf</span><span class="op">$</span><span class="fu">matmul</span><span class="op">(</span><span class="va">inputs</span>, <span class="va">self</span><span class="op">$</span><span class="va">w</span><span class="op">)</span> <span class="op">+</span> <span class="va">self</span><span class="op">$</span><span class="va">b</span>
  <span class="op">}</span>
<span class="op">}</span>

<span class="va">x</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="fu">ones</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html" class="external-link">shape</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span>
<span class="va">linear_layer</span> <span class="op">&lt;-</span> <span class="fu">Linear</span><span class="op">(</span><span class="fl">4</span>, <span class="fl">2</span><span class="op">)</span>
<span class="va">y</span> <span class="op">&lt;-</span> <span class="fu">linear_layer</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="layers-can-have-non-trainable-weights">Layers can have non-trainable weights<a class="anchor" aria-label="anchor" href="#layers-can-have-non-trainable-weights"></a>
</h2>
<p>Besides trainable weights, you can add non-trainable weights to a
layer as well. Such weights are meant not to be taken into account
during backpropagation, when you are training the layer.</p>
<p>Here’s how to add and use a non-trainable weight:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">ComputeSum</span><span class="op">(</span><span class="va">keras</span><span class="op">$</span><span class="va">layers</span><span class="op">$</span><span class="va">Layer</span><span class="op">)</span> <span class="op"><a href="../../reference/grapes-py_class-grapes.html">%py_class%</a></span> <span class="op">{</span>
  <span class="va">initialize</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">input_dim</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">total</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="fu">Variable</span><span class="op">(</span>
      initial_value <span class="op">=</span> <span class="va">tf</span><span class="op">$</span><span class="fu">zeros</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html" class="external-link">shape</a></span><span class="op">(</span><span class="va">input_dim</span><span class="op">)</span><span class="op">)</span>,
      trainable <span class="op">=</span> <span class="cn">FALSE</span>
    <span class="op">)</span>
  <span class="op">}</span>

  <span class="va">call</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">self</span><span class="op">$</span><span class="va">total</span><span class="op">$</span><span class="fu">assign_add</span><span class="op">(</span><span class="va">tf</span><span class="op">$</span><span class="fu">reduce_sum</span><span class="op">(</span><span class="va">inputs</span>, axis <span class="op">=</span> <span class="fl">0L</span><span class="op">)</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">total</span>
  <span class="op">}</span>
<span class="op">}</span>

<span class="va">x</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="fu">ones</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html" class="external-link">shape</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span>
<span class="va">my_sum</span> <span class="op">&lt;-</span> <span class="fu">ComputeSum</span><span class="op">(</span><span class="fl">2</span><span class="op">)</span>
<span class="va">y</span> <span class="op">&lt;-</span> <span class="fu">my_sum</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span>
<span class="va">y</span> <span class="op">&lt;-</span> <span class="fu">my_sum</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p>It’s part of <code>layer$weights</code>, but it gets categorized as a
non-trainable weight:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"weights:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">my_sum</span><span class="op">$</span><span class="va">weights</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"non-trainable weights:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">my_sum</span><span class="op">$</span><span class="va">non_trainable_weights</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span>

<span class="co"># It's not included in the trainable weights:</span>
<span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"trainable_weights:"</span>, <span class="va">my_sum</span><span class="op">$</span><span class="va">trainable_weights</span>, <span class="st">"\n"</span><span class="op">)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="best-practice-deferring-weight-creation-until-the-shape-of-the-inputs-is-known">Best practice: deferring weight creation until the shape of the
inputs is known<a class="anchor" aria-label="anchor" href="#best-practice-deferring-weight-creation-until-the-shape-of-the-inputs-is-known"></a>
</h2>
<p>Our <code>Linear</code> layer above took an
<code>input_dim</code>argument that was used to compute the shape of the
weights <code>w</code> and <code>b</code> in
<code>initialize()</code>:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">Linear</span><span class="op">(</span><span class="va">keras</span><span class="op">$</span><span class="va">layers</span><span class="op">$</span><span class="va">Layer</span><span class="op">)</span> <span class="op"><a href="../../reference/grapes-py_class-grapes.html">%py_class%</a></span> <span class="op">{</span>
  <span class="va">initialize</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">units</span> <span class="op">=</span> <span class="fl">32</span>, <span class="va">input_dim</span> <span class="op">=</span> <span class="fl">32</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">w</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">add_weight</span><span class="op">(</span>
      shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html" class="external-link">shape</a></span><span class="op">(</span><span class="va">input_dim</span>, <span class="va">units</span><span class="op">)</span>,
      initializer <span class="op">=</span> <span class="st">"random_normal"</span>,
      trainable <span class="op">=</span> <span class="cn">TRUE</span>
    <span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">b</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">add_weight</span><span class="op">(</span>
      shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html" class="external-link">shape</a></span><span class="op">(</span><span class="va">units</span><span class="op">)</span>,
      initializer <span class="op">=</span> <span class="st">"zeros"</span>,
      trainable <span class="op">=</span> <span class="cn">TRUE</span>
    <span class="op">)</span>
  <span class="op">}</span>

  <span class="va">call</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">tf</span><span class="op">$</span><span class="fu">matmul</span><span class="op">(</span><span class="va">inputs</span>, <span class="va">self</span><span class="op">$</span><span class="va">w</span><span class="op">)</span> <span class="op">+</span> <span class="va">self</span><span class="op">$</span><span class="va">b</span>
  <span class="op">}</span>
<span class="op">}</span></code></pre></div>
<p>In many cases, you may not know in advance the size of your inputs,
and you would like to lazily create weights when that value becomes
known, some time after instantiating the layer.</p>
<p>In the Keras API, we recommend creating layer weights in the
<code>build(self, inputs_shape)</code> method of your layer. Like
this:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">Linear</span><span class="op">(</span><span class="va">keras</span><span class="op">$</span><span class="va">layers</span><span class="op">$</span><span class="va">Layer</span><span class="op">)</span> <span class="op"><a href="../../reference/grapes-py_class-grapes.html">%py_class%</a></span> <span class="op">{</span>
  <span class="va">initialize</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">units</span> <span class="op">=</span> <span class="fl">32</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">units</span> <span class="op">&lt;-</span> <span class="va">units</span>
  <span class="op">}</span>

  <span class="va">build</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">input_shape</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">self</span><span class="op">$</span><span class="va">w</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">add_weight</span><span class="op">(</span>
      shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html" class="external-link">shape</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">tail</a></span><span class="op">(</span><span class="va">input_shape</span>, <span class="fl">1</span><span class="op">)</span>, <span class="va">self</span><span class="op">$</span><span class="va">units</span><span class="op">)</span>,
      initializer <span class="op">=</span> <span class="st">"random_normal"</span>,
      trainable <span class="op">=</span> <span class="cn">TRUE</span>
    <span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">b</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">add_weight</span><span class="op">(</span>
      shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html" class="external-link">shape</a></span><span class="op">(</span><span class="va">self</span><span class="op">$</span><span class="va">units</span><span class="op">)</span>,
      initializer <span class="op">=</span> <span class="st">"random_normal"</span>,
      trainable <span class="op">=</span> <span class="cn">TRUE</span>
    <span class="op">)</span>
  <span class="op">}</span>

  <span class="va">call</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">tf</span><span class="op">$</span><span class="fu">matmul</span><span class="op">(</span><span class="va">inputs</span>, <span class="va">self</span><span class="op">$</span><span class="va">w</span><span class="op">)</span> <span class="op">+</span> <span class="va">self</span><span class="op">$</span><span class="va">b</span>
  <span class="op">}</span>
<span class="op">}</span></code></pre></div>
<p>The <code><a href="https://rdrr.io/r/utils/PkgUtils.html" class="external-link">build()</a></code> method of your layer will automatically run
the first time your layer instance is called. You now have a layer that
can handle an arbitrary number of input features:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># At instantiation, we don't know on what inputs this is going to get called</span>
<span class="va">linear_layer</span> <span class="op">&lt;-</span> <span class="fu">Linear</span><span class="op">(</span><span class="fl">32</span><span class="op">)</span>

<span class="co"># The layer's weights are created dynamically the first time the layer is called</span>
<span class="va">y</span> <span class="op">&lt;-</span> <span class="fu">linear_layer</span><span class="op">(</span><span class="va">x</span><span class="op">)</span></code></pre></div>
<p>Implementing <code><a href="https://rdrr.io/r/utils/PkgUtils.html" class="external-link">build()</a></code> separately as shown above nicely
separates creating weights only once from using weights in every call.
However, for some advanced custom layers, it can become impractical to
separate the state creation and computation. Layer implementers are
allowed to defer weight creation to the first <code><a href="https://rdrr.io/r/base/call.html" class="external-link">call()</a></code>, but
need to take care that later calls use the same weights. In addition,
since <code><a href="https://rdrr.io/r/base/call.html" class="external-link">call()</a></code> is likely to be executed for the first time
inside a <code><a href="https://rdrr.io/pkg/tensorflow/man/tf_function.html" class="external-link">tf_function()</a></code>, any variable creation that takes
place in <code><a href="https://rdrr.io/r/base/call.html" class="external-link">call()</a></code> should be wrapped in a
<code>tf$init_scope()</code>.</p>
</div>
<div class="section level2">
<h2 id="layers-are-recursively-composable">Layers are recursively composable<a class="anchor" aria-label="anchor" href="#layers-are-recursively-composable"></a>
</h2>
<p>If you assign a Layer instance as an attribute of another Layer, the
outer layer will start tracking the weights created by the inner
layer.</p>
<p>We recommend creating such sublayers in the <code>initialize()</code>
method and leave it to the first <code><a href="https://rdrr.io/r/base/call.html" class="external-link">call()</a></code> to trigger building
their weights.</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Let's assume we are reusing the Linear class</span>
<span class="co"># with a `build` method that we defined above.</span>
<span class="fu">MLPBlock</span><span class="op">(</span><span class="va">keras</span><span class="op">$</span><span class="va">layers</span><span class="op">$</span><span class="va">Layer</span><span class="op">)</span> <span class="op"><a href="../../reference/grapes-py_class-grapes.html">%py_class%</a></span> <span class="op">{</span>
  <span class="va">initialize</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">linear_1</span> <span class="op">&lt;-</span> <span class="fu">Linear</span><span class="op">(</span><span class="fl">32</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">linear_2</span> <span class="op">&lt;-</span> <span class="fu">Linear</span><span class="op">(</span><span class="fl">32</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">linear_3</span> <span class="op">&lt;-</span> <span class="fu">Linear</span><span class="op">(</span><span class="fl">1</span><span class="op">)</span>
  <span class="op">}</span>

  <span class="va">call</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">x</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">linear_1</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span>
    <span class="va">x</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="va">nn</span><span class="op">$</span><span class="fu">relu</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>
    <span class="va">x</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">linear_2</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>
    <span class="va">x</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="va">nn</span><span class="op">$</span><span class="fu">relu</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="fu">linear_3</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>
  <span class="op">}</span>
<span class="op">}</span>

<span class="va">mlp</span> <span class="op">&lt;-</span> <span class="fu">MLPBlock</span><span class="op">(</span><span class="op">)</span>
<span class="va">y</span> <span class="op">&lt;-</span> <span class="fu">mlp</span><span class="op">(</span><span class="va">tf</span><span class="op">$</span><span class="fu">ones</span><span class="op">(</span>shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html" class="external-link">shape</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">64</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="co"># The first call to the `mlp` will create the weights</span>
<span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"weights:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">mlp</span><span class="op">$</span><span class="va">weights</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"trainable weights:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">mlp</span><span class="op">$</span><span class="va">trainable_weights</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="the-add_loss-method">The <code>add_loss()</code> method<a class="anchor" aria-label="anchor" href="#the-add_loss-method"></a>
</h2>
<p>When writing the <code><a href="https://rdrr.io/r/base/call.html" class="external-link">call()</a></code> method of a layer, you can
create loss tensors that you will want to use later, when writing your
training loop. This is doable by calling
<code>self$add_loss(value)</code>:</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># A layer that creates an activity regularization loss</span>
<span class="fu">ActivityRegularizationLayer</span><span class="op">(</span><span class="va">keras</span><span class="op">$</span><span class="va">layers</span><span class="op">$</span><span class="va">Layer</span><span class="op">)</span> <span class="op"><a href="../../reference/grapes-py_class-grapes.html">%py_class%</a></span> <span class="op">{</span>
  <span class="va">initialize</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">rate</span> <span class="op">=</span> <span class="fl">1e-2</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">rate</span> <span class="op">&lt;-</span> <span class="va">rate</span>
  <span class="op">}</span>

  <span class="va">call</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">self</span><span class="op">$</span><span class="fu">add_loss</span><span class="op">(</span><span class="va">self</span><span class="op">$</span><span class="va">rate</span> <span class="op">*</span> <span class="va">tf</span><span class="op">$</span><span class="fu">reduce_sum</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span><span class="op">)</span>
    <span class="va">inputs</span>
  <span class="op">}</span>
<span class="op">}</span></code></pre></div>
<p>These losses (including those created by any inner layer) can be
retrieved via <code>layer$losses</code>. This property is reset at the
start of every <code><a href="https://rdrr.io/r/base/call.html" class="external-link">call()</a></code> to the top-level layer, so that
<code>layer$losses</code> always contains the loss values created during
the last forward pass.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">OuterLayer</span><span class="op">(</span><span class="va">keras</span><span class="op">$</span><span class="va">layers</span><span class="op">$</span><span class="va">Layer</span><span class="op">)</span> <span class="op"><a href="../../reference/grapes-py_class-grapes.html">%py_class%</a></span> <span class="op">{</span>
  <span class="va">initialize</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">activity_reg</span> <span class="op">&lt;-</span> <span class="fu">ActivityRegularizationLayer</span><span class="op">(</span><span class="fl">1e-2</span><span class="op">)</span>
  <span class="op">}</span>
  <span class="va">call</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">self</span><span class="op">$</span><span class="fu">activity_reg</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span>
  <span class="op">}</span>
<span class="op">}</span>

<span class="va">layer</span> <span class="op">&lt;-</span> <span class="fu">OuterLayer</span><span class="op">(</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/stopifnot.html" class="external-link">stopifnot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">layer</span><span class="op">$</span><span class="va">losses</span><span class="op">)</span> <span class="op">==</span> <span class="fl">0</span><span class="op">)</span> <span class="co"># No losses yet since the layer has never been called</span>

<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/layer.html" class="external-link">layer</a></span><span class="op">(</span><span class="va">tf</span><span class="op">$</span><span class="fu">zeros</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html" class="external-link">shape</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> |&gt; <span class="fu"><a href="https://rdrr.io/r/base/invisible.html" class="external-link">invisible</a></span><span class="op">(</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/stopifnot.html" class="external-link">stopifnot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">layer</span><span class="op">$</span><span class="va">losses</span><span class="op">)</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span> <span class="co"># We created one loss value</span>

<span class="co"># `layer$losses` gets reset at the start of each call()</span>
<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/layer.html" class="external-link">layer</a></span><span class="op">(</span><span class="va">tf</span><span class="op">$</span><span class="fu">zeros</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html" class="external-link">shape</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> |&gt; <span class="fu"><a href="https://rdrr.io/r/base/invisible.html" class="external-link">invisible</a></span><span class="op">(</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/stopifnot.html" class="external-link">stopifnot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">layer</span><span class="op">$</span><span class="va">losses</span><span class="op">)</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span> <span class="co"># This is the loss created during the call above</span></code></pre></div>
<p>In addition, the <code>loss</code> property also contains
regularization losses created for the weights of any inner layer:</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">OuterLayerWithKernelRegularizer</span><span class="op">(</span><span class="va">keras</span><span class="op">$</span><span class="va">layers</span><span class="op">$</span><span class="va">Layer</span><span class="op">)</span> <span class="op"><a href="../../reference/grapes-py_class-grapes.html">%py_class%</a></span> <span class="op">{</span>
  <span class="va">initialize</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">dense</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="fl">32</span>, kernel_regularizer <span class="op">=</span> <span class="fu"><a href="../../reference/regularizer_l1.html">regularizer_l2</a></span><span class="op">(</span><span class="fl">1e-3</span><span class="op">)</span><span class="op">)</span>
  <span class="op">}</span>
  <span class="va">call</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">self</span><span class="op">$</span><span class="fu">dense</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span>
  <span class="op">}</span>
<span class="op">}</span>

<span class="va">layer</span> <span class="op">&lt;-</span> <span class="fu">OuterLayerWithKernelRegularizer</span><span class="op">(</span><span class="op">)</span>
<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/layer.html" class="external-link">layer</a></span><span class="op">(</span><span class="va">tf</span><span class="op">$</span><span class="fu">zeros</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html" class="external-link">shape</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> |&gt; <span class="fu"><a href="https://rdrr.io/r/base/invisible.html" class="external-link">invisible</a></span><span class="op">(</span><span class="op">)</span>

<span class="co"># This is `1e-3 * sum(layer$dense$kernel ** 2)`,</span>
<span class="co"># created by the `kernel_regularizer` above.</span>
<span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">layer</span><span class="op">$</span><span class="va">losses</span><span class="op">)</span></code></pre></div>
<p>These losses are meant to be taken into account when writing training
loops, like this:</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Instantiate an optimizer.</span>
<span class="va">optimizer</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/optimizer_sgd.html">optimizer_sgd</a></span><span class="op">(</span>learning_rate <span class="op">=</span> <span class="fl">1e-3</span><span class="op">)</span>
<span class="va">loss_fn</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/loss-functions.html">loss_sparse_categorical_crossentropy</a></span><span class="op">(</span>from_logits <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>

<span class="co"># Iterate over the batches of a dataset.</span>
<span class="va">dataset_iterator</span> <span class="op">&lt;-</span> <span class="fu">reticulate</span><span class="fu">::</span><span class="fu"><a href="https://rstudio.github.io/reticulate/reference/iterate.html" class="external-link">as_iterator</a></span><span class="op">(</span><span class="va">train_dataset</span><span class="op">)</span>
<span class="kw">while</span><span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/NULL.html" class="external-link">is.null</a></span><span class="op">(</span><span class="va">batch</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rstudio.github.io/reticulate/reference/iterate.html" class="external-link">iter_next</a></span><span class="op">(</span><span class="va">dataset_iterator</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span>
  <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">x_batch_train</span>, <span class="va">y_batch_train</span><span class="op">)</span> <span class="op"><a href="../../reference/multi-assign.html">%&lt;-%</a></span> <span class="va">batch</span>
  <span class="fu"><a href="https://rdrr.io/r/base/with.html" class="external-link">with</a></span><span class="op">(</span><span class="va">tf</span><span class="op">$</span><span class="fu">GradientTape</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://rstudio.github.io/reticulate/reference/with-as-operator.html" class="external-link">%as%</a></span> <span class="va">tape</span>, <span class="op">{</span>
    <span class="va">logits</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/layer.html" class="external-link">layer</a></span><span class="op">(</span><span class="va">x_batch_train</span><span class="op">)</span> <span class="co"># Logits for this minibatch</span>
    <span class="co"># Loss value for this minibatch</span>
    <span class="va">loss_value</span> <span class="op">&lt;-</span> <span class="fu">loss_fn</span><span class="op">(</span><span class="va">y_batch_train</span>, <span class="va">logits</span><span class="op">)</span>
    <span class="co"># Add extra losses created during this forward pass:</span>
    <span class="va">loss_value</span> <span class="op">&lt;-</span> <span class="va">loss_value</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">model</span><span class="op">$</span><span class="va">losses</span><span class="op">)</span>
  <span class="op">}</span><span class="op">)</span>
  <span class="va">grads</span> <span class="op">&lt;-</span> <span class="va">tape</span><span class="op">$</span><span class="fu">gradient</span><span class="op">(</span><span class="va">loss_value</span>, <span class="va">model</span><span class="op">$</span><span class="va">trainable_weights</span><span class="op">)</span>
  <span class="va">optimizer</span><span class="op">$</span><span class="fu">apply_gradients</span><span class="op">(</span>
    <span class="fu">purrr</span><span class="fu">::</span><span class="fu"><a href="https://purrr.tidyverse.org/reference/transpose.html" class="external-link">transpose</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">grads</span>, <span class="va">model</span><span class="op">$</span><span class="va">trainable_weights</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
<span class="op">}</span></code></pre></div>
<p>For a detailed guide about writing training loops, see the <a href="/guides/writing_a_training_loop_from_scratch/">guide to writing a
training loop from scratch</a>.</p>
<p>These losses also work seamlessly with <code><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit()</a></code> (they get
automatically summed and added to the main loss, if any):</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">input</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/layer_input.html">layer_input</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html" class="external-link">shape</a></span><span class="op">(</span><span class="fl">3</span><span class="op">)</span><span class="op">)</span>
<span class="va">output</span> <span class="op">&lt;-</span> <span class="va">input</span> <span class="op"><a href="../../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="../../reference/layer_activity_regularization.html">layer_activity_regularization</a></span><span class="op">(</span><span class="op">)</span>
<span class="co"># output &lt;- ActivityRegularizationLayer()(input)</span>
<span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/keras_model.html">keras_model</a></span><span class="op">(</span><span class="va">input</span>, <span class="va">output</span><span class="op">)</span>

<span class="co"># If there is a loss passed in `compile`, the regularization</span>
<span class="co"># losses get added to it</span>
<span class="va">model</span> <span class="op"><a href="../../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html" class="external-link">compile</a></span><span class="op">(</span>optimizer <span class="op">=</span> <span class="st">"adam"</span>, loss <span class="op">=</span> <span class="st">"mse"</span><span class="op">)</span>
<span class="va">model</span> <span class="op"><a href="../../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span><span class="fu"><a href="../../reference/k_random_uniform.html">k_random_uniform</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span>,
  <span class="fu"><a href="../../reference/k_random_uniform.html">k_random_uniform</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span>,
  epochs <span class="op">=</span> <span class="fl">1</span>, verbose <span class="op">=</span> <span class="cn">FALSE</span>
<span class="op">)</span>

<span class="co"># It's also possible not to pass any loss in `compile`,</span>
<span class="co"># since the model already has a loss to minimize, via the `add_loss`</span>
<span class="co"># call during the forward pass!</span>
<span class="va">model</span> <span class="op"><a href="../../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html" class="external-link">compile</a></span><span class="op">(</span>optimizer <span class="op">=</span> <span class="st">"adam"</span><span class="op">)</span>
<span class="va">model</span> <span class="op"><a href="../../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span><span class="fu"><a href="../../reference/k_random_uniform.html">k_random_uniform</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span>,
  <span class="fu"><a href="../../reference/k_random_uniform.html">k_random_uniform</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span>,
  epochs <span class="op">=</span> <span class="fl">1</span>, verbose <span class="op">=</span> <span class="cn">FALSE</span>
<span class="op">)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="the-add_metric-method">The <code>add_metric()</code> method<a class="anchor" aria-label="anchor" href="#the-add_metric-method"></a>
</h2>
<p>Similarly to <code>add_loss()</code>, layers also have an
<code>add_metric()</code> method for tracking the moving average of a
quantity during training.</p>
<p>Consider the following layer: a “logistic endpoint” layer. It takes
as inputs predictions and targets, it computes a loss which it tracks
via <code>add_loss()</code>, and it computes an accuracy scalar, which
it tracks via <code>add_metric()</code>.</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">LogisticEndpoint</span><span class="op">(</span><span class="va">keras</span><span class="op">$</span><span class="va">layers</span><span class="op">$</span><span class="va">Layer</span><span class="op">)</span> <span class="op"><a href="../../reference/grapes-py_class-grapes.html">%py_class%</a></span> <span class="op">{</span>
  <span class="va">initialize</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">name</span> <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span>name <span class="op">=</span> <span class="va">name</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">loss_fn</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/loss-functions.html">loss_binary_crossentropy</a></span><span class="op">(</span>from_logits <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">accuracy_fn</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/metric_binary_accuracy.html">metric_binary_accuracy</a></span><span class="op">(</span><span class="op">)</span>
  <span class="op">}</span>

  <span class="va">call</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">targets</span>, <span class="va">logits</span>, <span class="va">sample_weights</span> <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span> <span class="op">{</span>
    <span class="co"># Compute the training-time loss value and add it</span>
    <span class="co"># to the layer using `self$add_loss()`.</span>
    <span class="va">loss</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">loss_fn</span><span class="op">(</span><span class="va">targets</span>, <span class="va">logits</span>, <span class="va">sample_weights</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="fu">add_loss</span><span class="op">(</span><span class="va">loss</span><span class="op">)</span>

    <span class="co"># Log accuracy as a metric and add it</span>
    <span class="co"># to the layer using `self.add_metric()`.</span>
    <span class="va">acc</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">accuracy_fn</span><span class="op">(</span><span class="va">targets</span>, <span class="va">logits</span>, <span class="va">sample_weights</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="fu">add_metric</span><span class="op">(</span><span class="va">acc</span>, name <span class="op">=</span> <span class="st">"accuracy"</span><span class="op">)</span>

    <span class="co"># Return the inference-time prediction tensor (for `.predict()`).</span>
    <span class="va">tf</span><span class="op">$</span><span class="va">nn</span><span class="op">$</span><span class="fu">softmax</span><span class="op">(</span><span class="va">logits</span><span class="op">)</span>
  <span class="op">}</span>
<span class="op">}</span></code></pre></div>
<p>Metrics tracked in this way are accessible via
<code>layer$metrics</code>:</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">layer</span> <span class="op">&lt;-</span> <span class="fu">LogisticEndpoint</span><span class="op">(</span><span class="op">)</span>

<span class="va">targets</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="fu">ones</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html" class="external-link">shape</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span>
<span class="va">logits</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="fu">ones</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html" class="external-link">shape</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span>
<span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/layer.html" class="external-link">layer</a></span><span class="op">(</span><span class="va">targets</span>, <span class="va">logits</span><span class="op">)</span>

<span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"layer$metrics: "</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">layer</span><span class="op">$</span><span class="va">metrics</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"current accuracy value:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="va">layer</span><span class="op">$</span><span class="va">metrics</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">$</span><span class="fu">result</span><span class="op">(</span><span class="op">)</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></code></pre></div>
<p>Just like for <code>add_loss()</code>, these metrics are tracked by
<code><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit()</a></code>:</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/layer_input.html">layer_input</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html" class="external-link">shape</a></span><span class="op">(</span><span class="fl">3</span><span class="op">)</span>, name <span class="op">=</span> <span class="st">"inputs"</span><span class="op">)</span>
<span class="va">targets</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/layer_input.html">layer_input</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html" class="external-link">shape</a></span><span class="op">(</span><span class="fl">10</span><span class="op">)</span>, name <span class="op">=</span> <span class="st">"targets"</span><span class="op">)</span>
<span class="va">logits</span> <span class="op">&lt;-</span> <span class="va">inputs</span> <span class="op"><a href="../../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="../../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span><span class="fl">10</span><span class="op">)</span>
<span class="va">predictions</span> <span class="op">&lt;-</span> <span class="fu">LogisticEndpoint</span><span class="op">(</span>name <span class="op">=</span> <span class="st">"predictions"</span><span class="op">)</span><span class="op">(</span><span class="va">logits</span>, <span class="va">targets</span><span class="op">)</span>

<span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/keras_model.html">keras_model</a></span><span class="op">(</span>inputs <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="va">targets</span><span class="op">)</span>, outputs <span class="op">=</span> <span class="va">predictions</span><span class="op">)</span>
<span class="va">model</span> <span class="op"><a href="../../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html" class="external-link">compile</a></span><span class="op">(</span>optimizer <span class="op">=</span> <span class="st">"adam"</span><span class="op">)</span>

<span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>
  inputs <span class="op">=</span> <span class="fu"><a href="../../reference/k_random_uniform.html">k_random_uniform</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span>,
  targets <span class="op">=</span> <span class="fu"><a href="../../reference/k_random_uniform.html">k_random_uniform</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">10</span><span class="op">)</span><span class="op">)</span>
<span class="op">)</span>

<span class="va">model</span> <span class="op"><a href="../../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span><span class="va">data</span>, epochs <span class="op">=</span> <span class="fl">1</span>, verbose <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="you-can-optionally-enable-serialization-on-your-layers">You can optionally enable serialization on your layers<a class="anchor" aria-label="anchor" href="#you-can-optionally-enable-serialization-on-your-layers"></a>
</h2>
<p>If you need your custom layers to be serializable as part of a <a href="/guides/functional_api/">Functional model</a>, you can optionally
implement a <code><a href="../../reference/get_config.html">get_config()</a></code> method:</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">Linear</span><span class="op">(</span><span class="va">keras</span><span class="op">$</span><span class="va">layers</span><span class="op">$</span><span class="va">Layer</span><span class="op">)</span> <span class="op"><a href="../../reference/grapes-py_class-grapes.html">%py_class%</a></span> <span class="op">{</span>
  <span class="va">initialize</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">units</span> <span class="op">=</span> <span class="fl">32</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">units</span> <span class="op">&lt;-</span> <span class="va">units</span>
  <span class="op">}</span>

  <span class="va">build</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">input_shape</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">self</span><span class="op">$</span><span class="va">w</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">add_weight</span><span class="op">(</span>
      shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html" class="external-link">shape</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">tail</a></span><span class="op">(</span><span class="va">input_shape</span>, <span class="fl">1</span><span class="op">)</span>, <span class="va">self</span><span class="op">$</span><span class="va">units</span><span class="op">)</span>,
      initializer <span class="op">=</span> <span class="st">"random_normal"</span>,
      trainable <span class="op">=</span> <span class="cn">TRUE</span>
    <span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">b</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">add_weight</span><span class="op">(</span>
      shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html" class="external-link">shape</a></span><span class="op">(</span><span class="va">self</span><span class="op">$</span><span class="va">units</span><span class="op">)</span>,
      initializer <span class="op">=</span> <span class="st">"random_normal"</span>,
      trainable <span class="op">=</span> <span class="cn">TRUE</span>
    <span class="op">)</span>
  <span class="op">}</span>

  <span class="va">call</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">tf</span><span class="op">$</span><span class="fu">matmul</span><span class="op">(</span><span class="va">inputs</span>, <span class="va">self</span><span class="op">$</span><span class="va">w</span><span class="op">)</span> <span class="op">+</span> <span class="va">self</span><span class="op">$</span><span class="va">b</span>
  <span class="op">}</span>

  <span class="va">get_config</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="op">)</span> <span class="op">{</span>
    <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>units <span class="op">=</span> <span class="va">self</span><span class="op">$</span><span class="va">units</span><span class="op">)</span>
  <span class="op">}</span>
<span class="op">}</span>


<span class="co"># Now you can recreate the layer from its config:</span>
<span class="va">layer</span> <span class="op">&lt;-</span> <span class="fu">Linear</span><span class="op">(</span><span class="fl">64</span><span class="op">)</span>
<span class="va">config</span> <span class="op">&lt;-</span> <span class="va">layer</span><span class="op">$</span><span class="fu">get_config</span><span class="op">(</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">config</span><span class="op">)</span>
<span class="va">new_layer</span> <span class="op">&lt;-</span> <span class="va">Linear</span><span class="op">$</span><span class="fu">from_config</span><span class="op">(</span><span class="va">config</span><span class="op">)</span></code></pre></div>
<p>Note that the <code>initialize()</code> method of the base
<code>Layer</code> class takes some additional named arguments, in
particular a <code>name</code> and a <code>dtype</code>. It’s good
practice to pass these arguments to the parent class in
<code>initialize()</code> and to include them in the layer config:</p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">Linear</span><span class="op">(</span><span class="va">keras</span><span class="op">$</span><span class="va">layers</span><span class="op">$</span><span class="va">Layer</span><span class="op">)</span> <span class="op"><a href="../../reference/grapes-py_class-grapes.html">%py_class%</a></span> <span class="op">{</span>
  <span class="va">initialize</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">units</span> <span class="op">=</span> <span class="fl">32</span>, <span class="va">...</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span><span class="va">...</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">units</span> <span class="op">&lt;-</span> <span class="va">units</span>
  <span class="op">}</span>

  <span class="va">build</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">input_shape</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">self</span><span class="op">$</span><span class="va">w</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">add_weight</span><span class="op">(</span>
      shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html" class="external-link">shape</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">tail</a></span><span class="op">(</span><span class="va">input_shape</span>, <span class="fl">1</span><span class="op">)</span>, <span class="va">self</span><span class="op">$</span><span class="va">units</span><span class="op">)</span>,
      initializer <span class="op">=</span> <span class="st">"random_normal"</span>,
      trainable <span class="op">=</span> <span class="cn">TRUE</span>
    <span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">b</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">add_weight</span><span class="op">(</span>
      shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/shape.html" class="external-link">shape</a></span><span class="op">(</span><span class="va">self</span><span class="op">$</span><span class="va">units</span><span class="op">)</span>,
      initializer <span class="op">=</span> <span class="st">"random_normal"</span>,
      trainable <span class="op">=</span> <span class="cn">TRUE</span>
    <span class="op">)</span>
  <span class="op">}</span>

  <span class="va">call</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">tf</span><span class="op">$</span><span class="fu">matmul</span><span class="op">(</span><span class="va">inputs</span>, <span class="va">self</span><span class="op">$</span><span class="va">w</span><span class="op">)</span> <span class="op">+</span> <span class="va">self</span><span class="op">$</span><span class="va">b</span>
  <span class="op">}</span>

  <span class="va">get_config</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">config</span> <span class="op">&lt;-</span> <span class="va">super</span><span class="op">$</span><span class="fu">get_config</span><span class="op">(</span><span class="op">)</span>
    <span class="va">config</span><span class="op">$</span><span class="va">units</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="va">units</span>
    <span class="va">config</span>
  <span class="op">}</span>
<span class="op">}</span>


<span class="va">layer</span> <span class="op">&lt;-</span> <span class="fu">Linear</span><span class="op">(</span><span class="fl">64</span><span class="op">)</span>
<span class="va">config</span> <span class="op">&lt;-</span> <span class="va">layer</span><span class="op">$</span><span class="fu">get_config</span><span class="op">(</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">config</span><span class="op">)</span>
<span class="va">new_layer</span> <span class="op">&lt;-</span> <span class="va">Linear</span><span class="op">$</span><span class="fu">from_config</span><span class="op">(</span><span class="va">config</span><span class="op">)</span></code></pre></div>
<p>If you need more flexibility when deserializing the layer from its
config, you can also override the <code><a href="../../reference/get_config.html">from_config()</a></code> class
method. This is the base implementation of
<code><a href="../../reference/get_config.html">from_config()</a></code>:</p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">from_config</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">cls</span>, <span class="va">config</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/do.call.html" class="external-link">do.call</a></span><span class="op">(</span><span class="va">cls</span>, <span class="va">config</span><span class="op">)</span></code></pre></div>
<p>To learn more about serialization and saving, see the complete <a href="/guides/serialization_and_saving/">guide to saving and serializing
models</a>.</p>
</div>
<div class="section level2">
<h2 id="privileged-training-argument-in-the-call-method">Privileged <code>training</code> argument in the <code>call()</code>
method<a class="anchor" aria-label="anchor" href="#privileged-training-argument-in-the-call-method"></a>
</h2>
<p>Some layers, in particular the <code>BatchNormalization</code> layer
and the <code>Dropout</code> layer, have different behaviors during
training and inference. For such layers, it is standard practice to
expose a <code>training</code> (boolean) argument in the
<code><a href="https://rdrr.io/r/base/call.html" class="external-link">call()</a></code> method.</p>
<p>By exposing this argument in <code><a href="https://rdrr.io/r/base/call.html" class="external-link">call()</a></code>, you enable the
built-in training and evaluation loops (e.g. <code><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit()</a></code>) to
correctly use the layer in training and inference. Note, the default of
<code>NULL</code> means that the training parameter will be inferred by
keras from the training context (e.g., it will be <code>TRUE</code> if
called from <code><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit()</a></code>, <code>FALSE</code> if called from
<code><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict()</a></code>)</p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">CustomDropout</span><span class="op">(</span><span class="va">keras</span><span class="op">$</span><span class="va">layers</span><span class="op">$</span><span class="va">Layer</span><span class="op">)</span> <span class="op"><a href="../../reference/grapes-py_class-grapes.html">%py_class%</a></span> <span class="op">{</span>
  <span class="va">initialize</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">rate</span>, <span class="va">...</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span><span class="va">...</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">rate</span> <span class="op">&lt;-</span> <span class="va">rate</span>
  <span class="op">}</span>
  <span class="va">call</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span>, <span class="va">training</span> <span class="op">=</span> <span class="cn">NULL</span><span class="op">)</span> <span class="op">{</span>
    <span class="kw">if</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Logic.html" class="external-link">isTRUE</a></span><span class="op">(</span><span class="va">training</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span>
      <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="va">tf</span><span class="op">$</span><span class="va">nn</span><span class="op">$</span><span class="fu">dropout</span><span class="op">(</span><span class="va">inputs</span>, rate <span class="op">=</span> <span class="va">self</span><span class="op">$</span><span class="va">rate</span><span class="op">)</span><span class="op">)</span>
    <span class="op">}</span>
    <span class="va">inputs</span>
  <span class="op">}</span>
<span class="op">}</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="privileged-mask-argument-in-the-call-method">Privileged <code>mask</code> argument in the <code>call()</code>
method<a class="anchor" aria-label="anchor" href="#privileged-mask-argument-in-the-call-method"></a>
</h2>
<p>The other privileged argument supported by <code><a href="https://rdrr.io/r/base/call.html" class="external-link">call()</a></code> is the
<code>mask</code> argument.</p>
<p>You will find it in all Keras RNN layers. A mask is a boolean tensor
(one boolean value per timestep in the input) used to skip certain input
timesteps when processing timeseries data.</p>
<p>Keras will automatically pass the correct <code>mask</code> argument
to <code><a href="https://rdrr.io/r/base/call.html" class="external-link">call()</a></code> for layers that support it, when a mask is
generated by a prior layer. Mask-generating layers are the
<code>Embedding</code> layer configured with
<code>mask_zero=True</code>, and the <code>Masking</code> layer.</p>
<p>To learn more about masking and how to write masking-enabled layers,
please check out the guide <a href="/guides/understanding_masking_and_padding/">“understanding padding
and masking”</a>.</p>
</div>
<div class="section level2">
<h2 id="the-model-class">The <code>Model</code> class<a class="anchor" aria-label="anchor" href="#the-model-class"></a>
</h2>
<p>In general, you will use the <code>Layer</code> class to define inner
computation blocks, and will use the <code>Model</code> class to define
the outer model – the object you will train.</p>
<p>For instance, in a ResNet50 model, you would have several ResNet
blocks subclassing <code>Layer</code>, and a single <code>Model</code>
encompassing the entire ResNet50 network.</p>
<p>The <code>Model</code> class has the same API as <code>Layer</code>,
with the following differences:</p>
<ul>
<li>It has support for built-in training, evaluation, and prediction
methods (<code><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit()</a></code>, <code><a href="https://rdrr.io/pkg/tensorflow/man/evaluate.html" class="external-link">evaluate()</a></code>,
<code><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict()</a></code>).</li>
<li>It exposes the list of its inner layers, via the
<code>model$layers</code> property.</li>
<li>It exposes saving and serialization APIs
(<code><a href="../../reference/save_model_tf.html">save_model_tf()</a></code>, <code><a href="../../reference/save_model_weights_tf.html">save_model_weights_tf()</a></code>,
…)</li>
</ul>
<p>Effectively, the <code>Layer</code> class corresponds to what we
refer to in the literature as a “layer” (as in “convolution layer” or
“recurrent layer”) or as a “block” (as in “ResNet block” or “Inception
block”).</p>
<p>Meanwhile, the <code>Model</code> class corresponds to what is
referred to in the literature as a “model” (as in “deep learning model”)
or as a “network” (as in “deep neural network”).</p>
<p>So if you’re wondering, “should I use the <code>Layer</code> class or
the <code>Model</code> class?”, ask yourself: will I need to call
<code><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit()</a></code> on it? Will I need to call <code><a href="https://rdrr.io/r/base/save.html" class="external-link">save()</a></code> on it?
If so, go with <code>Model</code>. If not (either because your class is
just a block in a bigger system, or because you are writing training
&amp; saving code yourself), use <code>Layer</code>.</p>
<p>For instance, we could take our mini-resnet example above, and use it
to build a <code>Model</code> that we could train with
<code><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit()</a></code>, and that we could save with
<code><a href="../../reference/save_model_weights_tf.html">save_model_weights_tf()</a></code>:</p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">ResNet</span><span class="op">(</span><span class="va">keras</span><span class="op">$</span><span class="va">Model</span><span class="op">)</span> <span class="op"><a href="../../reference/grapes-py_class-grapes.html">%py_class%</a></span> <span class="op">{</span>
  <span class="va">initialize</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">num_classes</span> <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">block_1</span> <span class="op">&lt;-</span> <span class="fu">ResNetBlock</span><span class="op">(</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">block_2</span> <span class="op">&lt;-</span> <span class="fu">ResNetBlock</span><span class="op">(</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">global_pool</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/layer_global_average_pooling_2d.html">layer_global_average_pooling_2d</a></span><span class="op">(</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">classifier</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="va">num_classes</span><span class="op">)</span>
  <span class="op">}</span>

  <span class="va">call</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">x</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">block_1</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span>
    <span class="va">x</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">block_2</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>
    <span class="va">x</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">global_pool</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="fu">classifier</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>
  <span class="op">}</span>
<span class="op">}</span>


<span class="va">resnet</span> <span class="op">&lt;-</span> <span class="fu">ResNet</span><span class="op">(</span><span class="op">)</span>
<span class="va">dataset</span> <span class="op">&lt;-</span> <span class="va">...</span>
<span class="va">resnet</span> <span class="op"><a href="../../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span><span class="va">dataset</span>, epochs <span class="op">=</span> <span class="fl">10</span><span class="op">)</span>
<span class="va">resnet</span> <span class="op"><a href="../../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="../../reference/save_model_tf.html">save_model_tf</a></span><span class="op">(</span><span class="va">filepath</span><span class="op">)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="putting-it-all-together-an-end-to-end-example">Putting it all together: an end-to-end example<a class="anchor" aria-label="anchor" href="#putting-it-all-together-an-end-to-end-example"></a>
</h2>
<p>Here’s what you’ve learned so far:</p>
<ul>
<li>A <code>Layer</code> encapsulates a state (created in
<code>initialize()</code> or <code><a href="https://rdrr.io/r/utils/PkgUtils.html" class="external-link">build()</a></code>), and some computation
(defined in <code><a href="https://rdrr.io/r/base/call.html" class="external-link">call()</a></code>).</li>
<li>Layers can be recursively nested to create new, bigger computation
blocks.</li>
<li>Layers can create and track losses (typically regularization losses)
as well as metrics, via <code>add_loss()</code> and
<code>add_metric()</code>
</li>
<li>The outer container, the thing you want to train, is a
<code>Model</code>. A <code>Model</code> is just like a
<code>Layer</code>, but with added training and serialization
utilities.</li>
</ul>
<p>Let’s put all of these things together into an end-to-end example:
we’re going to implement a Variational AutoEncoder (VAE). We’ll train it
on MNIST digits.</p>
<p>Our VAE will be a subclass of <code>Model</code>, built as a nested
composition of layers that subclass <code>Layer</code>. It will feature
a regularization loss (KL divergence).</p>
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">Sampling</span><span class="op">(</span><span class="va">keras</span><span class="op">$</span><span class="va">layers</span><span class="op">$</span><span class="va">Layer</span><span class="op">)</span> <span class="op"><a href="../../reference/grapes-py_class-grapes.html">%py_class%</a></span> <span class="op">{</span>
  <span class="va">call</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span> <span class="op">{</span>
    <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">z_mean</span>, <span class="va">z_log_var</span><span class="op">)</span> <span class="op"><a href="../../reference/multi-assign.html">%&lt;-%</a></span> <span class="va">inputs</span>
    <span class="va">batch</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="fu">shape</span><span class="op">(</span><span class="va">z_mean</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>
    <span class="va">dim</span> <span class="op">&lt;-</span> <span class="va">tf</span><span class="op">$</span><span class="fu">shape</span><span class="op">(</span><span class="va">z_mean</span><span class="op">)</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>
    <span class="va">epsilon</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/k_random_normal.html">k_random_normal</a></span><span class="op">(</span>shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">batch</span>, <span class="va">dim</span><span class="op">)</span><span class="op">)</span>
    <span class="va">z_mean</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">exp</a></span><span class="op">(</span><span class="fl">0.5</span> <span class="op">*</span> <span class="va">z_log_var</span><span class="op">)</span> <span class="op">*</span> <span class="va">epsilon</span>
  <span class="op">}</span>
<span class="op">}</span>


<span class="fu">Encoder</span><span class="op">(</span><span class="va">keras</span><span class="op">$</span><span class="va">layers</span><span class="op">$</span><span class="va">Layer</span><span class="op">)</span> <span class="op"><a href="../../reference/grapes-py_class-grapes.html">%py_class%</a></span> <span class="op">{</span>
  <span class="st">"Maps MNIST digits to a triplet (z_mean, z_log_var, z)."</span>

  <span class="va">initialize</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">latent_dim</span> <span class="op">=</span> <span class="fl">32</span>, <span class="va">intermediate_dim</span> <span class="op">=</span> <span class="fl">64</span>, <span class="va">name</span> <span class="op">=</span> <span class="st">"encoder"</span>, <span class="va">...</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span>name <span class="op">=</span> <span class="va">name</span>, <span class="va">...</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">dense_proj</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="va">intermediate_dim</span>, activation <span class="op">=</span> <span class="st">"relu"</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">dense_mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="va">latent_dim</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">dense_log_var</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="va">latent_dim</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">sampling</span> <span class="op">&lt;-</span> <span class="fu">Sampling</span><span class="op">(</span><span class="op">)</span>
  <span class="op">}</span>

  <span class="va">call</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">x</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">dense_proj</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span>
    <span class="va">z_mean</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">dense_mean</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>
    <span class="va">z_log_var</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">dense_log_var</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>
    <span class="va">z</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">sampling</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">z_mean</span>, <span class="va">z_log_var</span><span class="op">)</span><span class="op">)</span>
    <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">z_mean</span>, <span class="va">z_log_var</span>, <span class="va">z</span><span class="op">)</span>
  <span class="op">}</span>
<span class="op">}</span>


<span class="fu">Decoder</span><span class="op">(</span><span class="va">keras</span><span class="op">$</span><span class="va">layers</span><span class="op">$</span><span class="va">Layer</span><span class="op">)</span> <span class="op"><a href="../../reference/grapes-py_class-grapes.html">%py_class%</a></span> <span class="op">{</span>
  <span class="st">"Converts z, the encoded digit vector, back into a readable digit."</span>

  <span class="va">initialize</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">original_dim</span>, <span class="va">intermediate_dim</span> <span class="op">=</span> <span class="fl">64</span>, <span class="va">name</span> <span class="op">=</span> <span class="st">"decoder"</span>, <span class="va">...</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span>name <span class="op">=</span> <span class="va">name</span>, <span class="va">...</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">dense_proj</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="va">intermediate_dim</span>, activation <span class="op">=</span> <span class="st">"relu"</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">dense_output</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="va">original_dim</span>, activation <span class="op">=</span> <span class="st">"sigmoid"</span><span class="op">)</span>
  <span class="op">}</span>

  <span class="va">call</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">x</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">dense_proj</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="fu">dense_output</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>
  <span class="op">}</span>
<span class="op">}</span>


<span class="fu">VariationalAutoEncoder</span><span class="op">(</span><span class="va">keras</span><span class="op">$</span><span class="va">Model</span><span class="op">)</span> <span class="op"><a href="../../reference/grapes-py_class-grapes.html">%py_class%</a></span> <span class="op">{</span>
  <span class="st">"Combines the encoder and decoder into an end-to-end model for training."</span>

  <span class="va">initialize</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">original_dim</span>, <span class="va">intermediate_dim</span> <span class="op">=</span> <span class="fl">64</span>, <span class="va">latent_dim</span> <span class="op">=</span> <span class="fl">32</span>,
                         <span class="va">name</span> <span class="op">=</span> <span class="st">"autoencoder"</span>, <span class="va">...</span><span class="op">)</span> <span class="op">{</span>
    <span class="va">super</span><span class="op">$</span><span class="fu">initialize</span><span class="op">(</span>name <span class="op">=</span> <span class="va">name</span>, <span class="va">...</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">original_dim</span> <span class="op">&lt;-</span> <span class="va">original_dim</span>
    <span class="va">self</span><span class="op">$</span><span class="va">encoder</span> <span class="op">&lt;-</span> <span class="fu">Encoder</span><span class="op">(</span>
      latent_dim <span class="op">=</span> <span class="va">latent_dim</span>,
      intermediate_dim <span class="op">=</span> <span class="va">intermediate_dim</span>
    <span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="va">decoder</span> <span class="op">&lt;-</span> <span class="fu">Decoder</span><span class="op">(</span><span class="va">original_dim</span>, intermediate_dim <span class="op">=</span> <span class="va">intermediate_dim</span><span class="op">)</span>
  <span class="op">}</span>

  <span class="va">call</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span> <span class="op">{</span>
    <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">z_mean</span>, <span class="va">z_log_var</span>, <span class="va">z</span><span class="op">)</span> <span class="op"><a href="../../reference/multi-assign.html">%&lt;-%</a></span> <span class="va">self</span><span class="op">$</span><span class="fu">encoder</span><span class="op">(</span><span class="va">inputs</span><span class="op">)</span>
    <span class="va">reconstructed</span> <span class="op">&lt;-</span> <span class="va">self</span><span class="op">$</span><span class="fu">decoder</span><span class="op">(</span><span class="va">z</span><span class="op">)</span>
    <span class="co"># Add KL divergence regularization loss.</span>
    <span class="va">kl_loss</span> <span class="op">&lt;-</span> <span class="op">-</span><span class="fl">0.5</span> <span class="op">*</span> <span class="va">tf</span><span class="op">$</span><span class="fu">reduce_mean</span><span class="op">(</span><span class="va">z_log_var</span> <span class="op">-</span> <span class="va">tf</span><span class="op">$</span><span class="fu">square</span><span class="op">(</span><span class="va">z_mean</span><span class="op">)</span> <span class="op">-</span> <span class="va">tf</span><span class="op">$</span><span class="fu">exp</span><span class="op">(</span><span class="va">z_log_var</span><span class="op">)</span> <span class="op">+</span> <span class="fl">1</span><span class="op">)</span>
    <span class="va">self</span><span class="op">$</span><span class="fu">add_loss</span><span class="op">(</span><span class="va">kl_loss</span><span class="op">)</span>
    <span class="va">reconstructed</span>
  <span class="op">}</span>
<span class="op">}</span></code></pre></div>
<p>Let’s write a simple training loop on MNIST:</p>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://t-kalinowski.github.io/tfautograph/" class="external-link">tfautograph</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/rstudio/tfdatasets" class="external-link">tfdatasets</a></span><span class="op">)</span>


<span class="va">original_dim</span> <span class="op">&lt;-</span> <span class="fl">784</span>
<span class="va">vae</span> <span class="op">&lt;-</span> <span class="fu">VariationalAutoEncoder</span><span class="op">(</span><span class="va">original_dim</span>, <span class="fl">64</span>, <span class="fl">32</span><span class="op">)</span>

<span class="va">optimizer</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/optimizer_adam.html">optimizer_adam</a></span><span class="op">(</span>learning_rate <span class="op">=</span> <span class="fl">1e-3</span><span class="op">)</span>
<span class="va">mse_loss_fn</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/loss-functions.html">loss_mean_squared_error</a></span><span class="op">(</span><span class="op">)</span>

<span class="va">loss_metric</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/metric_mean.html">metric_mean</a></span><span class="op">(</span><span class="op">)</span>

<span class="va">x_train</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/dataset_mnist.html">dataset_mnist</a></span><span class="op">(</span><span class="op">)</span><span class="op">$</span><span class="va">train</span><span class="op">$</span><span class="va">x</span> <span class="op"><a href="../../reference/pipe.html">%&gt;%</a></span>
  <span class="fu"><a href="https://rstudio.github.io/reticulate/reference/array_reshape.html" class="external-link">array_reshape</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">60000</span>, <span class="fl">784</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="../../reference/pipe.html">%&gt;%</a></span>
  <span class="fu">`/`</span><span class="op">(</span><span class="fl">255</span><span class="op">)</span>

<span class="va">train_dataset</span> <span class="op">&lt;-</span> <span class="fu">tensor_slices_dataset</span><span class="op">(</span><span class="va">x_train</span><span class="op">)</span> <span class="op"><a href="../../reference/pipe.html">%&gt;%</a></span>
  <span class="fu">dataset_shuffle</span><span class="op">(</span>buffer_size <span class="op">=</span> <span class="fl">1024</span><span class="op">)</span> <span class="op"><a href="../../reference/pipe.html">%&gt;%</a></span>
  <span class="fu">dataset_batch</span><span class="op">(</span><span class="fl">64</span><span class="op">)</span>

<span class="va">epochs</span> <span class="op">&lt;-</span> <span class="fl">2</span>

<span class="co"># Iterate over epochs.</span>
<span class="kw">for</span> <span class="op">(</span><span class="va">epoch</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="va">epochs</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span>
  <span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html" class="external-link">sprintf</a></span><span class="op">(</span><span class="st">"Start of epoch %d\n"</span>, <span class="va">epoch</span><span class="op">)</span><span class="op">)</span>

  <span class="co"># Iterate over the batches of the dataset.</span>
  <span class="co"># autograph lets you use tfdatasets in `for` and `while`</span>
  <span class="fu"><a href="https://t-kalinowski.github.io/tfautograph/reference/autograph.html" class="external-link">autograph</a></span><span class="op">(</span><span class="op">{</span>
    <span class="va">step</span> <span class="op">&lt;-</span> <span class="fl">0</span>
    <span class="kw">for</span> <span class="op">(</span><span class="va">x_batch_train</span> <span class="kw">in</span> <span class="va">train_dataset</span><span class="op">)</span> <span class="op">{</span>
      <span class="fu"><a href="https://rdrr.io/r/base/with.html" class="external-link">with</a></span><span class="op">(</span><span class="va">tf</span><span class="op">$</span><span class="fu">GradientTape</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://rstudio.github.io/reticulate/reference/with-as-operator.html" class="external-link">%as%</a></span> <span class="va">tape</span>, <span class="op">{</span>
        <span class="co">## Note: we're four opaque contexts deep here (for, autograph, for,</span>
        <span class="co">## with), When in doubt about the objects or methods that are available</span>
        <span class="co">## (e.g., what is `tape` here?), remember you can always drop into a</span>
        <span class="co">## debugger right here:</span>
        <span class="co"># browser()</span>

        <span class="va">reconstructed</span> <span class="op">&lt;-</span> <span class="fu">vae</span><span class="op">(</span><span class="va">x_batch_train</span><span class="op">)</span>
        <span class="co"># Compute reconstruction loss</span>
        <span class="va">loss</span> <span class="op">&lt;-</span> <span class="fu">mse_loss_fn</span><span class="op">(</span><span class="va">x_batch_train</span>, <span class="va">reconstructed</span><span class="op">)</span>

        <span class="va">loss</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/compound.html" class="external-link">%&lt;&gt;%</a></span> <span class="fu"><a href="https://magrittr.tidyverse.org/reference/aliases.html" class="external-link">add</a></span><span class="op">(</span><span class="va">vae</span><span class="op">$</span><span class="va">losses</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">)</span> <span class="co"># Add KLD regularization loss</span>
      <span class="op">}</span><span class="op">)</span>
      <span class="va">grads</span> <span class="op">&lt;-</span> <span class="va">tape</span><span class="op">$</span><span class="fu">gradient</span><span class="op">(</span><span class="va">loss</span>, <span class="va">vae</span><span class="op">$</span><span class="va">trainable_weights</span><span class="op">)</span>
      <span class="va">optimizer</span><span class="op">$</span><span class="fu">apply_gradients</span><span class="op">(</span>
        <span class="fu">purrr</span><span class="fu">::</span><span class="fu"><a href="https://purrr.tidyverse.org/reference/transpose.html" class="external-link">transpose</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">grads</span>, <span class="va">vae</span><span class="op">$</span><span class="va">trainable_weights</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>

      <span class="fu">loss_metric</span><span class="op">(</span><span class="va">loss</span><span class="op">)</span>

      <span class="va">step</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/compound.html" class="external-link">%&lt;&gt;%</a></span> <span class="fu"><a href="https://magrittr.tidyverse.org/reference/aliases.html" class="external-link">add</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span>
      <span class="kw">if</span> <span class="op">(</span><span class="va">step</span> <span class="op"><a href="https://rdrr.io/r/base/Arithmetic.html" class="external-link">%%</a></span> <span class="fl">100</span> <span class="op">==</span> <span class="fl">0</span><span class="op">)</span> <span class="op">{</span>
        <span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sprintf.html" class="external-link">sprintf</a></span><span class="op">(</span><span class="st">"step %d: mean loss = %.4f\n"</span>, <span class="va">step</span>, <span class="va">loss_metric</span><span class="op">$</span><span class="fu">result</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
      <span class="op">}</span>
    <span class="op">}</span>
  <span class="op">}</span><span class="op">)</span>
<span class="op">}</span></code></pre></div>
<p>Note that since the VAE is subclassing <code>Model</code>, it
features built-in training loops. So you could also have trained it like
this:</p>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">vae</span> <span class="op">&lt;-</span> <span class="fu">VariationalAutoEncoder</span><span class="op">(</span><span class="fl">784</span>, <span class="fl">64</span>, <span class="fl">32</span><span class="op">)</span>

<span class="va">optimizer</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/optimizer_adam.html">optimizer_adam</a></span><span class="op">(</span>learning_rate <span class="op">=</span> <span class="fl">1e-3</span><span class="op">)</span>

<span class="va">vae</span> <span class="op"><a href="../../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html" class="external-link">compile</a></span><span class="op">(</span><span class="va">optimizer</span>, loss <span class="op">=</span> <span class="fu"><a href="../../reference/loss-functions.html">loss_mean_squared_error</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span>
<span class="va">vae</span> <span class="op"><a href="../../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span><span class="va">x_train</span>, <span class="va">x_train</span>, epochs <span class="op">=</span> <span class="fl">2</span>, batch_size <span class="op">=</span> <span class="fl">64</span><span class="op">)</span></code></pre></div>
</div>
<div class="section level2">
<h2 id="beyond-object-oriented-development-the-functional-api">Beyond object-oriented development: the Functional API<a class="anchor" aria-label="anchor" href="#beyond-object-oriented-development-the-functional-api"></a>
</h2>
<p>If you prefer a less object-oriented way of programming, you can also
build models using the <a href="/guides/functional_api/">Functional
API</a>. Importantly, choosing one style or another does not prevent you
from leveraging components written in the other style: you can always
mix-and-match.</p>
<p>For instance, the Functional API example below reuses the same
<code>Sampling</code> layer we defined in the example above:</p>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">original_dim</span> <span class="op">&lt;-</span> <span class="fl">784</span>
<span class="va">intermediate_dim</span> <span class="op">&lt;-</span> <span class="fl">64</span>
<span class="va">latent_dim</span> <span class="op">&lt;-</span> <span class="fl">32</span>

<span class="co"># Define encoder model.</span>
<span class="va">original_inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/layer_input.html">layer_input</a></span><span class="op">(</span>shape <span class="op">=</span> <span class="va">original_dim</span>, name <span class="op">=</span> <span class="st">"encoder_input"</span><span class="op">)</span>
<span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="va">intermediate_dim</span>, activation <span class="op">=</span> <span class="st">"relu"</span><span class="op">)</span><span class="op">(</span><span class="va">original_inputs</span><span class="op">)</span>
<span class="va">z_mean</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="va">latent_dim</span>, name <span class="op">=</span> <span class="st">"z_mean"</span><span class="op">)</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>
<span class="va">z_log_var</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="va">latent_dim</span>, name <span class="op">=</span> <span class="st">"z_log_var"</span><span class="op">)</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>
<span class="va">z</span> <span class="op">&lt;-</span> <span class="fu">Sampling</span><span class="op">(</span><span class="op">)</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">z_mean</span>, <span class="va">z_log_var</span><span class="op">)</span><span class="op">)</span>
<span class="va">encoder</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/keras_model.html">keras_model</a></span><span class="op">(</span>inputs <span class="op">=</span> <span class="va">original_inputs</span>, outputs <span class="op">=</span> <span class="va">z</span>, name <span class="op">=</span> <span class="st">"encoder"</span><span class="op">)</span>

<span class="co"># Define decoder model.</span>
<span class="va">latent_inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/layer_input.html">layer_input</a></span><span class="op">(</span>shape <span class="op">=</span> <span class="va">latent_dim</span>, name <span class="op">=</span> <span class="st">"z_sampling"</span><span class="op">)</span>
<span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="va">intermediate_dim</span>, activation <span class="op">=</span> <span class="st">"relu"</span><span class="op">)</span><span class="op">(</span><span class="va">latent_inputs</span><span class="op">)</span>
<span class="va">outputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span>units <span class="op">=</span> <span class="va">original_dim</span>, activation <span class="op">=</span> <span class="st">"sigmoid"</span><span class="op">)</span><span class="op">(</span><span class="va">x</span><span class="op">)</span>
<span class="va">decoder</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/keras_model.html">keras_model</a></span><span class="op">(</span>inputs <span class="op">=</span> <span class="va">latent_inputs</span>, outputs <span class="op">=</span> <span class="va">outputs</span>, name <span class="op">=</span> <span class="st">"decoder"</span><span class="op">)</span>

<span class="co"># Define VAE model.</span>
<span class="va">outputs</span> <span class="op">&lt;-</span> <span class="fu">decoder</span><span class="op">(</span><span class="va">z</span><span class="op">)</span>
<span class="va">vae</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../reference/keras_model.html">keras_model</a></span><span class="op">(</span>inputs <span class="op">=</span> <span class="va">original_inputs</span>, outputs <span class="op">=</span> <span class="va">outputs</span>, name <span class="op">=</span> <span class="st">"vae"</span><span class="op">)</span>

<span class="co"># Add KL divergence regularization loss.</span>
<span class="va">kl_loss</span> <span class="op">&lt;-</span> <span class="op">-</span><span class="fl">0.5</span> <span class="op">*</span> <span class="va">tf</span><span class="op">$</span><span class="fu">reduce_mean</span><span class="op">(</span><span class="va">z_log_var</span> <span class="op">-</span> <span class="va">tf</span><span class="op">$</span><span class="fu">square</span><span class="op">(</span><span class="va">z_mean</span><span class="op">)</span> <span class="op">-</span> <span class="va">tf</span><span class="op">$</span><span class="fu">exp</span><span class="op">(</span><span class="va">z_log_var</span><span class="op">)</span> <span class="op">+</span> <span class="fl">1</span><span class="op">)</span>
<span class="va">vae</span><span class="op">$</span><span class="fu">add_loss</span><span class="op">(</span><span class="va">kl_loss</span><span class="op">)</span>

<span class="co"># Train.</span>
<span class="va">optimizer</span> <span class="op">&lt;-</span> <span class="va">keras</span><span class="op">$</span><span class="va">optimizers</span><span class="op">$</span><span class="fu">Adam</span><span class="op">(</span>learning_rate <span class="op">=</span> <span class="fl">1e-3</span><span class="op">)</span>
<span class="va">vae</span> <span class="op"><a href="../../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html" class="external-link">compile</a></span><span class="op">(</span><span class="va">optimizer</span>, loss <span class="op">=</span> <span class="fu"><a href="../../reference/loss-functions.html">loss_mean_squared_error</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span>
<span class="va">vae</span> <span class="op"><a href="../../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span><span class="va">x_train</span>, <span class="va">x_train</span>, epochs <span class="op">=</span> <span class="fl">3</span>, batch_size <span class="op">=</span> <span class="fl">64</span><span class="op">)</span></code></pre></div>
<p>For more information, make sure to read the <a href="/guides/functional_api/">Functional API guide</a>.</p>
</div>
<div class="section level2">
<h2 id="defining-custom-layers-and-models-in-an-r-package">Defining custom layers and models in an R package<a class="anchor" aria-label="anchor" href="#defining-custom-layers-and-models-in-an-r-package"></a>
</h2>
<p>Unfortunately you can’t use anything that creates references to
Python objects, at the top-level of an R package.</p>
<p>Here is why: when you build an R package, all the R files in the
<code>R/</code> directory get sourced in an R environment (the package
namespace), and then that environment is saved as part of the package
bundle. Loading the package means restoring the saved R environment.
This means that the R code only gets sourced once, at build time. If you
create references to external objects (e.g., Python objects) at package
build time, they will be NULL pointers when the package is loaded,
because the external objects they pointed to at build time no longer
exist at load time.</p>
<p>The solution is to delay creating references to Python objects until
run time. Fortunately, <code>%py_class%</code>, <code><a href="../../reference/Layer.html">Layer()</a></code>,
and <code>create_layer_wrapper(R6Class(...))</code> are all lazy about
initializing the Python reference, so they are safe to define and export
in an R package.</p>
<p>If you’re writing an R package that uses keras and reticulate, <a href="https://rstudio.github.io/reticulate/articles/package.html" class="external-link">this
article</a> might be helpful to read over.</p>
</div>
<div class="section level2">
<h2 id="summary">Summary<a class="anchor" aria-label="anchor" href="#summary"></a>
</h2>
<p>In this guide you learned about creating custom layers and models in
keras.</p>
<ul>
<li>The constructors available: <code>%py_class%</code>,
<code><a href="../../reference/create_layer_wrapper.html">create_layer_wrapper()</a></code>, <code><a href="https://r6.r-lib.org/reference/R6Class.html" class="external-link">R6Class()</a></code>, and
<code><a href="../../reference/Layer.html">Layer()</a></code>.</li>
<li>What methods to you might want to define to your model:
<code>initialize()</code>, <code><a href="https://rdrr.io/r/utils/PkgUtils.html" class="external-link">build()</a></code>, <code><a href="https://rdrr.io/r/base/call.html" class="external-link">call()</a></code>,
and <code><a href="../../reference/get_config.html">get_config()</a></code>.</li>
<li>What convenience methods are available when you subclass
<code>keras$layers$Layer</code>: <code>add_weight()</code>,
<code>add_loss()</code>, and <code>add_metric()</code>
</li>
</ul>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by Tomasz Kalinowski, JJ Allaire, François Chollet, RStudio, Google.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.3.</p>
</div>

      </footer>
</div>

  


  

  </body>
</html>
