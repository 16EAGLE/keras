<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Loss functions — loss-functions • keras</title><!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png"><link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png"><link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png"><link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png"><link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png"><link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png"><!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous"><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css"><script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet"><script src="../pkgdown.js"></script><link href="../extra.css" rel="stylesheet"><script src="../extra.js"></script><meta property="og:title" content="Loss functions — loss-functions"><meta property="og:description" content="Loss functions"><meta property="og:image" content="/logo.png"><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body data-spy="scroll" data-target="#toc">
    

    <div class="container template-reference-topic">
      <header><div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">keras</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">2.8.0.9000</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav"><li>
  <a href="../index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Tutorials
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu"><li>
      <a href="../articles/getting_started.html">Getting Started</a>
    </li>
    <li>
      <a href="../articles/tutorial_basic_classification.html">Basic Classification</a>
    </li>
    <li>
      <a href="../articles/tutorial_basic_text_classification.html">Text Classification</a>
    </li>
    <li>
      <a href="../articles/tutorial_basic_regression.html">Basic Regression</a>
    </li>
    <li>
      <a href="../articles/tutorial_overfit_underfit.html">Overfitting and Underfitting</a>
    </li>
    <li>
      <a href="../articles/tutorial_save_and_restore.html">Save and Restore Models</a>
    </li>
  </ul></li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu"><li class="dropdown-header">Guides (New for TF 2.6)</li>
    <li>
      <a href="../articles/new-guides/python_subclasses.html">Python Subclasses</a>
    </li>
    <li>
      <a href="../articles/new-guides/making_new_layers_and_models_via_subclassing.html">Making New Layers and Models via Subclassing</a>
    </li>
    <li>
      <a href="../articles/new-guides/customizing_what_happens_in_fit.html">Customizing What Happens in Fit</a>
    </li>
    <li>
      <a href="../articles/new-guides/writing_your_own_callbacks.html">Writing Your Own Callbacks</a>
    </li>
    <li>
      <a href="../articles/new-guides/preprocessing_layers.html">Working with Preprocessing Layers</a>
    </li>
    <li>
      <a href="../argicles/new-guides/working_with_rnns.html">Working with RNNs</a>
    </li>
    <li class="divider">
    <li class="dropdown-header">Using Keras</li>
    <li>
      <a href="../articles/guide_keras.html">Guide to Keras Basics</a>
    </li>
    <li>
      <a href="../articles/sequential_model.html">Sequential Model in Depth</a>
    </li>
    <li>
      <a href="../articles/functional_api.html">Functional API in Depth</a>
    </li>
    <li>
      <a href="../articles/about_keras_models.html">About Keras Models</a>
    </li>
    <li>
      <a href="../articles/about_keras_layers.html">About Keras Layers</a>
    </li>
    <li>
      <a href="../articles/training_visualization.html">Training Visualization</a>
    </li>
    <li>
      <a href="../articles/applications.html">Pre-Trained Models</a>
    </li>
    <li>
      <a href="../articles/faq.html">Frequently Asked Questions</a>
    </li>
    <li>
      <a href="../articles/why_use_keras.html">Why Use Keras?</a>
    </li>
    <li class="divider">
    <li class="dropdown-header">Advanced</li>
    <li>
      <a href="../articles/eager_guide.html">Eager Execution</a>
    </li>
    <li>
      <a href="../articles/training_callbacks.html">Training Callbacks</a>
    </li>
    <li>
      <a href="../articles/backend.html">Keras Backend</a>
    </li>
    <li>
      <a href="../articles/custom_layers.html">Custom Layers</a>
    </li>
    <li>
      <a href="../articles/custom_models.html">Custom Models</a>
    </li>
    <li>
      <a href="../articles/saving_serializing.html">Saving and serializing</a>
    </li>
  </ul></li>
<li>
  <a href="../articles/learn.html">Learn</a>
</li>
<li>
  <a href="../articles/tools.html">Tools</a>
</li>
<li>
  <a href="../articles/examples/index.html">Examples</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
      </ul><ul class="nav navbar-nav navbar-right"><li>
  <a href="https://github.com/rstudio/keras/" class="external-link">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul></div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Loss functions</h1>
    <small class="dont-index">Source: <a href="https://github.com/rstudio/keras/blob/HEAD/R/losses.R" class="external-link"><code>R/losses.R</code></a></small>
    <div class="hidden name"><code>loss-functions.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>Loss functions</p>
    </div>

    <div id="ref-usage">
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="fu">loss_binary_crossentropy</span><span class="op">(</span>
  <span class="va">y_true</span>,
  <span class="va">y_pred</span>,
  from_logits <span class="op">=</span> <span class="cn">FALSE</span>,
  label_smoothing <span class="op">=</span> <span class="fl">0</span>,
  axis <span class="op">=</span> <span class="op">-</span><span class="fl">1L</span>,
  <span class="va">...</span>,
  reduction <span class="op">=</span> <span class="st">"auto"</span>,
  name <span class="op">=</span> <span class="st">"binary_crossentropy"</span>
<span class="op">)</span>

<span class="fu">loss_categorical_crossentropy</span><span class="op">(</span>
  <span class="va">y_true</span>,
  <span class="va">y_pred</span>,
  from_logits <span class="op">=</span> <span class="cn">FALSE</span>,
  label_smoothing <span class="op">=</span> <span class="fl">0L</span>,
  axis <span class="op">=</span> <span class="op">-</span><span class="fl">1L</span>,
  <span class="va">...</span>,
  reduction <span class="op">=</span> <span class="st">"auto"</span>,
  name <span class="op">=</span> <span class="st">"categorical_crossentropy"</span>
<span class="op">)</span>

<span class="fu">loss_categorical_hinge</span><span class="op">(</span>
  <span class="va">y_true</span>,
  <span class="va">y_pred</span>,
  <span class="va">...</span>,
  reduction <span class="op">=</span> <span class="st">"auto"</span>,
  name <span class="op">=</span> <span class="st">"categorical_hinge"</span>
<span class="op">)</span>

<span class="fu">loss_cosine_similarity</span><span class="op">(</span>
  <span class="va">y_true</span>,
  <span class="va">y_pred</span>,
  axis <span class="op">=</span> <span class="op">-</span><span class="fl">1L</span>,
  <span class="va">...</span>,
  reduction <span class="op">=</span> <span class="st">"auto"</span>,
  name <span class="op">=</span> <span class="st">"cosine_similarity"</span>
<span class="op">)</span>

<span class="fu">loss_hinge</span><span class="op">(</span><span class="va">y_true</span>, <span class="va">y_pred</span>, <span class="va">...</span>, reduction <span class="op">=</span> <span class="st">"auto"</span>, name <span class="op">=</span> <span class="st">"hinge"</span><span class="op">)</span>

<span class="fu">loss_huber</span><span class="op">(</span>
  <span class="va">y_true</span>,
  <span class="va">y_pred</span>,
  delta <span class="op">=</span> <span class="fl">1</span>,
  <span class="va">...</span>,
  reduction <span class="op">=</span> <span class="st">"auto"</span>,
  name <span class="op">=</span> <span class="st">"huber_loss"</span>
<span class="op">)</span>

<span class="fu">loss_kullback_leibler_divergence</span><span class="op">(</span>
  <span class="va">y_true</span>,
  <span class="va">y_pred</span>,
  <span class="va">...</span>,
  reduction <span class="op">=</span> <span class="st">"auto"</span>,
  name <span class="op">=</span> <span class="st">"kl_divergence"</span>
<span class="op">)</span>

<span class="fu">loss_kl_divergence</span><span class="op">(</span>
  <span class="va">y_true</span>,
  <span class="va">y_pred</span>,
  <span class="va">...</span>,
  reduction <span class="op">=</span> <span class="st">"auto"</span>,
  name <span class="op">=</span> <span class="st">"kl_divergence"</span>
<span class="op">)</span>

<span class="fu">loss_logcosh</span><span class="op">(</span><span class="va">y_true</span>, <span class="va">y_pred</span>, <span class="va">...</span>, reduction <span class="op">=</span> <span class="st">"auto"</span>, name <span class="op">=</span> <span class="st">"log_cosh"</span><span class="op">)</span>

<span class="fu">loss_mean_absolute_error</span><span class="op">(</span>
  <span class="va">y_true</span>,
  <span class="va">y_pred</span>,
  <span class="va">...</span>,
  reduction <span class="op">=</span> <span class="st">"auto"</span>,
  name <span class="op">=</span> <span class="st">"mean_absolute_error"</span>
<span class="op">)</span>

<span class="fu">loss_mean_absolute_percentage_error</span><span class="op">(</span>
  <span class="va">y_true</span>,
  <span class="va">y_pred</span>,
  <span class="va">...</span>,
  reduction <span class="op">=</span> <span class="st">"auto"</span>,
  name <span class="op">=</span> <span class="st">"mean_absolute_percentage_error"</span>
<span class="op">)</span>

<span class="fu">loss_mean_squared_error</span><span class="op">(</span>
  <span class="va">y_true</span>,
  <span class="va">y_pred</span>,
  <span class="va">...</span>,
  reduction <span class="op">=</span> <span class="st">"auto"</span>,
  name <span class="op">=</span> <span class="st">"mean_squared_error"</span>
<span class="op">)</span>

<span class="fu">loss_mean_squared_logarithmic_error</span><span class="op">(</span>
  <span class="va">y_true</span>,
  <span class="va">y_pred</span>,
  <span class="va">...</span>,
  reduction <span class="op">=</span> <span class="st">"auto"</span>,
  name <span class="op">=</span> <span class="st">"mean_squared_logarithmic_error"</span>
<span class="op">)</span>

<span class="fu">loss_poisson</span><span class="op">(</span><span class="va">y_true</span>, <span class="va">y_pred</span>, <span class="va">...</span>, reduction <span class="op">=</span> <span class="st">"auto"</span>, name <span class="op">=</span> <span class="st">"poisson"</span><span class="op">)</span>

<span class="fu">loss_sparse_categorical_crossentropy</span><span class="op">(</span>
  <span class="va">y_true</span>,
  <span class="va">y_pred</span>,
  from_logits <span class="op">=</span> <span class="cn">FALSE</span>,
  axis <span class="op">=</span> <span class="op">-</span><span class="fl">1L</span>,
  <span class="va">...</span>,
  reduction <span class="op">=</span> <span class="st">"auto"</span>,
  name <span class="op">=</span> <span class="st">"sparse_categorical_crossentropy"</span>
<span class="op">)</span>

<span class="fu">loss_squared_hinge</span><span class="op">(</span>
  <span class="va">y_true</span>,
  <span class="va">y_pred</span>,
  <span class="va">...</span>,
  reduction <span class="op">=</span> <span class="st">"auto"</span>,
  name <span class="op">=</span> <span class="st">"squared_hinge"</span>
<span class="op">)</span></code></pre></div>
    </div>

    <div id="arguments">
    <h2>Arguments</h2>
    <dl><dt>y_true</dt>
<dd><p>Ground truth values. shape = <code>[batch_size, d1, .. dN]</code>.</p></dd>
<dt>y_pred</dt>
<dd><p>The predicted values. shape = <code>[batch_size, d1, .. dN]</code>.
(Tensor of the same shape as <code>y_true</code>)</p></dd>
<dt>from_logits</dt>
<dd><p>Whether <code>y_pred</code> is expected to be a logits tensor. By
default we assume that <code>y_pred</code> encodes a probability distribution.</p></dd>
<dt>label_smoothing</dt>
<dd><p>Float in <code>[0, 1]</code>. If <code>&gt; 0</code> then smooth the labels.
For example, if <code>0.1</code>, use <code>0.1 / num_classes</code> for non-target labels and
<code>0.9 + 0.1 / num_classes</code> for target labels.</p></dd>
<dt>axis</dt>
<dd><p>The axis along which to compute crossentropy (the features axis).
Axis is 1-based (e.g, first axis is <code>axis=1</code>). Defaults to <code>-1</code> (the last axis).</p></dd>
<dt>...</dt>
<dd><p>Additional arguments passed on to the Python callable (for forward
and backwards compatibility).</p></dd>
<dt>reduction</dt>
<dd><p>Only applicable if <code>y_true</code> and <code>y_pred</code> are missing. Type
of <code>keras$losses$Reduction</code> to apply to loss. Default value is <code>AUTO</code>.
<code>AUTO</code> indicates that the reduction option will be determined by the usage
context. For almost all cases this defaults to <code>SUM_OVER_BATCH_SIZE</code>. When
used with <code>tf$distribute$Strategy</code>, outside of built-in training loops such
as <code>compile</code> and <code>fit</code>, using <code>AUTO</code> or <code>SUM_OVER_BATCH_SIZE</code> will raise an
error. Please see this custom training <a href="https://www.tensorflow.org/tutorials/distribute/custom_training" class="external-link">tutorial</a> for more
details.</p></dd>
<dt>name</dt>
<dd><p>Only applicable if <code>y_true</code> and <code>y_pred</code> are missing. Optional
name for the Loss instance.</p></dd>
<dt>delta</dt>
<dd><p>A float, the point where the Huber loss function changes from a
quadratic to linear.</p></dd>
</dl></div>
    <div id="value">
    <h2>Value</h2>
    <p>If called with <code>y_true</code> and <code>y_pred</code>, then the corresponding loss is
evaluated and the result returned (as a tensor). Alternatively, if <code>y_true</code>and <code>y_pred</code> are missing, then a callable is returned that will compute the
loss function and, by default, reduce the loss to a scalar tensor; see the
<code>reduction</code> parameter for details. (The callable is a typically a class
instance that inherits from <code>keras$losses$Loss</code>).</p>
    </div>
    <div id="details">
    <h2>Details</h2>
    <p>Loss functions for model training. These are typically supplied in
the <code>loss</code> parameter of the <code><a href="compile.keras.engine.training.Model.html">compile.keras.engine.training.Model()</a></code>
function.</p>
    </div>
    <div id="binary-crossentropy">
    <h2>binary_crossentropy</h2>
    


<p>Computes the binary crossentropy loss.</p>
<p><code>label_smoothing</code> details: Float in <code>[0, 1]</code>. If <code>&gt; 0</code> then smooth the labels
by squeezing them towards 0.5 That is, using <code>1. - 0.5 * label_smoothing</code>
for the target class and <code>0.5 * label_smoothing</code> for the non-target class.</p>
    </div>
    <div id="categorical-crossentropy">
    <h2>categorical_crossentropy</h2>
    


<p>Computes the categorical crossentropy loss.</p>
<p>When using the categorical_crossentropy loss, your targets should be in
categorical format (e.g. if you have 10 classes, the target for each sample
should be a 10-dimensional vector that is all-zeros except for a 1 at the
index corresponding to the class of the sample). In order to convert
integer targets into categorical targets, you can use the Keras utility
function <code><a href="to_categorical.html">to_categorical()</a></code>:</p>
<p><code>categorical_labels &lt;- to_categorical(int_labels, num_classes = NULL)</code></p>
    </div>
    <div id="huber">
    <h2>huber</h2>
    


<p>Computes Huber loss value.
For each value x in <code>error = y_true - y_pred</code>:</p><div class="sourceCode"><pre><code>loss = 0.5 * x^2                  if |x| &lt;= d
loss = d * |x| - 0.5 * d^2        if |x| &gt; d
</code></pre></div>

<p>where d is <code>delta</code>. See: https://en.wikipedia.org/wiki/Huber_loss</p>
    </div>
    <div id="log-cosh">
    <h2>log_cosh</h2>
    


<p>Logarithm of the hyperbolic cosine of the prediction error.</p>
<p><code>log(cosh(x))</code> is approximately equal to <code>(x ** 2) / 2</code> for small <code>x</code> and
to <code>abs(x) - log(2)</code> for large <code>x</code>. This means that 'logcosh' works mostly
like the mean squared error, but will not be so strongly affected by the
occasional wildly incorrect prediction. However, it may return NaNs if the
intermediate value <code>cosh(y_pred - y_true)</code> is too large to be represented
in the chosen precision.</p>
    </div>
    <div id="see-also">
    <h2>See also</h2>
    <div class="dont-index"><p><code><a href="compile.keras.engine.training.Model.html">compile.keras.engine.training.Model()</a></code>,
<code>loss_binary_crossentropy()</code></p></div>
    </div>

  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top"><h2 data-toc-skip>Contents</h2>
    </nav></div>
</div>


      <footer><div class="copyright">
  <p></p><p>Developed by Tomasz Kalinowski, JJ Allaire, François Chollet, RStudio, Google.</p>
</div>

<div class="pkgdown">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.3.</p>
</div>

      </footer></div>

  


  

  </body></html>

