<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Function reference â€¢ keras</title><!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png"><link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png"><link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png"><link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png"><link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png"><link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png"><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><link href="../extra.css" rel="stylesheet"><script src="../extra.js"></script><meta property="og:title" content="Function reference"><meta property="og:image" content="https://keras.posit.co/logo.png"><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-inverse navbar-expand-lg bg-primary"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">keras</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">2.13.0.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="nav-item">
  <a class="nav-link" href="../index.html">Home</a>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-tutorials">Tutorials</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-tutorials">
    <a class="dropdown-item" href="../articles/getting_started.html">Getting Started</a>
    <a class="dropdown-item" href="../articles/tutorial_basic_classification.html">Basic Classification</a>
    <a class="dropdown-item" href="../articles/tutorial_basic_text_classification.html">Text Classification</a>
    <a class="dropdown-item" href="../articles/tutorial_basic_regression.html">Basic Regression</a>
    <a class="dropdown-item" href="../articles/tutorial_overfit_underfit.html">Overfitting and Underfitting</a>
    <a class="dropdown-item" href="../articles/tutorial_save_and_restore.html">Save and Restore Models</a>
  </div>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-guides">Guides</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-guides">
    <a class="dropdown-item" href="../articles/writing_your_own_callbacks.html">Writing Your Own Callbacks</a>
  </div>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <h6 class="dropdown-header" data-toc-skip>Guides (New for TF 2.6)</h6>
    <a class="dropdown-item" href="../articles/new-guides/python_subclasses.html">Python Subclasses</a>
    <a class="dropdown-item" href="../articles/new-guides/making_new_layers_and_models_via_subclassing.html">Making New Layers and Models via Subclassing</a>
    <a class="dropdown-item" href="../articles/new-guides/customizing_what_happens_in_fit.html">Customizing What Happens in Fit</a>
    <a class="dropdown-item" href="../articles/new-guides/writing_your_own_callbacks.html">Writing Your Own Callbacks</a>
    <a class="dropdown-item" href="../articles/new-guides/preprocessing_layers.html">Working with Preprocessing Layers</a>
    <a class="dropdown-item" href="../argicles/new-guides/working_with_rnns.html">Working with RNNs</a>
    <div class="dropdown-divider"></div>
    <h6 class="dropdown-header" data-toc-skip>Using Keras</h6>
    <a class="dropdown-item" href="../articles/guide_keras.html">Guide to Keras Basics</a>
    <a class="dropdown-item" href="../articles/sequential_model.html">Sequential Model in Depth</a>
    <a class="dropdown-item" href="../articles/functional_api.html">Functional API in Depth</a>
    <a class="dropdown-item" href="../articles/about_keras_models.html">About Keras Models</a>
    <a class="dropdown-item" href="../articles/about_keras_layers.html">About Keras Layers</a>
    <a class="dropdown-item" href="../articles/training_visualization.html">Training Visualization</a>
    <a class="dropdown-item" href="../articles/applications.html">Pre-Trained Models</a>
    <a class="dropdown-item" href="../articles/faq.html">Frequently Asked Questions</a>
    <a class="dropdown-item" href="../articles/why_use_keras.html">Why Use Keras?</a>
    <div class="dropdown-divider"></div>
    <h6 class="dropdown-header" data-toc-skip>Advanced</h6>
    <a class="dropdown-item" href="../articles/eager_guide.html">Eager Execution</a>
    <a class="dropdown-item" href="../articles/training_callbacks.html">Training Callbacks</a>
    <a class="dropdown-item" href="../articles/backend.html">Keras Backend</a>
    <a class="dropdown-item" href="../articles/custom_layers.html">Custom Layers</a>
    <a class="dropdown-item" href="../articles/custom_models.html">Custom Models</a>
    <a class="dropdown-item" href="../articles/saving_serializing.html">Saving and serializing</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../articles/learn.html">Learn</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../articles/tools.html">Tools</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../articles/examples/index.html">Examples</a>
</li>
<li class="active nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">News</a>
</li>
      </ul><form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off"></form>

      <ul class="navbar-nav"><li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/rstudio/keras/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul></div>

    
  </div>
</nav><div class="container template-reference-index">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Function reference</h1>
    </div>

    <div class="section level2">
      <h2 id="keras-models">Keras Models<a class="anchor" aria-label="anchor" href="#keras-models"></a></h2>
      
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="keras_model.html">keras_model()</a></code> 
        </dt>
        <dd>Keras Model</dd>
      </dl><dl><dt>
          
          <code><a href="keras_model_sequential.html">keras_model_sequential()</a></code> 
        </dt>
        <dd>Keras Model composed of a linear stack of layers</dd>
      </dl><dl><dt>
          
          <code><a href="summary.keras.models.model.Model.html">summary(<i>&lt;keras.models.model.Model&gt;</i>)</a></code> <code><a href="summary.keras.models.model.Model.html">format(<i>&lt;keras.models.model.Model&gt;</i>)</a></code> <code><a href="summary.keras.models.model.Model.html">print(<i>&lt;keras.models.model.Model&gt;</i>)</a></code> 
        </dt>
        <dd>Print a summary of a Keras model</dd>
      </dl><dl><dt>
          
          <code><a href="compile.keras.models.model.Model.html">compile(<i>&lt;keras.models.model.Model&gt;</i>)</a></code> 
        </dt>
        <dd>Configure a Keras model for training</dd>
      </dl><dl><dt>
          
          <code><a href="fit.keras.models.model.Model.html">fit(<i>&lt;keras.models.model.Model&gt;</i>)</a></code> 
        </dt>
        <dd>Train a Keras model</dd>
      </dl><dl><dt>
          
          <code><a href="predict.keras.models.model.Model.html">predict(<i>&lt;keras.models.model.Model&gt;</i>)</a></code> 
        </dt>
        <dd>Generate predictions from a Keras model</dd>
      </dl><dl><dt>
          
          <code><a href="evaluate.keras.models.model.Model.html">evaluate(<i>&lt;keras.models.model.Model&gt;</i>)</a></code> 
        </dt>
        <dd>Evaluate a Keras model</dd>
      </dl><dl><dt>
          
          <code><a href="export_savedmodel.keras.models.model.Model.html">export_savedmodel(<i>&lt;keras.models.model.Model&gt;</i>)</a></code> 
        </dt>
        <dd>Export a Saved Model</dd>
      </dl><dl><dt>
          
          <code><a href="train_on_batch.html">train_on_batch()</a></code> <code><a href="train_on_batch.html">test_on_batch()</a></code> 
        </dt>
        <dd>Single gradient update or model evaluation over one batch of samples.</dd>
      </dl><dl><dt>
          
          <code><a href="get_layer.html">get_layer()</a></code> 
        </dt>
        <dd>Retrieves a layer based on either its name (unique) or index.</dd>
      </dl><dl><dt>
          
          <code><a href="pop_layer.html">pop_layer()</a></code> 
        </dt>
        <dd>Remove the last layer in a model</dd>
      </dl><dl><dt>
          
          <code><a href="save_model_hdf5.html">save_model_hdf5()</a></code> <code><a href="save_model_hdf5.html">load_model_hdf5()</a></code> 
        </dt>
        <dd>Save/Load models using HDF5 files</dd>
      </dl><dl><dt>
          
          <code><a href="serialize_model.html">serialize_model()</a></code> <code><a href="serialize_model.html">unserialize_model()</a></code> 
        </dt>
        <dd>Serialize a model to an R object</dd>
      </dl><dl><dt>
          
          <code><a href="clone_model.html">clone_model()</a></code> 
        </dt>
        <dd>Clone a model instance.</dd>
      </dl><dl><dt>
          
          <code><a href="freeze_weights.html">freeze_weights()</a></code> <code><a href="freeze_weights.html">unfreeze_weights()</a></code> 
        </dt>
        <dd>Freeze and unfreeze weights</dd>
      </dl></div><div class="section level2">
      <h2 id="layers">Layers<a class="anchor" aria-label="anchor" href="#layers"></a></h2>
      
      

      
    </div><div class="section level2">
      
      <h3 id="core-layers">Core Layers<a class="anchor" aria-label="anchor" href="#core-layers"></a></h3>
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="layer_dense.html">layer_dense()</a></code> 
        </dt>
        <dd>Just your regular densely-connected NN layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_einsum_dense.html">layer_einsum_dense()</a></code> 
        </dt>
        <dd>A layer that uses <code>einsum</code> as the backing computation.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_embedding.html">layer_embedding()</a></code> 
        </dt>
        <dd>Turns positive integers (indexes) into dense vectors of fixed size.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_identity.html">layer_identity()</a></code> 
        </dt>
        <dd>Identity layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_lambda.html">layer_lambda()</a></code> 
        </dt>
        <dd>Wraps arbitrary expressions as a <code>Layer</code> object.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_masking.html">layer_masking()</a></code> 
        </dt>
        <dd>Masks a sequence by using a mask value to skip timesteps.</dd>
      </dl></div><div class="section level2">
      
      <h3 id="reshaping-layers">Reshaping Layers<a class="anchor" aria-label="anchor" href="#reshaping-layers"></a></h3>
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="layer_cropping_1d.html">layer_cropping_1d()</a></code> 
        </dt>
        <dd>Cropping layer for 1D input (e.g. temporal sequence).</dd>
      </dl><dl><dt>
          
          <code><a href="layer_cropping_2d.html">layer_cropping_2d()</a></code> 
        </dt>
        <dd>Cropping layer for 2D input (e.g. picture).</dd>
      </dl><dl><dt>
          
          <code><a href="layer_cropping_3d.html">layer_cropping_3d()</a></code> 
        </dt>
        <dd>Cropping layer for 3D data (e.g. spatial or spatio-temporal).</dd>
      </dl><dl><dt>
          
          <code><a href="layer_flatten.html">layer_flatten()</a></code> 
        </dt>
        <dd>Flattens the input. Does not affect the batch size.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_permute.html">layer_permute()</a></code> 
        </dt>
        <dd>Permutes the dimensions of the input according to a given pattern.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_repeat_vector.html">layer_repeat_vector()</a></code> 
        </dt>
        <dd>Repeats the input n times.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_reshape.html">layer_reshape()</a></code> 
        </dt>
        <dd>Layer that reshapes inputs into the given shape.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_upsampling_1d.html">layer_upsampling_1d()</a></code> 
        </dt>
        <dd>Upsampling layer for 1D inputs.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_upsampling_2d.html">layer_upsampling_2d()</a></code> 
        </dt>
        <dd>Upsampling layer for 2D inputs.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_upsampling_3d.html">layer_upsampling_3d()</a></code> 
        </dt>
        <dd>Upsampling layer for 3D inputs.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_zero_padding_1d.html">layer_zero_padding_1d()</a></code> 
        </dt>
        <dd>Zero-padding layer for 1D input (e.g. temporal sequence).</dd>
      </dl><dl><dt>
          
          <code><a href="layer_zero_padding_2d.html">layer_zero_padding_2d()</a></code> 
        </dt>
        <dd>Zero-padding layer for 2D input (e.g. picture).</dd>
      </dl><dl><dt>
          
          <code><a href="layer_zero_padding_3d.html">layer_zero_padding_3d()</a></code> 
        </dt>
        <dd>Zero-padding layer for 3D data (spatial or spatio-temporal).</dd>
      </dl></div><div class="section level2">
      
      <h3 id="convolutional-layers">Convolutional Layers<a class="anchor" aria-label="anchor" href="#convolutional-layers"></a></h3>
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="layer_conv_1d.html">layer_conv_1d()</a></code> 
        </dt>
        <dd>1D convolution layer (e.g. temporal convolution).</dd>
      </dl><dl><dt>
          
          <code><a href="layer_conv_1d_transpose.html">layer_conv_1d_transpose()</a></code> 
        </dt>
        <dd>1D transposed convolution layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_conv_2d.html">layer_conv_2d()</a></code> 
        </dt>
        <dd>2D convolution layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_conv_2d_transpose.html">layer_conv_2d_transpose()</a></code> 
        </dt>
        <dd>2D transposed convolution layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_conv_3d.html">layer_conv_3d()</a></code> 
        </dt>
        <dd>3D convolution layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_conv_3d_transpose.html">layer_conv_3d_transpose()</a></code> 
        </dt>
        <dd>3D transposed convolution layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_depthwise_conv_1d.html">layer_depthwise_conv_1d()</a></code> 
        </dt>
        <dd>1D depthwise convolution layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_depthwise_conv_2d.html">layer_depthwise_conv_2d()</a></code> 
        </dt>
        <dd>2D depthwise convolution layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_separable_conv_1d.html">layer_separable_conv_1d()</a></code> 
        </dt>
        <dd>1D separable convolution layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_separable_conv_2d.html">layer_separable_conv_2d()</a></code> 
        </dt>
        <dd>2D separable convolution layer.</dd>
      </dl></div><div class="section level2">
      
      <h3 id="pooling-layers">Pooling Layers<a class="anchor" aria-label="anchor" href="#pooling-layers"></a></h3>
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="layer_average_pooling_1d.html">layer_average_pooling_1d()</a></code> 
        </dt>
        <dd>Average pooling for temporal data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_average_pooling_2d.html">layer_average_pooling_2d()</a></code> 
        </dt>
        <dd>Average pooling operation for 2D spatial data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_average_pooling_3d.html">layer_average_pooling_3d()</a></code> 
        </dt>
        <dd>Average pooling operation for 3D data (spatial or spatio-temporal).</dd>
      </dl><dl><dt>
          
          <code><a href="layer_global_average_pooling_1d.html">layer_global_average_pooling_1d()</a></code> 
        </dt>
        <dd>Global average pooling operation for temporal data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_global_average_pooling_2d.html">layer_global_average_pooling_2d()</a></code> 
        </dt>
        <dd>Global average pooling operation for 2D data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_global_average_pooling_3d.html">layer_global_average_pooling_3d()</a></code> 
        </dt>
        <dd>Global average pooling operation for 3D data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_global_max_pooling_1d.html">layer_global_max_pooling_1d()</a></code> 
        </dt>
        <dd>Global max pooling operation for temporal data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_global_max_pooling_2d.html">layer_global_max_pooling_2d()</a></code> 
        </dt>
        <dd>Global max pooling operation for 2D data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_global_max_pooling_3d.html">layer_global_max_pooling_3d()</a></code> 
        </dt>
        <dd>Global max pooling operation for 3D data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_max_pooling_1d.html">layer_max_pooling_1d()</a></code> 
        </dt>
        <dd>Max pooling operation for 1D temporal data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_max_pooling_2d.html">layer_max_pooling_2d()</a></code> 
        </dt>
        <dd>Max pooling operation for 2D spatial data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_max_pooling_3d.html">layer_max_pooling_3d()</a></code> 
        </dt>
        <dd>Max pooling operation for 3D data (spatial or spatio-temporal).</dd>
      </dl></div><div class="section level2">
      
      <h3 id="activation-layers">Activation Layers<a class="anchor" aria-label="anchor" href="#activation-layers"></a></h3>
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="layer_activation.html">layer_activation()</a></code> 
        </dt>
        <dd>Applies an activation function to an output.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_activation_elu.html">layer_activation_elu()</a></code> 
        </dt>
        <dd>Applies an Exponential Linear Unit function to an output.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_activation_leaky_relu.html">layer_activation_leaky_relu()</a></code> 
        </dt>
        <dd>Leaky version of a Rectified Linear Unit activation layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_activation_parametric_relu.html">layer_activation_parametric_relu()</a></code> 
        </dt>
        <dd>Parametric Rectified Linear Unit activation layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_activation_relu.html">layer_activation_relu()</a></code> 
        </dt>
        <dd>Rectified Linear Unit activation function layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_activation_softmax.html">layer_activation_softmax()</a></code> 
        </dt>
        <dd>Softmax activation layer.</dd>
      </dl></div><div class="section level2">
      
      <h3 id="recurrent-layers">Recurrent Layers<a class="anchor" aria-label="anchor" href="#recurrent-layers"></a></h3>
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="layer_bidirectional.html">layer_bidirectional()</a></code> 
        </dt>
        <dd>Bidirectional wrapper for RNNs.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_conv_lstm_1d.html">layer_conv_lstm_1d()</a></code> 
        </dt>
        <dd>1D Convolutional LSTM.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_conv_lstm_2d.html">layer_conv_lstm_2d()</a></code> 
        </dt>
        <dd>2D Convolutional LSTM.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_conv_lstm_3d.html">layer_conv_lstm_3d()</a></code> 
        </dt>
        <dd>3D Convolutional LSTM.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_gru.html">layer_gru()</a></code> 
        </dt>
        <dd>Gated Recurrent Unit - Cho et al. 2014.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_gru_cell.html">layer_gru_cell()</a></code> 
        </dt>
        <dd>Cell class for the GRU layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_lstm.html">layer_lstm()</a></code> 
        </dt>
        <dd>Long Short-Term Memory layer - Hochreiter 1997.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_lstm_cell.html">layer_lstm_cell()</a></code> 
        </dt>
        <dd>Cell class for the LSTM layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_rnn.html">layer_rnn()</a></code> 
        </dt>
        <dd>Base class for recurrent layers.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_simple_rnn.html">layer_simple_rnn()</a></code> 
        </dt>
        <dd>Fully-connected RNN where the output is to be fed back as the new input.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_simple_rnn_cell.html">layer_simple_rnn_cell()</a></code> 
        </dt>
        <dd>Cell class for SimpleRNN.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_stacked_rnn_cells.html">layer_stacked_rnn_cells()</a></code> 
        </dt>
        <dd>Wrapper allowing a stack of RNN cells to behave as a single cell.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_time_distributed.html">layer_time_distributed()</a></code> 
        </dt>
        <dd>This wrapper allows to apply a layer to every temporal slice of an input.</dd>
      </dl></div><div class="section level2">
      
      <h3 id="preprocessing-layers">preprocessing Layers<a class="anchor" aria-label="anchor" href="#preprocessing-layers"></a></h3>
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="layer_category_encoding.html">layer_category_encoding()</a></code> 
        </dt>
        <dd>A preprocessing layer which encodes integer features.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_center_crop.html">layer_center_crop()</a></code> 
        </dt>
        <dd>A preprocessing layer which crops images.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_discretization.html">layer_discretization()</a></code> 
        </dt>
        <dd>A preprocessing layer which buckets continuous features by ranges.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_feature_space.html">layer_feature_space()</a></code> 
        </dt>
        <dd>One-stop utility for preprocessing and encoding structured data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_hashed_crossing.html">layer_hashed_crossing()</a></code> 
        </dt>
        <dd>A preprocessing layer which crosses features using the "hashing trick".</dd>
      </dl><dl><dt>
          
          <code><a href="layer_hashing.html">layer_hashing()</a></code> 
        </dt>
        <dd>A preprocessing layer which hashes and bins categorical features.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_integer_lookup.html">layer_integer_lookup()</a></code> 
        </dt>
        <dd>A preprocessing layer that maps integers to (possibly encoded) indices.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_normalization.html">layer_normalization()</a></code> 
        </dt>
        <dd>A preprocessing layer that normalizes continuous features.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_random_brightness.html">layer_random_brightness()</a></code> 
        </dt>
        <dd>A preprocessing layer which randomly adjusts brightness during training.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_random_contrast.html">layer_random_contrast()</a></code> 
        </dt>
        <dd>A preprocessing layer which randomly adjusts contrast during training.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_random_crop.html">layer_random_crop()</a></code> 
        </dt>
        <dd>A preprocessing layer which randomly crops images during training.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_random_flip.html">layer_random_flip()</a></code> 
        </dt>
        <dd>A preprocessing layer which randomly flips images during training.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_random_rotation.html">layer_random_rotation()</a></code> 
        </dt>
        <dd>A preprocessing layer which randomly rotates images during training.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_random_translation.html">layer_random_translation()</a></code> 
        </dt>
        <dd>A preprocessing layer which randomly translates images during training.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_random_zoom.html">layer_random_zoom()</a></code> 
        </dt>
        <dd>A preprocessing layer which randomly zooms images during training.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_rescaling.html">layer_rescaling()</a></code> 
        </dt>
        <dd>A preprocessing layer which rescales input values to a new range.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_resizing.html">layer_resizing()</a></code> 
        </dt>
        <dd>A preprocessing layer which resizes images.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_string_lookup.html">layer_string_lookup()</a></code> 
        </dt>
        <dd>A preprocessing layer that maps strings to (possibly encoded) indices.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_text_vectorization.html">layer_text_vectorization()</a></code> <code><a href="layer_text_vectorization.html">get_vocabulary()</a></code> <code><a href="layer_text_vectorization.html">set_vocabulary()</a></code> 
        </dt>
        <dd>A preprocessing layer which maps text features to integer sequences.</dd>
      </dl></div><div class="section level2">
      
      <h3 id="attention-layers">Attention Layers<a class="anchor" aria-label="anchor" href="#attention-layers"></a></h3>
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="layer_additive_attention.html">layer_additive_attention()</a></code> 
        </dt>
        <dd>Additive attention layer, a.k.a. Bahdanau-style attention.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_attention.html">layer_attention()</a></code> 
        </dt>
        <dd>Dot-product attention layer, a.k.a. Luong-style attention.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_group_query_attention.html">layer_group_query_attention()</a></code> 
        </dt>
        <dd>Grouped Query Attention layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_multi_head_attention.html">layer_multi_head_attention()</a></code> 
        </dt>
        <dd>MultiHeadAttention layer.</dd>
      </dl></div><div class="section level2">
      
      <h3 id="normalization-layers">Normalization Layers<a class="anchor" aria-label="anchor" href="#normalization-layers"></a></h3>
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="layer_batch_normalization.html">layer_batch_normalization()</a></code> 
        </dt>
        <dd>Layer that normalizes its inputs.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_group_normalization.html">layer_group_normalization()</a></code> 
        </dt>
        <dd>Group normalization layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_layer_normalization.html">layer_layer_normalization()</a></code> 
        </dt>
        <dd>Layer normalization layer (Ba et al., 2016).</dd>
      </dl><dl><dt>
          
          <code><a href="layer_spectral_normalization.html">layer_spectral_normalization()</a></code> 
        </dt>
        <dd>Performs spectral normalization on the weights of a target layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_unit_normalization.html">layer_unit_normalization()</a></code> 
        </dt>
        <dd>Unit normalization layer.</dd>
      </dl></div><div class="section level2">
      
      <h3 id="regularization-layers">Regularization Layers<a class="anchor" aria-label="anchor" href="#regularization-layers"></a></h3>
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="layer_activity_regularization.html">layer_activity_regularization()</a></code> 
        </dt>
        <dd>Layer that applies an update to the cost function based input activity.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_dropout.html">layer_dropout()</a></code> 
        </dt>
        <dd>Applies dropout to the input.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_gaussian_dropout.html">layer_gaussian_dropout()</a></code> 
        </dt>
        <dd>Apply multiplicative 1-centered Gaussian noise.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_gaussian_noise.html">layer_gaussian_noise()</a></code> 
        </dt>
        <dd>Apply additive zero-centered Gaussian noise.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_spatial_dropout_1d.html">layer_spatial_dropout_1d()</a></code> 
        </dt>
        <dd>Spatial 1D version of Dropout.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_spatial_dropout_2d.html">layer_spatial_dropout_2d()</a></code> 
        </dt>
        <dd>Spatial 2D version of Dropout.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_spatial_dropout_3d.html">layer_spatial_dropout_3d()</a></code> 
        </dt>
        <dd>Spatial 3D version of Dropout.</dd>
      </dl></div><div class="section level2">
      
      <h3 id="merge-layers">Merge Layers<a class="anchor" aria-label="anchor" href="#merge-layers"></a></h3>
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="layer_add.html">layer_add()</a></code> 
        </dt>
        <dd>Performs elementwise addition operation.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_average.html">layer_average()</a></code> 
        </dt>
        <dd>Averages a list of inputs element-wise..</dd>
      </dl><dl><dt>
          
          <code><a href="layer_concatenate.html">layer_concatenate()</a></code> 
        </dt>
        <dd>Concatenates a list of inputs.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_dot.html">layer_dot()</a></code> 
        </dt>
        <dd>Computes element-wise dot product of two tensors.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_maximum.html">layer_maximum()</a></code> 
        </dt>
        <dd>Computes element-wise maximum on a list of inputs.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_minimum.html">layer_minimum()</a></code> 
        </dt>
        <dd>Computes elementwise minimum on a list of inputs.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_multiply.html">layer_multiply()</a></code> 
        </dt>
        <dd>Performs elementwise multiplication.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_subtract.html">layer_subtract()</a></code> 
        </dt>
        <dd>Performs elementwise subtraction.</dd>
      </dl></div><div class="section level2">
      
      <h3 id="other-layers">Other Layers<a class="anchor" aria-label="anchor" href="#other-layers"></a></h3>
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="layer_activation.html">layer_activation()</a></code> 
        </dt>
        <dd>Applies an activation function to an output.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_activation_elu.html">layer_activation_elu()</a></code> 
        </dt>
        <dd>Applies an Exponential Linear Unit function to an output.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_activation_leaky_relu.html">layer_activation_leaky_relu()</a></code> 
        </dt>
        <dd>Leaky version of a Rectified Linear Unit activation layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_activation_parametric_relu.html">layer_activation_parametric_relu()</a></code> 
        </dt>
        <dd>Parametric Rectified Linear Unit activation layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_activation_relu.html">layer_activation_relu()</a></code> 
        </dt>
        <dd>Rectified Linear Unit activation function layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_activation_softmax.html">layer_activation_softmax()</a></code> 
        </dt>
        <dd>Softmax activation layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_activity_regularization.html">layer_activity_regularization()</a></code> 
        </dt>
        <dd>Layer that applies an update to the cost function based input activity.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_add.html">layer_add()</a></code> 
        </dt>
        <dd>Performs elementwise addition operation.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_additive_attention.html">layer_additive_attention()</a></code> 
        </dt>
        <dd>Additive attention layer, a.k.a. Bahdanau-style attention.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_attention.html">layer_attention()</a></code> 
        </dt>
        <dd>Dot-product attention layer, a.k.a. Luong-style attention.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_average.html">layer_average()</a></code> 
        </dt>
        <dd>Averages a list of inputs element-wise..</dd>
      </dl><dl><dt>
          
          <code><a href="layer_average_pooling_1d.html">layer_average_pooling_1d()</a></code> 
        </dt>
        <dd>Average pooling for temporal data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_average_pooling_2d.html">layer_average_pooling_2d()</a></code> 
        </dt>
        <dd>Average pooling operation for 2D spatial data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_average_pooling_3d.html">layer_average_pooling_3d()</a></code> 
        </dt>
        <dd>Average pooling operation for 3D data (spatial or spatio-temporal).</dd>
      </dl><dl><dt>
          
          <code><a href="layer_batch_normalization.html">layer_batch_normalization()</a></code> 
        </dt>
        <dd>Layer that normalizes its inputs.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_bidirectional.html">layer_bidirectional()</a></code> 
        </dt>
        <dd>Bidirectional wrapper for RNNs.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_category_encoding.html">layer_category_encoding()</a></code> 
        </dt>
        <dd>A preprocessing layer which encodes integer features.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_center_crop.html">layer_center_crop()</a></code> 
        </dt>
        <dd>A preprocessing layer which crops images.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_concatenate.html">layer_concatenate()</a></code> 
        </dt>
        <dd>Concatenates a list of inputs.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_conv_1d.html">layer_conv_1d()</a></code> 
        </dt>
        <dd>1D convolution layer (e.g. temporal convolution).</dd>
      </dl><dl><dt>
          
          <code><a href="layer_conv_1d_transpose.html">layer_conv_1d_transpose()</a></code> 
        </dt>
        <dd>1D transposed convolution layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_conv_2d.html">layer_conv_2d()</a></code> 
        </dt>
        <dd>2D convolution layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_conv_2d_transpose.html">layer_conv_2d_transpose()</a></code> 
        </dt>
        <dd>2D transposed convolution layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_conv_3d.html">layer_conv_3d()</a></code> 
        </dt>
        <dd>3D convolution layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_conv_3d_transpose.html">layer_conv_3d_transpose()</a></code> 
        </dt>
        <dd>3D transposed convolution layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_conv_lstm_1d.html">layer_conv_lstm_1d()</a></code> 
        </dt>
        <dd>1D Convolutional LSTM.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_conv_lstm_2d.html">layer_conv_lstm_2d()</a></code> 
        </dt>
        <dd>2D Convolutional LSTM.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_conv_lstm_3d.html">layer_conv_lstm_3d()</a></code> 
        </dt>
        <dd>3D Convolutional LSTM.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_cropping_1d.html">layer_cropping_1d()</a></code> 
        </dt>
        <dd>Cropping layer for 1D input (e.g. temporal sequence).</dd>
      </dl><dl><dt>
          
          <code><a href="layer_cropping_2d.html">layer_cropping_2d()</a></code> 
        </dt>
        <dd>Cropping layer for 2D input (e.g. picture).</dd>
      </dl><dl><dt>
          
          <code><a href="layer_cropping_3d.html">layer_cropping_3d()</a></code> 
        </dt>
        <dd>Cropping layer for 3D data (e.g. spatial or spatio-temporal).</dd>
      </dl><dl><dt>
          
          <code><a href="layer_dense.html">layer_dense()</a></code> 
        </dt>
        <dd>Just your regular densely-connected NN layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_depthwise_conv_1d.html">layer_depthwise_conv_1d()</a></code> 
        </dt>
        <dd>1D depthwise convolution layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_depthwise_conv_2d.html">layer_depthwise_conv_2d()</a></code> 
        </dt>
        <dd>2D depthwise convolution layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_discretization.html">layer_discretization()</a></code> 
        </dt>
        <dd>A preprocessing layer which buckets continuous features by ranges.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_dot.html">layer_dot()</a></code> 
        </dt>
        <dd>Computes element-wise dot product of two tensors.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_dropout.html">layer_dropout()</a></code> 
        </dt>
        <dd>Applies dropout to the input.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_einsum_dense.html">layer_einsum_dense()</a></code> 
        </dt>
        <dd>A layer that uses <code>einsum</code> as the backing computation.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_embedding.html">layer_embedding()</a></code> 
        </dt>
        <dd>Turns positive integers (indexes) into dense vectors of fixed size.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_feature_space.html">layer_feature_space()</a></code> 
        </dt>
        <dd>One-stop utility for preprocessing and encoding structured data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_flatten.html">layer_flatten()</a></code> 
        </dt>
        <dd>Flattens the input. Does not affect the batch size.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_gaussian_dropout.html">layer_gaussian_dropout()</a></code> 
        </dt>
        <dd>Apply multiplicative 1-centered Gaussian noise.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_gaussian_noise.html">layer_gaussian_noise()</a></code> 
        </dt>
        <dd>Apply additive zero-centered Gaussian noise.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_global_average_pooling_1d.html">layer_global_average_pooling_1d()</a></code> 
        </dt>
        <dd>Global average pooling operation for temporal data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_global_average_pooling_2d.html">layer_global_average_pooling_2d()</a></code> 
        </dt>
        <dd>Global average pooling operation for 2D data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_global_average_pooling_3d.html">layer_global_average_pooling_3d()</a></code> 
        </dt>
        <dd>Global average pooling operation for 3D data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_global_max_pooling_1d.html">layer_global_max_pooling_1d()</a></code> 
        </dt>
        <dd>Global max pooling operation for temporal data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_global_max_pooling_2d.html">layer_global_max_pooling_2d()</a></code> 
        </dt>
        <dd>Global max pooling operation for 2D data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_global_max_pooling_3d.html">layer_global_max_pooling_3d()</a></code> 
        </dt>
        <dd>Global max pooling operation for 3D data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_group_normalization.html">layer_group_normalization()</a></code> 
        </dt>
        <dd>Group normalization layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_group_query_attention.html">layer_group_query_attention()</a></code> 
        </dt>
        <dd>Grouped Query Attention layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_gru.html">layer_gru()</a></code> 
        </dt>
        <dd>Gated Recurrent Unit - Cho et al. 2014.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_gru_cell.html">layer_gru_cell()</a></code> 
        </dt>
        <dd>Cell class for the GRU layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_hashed_crossing.html">layer_hashed_crossing()</a></code> 
        </dt>
        <dd>A preprocessing layer which crosses features using the "hashing trick".</dd>
      </dl><dl><dt>
          
          <code><a href="layer_hashing.html">layer_hashing()</a></code> 
        </dt>
        <dd>A preprocessing layer which hashes and bins categorical features.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_identity.html">layer_identity()</a></code> 
        </dt>
        <dd>Identity layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_input.html">layer_input()</a></code> 
        </dt>
        <dd>Used to instantiate a Keras tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_integer_lookup.html">layer_integer_lookup()</a></code> 
        </dt>
        <dd>A preprocessing layer that maps integers to (possibly encoded) indices.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_lambda.html">layer_lambda()</a></code> 
        </dt>
        <dd>Wraps arbitrary expressions as a <code>Layer</code> object.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_layer_normalization.html">layer_layer_normalization()</a></code> 
        </dt>
        <dd>Layer normalization layer (Ba et al., 2016).</dd>
      </dl><dl><dt>
          
          <code><a href="layer_lstm.html">layer_lstm()</a></code> 
        </dt>
        <dd>Long Short-Term Memory layer - Hochreiter 1997.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_lstm_cell.html">layer_lstm_cell()</a></code> 
        </dt>
        <dd>Cell class for the LSTM layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_masking.html">layer_masking()</a></code> 
        </dt>
        <dd>Masks a sequence by using a mask value to skip timesteps.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_max_pooling_1d.html">layer_max_pooling_1d()</a></code> 
        </dt>
        <dd>Max pooling operation for 1D temporal data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_max_pooling_2d.html">layer_max_pooling_2d()</a></code> 
        </dt>
        <dd>Max pooling operation for 2D spatial data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_max_pooling_3d.html">layer_max_pooling_3d()</a></code> 
        </dt>
        <dd>Max pooling operation for 3D data (spatial or spatio-temporal).</dd>
      </dl><dl><dt>
          
          <code><a href="layer_maximum.html">layer_maximum()</a></code> 
        </dt>
        <dd>Computes element-wise maximum on a list of inputs.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_minimum.html">layer_minimum()</a></code> 
        </dt>
        <dd>Computes elementwise minimum on a list of inputs.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_multi_head_attention.html">layer_multi_head_attention()</a></code> 
        </dt>
        <dd>MultiHeadAttention layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_multiply.html">layer_multiply()</a></code> 
        </dt>
        <dd>Performs elementwise multiplication.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_normalization.html">layer_normalization()</a></code> 
        </dt>
        <dd>A preprocessing layer that normalizes continuous features.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_permute.html">layer_permute()</a></code> 
        </dt>
        <dd>Permutes the dimensions of the input according to a given pattern.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_random_brightness.html">layer_random_brightness()</a></code> 
        </dt>
        <dd>A preprocessing layer which randomly adjusts brightness during training.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_random_contrast.html">layer_random_contrast()</a></code> 
        </dt>
        <dd>A preprocessing layer which randomly adjusts contrast during training.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_random_crop.html">layer_random_crop()</a></code> 
        </dt>
        <dd>A preprocessing layer which randomly crops images during training.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_random_flip.html">layer_random_flip()</a></code> 
        </dt>
        <dd>A preprocessing layer which randomly flips images during training.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_random_rotation.html">layer_random_rotation()</a></code> 
        </dt>
        <dd>A preprocessing layer which randomly rotates images during training.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_random_translation.html">layer_random_translation()</a></code> 
        </dt>
        <dd>A preprocessing layer which randomly translates images during training.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_random_zoom.html">layer_random_zoom()</a></code> 
        </dt>
        <dd>A preprocessing layer which randomly zooms images during training.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_repeat_vector.html">layer_repeat_vector()</a></code> 
        </dt>
        <dd>Repeats the input n times.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_rescaling.html">layer_rescaling()</a></code> 
        </dt>
        <dd>A preprocessing layer which rescales input values to a new range.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_reshape.html">layer_reshape()</a></code> 
        </dt>
        <dd>Layer that reshapes inputs into the given shape.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_resizing.html">layer_resizing()</a></code> 
        </dt>
        <dd>A preprocessing layer which resizes images.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_rnn.html">layer_rnn()</a></code> 
        </dt>
        <dd>Base class for recurrent layers.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_separable_conv_1d.html">layer_separable_conv_1d()</a></code> 
        </dt>
        <dd>1D separable convolution layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_separable_conv_2d.html">layer_separable_conv_2d()</a></code> 
        </dt>
        <dd>2D separable convolution layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_simple_rnn.html">layer_simple_rnn()</a></code> 
        </dt>
        <dd>Fully-connected RNN where the output is to be fed back as the new input.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_simple_rnn_cell.html">layer_simple_rnn_cell()</a></code> 
        </dt>
        <dd>Cell class for SimpleRNN.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_spatial_dropout_1d.html">layer_spatial_dropout_1d()</a></code> 
        </dt>
        <dd>Spatial 1D version of Dropout.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_spatial_dropout_2d.html">layer_spatial_dropout_2d()</a></code> 
        </dt>
        <dd>Spatial 2D version of Dropout.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_spatial_dropout_3d.html">layer_spatial_dropout_3d()</a></code> 
        </dt>
        <dd>Spatial 3D version of Dropout.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_spectral_normalization.html">layer_spectral_normalization()</a></code> 
        </dt>
        <dd>Performs spectral normalization on the weights of a target layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_stacked_rnn_cells.html">layer_stacked_rnn_cells()</a></code> 
        </dt>
        <dd>Wrapper allowing a stack of RNN cells to behave as a single cell.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_string_lookup.html">layer_string_lookup()</a></code> 
        </dt>
        <dd>A preprocessing layer that maps strings to (possibly encoded) indices.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_subtract.html">layer_subtract()</a></code> 
        </dt>
        <dd>Performs elementwise subtraction.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_text_vectorization.html">layer_text_vectorization()</a></code> <code><a href="layer_text_vectorization.html">get_vocabulary()</a></code> <code><a href="layer_text_vectorization.html">set_vocabulary()</a></code> 
        </dt>
        <dd>A preprocessing layer which maps text features to integer sequences.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_tfsm.html">layer_tfsm()</a></code> 
        </dt>
        <dd>Reload a Keras model/layer that was saved via SavedModel / ExportArchive.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_time_distributed.html">layer_time_distributed()</a></code> 
        </dt>
        <dd>This wrapper allows to apply a layer to every temporal slice of an input.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_torch_module_wrapper.html">layer_torch_module_wrapper()</a></code> 
        </dt>
        <dd>Torch module wrapper layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_unit_normalization.html">layer_unit_normalization()</a></code> 
        </dt>
        <dd>Unit normalization layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_upsampling_1d.html">layer_upsampling_1d()</a></code> 
        </dt>
        <dd>Upsampling layer for 1D inputs.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_upsampling_2d.html">layer_upsampling_2d()</a></code> 
        </dt>
        <dd>Upsampling layer for 2D inputs.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_upsampling_3d.html">layer_upsampling_3d()</a></code> 
        </dt>
        <dd>Upsampling layer for 3D inputs.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_zero_padding_1d.html">layer_zero_padding_1d()</a></code> 
        </dt>
        <dd>Zero-padding layer for 1D input (e.g. temporal sequence).</dd>
      </dl><dl><dt>
          
          <code><a href="layer_zero_padding_2d.html">layer_zero_padding_2d()</a></code> 
        </dt>
        <dd>Zero-padding layer for 2D input (e.g. picture).</dd>
      </dl><dl><dt>
          
          <code><a href="layer_zero_padding_3d.html">layer_zero_padding_3d()</a></code> 
        </dt>
        <dd>Zero-padding layer for 3D data (spatial or spatio-temporal).</dd>
      </dl></div><div class="section level2">
      <h2 id="layer-methods">Layer Methods<a class="anchor" aria-label="anchor" href="#layer-methods"></a></h2>
      
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="get_config.html">get_config()</a></code> <code><a href="get_config.html">from_config()</a></code> 
        </dt>
        <dd>Layer/Model configuration</dd>
      </dl><dl><dt>
          
          <code><a href="get_weights.html">get_weights()</a></code> <code><a href="get_weights.html">set_weights()</a></code> 
        </dt>
        <dd>Layer/Model weights as R arrays</dd>
      </dl><dl><dt>
          
          <code><a href="get_input_at.html">get_input_at()</a></code> <code><a href="get_input_at.html">get_output_at()</a></code> <code><a href="get_input_at.html">get_input_shape_at()</a></code> <code><a href="get_input_at.html">get_output_shape_at()</a></code> <code><a href="get_input_at.html">get_input_mask_at()</a></code> <code><a href="get_input_at.html">get_output_mask_at()</a></code> 
        </dt>
        <dd>Retrieve tensors for layers with multiple nodes</dd>
      </dl><dl><dt>
          
          <code><a href="count_params.html">count_params()</a></code> 
        </dt>
        <dd>Count the total number of scalars composing the weights.</dd>
      </dl><dl><dt>
          
          <code><a href="reset_states.html">reset_states()</a></code> 
        </dt>
        <dd>Reset the states for a layer</dd>
      </dl></div><div class="section level2">
      <h2 id="custom-layers">Custom Layers<a class="anchor" aria-label="anchor" href="#custom-layers"></a></h2>
      
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="grapes-py_class-grapes.html">`%py_class%`</a></code> 
        </dt>
        <dd>Make a python class constructor</dd>
      </dl><dl><dt>
          
          <code><a href="Layer.html">Layer()</a></code> 
        </dt>
        <dd>(Deprecated) Create a custom Layer</dd>
      </dl><dl><dt>
          
          <code><a href="create_layer_wrapper.html">create_layer_wrapper()</a></code> 
        </dt>
        <dd>Create a Keras Layer wrapper</dd>
      </dl><dl><dt>
          
          <code><a href="create_layer.html">create_layer()</a></code> 
        </dt>
        <dd>Create a Keras Layer</dd>
      </dl></div><div class="section level2">
      <h2 id="model-persistence">Model Persistence<a class="anchor" aria-label="anchor" href="#model-persistence"></a></h2>
      
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="save_model_hdf5.html">save_model_hdf5()</a></code> <code><a href="save_model_hdf5.html">load_model_hdf5()</a></code> 
        </dt>
        <dd>Save/Load models using HDF5 files</dd>
      </dl><dl><dt>
          
          <code><a href="save_model_weights_hdf5.html">save_model_weights_hdf5()</a></code> <code><a href="save_model_weights_hdf5.html">load_model_weights_hdf5()</a></code> 
        </dt>
        <dd>Save/Load model weights using HDF5 files</dd>
      </dl><dl><dt>
          
          <code><a href="serialize_model.html">serialize_model()</a></code> <code><a href="serialize_model.html">unserialize_model()</a></code> 
        </dt>
        <dd>Serialize a model to an R object</dd>
      </dl><dl><dt>
          
          <code><a href="get_weights.html">get_weights()</a></code> <code><a href="get_weights.html">set_weights()</a></code> 
        </dt>
        <dd>Layer/Model weights as R arrays</dd>
      </dl><dl><dt>
          
          <code><a href="get_config.html">get_config()</a></code> <code><a href="get_config.html">from_config()</a></code> 
        </dt>
        <dd>Layer/Model configuration</dd>
      </dl><dl><dt>
          
          <code><a href="model_to_saved_model.html">model_to_saved_model()</a></code> 
        </dt>
        <dd>(Deprecated) Export to Saved Model format</dd>
      </dl><dl><dt>
          
          <code><a href="model_from_saved_model.html">model_from_saved_model()</a></code> 
        </dt>
        <dd>Load a Keras model from the Saved Model format</dd>
      </dl><dl><dt>
          
          <code><a href="save_model_tf.html">save_model_tf()</a></code> <code><a href="save_model_tf.html">load_model_tf()</a></code> 
        </dt>
        <dd>Save/Load models using SavedModel format</dd>
      </dl><dl><dt>
          
          <code><a href="save_model_weights_tf.html">save_model_weights_tf()</a></code> <code><a href="save_model_weights_tf.html">load_model_weights_tf()</a></code> 
        </dt>
        <dd>Save model weights in the SavedModel format</dd>
      </dl><dl><dt>
          
          <code><a href="model_to_json.html">model_to_json()</a></code> <code><a href="model_to_json.html">model_from_json()</a></code> 
        </dt>
        <dd>Model configuration as JSON</dd>
      </dl><dl><dt>
          
          <code><a href="model_to_yaml.html">model_to_yaml()</a></code> <code><a href="model_to_yaml.html">model_from_yaml()</a></code> 
        </dt>
        <dd>Model configuration as YAML</dd>
      </dl></div><div class="section level2">
      <h2 id="datasets">Datasets<a class="anchor" aria-label="anchor" href="#datasets"></a></h2>
      
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="dataset_boston_housing.html">dataset_boston_housing()</a></code> 
        </dt>
        <dd>Boston housing price regression dataset</dd>
      </dl><dl><dt>
          
          <code><a href="dataset_cifar10.html">dataset_cifar10()</a></code> 
        </dt>
        <dd>CIFAR10 small image classification</dd>
      </dl><dl><dt>
          
          <code><a href="dataset_cifar100.html">dataset_cifar100()</a></code> 
        </dt>
        <dd>CIFAR100 small image classification</dd>
      </dl><dl><dt>
          
          <code><a href="dataset_fashion_mnist.html">dataset_fashion_mnist()</a></code> 
        </dt>
        <dd>Fashion-MNIST database of fashion articles</dd>
      </dl><dl><dt>
          
          <code><a href="dataset_imdb.html">dataset_imdb()</a></code> <code><a href="dataset_imdb.html">dataset_imdb_word_index()</a></code> 
        </dt>
        <dd>IMDB Movie reviews sentiment classification</dd>
      </dl><dl><dt>
          
          <code><a href="dataset_mnist.html">dataset_mnist()</a></code> 
        </dt>
        <dd>MNIST database of handwritten digits</dd>
      </dl><dl><dt>
          
          <code><a href="dataset_reuters.html">dataset_reuters()</a></code> <code><a href="dataset_reuters.html">dataset_reuters_word_index()</a></code> 
        </dt>
        <dd>Reuters newswire topics classification</dd>
      </dl></div><div class="section level2">
      <h2 id="applications">Applications<a class="anchor" aria-label="anchor" href="#applications"></a></h2>
      
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="application_convnext_base.html">application_convnext_base()</a></code> 
        </dt>
        <dd>Instantiates the ConvNeXtBase architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_convnext_large.html">application_convnext_large()</a></code> 
        </dt>
        <dd>Instantiates the ConvNeXtLarge architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_convnext_small.html">application_convnext_small()</a></code> 
        </dt>
        <dd>Instantiates the ConvNeXtSmall architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_convnext_tiny.html">application_convnext_tiny()</a></code> 
        </dt>
        <dd>Instantiates the ConvNeXtTiny architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_convnext_xlarge.html">application_convnext_xlarge()</a></code> 
        </dt>
        <dd>Instantiates the ConvNeXtXLarge architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_densenet121.html">application_densenet121()</a></code> 
        </dt>
        <dd>Instantiates the Densenet121 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_densenet169.html">application_densenet169()</a></code> 
        </dt>
        <dd>Instantiates the Densenet169 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_densenet201.html">application_densenet201()</a></code> 
        </dt>
        <dd>Instantiates the Densenet201 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_efficientnet_b0.html">application_efficientnet_b0()</a></code> 
        </dt>
        <dd>Instantiates the EfficientNetB0 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_efficientnet_b1.html">application_efficientnet_b1()</a></code> 
        </dt>
        <dd>Instantiates the EfficientNetB1 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_efficientnet_b2.html">application_efficientnet_b2()</a></code> 
        </dt>
        <dd>Instantiates the EfficientNetB2 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_efficientnet_b3.html">application_efficientnet_b3()</a></code> 
        </dt>
        <dd>Instantiates the EfficientNetB3 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_efficientnet_b4.html">application_efficientnet_b4()</a></code> 
        </dt>
        <dd>Instantiates the EfficientNetB4 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_efficientnet_b5.html">application_efficientnet_b5()</a></code> 
        </dt>
        <dd>Instantiates the EfficientNetB5 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_efficientnet_b6.html">application_efficientnet_b6()</a></code> 
        </dt>
        <dd>Instantiates the EfficientNetB6 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_efficientnet_b7.html">application_efficientnet_b7()</a></code> 
        </dt>
        <dd>Instantiates the EfficientNetB7 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_efficientnet_v2b0.html">application_efficientnet_v2b0()</a></code> 
        </dt>
        <dd>Instantiates the EfficientNetV2B0 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_efficientnet_v2b1.html">application_efficientnet_v2b1()</a></code> 
        </dt>
        <dd>Instantiates the EfficientNetV2B1 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_efficientnet_v2b2.html">application_efficientnet_v2b2()</a></code> 
        </dt>
        <dd>Instantiates the EfficientNetV2B2 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_efficientnet_v2b3.html">application_efficientnet_v2b3()</a></code> 
        </dt>
        <dd>Instantiates the EfficientNetV2B3 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_efficientnet_v2l.html">application_efficientnet_v2l()</a></code> 
        </dt>
        <dd>Instantiates the EfficientNetV2L architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_efficientnet_v2m.html">application_efficientnet_v2m()</a></code> 
        </dt>
        <dd>Instantiates the EfficientNetV2M architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_efficientnet_v2s.html">application_efficientnet_v2s()</a></code> 
        </dt>
        <dd>Instantiates the EfficientNetV2S architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_inception_resnet_v2.html">application_inception_resnet_v2()</a></code> 
        </dt>
        <dd>Instantiates the Inception-ResNet v2 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_inception_v3.html">application_inception_v3()</a></code> 
        </dt>
        <dd>Instantiates the Inception v3 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_mobilenet.html">application_mobilenet()</a></code> 
        </dt>
        <dd>Instantiates the MobileNet architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_mobilenet_v2.html">application_mobilenet_v2()</a></code> 
        </dt>
        <dd>Instantiates the MobileNetV2 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_mobilenet_v3_large.html">application_mobilenet_v3_large()</a></code> 
        </dt>
        <dd>Instantiates the MobileNetV3Large architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_mobilenet_v3_small.html">application_mobilenet_v3_small()</a></code> 
        </dt>
        <dd>Instantiates the MobileNetV3Small architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_nasnetlarge.html">application_nasnetlarge()</a></code> 
        </dt>
        <dd>Instantiates a NASNet model in ImageNet mode.</dd>
      </dl><dl><dt>
          
          <code><a href="application_nasnetmobile.html">application_nasnetmobile()</a></code> 
        </dt>
        <dd>Instantiates a Mobile NASNet model in ImageNet mode.</dd>
      </dl><dl><dt>
          
          <code><a href="application_resnet101.html">application_resnet101()</a></code> 
        </dt>
        <dd>Instantiates the ResNet101 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_resnet101_v2.html">application_resnet101_v2()</a></code> 
        </dt>
        <dd>Instantiates the ResNet101V2 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_resnet152.html">application_resnet152()</a></code> 
        </dt>
        <dd>Instantiates the ResNet152 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_resnet152_v2.html">application_resnet152_v2()</a></code> 
        </dt>
        <dd>Instantiates the ResNet152V2 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_resnet50.html">application_resnet50()</a></code> 
        </dt>
        <dd>Instantiates the ResNet50 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_resnet50_v2.html">application_resnet50_v2()</a></code> 
        </dt>
        <dd>Instantiates the ResNet50V2 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_vgg16.html">application_vgg16()</a></code> 
        </dt>
        <dd>Instantiates the VGG16 model.</dd>
      </dl><dl><dt>
          
          <code><a href="application_vgg19.html">application_vgg19()</a></code> 
        </dt>
        <dd>Instantiates the VGG19 model.</dd>
      </dl><dl><dt>
          
          <code><a href="application_xception.html">application_xception()</a></code> 
        </dt>
        <dd>Instantiates the Xception architecture.</dd>
      </dl></div><div class="section level2">
      <h2 id="sequence-preprocessing">Sequence Preprocessing<a class="anchor" aria-label="anchor" href="#sequence-preprocessing"></a></h2>
      
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="pad_sequences.html">pad_sequences()</a></code> 
        </dt>
        <dd>Pads sequences to the same length.</dd>
      </dl><dl><dt>
          
          <code><a href="timeseries_dataset_from_array.html">timeseries_dataset_from_array()</a></code> 
        </dt>
        <dd>Creates a dataset of sliding windows over a timeseries provided as array.</dd>
      </dl></div><div class="section level2">
      <h2 id="text-preprocessing">Text Preprocessing<a class="anchor" aria-label="anchor" href="#text-preprocessing"></a></h2>
      
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="text_dataset_from_directory.html">text_dataset_from_directory()</a></code> 
        </dt>
        <dd>Generates a <code>tf.data.Dataset</code> from text files in a directory.</dd>
      </dl></div><div class="section level2">
      <h2 id="image-preprocessing">Image Preprocessing<a class="anchor" aria-label="anchor" href="#image-preprocessing"></a></h2>
      
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="image_array_save.html">image_array_save()</a></code> 
        </dt>
        <dd>Saves an image stored as a NumPy array to a path or file object.</dd>
      </dl><dl><dt>
          
          <code><a href="image_dataset_from_directory.html">image_dataset_from_directory()</a></code> 
        </dt>
        <dd>Generates a <code>tf.data.Dataset</code> from image files in a directory.</dd>
      </dl><dl><dt>
          
          <code><a href="image_from_array.html">image_from_array()</a></code> 
        </dt>
        <dd>Converts a 3D array to a PIL Image instance.</dd>
      </dl><dl><dt>
          
          <code><a href="image_load.html">image_load()</a></code> 
        </dt>
        <dd>Loads an image into PIL format.</dd>
      </dl><dl><dt>
          
          <code><a href="image_smart_resize.html">image_smart_resize()</a></code> 
        </dt>
        <dd>Resize images to a target size without aspect ratio distortion.</dd>
      </dl><dl><dt>
          
          <code><a href="image_to_array.html">image_to_array()</a></code> 
        </dt>
        <dd>Converts a PIL Image instance to a matrix.</dd>
      </dl><dl><dt>
          
          <code><a href="k_image_affine_transform.html">k_image_affine_transform()</a></code> 
        </dt>
        <dd>Applies the given transform(s) to the image(s).</dd>
      </dl><dl><dt>
          
          <code><a href="k_image_extract_patches.html">k_image_extract_patches()</a></code> 
        </dt>
        <dd>Extracts patches from the image(s).</dd>
      </dl><dl><dt>
          
          <code><a href="k_image_map_coordinates.html">k_image_map_coordinates()</a></code> 
        </dt>
        <dd>Map the input array to new coordinates by interpolation..</dd>
      </dl><dl><dt>
          
          <code><a href="k_image_pad_images.html">k_image_pad_images()</a></code> 
        </dt>
        <dd>Pad <code>images</code> with zeros to the specified <code>height</code> and <code>width</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_image_resize.html">k_image_resize()</a></code> 
        </dt>
        <dd>Resize images to size using the specified interpolation method.</dd>
      </dl></div><div class="section level2">
      <h2 id="optimizers">Optimizers<a class="anchor" aria-label="anchor" href="#optimizers"></a></h2>
      
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="optimizer_adadelta.html">optimizer_adadelta()</a></code> 
        </dt>
        <dd>Optimizer that implements the Adadelta algorithm.</dd>
      </dl><dl><dt>
          
          <code><a href="optimizer_adafactor.html">optimizer_adafactor()</a></code> 
        </dt>
        <dd>Optimizer that implements the Adafactor algorithm.</dd>
      </dl><dl><dt>
          
          <code><a href="optimizer_adagrad.html">optimizer_adagrad()</a></code> 
        </dt>
        <dd>Optimizer that implements the Adagrad algorithm.</dd>
      </dl><dl><dt>
          
          <code><a href="optimizer_adam.html">optimizer_adam()</a></code> 
        </dt>
        <dd>Optimizer that implements the Adam algorithm.</dd>
      </dl><dl><dt>
          
          <code><a href="optimizer_adam_w.html">optimizer_adam_w()</a></code> 
        </dt>
        <dd>Optimizer that implements the AdamW algorithm.</dd>
      </dl><dl><dt>
          
          <code><a href="optimizer_adamax.html">optimizer_adamax()</a></code> 
        </dt>
        <dd>Optimizer that implements the Adamax algorithm.</dd>
      </dl><dl><dt>
          
          <code><a href="optimizer_ftrl.html">optimizer_ftrl()</a></code> 
        </dt>
        <dd>Optimizer that implements the FTRL algorithm.</dd>
      </dl><dl><dt>
          
          <code><a href="optimizer_lion.html">optimizer_lion()</a></code> 
        </dt>
        <dd>Optimizer that implements the Lion algorithm.</dd>
      </dl><dl><dt>
          
          <code><a href="optimizer_loss_scale.html">optimizer_loss_scale()</a></code> 
        </dt>
        <dd>An optimizer that dynamically scales the loss to prevent underflow.</dd>
      </dl><dl><dt>
          
          <code><a href="optimizer_nadam.html">optimizer_nadam()</a></code> 
        </dt>
        <dd>Optimizer that implements the Nadam algorithm.</dd>
      </dl><dl><dt>
          
          <code><a href="optimizer_rmsprop.html">optimizer_rmsprop()</a></code> 
        </dt>
        <dd>Optimizer that implements the RMSprop algorithm.</dd>
      </dl><dl><dt>
          
          <code><a href="optimizer_sgd.html">optimizer_sgd()</a></code> 
        </dt>
        <dd>Gradient descent (with momentum) optimizer.</dd>
      </dl></div><div class="section level2">
      <h2 id="learning-rate-schedules">Learning Rate Schedules<a class="anchor" aria-label="anchor" href="#learning-rate-schedules"></a></h2>
      
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="learning_rate_schedule_cosine_decay.html">learning_rate_schedule_cosine_decay()</a></code> <code><a href="learning_rate_schedule_cosine_decay.html">learning_rate_schedule_cosine_decay()</a></code> 
        </dt>
        <dd>A <code>LearningRateSchedule</code> that uses a cosine decay with optional warmup.</dd>
      </dl><dl><dt>
          
          <code><a href="learning_rate_schedule_cosine_decay_restarts.html">learning_rate_schedule_cosine_decay_restarts()</a></code> <code><a href="learning_rate_schedule_cosine_decay_restarts.html">learning_rate_schedule_cosine_decay_restarts()</a></code> 
        </dt>
        <dd>A <code>LearningRateSchedule</code> that uses a cosine decay schedule with restarts.</dd>
      </dl><dl><dt>
          
          <code><a href="learning_rate_schedule_exponential_decay.html">learning_rate_schedule_exponential_decay()</a></code> <code><a href="learning_rate_schedule_exponential_decay.html">learning_rate_schedule_exponential_decay()</a></code> 
        </dt>
        <dd>A <code>LearningRateSchedule</code> that uses an exponential decay schedule.</dd>
      </dl><dl><dt>
          
          <code><a href="learning_rate_schedule_inverse_time_decay.html">learning_rate_schedule_inverse_time_decay()</a></code> <code><a href="learning_rate_schedule_inverse_time_decay.html">learning_rate_schedule_inverse_time_decay()</a></code> 
        </dt>
        <dd>A <code>LearningRateSchedule</code> that uses an inverse time decay schedule.</dd>
      </dl><dl><dt>
          
          <code><a href="learning_rate_schedule_piecewise_constant_decay.html">learning_rate_schedule_piecewise_constant_decay()</a></code> <code><a href="learning_rate_schedule_piecewise_constant_decay.html">learning_rate_schedule_piecewise_constant_decay()</a></code> 
        </dt>
        <dd>A <code>LearningRateSchedule</code> that uses a piecewise constant decay schedule.</dd>
      </dl><dl><dt>
          
          <code><a href="learning_rate_schedule_polynomial_decay.html">learning_rate_schedule_polynomial_decay()</a></code> <code><a href="learning_rate_schedule_polynomial_decay.html">learning_rate_schedule_polynomial_decay()</a></code> 
        </dt>
        <dd>A <code>LearningRateSchedule</code> that uses a polynomial decay schedule.</dd>
      </dl><dl><dt>
          
          <code><a href="new_learning_rate_schedule_class.html">new_learning_rate_schedule_class()</a></code> 
        </dt>
        <dd>Create a new learning rate schedule type</dd>
      </dl></div><div class="section level2">
      <h2 id="callbacks">Callbacks<a class="anchor" aria-label="anchor" href="#callbacks"></a></h2>
      
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="callback_backup_and_restore.html">callback_backup_and_restore()</a></code> 
        </dt>
        <dd>Callback to back up and restore the training state.</dd>
      </dl><dl><dt>
          
          <code><a href="callback_csv_logger.html">callback_csv_logger()</a></code> 
        </dt>
        <dd>Callback that streams epoch results to a CSV file.</dd>
      </dl><dl><dt>
          
          <code><a href="callback_early_stopping.html">callback_early_stopping()</a></code> 
        </dt>
        <dd>Stop training when a monitored metric has stopped improving.</dd>
      </dl><dl><dt>
          
          <code><a href="callback_lambda.html">callback_lambda()</a></code> 
        </dt>
        <dd>Callback for creating simple, custom callbacks on-the-fly.</dd>
      </dl><dl><dt>
          
          <code><a href="callback_learning_rate_scheduler.html">callback_learning_rate_scheduler()</a></code> 
        </dt>
        <dd>Learning rate scheduler.</dd>
      </dl><dl><dt>
          
          <code><a href="callback_model_checkpoint.html">callback_model_checkpoint()</a></code> 
        </dt>
        <dd>Callback to save the Keras model or model weights at some frequency.
@description
<code><a href="../reference/callback_model_checkpoint.html">callback_model_checkpoint()</a></code> is used in conjunction with training using
<code>model |&gt; fit()</code> to save a model or weights (in a checkpoint file) at some
interval, so the model or weights can be loaded later to continue the
training from the state saved.</dd>
      </dl><dl><dt>
          
          <code><a href="callback_progbar_logger.html">callback_progbar_logger()</a></code> 
        </dt>
        <dd>Callback that prints metrics to stdout.</dd>
      </dl><dl><dt>
          
          <code><a href="callback_reduce_lr_on_plateau.html">callback_reduce_lr_on_plateau()</a></code> 
        </dt>
        <dd>Reduce learning rate when a metric has stopped improving.</dd>
      </dl><dl><dt>
          
          <code><a href="callback_remote_monitor.html">callback_remote_monitor()</a></code> 
        </dt>
        <dd>Callback used to stream events to a server.</dd>
      </dl><dl><dt>
          
          <code><a href="callback_tensorboard.html">callback_tensorboard()</a></code> 
        </dt>
        <dd>Enable visualizations for TensorBoard.</dd>
      </dl><dl><dt>
          
          <code><a href="callback_terminate_on_nan.html">callback_terminate_on_nan()</a></code> 
        </dt>
        <dd>Callback that terminates training when a NaN loss is encountered.</dd>
      </dl><dl><dt>
          
          <code><a href="KerasCallback.html">KerasCallback</a></code> 
        </dt>
        <dd>(Deprecated) Base R6 class for Keras callbacks</dd>
      </dl></div><div class="section level2">
      <h2 id="initializers">Initializers<a class="anchor" aria-label="anchor" href="#initializers"></a></h2>
      
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="initializer_constant.html">initializer_constant()</a></code> 
        </dt>
        <dd>Initializer that generates tensors with constant values.</dd>
      </dl><dl><dt>
          
          <code><a href="initializer_glorot_normal.html">initializer_glorot_normal()</a></code> 
        </dt>
        <dd>The Glorot normal initializer, also called Xavier normal initializer.</dd>
      </dl><dl><dt>
          
          <code><a href="initializer_glorot_uniform.html">initializer_glorot_uniform()</a></code> 
        </dt>
        <dd>The Glorot uniform initializer, also called Xavier uniform initializer.</dd>
      </dl><dl><dt>
          
          <code><a href="initializer_he_normal.html">initializer_he_normal()</a></code> 
        </dt>
        <dd>He normal initializer.</dd>
      </dl><dl><dt>
          
          <code><a href="initializer_he_uniform.html">initializer_he_uniform()</a></code> 
        </dt>
        <dd>He uniform variance scaling initializer.</dd>
      </dl><dl><dt>
          
          <code><a href="initializer_identity.html">initializer_identity()</a></code> 
        </dt>
        <dd>Initializer that generates the identity matrix.</dd>
      </dl><dl><dt>
          
          <code><a href="initializer_lecun_normal.html">initializer_lecun_normal()</a></code> 
        </dt>
        <dd>Lecun normal initializer.</dd>
      </dl><dl><dt>
          
          <code><a href="initializer_lecun_uniform.html">initializer_lecun_uniform()</a></code> 
        </dt>
        <dd>Lecun uniform initializer.</dd>
      </dl><dl><dt>
          
          <code><a href="initializer_ones.html">initializer_ones()</a></code> 
        </dt>
        <dd>Initializer that generates tensors initialized to 1.</dd>
      </dl><dl><dt>
          
          <code><a href="initializer_orthogonal.html">initializer_orthogonal()</a></code> 
        </dt>
        <dd>Initializer that generates an orthogonal matrix.</dd>
      </dl><dl><dt>
          
          <code><a href="initializer_random_normal.html">initializer_random_normal()</a></code> 
        </dt>
        <dd>Random normal initializer.</dd>
      </dl><dl><dt>
          
          <code><a href="initializer_random_uniform.html">initializer_random_uniform()</a></code> 
        </dt>
        <dd>Random uniform initializer.</dd>
      </dl><dl><dt>
          
          <code><a href="initializer_truncated_normal.html">initializer_truncated_normal()</a></code> 
        </dt>
        <dd>Initializer that generates a truncated normal distribution.</dd>
      </dl><dl><dt>
          
          <code><a href="initializer_variance_scaling.html">initializer_variance_scaling()</a></code> 
        </dt>
        <dd>Initializer that adapts its scale to the shape of its input tensors.</dd>
      </dl><dl><dt>
          
          <code><a href="initializer_zeros.html">initializer_zeros()</a></code> 
        </dt>
        <dd>Initializer that generates tensors initialized to 0.</dd>
      </dl></div><div class="section level2">
      <h2 id="constraints">Constraints<a class="anchor" aria-label="anchor" href="#constraints"></a></h2>
      
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="constraint_maxnorm.html">constraint_maxnorm()</a></code> 
        </dt>
        <dd>MaxNorm weight constraint.</dd>
      </dl><dl><dt>
          
          <code><a href="constraint_minmaxnorm.html">constraint_minmaxnorm()</a></code> 
        </dt>
        <dd>MinMaxNorm weight constraint.</dd>
      </dl><dl><dt>
          
          <code><a href="constraint_nonneg.html">constraint_nonneg()</a></code> 
        </dt>
        <dd>Constrains the weights to be non-negative.</dd>
      </dl><dl><dt>
          
          <code><a href="constraint_unitnorm.html">constraint_unitnorm()</a></code> 
        </dt>
        <dd>Constrains the weights incident to each hidden unit to have unit norm.</dd>
      </dl><dl><dt>
          
          <code><a href="KerasConstraint.html">KerasConstraint</a></code> 
        </dt>
        <dd>(Deprecated) Base R6 class for Keras constraints</dd>
      </dl></div><div class="section level2">
      <h2 id="utils">Utils<a class="anchor" aria-label="anchor" href="#utils"></a></h2>
      
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="audio_dataset_from_directory.html">audio_dataset_from_directory()</a></code> 
        </dt>
        <dd>Generates a <code>tf.data.Dataset</code> from audio files in a directory.</dd>
      </dl><dl><dt>
          
          <code><a href="clear_session.html">clear_session()</a></code> 
        </dt>
        <dd>Resets all state generated by Keras.</dd>
      </dl><dl><dt>
          
          <code><a href="get_custom_objects.html">get_custom_objects()</a></code> 
        </dt>
        <dd>Retrieves a live reference to the global dictionary of custom objects.</dd>
      </dl><dl><dt>
          
          <code><a href="get_file.html">get_file()</a></code> 
        </dt>
        <dd>Downloads a file from a URL if it not already in the cache.</dd>
      </dl><dl><dt>
          
          <code><a href="get_registered_name.html">get_registered_name()</a></code> 
        </dt>
        <dd>Returns the name registered to an object within the Keras framework.</dd>
      </dl><dl><dt>
          
          <code><a href="get_registered_object.html">get_registered_object()</a></code> 
        </dt>
        <dd>Returns the class associated with <code>name</code> if it is registered with Keras.</dd>
      </dl><dl><dt>
          
          <code><a href="get_source_inputs.html">get_source_inputs()</a></code> 
        </dt>
        <dd>Returns the list of input tensors necessary to compute <code>tensor</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="image_array_save.html">image_array_save()</a></code> 
        </dt>
        <dd>Saves an image stored as a NumPy array to a path or file object.</dd>
      </dl><dl><dt>
          
          <code><a href="image_dataset_from_directory.html">image_dataset_from_directory()</a></code> 
        </dt>
        <dd>Generates a <code>tf.data.Dataset</code> from image files in a directory.</dd>
      </dl><dl><dt>
          
          <code><a href="image_from_array.html">image_from_array()</a></code> 
        </dt>
        <dd>Converts a 3D array to a PIL Image instance.</dd>
      </dl><dl><dt>
          
          <code><a href="image_load.html">image_load()</a></code> 
        </dt>
        <dd>Loads an image into PIL format.</dd>
      </dl><dl><dt>
          
          <code><a href="image_to_array.html">image_to_array()</a></code> 
        </dt>
        <dd>Converts a PIL Image instance to a matrix.</dd>
      </dl><dl><dt>
          
          <code><a href="model_to_dot.html">model_to_dot()</a></code> 
        </dt>
        <dd>Convert a Keras model to dot format.</dd>
      </dl><dl><dt>
          
          <code><a href="normalize.html">normalize()</a></code> 
        </dt>
        <dd>Normalizes an array.</dd>
      </dl><dl><dt>
          
          <code><a href="pack_x_y_sample_weight.html">pack_x_y_sample_weight()</a></code> 
        </dt>
        <dd>Packs user-provided data into a tuple.</dd>
      </dl><dl><dt>
          
          <code><a href="pad_sequences.html">pad_sequences()</a></code> 
        </dt>
        <dd>Pads sequences to the same length.</dd>
      </dl><dl><dt>
          
          <code><a href="set_random_seed.html">set_random_seed()</a></code> 
        </dt>
        <dd>Sets all random seeds (Python, NumPy, and backend framework, e.g. TF).</dd>
      </dl><dl><dt>
          
          <code><a href="split_dataset.html">split_dataset()</a></code> 
        </dt>
        <dd>Splits a dataset into a left half and a right half (e.g. train / test).</dd>
      </dl><dl><dt>
          
          <code><a href="text_dataset_from_directory.html">text_dataset_from_directory()</a></code> 
        </dt>
        <dd>Generates a <code>tf.data.Dataset</code> from text files in a directory.</dd>
      </dl><dl><dt>
          
          <code><a href="timeseries_dataset_from_array.html">timeseries_dataset_from_array()</a></code> 
        </dt>
        <dd>Creates a dataset of sliding windows over a timeseries provided as array.</dd>
      </dl><dl><dt>
          
          <code><a href="to_categorical.html">to_categorical()</a></code> 
        </dt>
        <dd>Converts a class vector (integers) to binary class matrix.</dd>
      </dl><dl><dt>
          
          <code><a href="unpack_x_y_sample_weight.html">unpack_x_y_sample_weight()</a></code> 
        </dt>
        <dd>Unpacks user-provided data tuple.</dd>
      </dl><dl><dt>
          
          <code><a href="plot.keras_training_history.html">plot(<i>&lt;keras_training_history&gt;</i>)</a></code> 
        </dt>
        <dd>Plot training history</dd>
      </dl><dl><dt>
          
          <code><a href="plot.keras.models.model.Model.html">plot(<i>&lt;keras.models.model.Model&gt;</i>)</a></code> 
        </dt>
        <dd>Plot a Keras model</dd>
      </dl><dl><dt>
          
          <code><a href="zip_lists.html">zip_lists()</a></code> 
        </dt>
        <dd>zip lists</dd>
      </dl><dl><dt>
          
          <code><a href="new-classes.html">new_metric_class()</a></code> <code><a href="new-classes.html">new_loss_class()</a></code> <code><a href="new-classes.html">new_callback_class()</a></code> <code><a href="new-classes.html">new_model_class()</a></code> <code><a href="new-classes.html">new_layer_class()</a></code> <code><a href="new-classes.html">mark_active()</a></code> 
        </dt>
        <dd>Define new keras types</dd>
      </dl><dl><dt>
          
          <code><a href="timeseries_generator.html">timeseries_generator()</a></code> 
        </dt>
        <dd>Utility function for generating batches of temporal data.</dd>
      </dl><dl><dt>
          
          <code><a href="with_custom_object_scope.html">with_custom_object_scope()</a></code> 
        </dt>
        <dd>Provide a scope with mappings of names to custom objects</dd>
      </dl><dl><dt>
          
          <code><a href="keras_array.html">keras_array()</a></code> 
        </dt>
        <dd>Keras array object</dd>
      </dl><dl><dt>
          
          <code><a href="install_keras.html">install_keras()</a></code> 
        </dt>
        <dd>Install Keras</dd>
      </dl><dl><dt>
          
          <code><a href="is_keras_available.html">is_keras_available()</a></code> 
        </dt>
        <dd>Check if Keras is Available</dd>
      </dl><dl><dt>
          
          <code><a href="backend.html">backend()</a></code> 
        </dt>
        <dd>Keras backend tensor engine</dd>
      </dl><dl><dt>
          
          <code><a href="implementation.html">implementation()</a></code> 
        </dt>
        <dd>Keras implementation</dd>
      </dl><dl><dt>
          
          <code><a href="use_implementation.html">use_implementation()</a></code> <code><a href="use_implementation.html">use_backend()</a></code> 
        </dt>
        <dd>Select a Keras implementation and backend</dd>
      </dl></div><div class="section level2">
      <h2 id="losses">Losses<a class="anchor" aria-label="anchor" href="#losses"></a></h2>
      
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="loss_mean_squared_error.html">loss_mean_squared_error()</a></code> 
        </dt>
        <dd>Computes the mean of squares of errors between labels and predictions.</dd>
      </dl><dl><dt>
          
          <code><a href="loss_binary_crossentropy.html">loss_binary_crossentropy()</a></code> 
        </dt>
        <dd>Computes the cross-entropy loss between true labels and predicted labels.</dd>
      </dl><dl><dt>
          
          <code><a href="loss_binary_focal_crossentropy.html">loss_binary_focal_crossentropy()</a></code> 
        </dt>
        <dd>Computes focal cross-entropy loss between true labels and predictions.</dd>
      </dl><dl><dt>
          
          <code><a href="loss_categorical_crossentropy.html">loss_categorical_crossentropy()</a></code> 
        </dt>
        <dd>Computes the crossentropy loss between the labels and predictions.</dd>
      </dl><dl><dt>
          
          <code><a href="loss_categorical_focal_crossentropy.html">loss_categorical_focal_crossentropy()</a></code> 
        </dt>
        <dd>Computes the alpha balanced focal crossentropy loss.</dd>
      </dl><dl><dt>
          
          <code><a href="loss_categorical_hinge.html">loss_categorical_hinge()</a></code> 
        </dt>
        <dd>Computes the categorical hinge loss between <code>y_true</code> &amp; <code>y_pred</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="loss_cosine_similarity.html">loss_cosine_similarity()</a></code> 
        </dt>
        <dd>Computes the cosine similarity between <code>y_true</code> &amp; <code>y_pred</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="loss_hinge.html">loss_hinge()</a></code> 
        </dt>
        <dd>Computes the hinge loss between <code>y_true</code> &amp; <code>y_pred</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="loss_huber.html">loss_huber()</a></code> 
        </dt>
        <dd>Computes the Huber loss between <code>y_true</code> &amp; <code>y_pred</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="loss_kl_divergence.html">loss_kl_divergence()</a></code> 
        </dt>
        <dd>Computes Kullback-Leibler divergence loss between <code>y_true</code> &amp; <code>y_pred</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="loss_log_cosh.html">loss_log_cosh()</a></code> 
        </dt>
        <dd>Computes the logarithm of the hyperbolic cosine of the prediction error.</dd>
      </dl><dl><dt>
          
          <code><a href="loss_mean_absolute_error.html">loss_mean_absolute_error()</a></code> 
        </dt>
        <dd>Computes the mean of absolute difference between labels and predictions.</dd>
      </dl><dl><dt>
          
          <code><a href="loss_mean_absolute_percentage_error.html">loss_mean_absolute_percentage_error()</a></code> 
        </dt>
        <dd>Computes the mean absolute percentage error between <code>y_true</code> &amp; <code>y_pred</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="loss_mean_squared_logarithmic_error.html">loss_mean_squared_logarithmic_error()</a></code> 
        </dt>
        <dd>Computes the mean squared logarithmic error between <code>y_true</code> &amp; <code>y_pred</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="loss_poisson.html">loss_poisson()</a></code> 
        </dt>
        <dd>Computes the Poisson loss between <code>y_true</code> &amp; <code>y_pred</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="loss_sparse_categorical_crossentropy.html">loss_sparse_categorical_crossentropy()</a></code> 
        </dt>
        <dd>Computes the crossentropy loss between the labels and predictions.</dd>
      </dl><dl><dt>
          
          <code><a href="loss_squared_hinge.html">loss_squared_hinge()</a></code> 
        </dt>
        <dd>Computes the squared hinge loss between <code>y_true</code> &amp; <code>y_pred</code>.</dd>
      </dl></div><div class="section level2">
      <h2 id="metrics">Metrics<a class="anchor" aria-label="anchor" href="#metrics"></a></h2>
      
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="Metric.html">Metric</a></code> 
        </dt>
        <dd>Metric</dd>
      </dl><dl><dt>
          
          <code><a href="metric_auc.html">metric_auc()</a></code> 
        </dt>
        <dd>Approximates the AUC (Area under the curve) of the ROC or PR curves.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_binary_accuracy.html">metric_binary_accuracy()</a></code> 
        </dt>
        <dd>Calculates how often predictions match binary labels.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_binary_crossentropy.html">metric_binary_crossentropy()</a></code> 
        </dt>
        <dd>Computes the crossentropy metric between the labels and predictions.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_binary_focal_crossentropy.html">metric_binary_focal_crossentropy()</a></code> 
        </dt>
        <dd>Computes the binary focal crossentropy loss.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_binary_iou.html">metric_binary_iou()</a></code> 
        </dt>
        <dd>Computes the Intersection-Over-Union metric for class 0 and/or 1.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_categorical_accuracy.html">metric_categorical_accuracy()</a></code> 
        </dt>
        <dd>Calculates how often predictions match one-hot labels.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_categorical_crossentropy.html">metric_categorical_crossentropy()</a></code> 
        </dt>
        <dd>Computes the crossentropy metric between the labels and predictions.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_categorical_focal_crossentropy.html">metric_categorical_focal_crossentropy()</a></code> 
        </dt>
        <dd>Computes the categorical focal crossentropy loss.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_categorical_hinge.html">metric_categorical_hinge()</a></code> 
        </dt>
        <dd>Computes the categorical hinge metric between <code>y_true</code> and <code>y_pred</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_cosine_similarity.html">metric_cosine_similarity()</a></code> 
        </dt>
        <dd>Computes the cosine similarity between the labels and predictions.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_f1_score.html">metric_f1_score()</a></code> 
        </dt>
        <dd>Computes F-1 Score.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_false_negatives.html">metric_false_negatives()</a></code> 
        </dt>
        <dd>Calculates the number of false negatives.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_false_positives.html">metric_false_positives()</a></code> 
        </dt>
        <dd>Calculates the number of false positives.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_fbeta_score.html">metric_fbeta_score()</a></code> 
        </dt>
        <dd>Computes F-Beta score.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_hinge.html">metric_hinge()</a></code> 
        </dt>
        <dd>Computes the hinge metric between <code>y_true</code> and <code>y_pred</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_huber.html">metric_huber()</a></code> 
        </dt>
        <dd>Computes Huber loss value.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_iou.html">metric_iou()</a></code> 
        </dt>
        <dd>Computes the Intersection-Over-Union metric for specific target classes.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_kl_divergence.html">metric_kl_divergence()</a></code> 
        </dt>
        <dd>Computes Kullback-Leibler divergence metric between <code>y_true</code> and</dd>
      </dl><dl><dt>
          
          <code><a href="metric_log_cosh.html">metric_log_cosh()</a></code> 
        </dt>
        <dd>Logarithm of the hyperbolic cosine of the prediction error.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_log_cosh_error.html">metric_log_cosh_error()</a></code> 
        </dt>
        <dd>Computes the logarithm of the hyperbolic cosine of the prediction error.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_mean.html">metric_mean()</a></code> 
        </dt>
        <dd>Compute the (weighted) mean of the given values.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_mean_absolute_error.html">metric_mean_absolute_error()</a></code> 
        </dt>
        <dd>Computes the mean absolute error between the labels and predictions.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_mean_absolute_percentage_error.html">metric_mean_absolute_percentage_error()</a></code> 
        </dt>
        <dd>Computes mean absolute percentage error between <code>y_true</code> and <code>y_pred</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_mean_iou.html">metric_mean_iou()</a></code> 
        </dt>
        <dd>Computes the mean Intersection-Over-Union metric.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_mean_squared_error.html">metric_mean_squared_error()</a></code> 
        </dt>
        <dd>Computes the mean squared error between <code>y_true</code> and <code>y_pred</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_mean_squared_logarithmic_error.html">metric_mean_squared_logarithmic_error()</a></code> 
        </dt>
        <dd>Computes mean squared logarithmic error between <code>y_true</code> and <code>y_pred</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_mean_wrapper.html">metric_mean_wrapper()</a></code> 
        </dt>
        <dd>Wrap a stateless metric function with the Mean metric.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_one_hot_iou.html">metric_one_hot_iou()</a></code> 
        </dt>
        <dd>Computes the Intersection-Over-Union metric for one-hot encoded labels.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_one_hot_mean_iou.html">metric_one_hot_mean_iou()</a></code> 
        </dt>
        <dd>Computes mean Intersection-Over-Union metric for one-hot encoded labels.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_poisson.html">metric_poisson()</a></code> 
        </dt>
        <dd>Computes the Poisson metric between <code>y_true</code> and <code>y_pred</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_precision.html">metric_precision()</a></code> 
        </dt>
        <dd>Computes the precision of the predictions with respect to the labels.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_precision_at_recall.html">metric_precision_at_recall()</a></code> 
        </dt>
        <dd>Computes best precision where recall is &gt;= specified value.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_r2_score.html">metric_r2_score()</a></code> 
        </dt>
        <dd>Computes R2 score.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_recall.html">metric_recall()</a></code> 
        </dt>
        <dd>Computes the recall of the predictions with respect to the labels.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_recall_at_precision.html">metric_recall_at_precision()</a></code> 
        </dt>
        <dd>Computes best recall where precision is &gt;= specified value.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_root_mean_squared_error.html">metric_root_mean_squared_error()</a></code> 
        </dt>
        <dd>Computes root mean squared error metric between <code>y_true</code> and <code>y_pred</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_sensitivity_at_specificity.html">metric_sensitivity_at_specificity()</a></code> 
        </dt>
        <dd>Computes best sensitivity where specificity is &gt;= specified value.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_sparse_categorical_accuracy.html">metric_sparse_categorical_accuracy()</a></code> 
        </dt>
        <dd>Calculates how often predictions match integer labels.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_sparse_categorical_crossentropy.html">metric_sparse_categorical_crossentropy()</a></code> 
        </dt>
        <dd>Computes the crossentropy metric between the labels and predictions.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_sparse_top_k_categorical_accuracy.html">metric_sparse_top_k_categorical_accuracy()</a></code> 
        </dt>
        <dd>Computes how often integer targets are in the top <code>K</code> predictions.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_specificity_at_sensitivity.html">metric_specificity_at_sensitivity()</a></code> 
        </dt>
        <dd>Computes best specificity where sensitivity is &gt;= specified value.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_squared_hinge.html">metric_squared_hinge()</a></code> 
        </dt>
        <dd>Computes the hinge metric between <code>y_true</code> and <code>y_pred</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_sum.html">metric_sum()</a></code> 
        </dt>
        <dd>Compute the (weighted) sum of the given values.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_top_k_categorical_accuracy.html">metric_top_k_categorical_accuracy()</a></code> 
        </dt>
        <dd>Computes how often targets are in the top <code>K</code> predictions.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_true_negatives.html">metric_true_negatives()</a></code> 
        </dt>
        <dd>Calculates the number of true negatives.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_true_positives.html">metric_true_positives()</a></code> 
        </dt>
        <dd>Calculates the number of true positives.</dd>
      </dl><dl><dt>
          
          <code><a href="custom_metric.html">custom_metric()</a></code> 
        </dt>
        <dd>Custom metric function</dd>
      </dl></div><div class="section level2">
      <h2 id="regularizers">Regularizers<a class="anchor" aria-label="anchor" href="#regularizers"></a></h2>
      
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="regularizer_l1.html">regularizer_l1()</a></code> 
        </dt>
        <dd>A regularizer that applies a L1 regularization penalty.</dd>
      </dl><dl><dt>
          
          <code><a href="regularizer_l1_l2.html">regularizer_l1_l2()</a></code> 
        </dt>
        <dd>A regularizer that applies both L1 and L2 regularization penalties.</dd>
      </dl><dl><dt>
          
          <code><a href="regularizer_l2.html">regularizer_l2()</a></code> 
        </dt>
        <dd>A regularizer that applies a L2 regularization penalty.</dd>
      </dl><dl><dt>
          
          <code><a href="regularizer_orthogonal.html">regularizer_orthogonal()</a></code> 
        </dt>
        <dd>Regularizer that encourages input vectors to be orthogonal to each other.</dd>
      </dl></div><div class="section level2">
      <h2 id="activations">Activations<a class="anchor" aria-label="anchor" href="#activations"></a></h2>
      
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="activation_elu.html">activation_elu()</a></code> 
        </dt>
        <dd>Exponential Linear Unit.</dd>
      </dl><dl><dt>
          
          <code><a href="activation_exponential.html">activation_exponential()</a></code> 
        </dt>
        <dd>Exponential activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="activation_gelu.html">activation_gelu()</a></code> 
        </dt>
        <dd>Gaussian error linear unit (GELU) activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="activation_hard_sigmoid.html">activation_hard_sigmoid()</a></code> 
        </dt>
        <dd>Hard sigmoid activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="activation_leaky_relu.html">activation_leaky_relu()</a></code> 
        </dt>
        <dd>Leaky relu activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="activation_linear.html">activation_linear()</a></code> 
        </dt>
        <dd>Linear activation function (pass-through).</dd>
      </dl><dl><dt>
          
          <code><a href="activation_log_softmax.html">activation_log_softmax()</a></code> 
        </dt>
        <dd>Log-Softmax activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="activation_mish.html">activation_mish()</a></code> 
        </dt>
        <dd>Mish activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="activation_relu.html">activation_relu()</a></code> 
        </dt>
        <dd>Applies the rectified linear unit activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="activation_relu6.html">activation_relu6()</a></code> 
        </dt>
        <dd>Relu6 activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="activation_selu.html">activation_selu()</a></code> 
        </dt>
        <dd>Scaled Exponential Linear Unit (SELU).</dd>
      </dl><dl><dt>
          
          <code><a href="activation_sigmoid.html">activation_sigmoid()</a></code> 
        </dt>
        <dd>Sigmoid activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="activation_silu.html">activation_silu()</a></code> 
        </dt>
        <dd>Swish (or Silu) activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="activation_softmax.html">activation_softmax()</a></code> 
        </dt>
        <dd>Softmax converts a vector of values to a probability distribution.</dd>
      </dl><dl><dt>
          
          <code><a href="activation_softplus.html">activation_softplus()</a></code> 
        </dt>
        <dd>Softplus activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="activation_softsign.html">activation_softsign()</a></code> 
        </dt>
        <dd>Softsign activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="activation_tanh.html">activation_tanh()</a></code> 
        </dt>
        <dd>Hyperbolic tangent activation function.</dd>
      </dl></div><div class="section level2">
      <h2 id="misc-other-layers">Misc other layers<a class="anchor" aria-label="anchor" href="#misc-other-layers"></a></h2>
      
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="layer_activation.html">layer_activation()</a></code> 
        </dt>
        <dd>Applies an activation function to an output.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_activation_elu.html">layer_activation_elu()</a></code> 
        </dt>
        <dd>Applies an Exponential Linear Unit function to an output.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_activation_leaky_relu.html">layer_activation_leaky_relu()</a></code> 
        </dt>
        <dd>Leaky version of a Rectified Linear Unit activation layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_activation_parametric_relu.html">layer_activation_parametric_relu()</a></code> 
        </dt>
        <dd>Parametric Rectified Linear Unit activation layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_activation_relu.html">layer_activation_relu()</a></code> 
        </dt>
        <dd>Rectified Linear Unit activation function layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_activation_softmax.html">layer_activation_softmax()</a></code> 
        </dt>
        <dd>Softmax activation layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_activity_regularization.html">layer_activity_regularization()</a></code> 
        </dt>
        <dd>Layer that applies an update to the cost function based input activity.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_add.html">layer_add()</a></code> 
        </dt>
        <dd>Performs elementwise addition operation.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_additive_attention.html">layer_additive_attention()</a></code> 
        </dt>
        <dd>Additive attention layer, a.k.a. Bahdanau-style attention.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_attention.html">layer_attention()</a></code> 
        </dt>
        <dd>Dot-product attention layer, a.k.a. Luong-style attention.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_average.html">layer_average()</a></code> 
        </dt>
        <dd>Averages a list of inputs element-wise..</dd>
      </dl><dl><dt>
          
          <code><a href="layer_average_pooling_1d.html">layer_average_pooling_1d()</a></code> 
        </dt>
        <dd>Average pooling for temporal data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_average_pooling_2d.html">layer_average_pooling_2d()</a></code> 
        </dt>
        <dd>Average pooling operation for 2D spatial data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_average_pooling_3d.html">layer_average_pooling_3d()</a></code> 
        </dt>
        <dd>Average pooling operation for 3D data (spatial or spatio-temporal).</dd>
      </dl><dl><dt>
          
          <code><a href="layer_batch_normalization.html">layer_batch_normalization()</a></code> 
        </dt>
        <dd>Layer that normalizes its inputs.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_bidirectional.html">layer_bidirectional()</a></code> 
        </dt>
        <dd>Bidirectional wrapper for RNNs.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_category_encoding.html">layer_category_encoding()</a></code> 
        </dt>
        <dd>A preprocessing layer which encodes integer features.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_center_crop.html">layer_center_crop()</a></code> 
        </dt>
        <dd>A preprocessing layer which crops images.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_concatenate.html">layer_concatenate()</a></code> 
        </dt>
        <dd>Concatenates a list of inputs.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_conv_1d.html">layer_conv_1d()</a></code> 
        </dt>
        <dd>1D convolution layer (e.g. temporal convolution).</dd>
      </dl><dl><dt>
          
          <code><a href="layer_conv_1d_transpose.html">layer_conv_1d_transpose()</a></code> 
        </dt>
        <dd>1D transposed convolution layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_conv_2d.html">layer_conv_2d()</a></code> 
        </dt>
        <dd>2D convolution layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_conv_2d_transpose.html">layer_conv_2d_transpose()</a></code> 
        </dt>
        <dd>2D transposed convolution layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_conv_3d.html">layer_conv_3d()</a></code> 
        </dt>
        <dd>3D convolution layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_conv_3d_transpose.html">layer_conv_3d_transpose()</a></code> 
        </dt>
        <dd>3D transposed convolution layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_conv_lstm_1d.html">layer_conv_lstm_1d()</a></code> 
        </dt>
        <dd>1D Convolutional LSTM.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_conv_lstm_2d.html">layer_conv_lstm_2d()</a></code> 
        </dt>
        <dd>2D Convolutional LSTM.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_conv_lstm_3d.html">layer_conv_lstm_3d()</a></code> 
        </dt>
        <dd>3D Convolutional LSTM.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_cropping_1d.html">layer_cropping_1d()</a></code> 
        </dt>
        <dd>Cropping layer for 1D input (e.g. temporal sequence).</dd>
      </dl><dl><dt>
          
          <code><a href="layer_cropping_2d.html">layer_cropping_2d()</a></code> 
        </dt>
        <dd>Cropping layer for 2D input (e.g. picture).</dd>
      </dl><dl><dt>
          
          <code><a href="layer_cropping_3d.html">layer_cropping_3d()</a></code> 
        </dt>
        <dd>Cropping layer for 3D data (e.g. spatial or spatio-temporal).</dd>
      </dl><dl><dt>
          
          <code><a href="layer_dense.html">layer_dense()</a></code> 
        </dt>
        <dd>Just your regular densely-connected NN layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_depthwise_conv_1d.html">layer_depthwise_conv_1d()</a></code> 
        </dt>
        <dd>1D depthwise convolution layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_depthwise_conv_2d.html">layer_depthwise_conv_2d()</a></code> 
        </dt>
        <dd>2D depthwise convolution layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_discretization.html">layer_discretization()</a></code> 
        </dt>
        <dd>A preprocessing layer which buckets continuous features by ranges.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_dot.html">layer_dot()</a></code> 
        </dt>
        <dd>Computes element-wise dot product of two tensors.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_dropout.html">layer_dropout()</a></code> 
        </dt>
        <dd>Applies dropout to the input.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_einsum_dense.html">layer_einsum_dense()</a></code> 
        </dt>
        <dd>A layer that uses <code>einsum</code> as the backing computation.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_embedding.html">layer_embedding()</a></code> 
        </dt>
        <dd>Turns positive integers (indexes) into dense vectors of fixed size.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_feature_space.html">layer_feature_space()</a></code> 
        </dt>
        <dd>One-stop utility for preprocessing and encoding structured data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_flatten.html">layer_flatten()</a></code> 
        </dt>
        <dd>Flattens the input. Does not affect the batch size.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_gaussian_dropout.html">layer_gaussian_dropout()</a></code> 
        </dt>
        <dd>Apply multiplicative 1-centered Gaussian noise.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_gaussian_noise.html">layer_gaussian_noise()</a></code> 
        </dt>
        <dd>Apply additive zero-centered Gaussian noise.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_global_average_pooling_1d.html">layer_global_average_pooling_1d()</a></code> 
        </dt>
        <dd>Global average pooling operation for temporal data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_global_average_pooling_2d.html">layer_global_average_pooling_2d()</a></code> 
        </dt>
        <dd>Global average pooling operation for 2D data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_global_average_pooling_3d.html">layer_global_average_pooling_3d()</a></code> 
        </dt>
        <dd>Global average pooling operation for 3D data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_global_max_pooling_1d.html">layer_global_max_pooling_1d()</a></code> 
        </dt>
        <dd>Global max pooling operation for temporal data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_global_max_pooling_2d.html">layer_global_max_pooling_2d()</a></code> 
        </dt>
        <dd>Global max pooling operation for 2D data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_global_max_pooling_3d.html">layer_global_max_pooling_3d()</a></code> 
        </dt>
        <dd>Global max pooling operation for 3D data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_group_normalization.html">layer_group_normalization()</a></code> 
        </dt>
        <dd>Group normalization layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_group_query_attention.html">layer_group_query_attention()</a></code> 
        </dt>
        <dd>Grouped Query Attention layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_gru.html">layer_gru()</a></code> 
        </dt>
        <dd>Gated Recurrent Unit - Cho et al. 2014.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_gru_cell.html">layer_gru_cell()</a></code> 
        </dt>
        <dd>Cell class for the GRU layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_hashed_crossing.html">layer_hashed_crossing()</a></code> 
        </dt>
        <dd>A preprocessing layer which crosses features using the "hashing trick".</dd>
      </dl><dl><dt>
          
          <code><a href="layer_hashing.html">layer_hashing()</a></code> 
        </dt>
        <dd>A preprocessing layer which hashes and bins categorical features.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_identity.html">layer_identity()</a></code> 
        </dt>
        <dd>Identity layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_input.html">layer_input()</a></code> 
        </dt>
        <dd>Used to instantiate a Keras tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_integer_lookup.html">layer_integer_lookup()</a></code> 
        </dt>
        <dd>A preprocessing layer that maps integers to (possibly encoded) indices.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_lambda.html">layer_lambda()</a></code> 
        </dt>
        <dd>Wraps arbitrary expressions as a <code>Layer</code> object.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_layer_normalization.html">layer_layer_normalization()</a></code> 
        </dt>
        <dd>Layer normalization layer (Ba et al., 2016).</dd>
      </dl><dl><dt>
          
          <code><a href="layer_lstm.html">layer_lstm()</a></code> 
        </dt>
        <dd>Long Short-Term Memory layer - Hochreiter 1997.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_lstm_cell.html">layer_lstm_cell()</a></code> 
        </dt>
        <dd>Cell class for the LSTM layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_masking.html">layer_masking()</a></code> 
        </dt>
        <dd>Masks a sequence by using a mask value to skip timesteps.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_max_pooling_1d.html">layer_max_pooling_1d()</a></code> 
        </dt>
        <dd>Max pooling operation for 1D temporal data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_max_pooling_2d.html">layer_max_pooling_2d()</a></code> 
        </dt>
        <dd>Max pooling operation for 2D spatial data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_max_pooling_3d.html">layer_max_pooling_3d()</a></code> 
        </dt>
        <dd>Max pooling operation for 3D data (spatial or spatio-temporal).</dd>
      </dl><dl><dt>
          
          <code><a href="layer_maximum.html">layer_maximum()</a></code> 
        </dt>
        <dd>Computes element-wise maximum on a list of inputs.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_minimum.html">layer_minimum()</a></code> 
        </dt>
        <dd>Computes elementwise minimum on a list of inputs.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_multi_head_attention.html">layer_multi_head_attention()</a></code> 
        </dt>
        <dd>MultiHeadAttention layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_multiply.html">layer_multiply()</a></code> 
        </dt>
        <dd>Performs elementwise multiplication.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_normalization.html">layer_normalization()</a></code> 
        </dt>
        <dd>A preprocessing layer that normalizes continuous features.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_permute.html">layer_permute()</a></code> 
        </dt>
        <dd>Permutes the dimensions of the input according to a given pattern.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_random_brightness.html">layer_random_brightness()</a></code> 
        </dt>
        <dd>A preprocessing layer which randomly adjusts brightness during training.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_random_contrast.html">layer_random_contrast()</a></code> 
        </dt>
        <dd>A preprocessing layer which randomly adjusts contrast during training.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_random_crop.html">layer_random_crop()</a></code> 
        </dt>
        <dd>A preprocessing layer which randomly crops images during training.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_random_flip.html">layer_random_flip()</a></code> 
        </dt>
        <dd>A preprocessing layer which randomly flips images during training.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_random_rotation.html">layer_random_rotation()</a></code> 
        </dt>
        <dd>A preprocessing layer which randomly rotates images during training.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_random_translation.html">layer_random_translation()</a></code> 
        </dt>
        <dd>A preprocessing layer which randomly translates images during training.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_random_zoom.html">layer_random_zoom()</a></code> 
        </dt>
        <dd>A preprocessing layer which randomly zooms images during training.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_repeat_vector.html">layer_repeat_vector()</a></code> 
        </dt>
        <dd>Repeats the input n times.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_rescaling.html">layer_rescaling()</a></code> 
        </dt>
        <dd>A preprocessing layer which rescales input values to a new range.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_reshape.html">layer_reshape()</a></code> 
        </dt>
        <dd>Layer that reshapes inputs into the given shape.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_resizing.html">layer_resizing()</a></code> 
        </dt>
        <dd>A preprocessing layer which resizes images.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_rnn.html">layer_rnn()</a></code> 
        </dt>
        <dd>Base class for recurrent layers.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_separable_conv_1d.html">layer_separable_conv_1d()</a></code> 
        </dt>
        <dd>1D separable convolution layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_separable_conv_2d.html">layer_separable_conv_2d()</a></code> 
        </dt>
        <dd>2D separable convolution layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_simple_rnn.html">layer_simple_rnn()</a></code> 
        </dt>
        <dd>Fully-connected RNN where the output is to be fed back as the new input.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_simple_rnn_cell.html">layer_simple_rnn_cell()</a></code> 
        </dt>
        <dd>Cell class for SimpleRNN.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_spatial_dropout_1d.html">layer_spatial_dropout_1d()</a></code> 
        </dt>
        <dd>Spatial 1D version of Dropout.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_spatial_dropout_2d.html">layer_spatial_dropout_2d()</a></code> 
        </dt>
        <dd>Spatial 2D version of Dropout.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_spatial_dropout_3d.html">layer_spatial_dropout_3d()</a></code> 
        </dt>
        <dd>Spatial 3D version of Dropout.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_spectral_normalization.html">layer_spectral_normalization()</a></code> 
        </dt>
        <dd>Performs spectral normalization on the weights of a target layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_stacked_rnn_cells.html">layer_stacked_rnn_cells()</a></code> 
        </dt>
        <dd>Wrapper allowing a stack of RNN cells to behave as a single cell.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_string_lookup.html">layer_string_lookup()</a></code> 
        </dt>
        <dd>A preprocessing layer that maps strings to (possibly encoded) indices.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_subtract.html">layer_subtract()</a></code> 
        </dt>
        <dd>Performs elementwise subtraction.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_text_vectorization.html">layer_text_vectorization()</a></code> <code><a href="layer_text_vectorization.html">get_vocabulary()</a></code> <code><a href="layer_text_vectorization.html">set_vocabulary()</a></code> 
        </dt>
        <dd>A preprocessing layer which maps text features to integer sequences.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_tfsm.html">layer_tfsm()</a></code> 
        </dt>
        <dd>Reload a Keras model/layer that was saved via SavedModel / ExportArchive.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_time_distributed.html">layer_time_distributed()</a></code> 
        </dt>
        <dd>This wrapper allows to apply a layer to every temporal slice of an input.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_torch_module_wrapper.html">layer_torch_module_wrapper()</a></code> 
        </dt>
        <dd>Torch module wrapper layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_unit_normalization.html">layer_unit_normalization()</a></code> 
        </dt>
        <dd>Unit normalization layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_upsampling_1d.html">layer_upsampling_1d()</a></code> 
        </dt>
        <dd>Upsampling layer for 1D inputs.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_upsampling_2d.html">layer_upsampling_2d()</a></code> 
        </dt>
        <dd>Upsampling layer for 2D inputs.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_upsampling_3d.html">layer_upsampling_3d()</a></code> 
        </dt>
        <dd>Upsampling layer for 3D inputs.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_zero_padding_1d.html">layer_zero_padding_1d()</a></code> 
        </dt>
        <dd>Zero-padding layer for 1D input (e.g. temporal sequence).</dd>
      </dl><dl><dt>
          
          <code><a href="layer_zero_padding_2d.html">layer_zero_padding_2d()</a></code> 
        </dt>
        <dd>Zero-padding layer for 2D input (e.g. picture).</dd>
      </dl><dl><dt>
          
          <code><a href="layer_zero_padding_3d.html">layer_zero_padding_3d()</a></code> 
        </dt>
        <dd>Zero-padding layer for 3D data (spatial or spatio-temporal).</dd>
      </dl></div><div class="section level2">
      <h2 id="random-tensor-generators">Random Tensor Generators<a class="anchor" aria-label="anchor" href="#random-tensor-generators"></a></h2>
      
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="random_categorical.html">random_categorical()</a></code> 
        </dt>
        <dd>Draws samples from a categorical distribution.</dd>
      </dl><dl><dt>
          
          <code><a href="random_dropout.html">random_dropout()</a></code> 
        </dt>
        <dd>random dropout</dd>
      </dl><dl><dt>
          
          <code><a href="random_integer.html">random_integer()</a></code> 
        </dt>
        <dd>Draw random integers from a uniform distribution.</dd>
      </dl><dl><dt>
          
          <code><a href="random_normal.html">random_normal()</a></code> 
        </dt>
        <dd>Draw random samples from a normal (Gaussian) distribution.</dd>
      </dl><dl><dt>
          
          <code><a href="random_seed_generator.html">random_seed_generator()</a></code> 
        </dt>
        <dd>Generates variable seeds upon each call to a RNG-using function.</dd>
      </dl><dl><dt>
          
          <code><a href="random_shuffle.html">random_shuffle()</a></code> 
        </dt>
        <dd>Shuffle the elements of a tensor uniformly at random along an axis.</dd>
      </dl><dl><dt>
          
          <code><a href="random_truncated_normal.html">random_truncated_normal()</a></code> 
        </dt>
        <dd>Draw samples from a truncated normal distribution.</dd>
      </dl><dl><dt>
          
          <code><a href="random_uniform.html">random_uniform()</a></code> 
        </dt>
        <dd>Draw samples from a uniform distribution.</dd>
      </dl></div><div class="section level2">
      <h2 id="operations">Operations<a class="anchor" aria-label="anchor" href="#operations"></a></h2>
      
      <p class="section-desc"></p><p>Functions that are safe to call in Eager and Graph mode</p>

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="k_abs.html">k_abs()</a></code> 
        </dt>
        <dd>Shorthand for <code>keras.ops.absolute</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_add.html">k_add()</a></code> 
        </dt>
        <dd>Add arguments element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_all.html">k_all()</a></code> 
        </dt>
        <dd>Test whether all array elements along a given axis evaluate to <code>TRUE</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_amax.html">k_amax()</a></code> 
        </dt>
        <dd>Returns the maximum of a vector or maximum value along an axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_amin.html">k_amin()</a></code> 
        </dt>
        <dd>Returns the minimum of a vector or minimum value along an axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_any.html">k_any()</a></code> 
        </dt>
        <dd>Test whether any array element along a given axis evaluates to <code>TRUE</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_append.html">k_append()</a></code> 
        </dt>
        <dd>Append tensor <code>x2</code> to the end of tensor <code>x1</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_arange.html">k_arange()</a></code> 
        </dt>
        <dd>Return evenly spaced values within a given interval.</dd>
      </dl><dl><dt>
          
          <code><a href="k_arccos.html">k_arccos()</a></code> 
        </dt>
        <dd>Trigonometric inverse cosine, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_arccosh.html">k_arccosh()</a></code> 
        </dt>
        <dd>Inverse hyperbolic cosine, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_arcsin.html">k_arcsin()</a></code> 
        </dt>
        <dd>Inverse sine, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_arcsinh.html">k_arcsinh()</a></code> 
        </dt>
        <dd>Inverse hyperbolic sine, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_arctan.html">k_arctan()</a></code> 
        </dt>
        <dd>Trigonometric inverse tangent, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_arctan2.html">k_arctan2()</a></code> 
        </dt>
        <dd>Element-wise arc tangent of <code>x1/x2</code> choosing the quadrant correctly.</dd>
      </dl><dl><dt>
          
          <code><a href="k_arctanh.html">k_arctanh()</a></code> 
        </dt>
        <dd>Inverse hyperbolic tangent, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_argmax.html">k_argmax()</a></code> 
        </dt>
        <dd>Returns the indices of the maximum values along an axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_argmin.html">k_argmin()</a></code> 
        </dt>
        <dd>Returns the indices of the minimum values along an axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_argsort.html">k_argsort()</a></code> 
        </dt>
        <dd>Returns the indices that would sort a tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_array.html">k_array()</a></code> 
        </dt>
        <dd>Create a tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_average.html">k_average()</a></code> 
        </dt>
        <dd>Compute the weighted average along the specified axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_average_pool.html">k_average_pool()</a></code> 
        </dt>
        <dd>Average pooling operation.</dd>
      </dl><dl><dt>
          
          <code><a href="k_binary_crossentropy.html">k_binary_crossentropy()</a></code> 
        </dt>
        <dd>Computes binary cross-entropy loss between target and output tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_bincount.html">k_bincount()</a></code> 
        </dt>
        <dd>Count the number of occurrences of each value in a tensor of integers.</dd>
      </dl><dl><dt>
          
          <code><a href="k_broadcast_to.html">k_broadcast_to()</a></code> 
        </dt>
        <dd>Broadcast a tensor to a new shape.</dd>
      </dl><dl><dt>
          
          <code><a href="k_cast.html">k_cast()</a></code> 
        </dt>
        <dd>Cast a tensor to the desired dtype.</dd>
      </dl><dl><dt>
          
          <code><a href="k_categorical_crossentropy.html">k_categorical_crossentropy()</a></code> 
        </dt>
        <dd>Computes categorical cross-entropy loss between target and output tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_ceil.html">k_ceil()</a></code> 
        </dt>
        <dd>Return the ceiling of the input, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_clip.html">k_clip()</a></code> 
        </dt>
        <dd>Clip (limit) the values in a tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_concatenate.html">k_concatenate()</a></code> 
        </dt>
        <dd>Join a sequence of tensors along an existing axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_cond.html">k_cond()</a></code> 
        </dt>
        <dd>Conditionally applies <code>true_fn</code> or <code>false_fn</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_conj.html">k_conj()</a></code> 
        </dt>
        <dd>Shorthand for <code>keras.ops.conjugate</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_conjugate.html">k_conjugate()</a></code> 
        </dt>
        <dd>Returns the complex conjugate, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_conv.html">k_conv()</a></code> 
        </dt>
        <dd>General N-D convolution.</dd>
      </dl><dl><dt>
          
          <code><a href="k_conv_transpose.html">k_conv_transpose()</a></code> 
        </dt>
        <dd>General N-D convolution transpose.</dd>
      </dl><dl><dt>
          
          <code><a href="k_convert_to_numpy.html">k_convert_to_numpy()</a></code> 
        </dt>
        <dd>Convert a tensor to a NumPy array.</dd>
      </dl><dl><dt>
          
          <code><a href="k_convert_to_tensor.html">k_convert_to_tensor()</a></code> 
        </dt>
        <dd>Convert an array to a tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_copy.html">k_copy()</a></code> 
        </dt>
        <dd>Returns a copy of <code>x</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_cos.html">k_cos()</a></code> 
        </dt>
        <dd>Cosine, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_cosh.html">k_cosh()</a></code> 
        </dt>
        <dd>Hyperbolic cosine, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_count_nonzero.html">k_count_nonzero()</a></code> 
        </dt>
        <dd>Counts the number of non-zero values in <code>x</code> along the given <code>axis</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_cross.html">k_cross()</a></code> 
        </dt>
        <dd>Returns the cross product of two (arrays of) vectors.</dd>
      </dl><dl><dt>
          
          <code><a href="k_cumprod.html">k_cumprod()</a></code> 
        </dt>
        <dd>Return the cumulative product of elements along a given axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_cumsum.html">k_cumsum()</a></code> 
        </dt>
        <dd>Returns the cumulative sum of elements along a given axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_depthwise_conv.html">k_depthwise_conv()</a></code> 
        </dt>
        <dd>General N-D depthwise convolution.</dd>
      </dl><dl><dt>
          
          <code><a href="k_diag.html">k_diag()</a></code> 
        </dt>
        <dd>Extract a diagonal or construct a diagonal array.</dd>
      </dl><dl><dt>
          
          <code><a href="k_diagonal.html">k_diagonal()</a></code> 
        </dt>
        <dd>Return specified diagonals.</dd>
      </dl><dl><dt>
          
          <code><a href="k_diff.html">k_diff()</a></code> 
        </dt>
        <dd>Calculate the n-th discrete difference along the given axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_digitize.html">k_digitize()</a></code> 
        </dt>
        <dd>Returns the indices of the bins to which each value in <code>x</code> belongs.</dd>
      </dl><dl><dt>
          
          <code><a href="k_divide.html">k_divide()</a></code> 
        </dt>
        <dd>Divide arguments element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_dot.html">k_dot()</a></code> 
        </dt>
        <dd>Dot product of two tensors.</dd>
      </dl><dl><dt>
          
          <code><a href="k_einsum.html">k_einsum()</a></code> 
        </dt>
        <dd>Evaluates the Einstein summation convention on the operands.</dd>
      </dl><dl><dt>
          
          <code><a href="k_elu.html">k_elu()</a></code> 
        </dt>
        <dd>Exponential Linear Unit activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="k_empty.html">k_empty()</a></code> 
        </dt>
        <dd>Return a tensor of given shape and type filled with uninitialized data.</dd>
      </dl><dl><dt>
          
          <code><a href="k_equal.html">k_equal()</a></code> 
        </dt>
        <dd>Returns <code>(x1 == x2)</code> element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_erf.html">k_erf()</a></code> 
        </dt>
        <dd>Computes the error function of <code>x</code>, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_exp.html">k_exp()</a></code> 
        </dt>
        <dd>Calculate the exponential of all elements in the input tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_expand_dims.html">k_expand_dims()</a></code> 
        </dt>
        <dd>Expand the shape of a tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_expm1.html">k_expm1()</a></code> 
        </dt>
        <dd>Calculate <code>exp(x) - 1</code> for all elements in the tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_extract_sequences.html">k_extract_sequences()</a></code> 
        </dt>
        <dd>Expands the dimension of last axis into sequences of <code>sequence_length</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_eye.html">k_eye()</a></code> 
        </dt>
        <dd>Return a 2-D tensor with ones on the diagonal and zeros elsewhere.</dd>
      </dl><dl><dt>
          
          <code><a href="k_fft.html">k_fft()</a></code> 
        </dt>
        <dd>Computes the Fast Fourier Transform along last axis of input.</dd>
      </dl><dl><dt>
          
          <code><a href="k_fft2.html">k_fft2()</a></code> 
        </dt>
        <dd>Computes the 2D Fast Fourier Transform along the last two axes of input.</dd>
      </dl><dl><dt>
          
          <code><a href="k_flip.html">k_flip()</a></code> 
        </dt>
        <dd>Reverse the order of elements in the tensor along the given axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_floatx.html">k_floatx()</a></code> 
        </dt>
        <dd>Return the default float type, as a string.</dd>
      </dl><dl><dt>
          
          <code><a href="k_floor.html">k_floor()</a></code> 
        </dt>
        <dd>Return the floor of the input, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_floor_divide.html">k_floor_divide()</a></code> 
        </dt>
        <dd>Returns the largest integer smaller or equal to the division of inputs.</dd>
      </dl><dl><dt>
          
          <code><a href="k_fori_loop.html">k_fori_loop()</a></code> 
        </dt>
        <dd>For loop implementation.</dd>
      </dl><dl><dt>
          
          <code><a href="k_full.html">k_full()</a></code> 
        </dt>
        <dd>Return a new tensor of given shape and type, filled with <code>fill_value</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_full_like.html">k_full_like()</a></code> 
        </dt>
        <dd>Return a full tensor with the same shape and type as the given tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_gelu.html">k_gelu()</a></code> 
        </dt>
        <dd>Gaussian Error Linear Unit (GELU) activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="k_get_item.html">k_get_item()</a></code> 
        </dt>
        <dd>Return <code>x[key]</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_greater.html">k_greater()</a></code> 
        </dt>
        <dd>Return the truth value of <code>x1 &gt; x2</code> element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_greater_equal.html">k_greater_equal()</a></code> 
        </dt>
        <dd>Return the truth value of <code>x1 &gt;= x2</code> element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_hard_sigmoid.html">k_hard_sigmoid()</a></code> 
        </dt>
        <dd>Hard sigmoid activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="k_hstack.html">k_hstack()</a></code> 
        </dt>
        <dd>Stack tensors in sequence horizontally (column wise).</dd>
      </dl><dl><dt>
          
          <code><a href="k_identity.html">k_identity()</a></code> 
        </dt>
        <dd>Return the identity tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_imag.html">k_imag()</a></code> 
        </dt>
        <dd>Return the imaginary part of the complex argument.</dd>
      </dl><dl><dt>
          
          <code><a href="k_image_affine_transform.html">k_image_affine_transform()</a></code> 
        </dt>
        <dd>Applies the given transform(s) to the image(s).</dd>
      </dl><dl><dt>
          
          <code><a href="k_image_extract_patches.html">k_image_extract_patches()</a></code> 
        </dt>
        <dd>Extracts patches from the image(s).</dd>
      </dl><dl><dt>
          
          <code><a href="k_image_map_coordinates.html">k_image_map_coordinates()</a></code> 
        </dt>
        <dd>Map the input array to new coordinates by interpolation..</dd>
      </dl><dl><dt>
          
          <code><a href="k_image_pad_images.html">k_image_pad_images()</a></code> 
        </dt>
        <dd>Pad <code>images</code> with zeros to the specified <code>height</code> and <code>width</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_image_resize.html">k_image_resize()</a></code> 
        </dt>
        <dd>Resize images to size using the specified interpolation method.</dd>
      </dl><dl><dt>
          
          <code><a href="k_in_top_k.html">k_in_top_k()</a></code> 
        </dt>
        <dd>Checks if the targets are in the top-k predictions.</dd>
      </dl><dl><dt>
          
          <code><a href="k_irfft.html">k_irfft()</a></code> 
        </dt>
        <dd>Inverse real-valued Fast Fourier transform along the last axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_isclose.html">k_isclose()</a></code> 
        </dt>
        <dd>Return whether two tensors are element-wise almost equal.</dd>
      </dl><dl><dt>
          
          <code><a href="k_isfinite.html">k_isfinite()</a></code> 
        </dt>
        <dd>Return whether a tensor is finite, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_isinf.html">k_isinf()</a></code> 
        </dt>
        <dd>Test element-wise for positive or negative infinity.</dd>
      </dl><dl><dt>
          
          <code><a href="k_isnan.html">k_isnan()</a></code> 
        </dt>
        <dd>Test element-wise for NaN and return result as a boolean tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_istft.html">k_istft()</a></code> 
        </dt>
        <dd>Inverse Short-Time Fourier Transform along the last axis of the input.</dd>
      </dl><dl><dt>
          
          <code><a href="k_leaky_relu.html">k_leaky_relu()</a></code> 
        </dt>
        <dd>Leaky version of a Rectified Linear Unit activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="k_less.html">k_less()</a></code> 
        </dt>
        <dd>Return the truth value of <code>x1 &lt; x2</code> element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_less_equal.html">k_less_equal()</a></code> 
        </dt>
        <dd>Return the truth value of <code>x1 &lt;= x2</code> element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_linspace.html">k_linspace()</a></code> 
        </dt>
        <dd>Return evenly spaced numbers over a specified interval.</dd>
      </dl><dl><dt>
          
          <code><a href="k_log.html">k_log()</a></code> 
        </dt>
        <dd>Natural logarithm, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_log10.html">k_log10()</a></code> 
        </dt>
        <dd>Return the base 10 logarithm of the input tensor, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_log1p.html">k_log1p()</a></code> 
        </dt>
        <dd>Returns the natural logarithm of one plus the <code>x</code>, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_log2.html">k_log2()</a></code> 
        </dt>
        <dd>Base-2 logarithm of <code>x</code>, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_log_sigmoid.html">k_log_sigmoid()</a></code> 
        </dt>
        <dd>Logarithm of the sigmoid activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="k_log_softmax.html">k_log_softmax()</a></code> 
        </dt>
        <dd>Log-softmax activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="k_logaddexp.html">k_logaddexp()</a></code> 
        </dt>
        <dd>Logarithm of the sum of exponentiations of the inputs.</dd>
      </dl><dl><dt>
          
          <code><a href="k_logical_and.html">k_logical_and()</a></code> 
        </dt>
        <dd>Computes the element-wise logical AND of the given input tensors.</dd>
      </dl><dl><dt>
          
          <code><a href="k_logical_not.html">k_logical_not()</a></code> 
        </dt>
        <dd>Computes the element-wise NOT of the given input tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_logical_or.html">k_logical_or()</a></code> 
        </dt>
        <dd>Computes the element-wise logical OR of the given input tensors.</dd>
      </dl><dl><dt>
          
          <code><a href="k_logical_xor.html">k_logical_xor()</a></code> 
        </dt>
        <dd>Compute the truth value of <code>x1 XOR x2</code>, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_logspace.html">k_logspace()</a></code> 
        </dt>
        <dd>Returns numbers spaced evenly on a log scale.</dd>
      </dl><dl><dt>
          
          <code><a href="k_logsumexp.html">k_logsumexp()</a></code> 
        </dt>
        <dd>Computes the logarithm of sum of exponentials of elements in a tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_matmul.html">k_matmul()</a></code> 
        </dt>
        <dd>Matrix product of two tensors.</dd>
      </dl><dl><dt>
          
          <code><a href="k_max.html">k_max()</a></code> 
        </dt>
        <dd>Return the maximum of a tensor or maximum along an axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_max_pool.html">k_max_pool()</a></code> 
        </dt>
        <dd>Max pooling operation.</dd>
      </dl><dl><dt>
          
          <code><a href="k_maximum.html">k_maximum()</a></code> 
        </dt>
        <dd>Element-wise maximum of <code>x1</code> and <code>x2</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_mean.html">k_mean()</a></code> 
        </dt>
        <dd>Compute the arithmetic mean along the specified axes.</dd>
      </dl><dl><dt>
          
          <code><a href="k_median.html">k_median()</a></code> 
        </dt>
        <dd>Compute the median along the specified axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_meshgrid.html">k_meshgrid()</a></code> 
        </dt>
        <dd>Creates grids of coordinates from coordinate vectors.</dd>
      </dl><dl><dt>
          
          <code><a href="k_min.html">k_min()</a></code> 
        </dt>
        <dd>Return the minimum of a tensor or minimum along an axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_minimum.html">k_minimum()</a></code> 
        </dt>
        <dd>Element-wise minimum of <code>x1</code> and <code>x2</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_mod.html">k_mod()</a></code> 
        </dt>
        <dd>Returns the element-wise remainder of division.</dd>
      </dl><dl><dt>
          
          <code><a href="k_moments.html">k_moments()</a></code> 
        </dt>
        <dd>Calculates the mean and variance of <code>x</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_moveaxis.html">k_moveaxis()</a></code> 
        </dt>
        <dd>Move axes of a tensor to new positions.</dd>
      </dl><dl><dt>
          
          <code><a href="k_multi_hot.html">k_multi_hot()</a></code> 
        </dt>
        <dd>Encodes integer labels as multi-hot vectors.</dd>
      </dl><dl><dt>
          
          <code><a href="k_multiply.html">k_multiply()</a></code> 
        </dt>
        <dd>Multiply arguments element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_nan_to_num.html">k_nan_to_num()</a></code> 
        </dt>
        <dd>Replace NaN with zero and infinity with large finite numbers.</dd>
      </dl><dl><dt>
          
          <code><a href="k_ndim.html">k_ndim()</a></code> 
        </dt>
        <dd>Return the number of dimensions of a tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_negative.html">k_negative()</a></code> 
        </dt>
        <dd>Numerical negative, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_nonzero.html">k_nonzero()</a></code> 
        </dt>
        <dd>Return the indices of the elements that are non-zero.</dd>
      </dl><dl><dt>
          
          <code><a href="k_not_equal.html">k_not_equal()</a></code> 
        </dt>
        <dd>Return <code>(x1 != x2)</code> element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_one_hot.html">k_one_hot()</a></code> 
        </dt>
        <dd>Converts integer tensor <code>x</code> into a one-hot tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_ones.html">k_ones()</a></code> 
        </dt>
        <dd>Return a new tensor of given shape and type, filled with ones.</dd>
      </dl><dl><dt>
          
          <code><a href="k_ones_like.html">k_ones_like()</a></code> 
        </dt>
        <dd>Return a tensor of ones with the same shape and type of <code>x</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_outer.html">k_outer()</a></code> 
        </dt>
        <dd>Compute the outer product of two vectors.</dd>
      </dl><dl><dt>
          
          <code><a href="k_pad.html">k_pad()</a></code> 
        </dt>
        <dd>Pad a tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_power.html">k_power()</a></code> 
        </dt>
        <dd>First tensor elements raised to powers from second tensor, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_prod.html">k_prod()</a></code> 
        </dt>
        <dd>Return the product of tensor elements over a given axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_qr.html">k_qr()</a></code> 
        </dt>
        <dd>Computes the QR decomposition of a tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_quantile.html">k_quantile()</a></code> 
        </dt>
        <dd>Compute the q-th quantile(s) of the data along the specified axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_ravel.html">k_ravel()</a></code> 
        </dt>
        <dd>Return a contiguous flattened tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_real.html">k_real()</a></code> 
        </dt>
        <dd>Return the real part of the complex argument.</dd>
      </dl><dl><dt>
          
          <code><a href="k_reciprocal.html">k_reciprocal()</a></code> 
        </dt>
        <dd>Return the reciprocal of the argument, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_relu.html">k_relu()</a></code> 
        </dt>
        <dd>Rectified linear unit activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="k_relu6.html">k_relu6()</a></code> 
        </dt>
        <dd>Rectified linear unit activation function with upper bound of 6.</dd>
      </dl><dl><dt>
          
          <code><a href="k_repeat.html">k_repeat()</a></code> 
        </dt>
        <dd>Repeat each element of a tensor after themselves.</dd>
      </dl><dl><dt>
          
          <code><a href="k_reshape.html">k_reshape()</a></code> 
        </dt>
        <dd>Gives a new shape to a tensor without changing its data.</dd>
      </dl><dl><dt>
          
          <code><a href="k_rfft.html">k_rfft()</a></code> 
        </dt>
        <dd>Real-valued Fast Fourier Transform along the last axis of the input.</dd>
      </dl><dl><dt>
          
          <code><a href="k_roll.html">k_roll()</a></code> 
        </dt>
        <dd>Roll tensor elements along a given axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_round.html">k_round()</a></code> 
        </dt>
        <dd>Evenly round to the given number of decimals.</dd>
      </dl><dl><dt>
          
          <code><a href="k_rsqrt.html">k_rsqrt()</a></code> 
        </dt>
        <dd>Computes reciprocal of square root of x element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_scatter.html">k_scatter()</a></code> 
        </dt>
        <dd>Returns a tensor of shape <code>shape</code> where <code>indices</code> are set to <code>values</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_scatter_update.html">k_scatter_update()</a></code> 
        </dt>
        <dd>Update inputs via updates at scattered (sparse) indices.</dd>
      </dl><dl><dt>
          
          <code><a href="k_segment_max.html">k_segment_max()</a></code> 
        </dt>
        <dd>Computes the max of segments in a tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_segment_sum.html">k_segment_sum()</a></code> 
        </dt>
        <dd>Computes the sum of segments in a tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_selu.html">k_selu()</a></code> 
        </dt>
        <dd>Scaled Exponential Linear Unit (SELU) activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="k_separable_conv.html">k_separable_conv()</a></code> 
        </dt>
        <dd>General N-D separable convolution.</dd>
      </dl><dl><dt>
          
          <code><a href="k_shape.html">k_shape()</a></code> 
        </dt>
        <dd>Gets the shape of the tensor input.</dd>
      </dl><dl><dt>
          
          <code><a href="k_sigmoid.html">k_sigmoid()</a></code> 
        </dt>
        <dd>Sigmoid activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="k_sign.html">k_sign()</a></code> 
        </dt>
        <dd>Returns a tensor with the signs of the elements of <code>x</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_silu.html">k_silu()</a></code> 
        </dt>
        <dd>Sigmoid Linear Unit (SiLU) activation function, also known as Swish.</dd>
      </dl><dl><dt>
          
          <code><a href="k_sin.html">k_sin()</a></code> 
        </dt>
        <dd>Trigonomeric sine, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_sinh.html">k_sinh()</a></code> 
        </dt>
        <dd>Hyperbolic sine, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_size.html">k_size()</a></code> 
        </dt>
        <dd>Return the number of elements in a tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_slice.html">k_slice()</a></code> 
        </dt>
        <dd>Return a slice of an input tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_slice_update.html">k_slice_update()</a></code> 
        </dt>
        <dd>Update an input by slicing in a tensor of updated values.</dd>
      </dl><dl><dt>
          
          <code><a href="k_softmax.html">k_softmax()</a></code> 
        </dt>
        <dd>Softmax activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="k_softplus.html">k_softplus()</a></code> 
        </dt>
        <dd>Softplus activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="k_softsign.html">k_softsign()</a></code> 
        </dt>
        <dd>Softsign activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="k_solve.html">k_solve()</a></code> 
        </dt>
        <dd>Solves for <code>x</code> in the equation <code>a * x = b</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_sort.html">k_sort()</a></code> 
        </dt>
        <dd>Sorts the elements of <code>x</code> along a given axis in ascending order.</dd>
      </dl><dl><dt>
          
          <code><a href="k_sparse_categorical_crossentropy.html">k_sparse_categorical_crossentropy()</a></code> 
        </dt>
        <dd>Computes sparse categorical cross-entropy loss.</dd>
      </dl><dl><dt>
          
          <code><a href="k_split.html">k_split()</a></code> 
        </dt>
        <dd>Split a tensor into chunks.</dd>
      </dl><dl><dt>
          
          <code><a href="k_sqrt.html">k_sqrt()</a></code> 
        </dt>
        <dd>Return the non-negative square root of a tensor, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_square.html">k_square()</a></code> 
        </dt>
        <dd>Return the element-wise square of the input.</dd>
      </dl><dl><dt>
          
          <code><a href="k_squeeze.html">k_squeeze()</a></code> 
        </dt>
        <dd>Remove axes of length one from <code>x</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_stack.html">k_stack()</a></code> 
        </dt>
        <dd>Join a sequence of tensors along a new axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_std.html">k_std()</a></code> 
        </dt>
        <dd>Compute the standard deviation along the specified axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_stft.html">k_stft()</a></code> 
        </dt>
        <dd>Short-Time Fourier Transform along the last axis of the input.</dd>
      </dl><dl><dt>
          
          <code><a href="k_stop_gradient.html">k_stop_gradient()</a></code> 
        </dt>
        <dd>Stops gradient computation.</dd>
      </dl><dl><dt>
          
          <code><a href="k_subtract.html">k_subtract()</a></code> 
        </dt>
        <dd>Subtract arguments element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_sum.html">k_sum()</a></code> 
        </dt>
        <dd>Sum of a tensor over the given axes.</dd>
      </dl><dl><dt>
          
          <code><a href="k_swapaxes.html">k_swapaxes()</a></code> 
        </dt>
        <dd>Interchange two axes of a tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_take.html">k_take()</a></code> 
        </dt>
        <dd>Take elements from a tensor along an axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_take_along_axis.html">k_take_along_axis()</a></code> 
        </dt>
        <dd>Select values from <code>x</code> at the 1-D <code>indices</code> along the given axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_tan.html">k_tan()</a></code> 
        </dt>
        <dd>Compute tangent, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_tanh.html">k_tanh()</a></code> 
        </dt>
        <dd>Hyperbolic tangent, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_tensordot.html">k_tensordot()</a></code> 
        </dt>
        <dd>Compute the tensor dot product along specified axes.</dd>
      </dl><dl><dt>
          
          <code><a href="k_tile.html">k_tile()</a></code> 
        </dt>
        <dd>Repeat <code>x</code> the number of times given by <code>repeats</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_top_k.html">k_top_k()</a></code> 
        </dt>
        <dd>Finds the top-k values and their indices in a tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_trace.html">k_trace()</a></code> 
        </dt>
        <dd>Return the sum along diagonals of the tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_transpose.html">k_transpose()</a></code> 
        </dt>
        <dd>Returns a tensor with <code>axes</code> transposed.</dd>
      </dl><dl><dt>
          
          <code><a href="k_tri.html">k_tri()</a></code> 
        </dt>
        <dd>Return a tensor with ones at and below a diagonal and zeros elsewhere.</dd>
      </dl><dl><dt>
          
          <code><a href="k_tril.html">k_tril()</a></code> 
        </dt>
        <dd>Return lower triangle of a tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_triu.html">k_triu()</a></code> 
        </dt>
        <dd>Return upper triangle of a tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_true_divide.html">k_true_divide()</a></code> 
        </dt>
        <dd>Alias for <code>keras.ops.divide</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_unstack.html">k_unstack()</a></code> 
        </dt>
        <dd>Unpacks the given dimension of a rank-R tensor into rank-(R-1) tensors.</dd>
      </dl><dl><dt>
          
          <code><a href="k_var.html">k_var()</a></code> 
        </dt>
        <dd>Compute the variance along the specified axes.</dd>
      </dl><dl><dt>
          
          <code><a href="k_vdot.html">k_vdot()</a></code> 
        </dt>
        <dd>Return the dot product of two vectors.</dd>
      </dl><dl><dt>
          
          <code><a href="k_vectorized_map.html">k_vectorized_map()</a></code> 
        </dt>
        <dd>Parallel map of <code>function</code> on axis 0 of tensor(s) <code>elements</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_vstack.html">k_vstack()</a></code> 
        </dt>
        <dd>Stack tensors in sequence vertically (row wise).</dd>
      </dl><dl><dt>
          
          <code><a href="k_where.html">k_where()</a></code> 
        </dt>
        <dd>Return elements chosen from <code>x1</code> or <code>x2</code> depending on <code>condition</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_while_loop.html">k_while_loop()</a></code> 
        </dt>
        <dd>While loop implementation.</dd>
      </dl><dl><dt>
          
          <code><a href="k_zeros.html">k_zeros()</a></code> 
        </dt>
        <dd>Return a new tensor of given shape and type, filled with zeros.</dd>
      </dl><dl><dt>
          
          <code><a href="k_zeros_like.html">k_zeros_like()</a></code> 
        </dt>
        <dd>Return a tensor of zeros with the same shape and type as <code>x</code>.</dd>
      </dl></div><div class="section level2">
      <h2 id="configuration">Configuration<a class="anchor" aria-label="anchor" href="#configuration"></a></h2>
      
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="config_backend.html">config_backend()</a></code> 
        </dt>
        <dd>Publicly accessible method for determining the current backend.</dd>
      </dl><dl><dt>
          
          <code><a href="config_disable_interactive_logging.html">config_disable_interactive_logging()</a></code> 
        </dt>
        <dd>Turn off interactive logging.</dd>
      </dl><dl><dt>
          
          <code><a href="config_disable_traceback_filtering.html">config_disable_traceback_filtering()</a></code> 
        </dt>
        <dd>Turn off traceback filtering.</dd>
      </dl><dl><dt>
          
          <code><a href="config_enable_interactive_logging.html">config_enable_interactive_logging()</a></code> 
        </dt>
        <dd>Turn on interactive logging.</dd>
      </dl><dl><dt>
          
          <code><a href="config_enable_traceback_filtering.html">config_enable_traceback_filtering()</a></code> 
        </dt>
        <dd>Turn on traceback filtering.</dd>
      </dl><dl><dt>
          
          <code><a href="config_enable_unsafe_deserialization.html">config_enable_unsafe_deserialization()</a></code> 
        </dt>
        <dd>Disables safe mode globally, allowing deserialization of lambdas.</dd>
      </dl><dl><dt>
          
          <code><a href="config_epsilon.html">config_epsilon()</a></code> 
        </dt>
        <dd>Return the value of the fuzz factor used in numeric expressions.</dd>
      </dl><dl><dt>
          
          <code><a href="config_floatx.html">config_floatx()</a></code> 
        </dt>
        <dd>Return the default float type, as a string.</dd>
      </dl><dl><dt>
          
          <code><a href="config_image_data_format.html">config_image_data_format()</a></code> 
        </dt>
        <dd>Return the default image data format convention.</dd>
      </dl><dl><dt>
          
          <code><a href="config_is_interactive_logging_enabled.html">config_is_interactive_logging_enabled()</a></code> 
        </dt>
        <dd>Check if interactive logging is enabled.</dd>
      </dl><dl><dt>
          
          <code><a href="config_is_traceback_filtering_enabled.html">config_is_traceback_filtering_enabled()</a></code> 
        </dt>
        <dd>Check if traceback filtering is enabled.</dd>
      </dl><dl><dt>
          
          <code><a href="config_set_epsilon.html">config_set_epsilon()</a></code> 
        </dt>
        <dd>Set the value of the fuzz factor used in numeric expressions.</dd>
      </dl><dl><dt>
          
          <code><a href="config_set_floatx.html">config_set_floatx()</a></code> 
        </dt>
        <dd>Set the default float dtype.</dd>
      </dl><dl><dt>
          
          <code><a href="config_set_image_data_format.html">config_set_image_data_format()</a></code> 
        </dt>
        <dd>Set the value of the image data format convention.</dd>
      </dl></div><div class="section level2">
      <h2 id="python">Python<a class="anchor" aria-label="anchor" href="#python"></a></h2>
      
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="keras.html">keras</a></code> 
        </dt>
        <dd>Main Keras module</dd>
      </dl><dl><dt>
          
          <code><a href="grapes-py_class-grapes.html">`%py_class%`</a></code> 
        </dt>
        <dd>Make a python class constructor</dd>
      </dl><dl><dt>
          
          <code><a href="grapes-set-active-grapes.html">`%&lt;-active%`</a></code> 
        </dt>
        <dd>Make an Active Binding</dd>
      </dl></div><div class="section level2">
      <h2 id="catchall">Catchall<a class="anchor" aria-label="anchor" href="#catchall"></a></h2>
      
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="activation_elu.html">activation_elu()</a></code> 
        </dt>
        <dd>Exponential Linear Unit.</dd>
      </dl><dl><dt>
          
          <code><a href="activation_exponential.html">activation_exponential()</a></code> 
        </dt>
        <dd>Exponential activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="activation_gelu.html">activation_gelu()</a></code> 
        </dt>
        <dd>Gaussian error linear unit (GELU) activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="activation_hard_sigmoid.html">activation_hard_sigmoid()</a></code> 
        </dt>
        <dd>Hard sigmoid activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="activation_leaky_relu.html">activation_leaky_relu()</a></code> 
        </dt>
        <dd>Leaky relu activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="activation_linear.html">activation_linear()</a></code> 
        </dt>
        <dd>Linear activation function (pass-through).</dd>
      </dl><dl><dt>
          
          <code><a href="activation_log_softmax.html">activation_log_softmax()</a></code> 
        </dt>
        <dd>Log-Softmax activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="activation_mish.html">activation_mish()</a></code> 
        </dt>
        <dd>Mish activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="activation_relu.html">activation_relu()</a></code> 
        </dt>
        <dd>Applies the rectified linear unit activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="activation_relu6.html">activation_relu6()</a></code> 
        </dt>
        <dd>Relu6 activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="activation_selu.html">activation_selu()</a></code> 
        </dt>
        <dd>Scaled Exponential Linear Unit (SELU).</dd>
      </dl><dl><dt>
          
          <code><a href="activation_sigmoid.html">activation_sigmoid()</a></code> 
        </dt>
        <dd>Sigmoid activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="activation_silu.html">activation_silu()</a></code> 
        </dt>
        <dd>Swish (or Silu) activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="activation_softmax.html">activation_softmax()</a></code> 
        </dt>
        <dd>Softmax converts a vector of values to a probability distribution.</dd>
      </dl><dl><dt>
          
          <code><a href="activation_softplus.html">activation_softplus()</a></code> 
        </dt>
        <dd>Softplus activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="activation_softsign.html">activation_softsign()</a></code> 
        </dt>
        <dd>Softsign activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="activation_tanh.html">activation_tanh()</a></code> 
        </dt>
        <dd>Hyperbolic tangent activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="adapt.html">adapt()</a></code> 
        </dt>
        <dd>Fits the state of the preprocessing layer to the data being passed</dd>
      </dl><dl><dt>
          
          <code><a href="application_convnext_base.html">application_convnext_base()</a></code> 
        </dt>
        <dd>Instantiates the ConvNeXtBase architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_convnext_large.html">application_convnext_large()</a></code> 
        </dt>
        <dd>Instantiates the ConvNeXtLarge architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_convnext_small.html">application_convnext_small()</a></code> 
        </dt>
        <dd>Instantiates the ConvNeXtSmall architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_convnext_tiny.html">application_convnext_tiny()</a></code> 
        </dt>
        <dd>Instantiates the ConvNeXtTiny architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_convnext_xlarge.html">application_convnext_xlarge()</a></code> 
        </dt>
        <dd>Instantiates the ConvNeXtXLarge architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_densenet121.html">application_densenet121()</a></code> 
        </dt>
        <dd>Instantiates the Densenet121 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_densenet169.html">application_densenet169()</a></code> 
        </dt>
        <dd>Instantiates the Densenet169 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_densenet201.html">application_densenet201()</a></code> 
        </dt>
        <dd>Instantiates the Densenet201 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_efficientnet_b0.html">application_efficientnet_b0()</a></code> 
        </dt>
        <dd>Instantiates the EfficientNetB0 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_efficientnet_b1.html">application_efficientnet_b1()</a></code> 
        </dt>
        <dd>Instantiates the EfficientNetB1 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_efficientnet_b2.html">application_efficientnet_b2()</a></code> 
        </dt>
        <dd>Instantiates the EfficientNetB2 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_efficientnet_b3.html">application_efficientnet_b3()</a></code> 
        </dt>
        <dd>Instantiates the EfficientNetB3 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_efficientnet_b4.html">application_efficientnet_b4()</a></code> 
        </dt>
        <dd>Instantiates the EfficientNetB4 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_efficientnet_b5.html">application_efficientnet_b5()</a></code> 
        </dt>
        <dd>Instantiates the EfficientNetB5 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_efficientnet_b6.html">application_efficientnet_b6()</a></code> 
        </dt>
        <dd>Instantiates the EfficientNetB6 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_efficientnet_b7.html">application_efficientnet_b7()</a></code> 
        </dt>
        <dd>Instantiates the EfficientNetB7 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_efficientnet_v2b0.html">application_efficientnet_v2b0()</a></code> 
        </dt>
        <dd>Instantiates the EfficientNetV2B0 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_efficientnet_v2b1.html">application_efficientnet_v2b1()</a></code> 
        </dt>
        <dd>Instantiates the EfficientNetV2B1 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_efficientnet_v2b2.html">application_efficientnet_v2b2()</a></code> 
        </dt>
        <dd>Instantiates the EfficientNetV2B2 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_efficientnet_v2b3.html">application_efficientnet_v2b3()</a></code> 
        </dt>
        <dd>Instantiates the EfficientNetV2B3 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_efficientnet_v2l.html">application_efficientnet_v2l()</a></code> 
        </dt>
        <dd>Instantiates the EfficientNetV2L architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_efficientnet_v2m.html">application_efficientnet_v2m()</a></code> 
        </dt>
        <dd>Instantiates the EfficientNetV2M architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_efficientnet_v2s.html">application_efficientnet_v2s()</a></code> 
        </dt>
        <dd>Instantiates the EfficientNetV2S architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_inception_resnet_v2.html">application_inception_resnet_v2()</a></code> 
        </dt>
        <dd>Instantiates the Inception-ResNet v2 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_inception_v3.html">application_inception_v3()</a></code> 
        </dt>
        <dd>Instantiates the Inception v3 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_mobilenet.html">application_mobilenet()</a></code> 
        </dt>
        <dd>Instantiates the MobileNet architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_mobilenet_v2.html">application_mobilenet_v2()</a></code> 
        </dt>
        <dd>Instantiates the MobileNetV2 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_mobilenet_v3_large.html">application_mobilenet_v3_large()</a></code> 
        </dt>
        <dd>Instantiates the MobileNetV3Large architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_mobilenet_v3_small.html">application_mobilenet_v3_small()</a></code> 
        </dt>
        <dd>Instantiates the MobileNetV3Small architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_nasnetlarge.html">application_nasnetlarge()</a></code> 
        </dt>
        <dd>Instantiates a NASNet model in ImageNet mode.</dd>
      </dl><dl><dt>
          
          <code><a href="application_nasnetmobile.html">application_nasnetmobile()</a></code> 
        </dt>
        <dd>Instantiates a Mobile NASNet model in ImageNet mode.</dd>
      </dl><dl><dt>
          
          <code><a href="application_resnet101.html">application_resnet101()</a></code> 
        </dt>
        <dd>Instantiates the ResNet101 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_resnet101_v2.html">application_resnet101_v2()</a></code> 
        </dt>
        <dd>Instantiates the ResNet101V2 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_resnet152.html">application_resnet152()</a></code> 
        </dt>
        <dd>Instantiates the ResNet152 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_resnet152_v2.html">application_resnet152_v2()</a></code> 
        </dt>
        <dd>Instantiates the ResNet152V2 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_resnet50.html">application_resnet50()</a></code> 
        </dt>
        <dd>Instantiates the ResNet50 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_resnet50_v2.html">application_resnet50_v2()</a></code> 
        </dt>
        <dd>Instantiates the ResNet50V2 architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="application_vgg16.html">application_vgg16()</a></code> 
        </dt>
        <dd>Instantiates the VGG16 model.</dd>
      </dl><dl><dt>
          
          <code><a href="application_vgg19.html">application_vgg19()</a></code> 
        </dt>
        <dd>Instantiates the VGG19 model.</dd>
      </dl><dl><dt>
          
          <code><a href="application_xception.html">application_xception()</a></code> 
        </dt>
        <dd>Instantiates the Xception architecture.</dd>
      </dl><dl><dt>
          
          <code><a href="audio_dataset_from_directory.html">audio_dataset_from_directory()</a></code> 
        </dt>
        <dd>Generates a <code>tf.data.Dataset</code> from audio files in a directory.</dd>
      </dl><dl><dt>
          
          <code><a href="backend.html">backend()</a></code> 
        </dt>
        <dd>Keras backend tensor engine</dd>
      </dl><dl><dt>
          
          <code><a href="bidirectional.html">bidirectional()</a></code> 
        </dt>
        <dd>Bidirectional wrapper for RNNs</dd>
      </dl><dl><dt>
          
          <code><a href="callback_backup_and_restore.html">callback_backup_and_restore()</a></code> 
        </dt>
        <dd>Callback to back up and restore the training state.</dd>
      </dl><dl><dt>
          
          <code><a href="callback_csv_logger.html">callback_csv_logger()</a></code> 
        </dt>
        <dd>Callback that streams epoch results to a CSV file.</dd>
      </dl><dl><dt>
          
          <code><a href="callback_early_stopping.html">callback_early_stopping()</a></code> 
        </dt>
        <dd>Stop training when a monitored metric has stopped improving.</dd>
      </dl><dl><dt>
          
          <code><a href="callback_lambda.html">callback_lambda()</a></code> 
        </dt>
        <dd>Callback for creating simple, custom callbacks on-the-fly.</dd>
      </dl><dl><dt>
          
          <code><a href="callback_learning_rate_scheduler.html">callback_learning_rate_scheduler()</a></code> 
        </dt>
        <dd>Learning rate scheduler.</dd>
      </dl><dl><dt>
          
          <code><a href="callback_model_checkpoint.html">callback_model_checkpoint()</a></code> 
        </dt>
        <dd>Callback to save the Keras model or model weights at some frequency.
@description
<code><a href="../reference/callback_model_checkpoint.html">callback_model_checkpoint()</a></code> is used in conjunction with training using
<code>model |&gt; fit()</code> to save a model or weights (in a checkpoint file) at some
interval, so the model or weights can be loaded later to continue the
training from the state saved.</dd>
      </dl><dl><dt>
          
          <code><a href="callback_progbar_logger.html">callback_progbar_logger()</a></code> 
        </dt>
        <dd>Callback that prints metrics to stdout.</dd>
      </dl><dl><dt>
          
          <code><a href="callback_reduce_lr_on_plateau.html">callback_reduce_lr_on_plateau()</a></code> 
        </dt>
        <dd>Reduce learning rate when a metric has stopped improving.</dd>
      </dl><dl><dt>
          
          <code><a href="callback_remote_monitor.html">callback_remote_monitor()</a></code> 
        </dt>
        <dd>Callback used to stream events to a server.</dd>
      </dl><dl><dt>
          
          <code><a href="callback_tensorboard.html">callback_tensorboard()</a></code> 
        </dt>
        <dd>Enable visualizations for TensorBoard.</dd>
      </dl><dl><dt>
          
          <code><a href="callback_terminate_on_nan.html">callback_terminate_on_nan()</a></code> 
        </dt>
        <dd>Callback that terminates training when a NaN loss is encountered.</dd>
      </dl><dl><dt>
          
          <code><a href="clear_session.html">clear_session()</a></code> 
        </dt>
        <dd>Resets all state generated by Keras.</dd>
      </dl><dl><dt>
          
          <code><a href="clone_model.html">clone_model()</a></code> 
        </dt>
        <dd>Clone a model instance.</dd>
      </dl><dl><dt>
          
          <code><a href="compile.keras.models.model.Model.html">compile(<i>&lt;keras.models.model.Model&gt;</i>)</a></code> 
        </dt>
        <dd>Configure a Keras model for training</dd>
      </dl><dl><dt>
          
          <code><a href="config_backend.html">config_backend()</a></code> 
        </dt>
        <dd>Publicly accessible method for determining the current backend.</dd>
      </dl><dl><dt>
          
          <code><a href="config_disable_interactive_logging.html">config_disable_interactive_logging()</a></code> 
        </dt>
        <dd>Turn off interactive logging.</dd>
      </dl><dl><dt>
          
          <code><a href="config_disable_traceback_filtering.html">config_disable_traceback_filtering()</a></code> 
        </dt>
        <dd>Turn off traceback filtering.</dd>
      </dl><dl><dt>
          
          <code><a href="config_enable_interactive_logging.html">config_enable_interactive_logging()</a></code> 
        </dt>
        <dd>Turn on interactive logging.</dd>
      </dl><dl><dt>
          
          <code><a href="config_enable_traceback_filtering.html">config_enable_traceback_filtering()</a></code> 
        </dt>
        <dd>Turn on traceback filtering.</dd>
      </dl><dl><dt>
          
          <code><a href="config_enable_unsafe_deserialization.html">config_enable_unsafe_deserialization()</a></code> 
        </dt>
        <dd>Disables safe mode globally, allowing deserialization of lambdas.</dd>
      </dl><dl><dt>
          
          <code><a href="config_epsilon.html">config_epsilon()</a></code> 
        </dt>
        <dd>Return the value of the fuzz factor used in numeric expressions.</dd>
      </dl><dl><dt>
          
          <code><a href="config_floatx.html">config_floatx()</a></code> 
        </dt>
        <dd>Return the default float type, as a string.</dd>
      </dl><dl><dt>
          
          <code><a href="config_image_data_format.html">config_image_data_format()</a></code> 
        </dt>
        <dd>Return the default image data format convention.</dd>
      </dl><dl><dt>
          
          <code><a href="config_is_interactive_logging_enabled.html">config_is_interactive_logging_enabled()</a></code> 
        </dt>
        <dd>Check if interactive logging is enabled.</dd>
      </dl><dl><dt>
          
          <code><a href="config_is_traceback_filtering_enabled.html">config_is_traceback_filtering_enabled()</a></code> 
        </dt>
        <dd>Check if traceback filtering is enabled.</dd>
      </dl><dl><dt>
          
          <code><a href="config_set_epsilon.html">config_set_epsilon()</a></code> 
        </dt>
        <dd>Set the value of the fuzz factor used in numeric expressions.</dd>
      </dl><dl><dt>
          
          <code><a href="config_set_floatx.html">config_set_floatx()</a></code> 
        </dt>
        <dd>Set the default float dtype.</dd>
      </dl><dl><dt>
          
          <code><a href="config_set_image_data_format.html">config_set_image_data_format()</a></code> 
        </dt>
        <dd>Set the value of the image data format convention.</dd>
      </dl><dl><dt>
          
          <code><a href="constraint_maxnorm.html">constraint_maxnorm()</a></code> 
        </dt>
        <dd>MaxNorm weight constraint.</dd>
      </dl><dl><dt>
          
          <code><a href="constraint_minmaxnorm.html">constraint_minmaxnorm()</a></code> 
        </dt>
        <dd>MinMaxNorm weight constraint.</dd>
      </dl><dl><dt>
          
          <code><a href="constraint_nonneg.html">constraint_nonneg()</a></code> 
        </dt>
        <dd>Constrains the weights to be non-negative.</dd>
      </dl><dl><dt>
          
          <code><a href="constraint_unitnorm.html">constraint_unitnorm()</a></code> 
        </dt>
        <dd>Constrains the weights incident to each hidden unit to have unit norm.</dd>
      </dl><dl><dt>
          
          <code><a href="count_params.html">count_params()</a></code> 
        </dt>
        <dd>Count the total number of scalars composing the weights.</dd>
      </dl><dl><dt>
          
          <code><a href="create_layer.html">create_layer()</a></code> 
        </dt>
        <dd>Create a Keras Layer</dd>
      </dl><dl><dt>
          
          <code><a href="create_layer_wrapper.html">create_layer_wrapper()</a></code> 
        </dt>
        <dd>Create a Keras Layer wrapper</dd>
      </dl><dl><dt>
          
          <code><a href="custom_metric.html">custom_metric()</a></code> 
        </dt>
        <dd>Custom metric function</dd>
      </dl><dl><dt>
          
          <code><a href="dataset_boston_housing.html">dataset_boston_housing()</a></code> 
        </dt>
        <dd>Boston housing price regression dataset</dd>
      </dl><dl><dt>
          
          <code><a href="dataset_cifar10.html">dataset_cifar10()</a></code> 
        </dt>
        <dd>CIFAR10 small image classification</dd>
      </dl><dl><dt>
          
          <code><a href="dataset_cifar100.html">dataset_cifar100()</a></code> 
        </dt>
        <dd>CIFAR100 small image classification</dd>
      </dl><dl><dt>
          
          <code><a href="dataset_fashion_mnist.html">dataset_fashion_mnist()</a></code> 
        </dt>
        <dd>Fashion-MNIST database of fashion articles</dd>
      </dl><dl><dt>
          
          <code><a href="dataset_imdb.html">dataset_imdb()</a></code> <code><a href="dataset_imdb.html">dataset_imdb_word_index()</a></code> 
        </dt>
        <dd>IMDB Movie reviews sentiment classification</dd>
      </dl><dl><dt>
          
          <code><a href="dataset_mnist.html">dataset_mnist()</a></code> 
        </dt>
        <dd>MNIST database of handwritten digits</dd>
      </dl><dl><dt>
          
          <code><a href="dataset_reuters.html">dataset_reuters()</a></code> <code><a href="dataset_reuters.html">dataset_reuters_word_index()</a></code> 
        </dt>
        <dd>Reuters newswire topics classification</dd>
      </dl><dl><dt>
          
          <code><a href="evaluate.keras.models.model.Model.html">evaluate(<i>&lt;keras.models.model.Model&gt;</i>)</a></code> 
        </dt>
        <dd>Evaluate a Keras model</dd>
      </dl><dl><dt>
          
          <code><a href="export_savedmodel.keras.models.model.Model.html">export_savedmodel(<i>&lt;keras.models.model.Model&gt;</i>)</a></code> 
        </dt>
        <dd>Export a Saved Model</dd>
      </dl><dl><dt>
          
          <code><a href="fit.keras.models.model.Model.html">fit(<i>&lt;keras.models.model.Model&gt;</i>)</a></code> 
        </dt>
        <dd>Train a Keras model</dd>
      </dl><dl><dt>
          
          <code><a href="freeze_weights.html">freeze_weights()</a></code> <code><a href="freeze_weights.html">unfreeze_weights()</a></code> 
        </dt>
        <dd>Freeze and unfreeze weights</dd>
      </dl><dl><dt>
          
          <code><a href="get_config.html">get_config()</a></code> <code><a href="get_config.html">from_config()</a></code> 
        </dt>
        <dd>Layer/Model configuration</dd>
      </dl><dl><dt>
          
          <code><a href="summary.keras.models.model.Model.html">summary(<i>&lt;keras.models.model.Model&gt;</i>)</a></code> <code><a href="summary.keras.models.model.Model.html">format(<i>&lt;keras.models.model.Model&gt;</i>)</a></code> <code><a href="summary.keras.models.model.Model.html">print(<i>&lt;keras.models.model.Model&gt;</i>)</a></code> 
        </dt>
        <dd>Print a summary of a Keras model</dd>
      </dl><dl><dt>
          
          <code><a href="get_custom_objects.html">get_custom_objects()</a></code> 
        </dt>
        <dd>Retrieves a live reference to the global dictionary of custom objects.</dd>
      </dl><dl><dt>
          
          <code><a href="get_file.html">get_file()</a></code> 
        </dt>
        <dd>Downloads a file from a URL if it not already in the cache.</dd>
      </dl><dl><dt>
          
          <code><a href="get_input_at.html">get_input_at()</a></code> <code><a href="get_input_at.html">get_output_at()</a></code> <code><a href="get_input_at.html">get_input_shape_at()</a></code> <code><a href="get_input_at.html">get_output_shape_at()</a></code> <code><a href="get_input_at.html">get_input_mask_at()</a></code> <code><a href="get_input_at.html">get_output_mask_at()</a></code> 
        </dt>
        <dd>Retrieve tensors for layers with multiple nodes</dd>
      </dl><dl><dt>
          
          <code><a href="get_layer.html">get_layer()</a></code> 
        </dt>
        <dd>Retrieves a layer based on either its name (unique) or index.</dd>
      </dl><dl><dt>
          
          <code><a href="get_registered_name.html">get_registered_name()</a></code> 
        </dt>
        <dd>Returns the name registered to an object within the Keras framework.</dd>
      </dl><dl><dt>
          
          <code><a href="get_registered_object.html">get_registered_object()</a></code> 
        </dt>
        <dd>Returns the class associated with <code>name</code> if it is registered with Keras.</dd>
      </dl><dl><dt>
          
          <code><a href="get_source_inputs.html">get_source_inputs()</a></code> 
        </dt>
        <dd>Returns the list of input tensors necessary to compute <code>tensor</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="get_weights.html">get_weights()</a></code> <code><a href="get_weights.html">set_weights()</a></code> 
        </dt>
        <dd>Layer/Model weights as R arrays</dd>
      </dl><dl><dt>
          
          <code><a href="layer_text_vectorization.html">layer_text_vectorization()</a></code> <code><a href="layer_text_vectorization.html">get_vocabulary()</a></code> <code><a href="layer_text_vectorization.html">set_vocabulary()</a></code> 
        </dt>
        <dd>A preprocessing layer which maps text features to integer sequences.</dd>
      </dl><dl><dt>
          
          <code><a href="image_array_save.html">image_array_save()</a></code> 
        </dt>
        <dd>Saves an image stored as a NumPy array to a path or file object.</dd>
      </dl><dl><dt>
          
          <code><a href="image_dataset_from_directory.html">image_dataset_from_directory()</a></code> 
        </dt>
        <dd>Generates a <code>tf.data.Dataset</code> from image files in a directory.</dd>
      </dl><dl><dt>
          
          <code><a href="image_from_array.html">image_from_array()</a></code> 
        </dt>
        <dd>Converts a 3D array to a PIL Image instance.</dd>
      </dl><dl><dt>
          
          <code><a href="image_load.html">image_load()</a></code> 
        </dt>
        <dd>Loads an image into PIL format.</dd>
      </dl><dl><dt>
          
          <code><a href="image_smart_resize.html">image_smart_resize()</a></code> 
        </dt>
        <dd>Resize images to a target size without aspect ratio distortion.</dd>
      </dl><dl><dt>
          
          <code><a href="image_to_array.html">image_to_array()</a></code> 
        </dt>
        <dd>Converts a PIL Image instance to a matrix.</dd>
      </dl><dl><dt>
          
          <code><a href="implementation.html">implementation()</a></code> 
        </dt>
        <dd>Keras implementation</dd>
      </dl><dl><dt>
          
          <code><a href="initializer_constant.html">initializer_constant()</a></code> 
        </dt>
        <dd>Initializer that generates tensors with constant values.</dd>
      </dl><dl><dt>
          
          <code><a href="initializer_glorot_normal.html">initializer_glorot_normal()</a></code> 
        </dt>
        <dd>The Glorot normal initializer, also called Xavier normal initializer.</dd>
      </dl><dl><dt>
          
          <code><a href="initializer_glorot_uniform.html">initializer_glorot_uniform()</a></code> 
        </dt>
        <dd>The Glorot uniform initializer, also called Xavier uniform initializer.</dd>
      </dl><dl><dt>
          
          <code><a href="initializer_he_normal.html">initializer_he_normal()</a></code> 
        </dt>
        <dd>He normal initializer.</dd>
      </dl><dl><dt>
          
          <code><a href="initializer_he_uniform.html">initializer_he_uniform()</a></code> 
        </dt>
        <dd>He uniform variance scaling initializer.</dd>
      </dl><dl><dt>
          
          <code><a href="initializer_identity.html">initializer_identity()</a></code> 
        </dt>
        <dd>Initializer that generates the identity matrix.</dd>
      </dl><dl><dt>
          
          <code><a href="initializer_lecun_normal.html">initializer_lecun_normal()</a></code> 
        </dt>
        <dd>Lecun normal initializer.</dd>
      </dl><dl><dt>
          
          <code><a href="initializer_lecun_uniform.html">initializer_lecun_uniform()</a></code> 
        </dt>
        <dd>Lecun uniform initializer.</dd>
      </dl><dl><dt>
          
          <code><a href="initializer_ones.html">initializer_ones()</a></code> 
        </dt>
        <dd>Initializer that generates tensors initialized to 1.</dd>
      </dl><dl><dt>
          
          <code><a href="initializer_orthogonal.html">initializer_orthogonal()</a></code> 
        </dt>
        <dd>Initializer that generates an orthogonal matrix.</dd>
      </dl><dl><dt>
          
          <code><a href="initializer_random_normal.html">initializer_random_normal()</a></code> 
        </dt>
        <dd>Random normal initializer.</dd>
      </dl><dl><dt>
          
          <code><a href="initializer_random_uniform.html">initializer_random_uniform()</a></code> 
        </dt>
        <dd>Random uniform initializer.</dd>
      </dl><dl><dt>
          
          <code><a href="initializer_truncated_normal.html">initializer_truncated_normal()</a></code> 
        </dt>
        <dd>Initializer that generates a truncated normal distribution.</dd>
      </dl><dl><dt>
          
          <code><a href="initializer_variance_scaling.html">initializer_variance_scaling()</a></code> 
        </dt>
        <dd>Initializer that adapts its scale to the shape of its input tensors.</dd>
      </dl><dl><dt>
          
          <code><a href="initializer_zeros.html">initializer_zeros()</a></code> 
        </dt>
        <dd>Initializer that generates tensors initialized to 0.</dd>
      </dl><dl><dt>
          
          <code><a href="install_keras.html">install_keras()</a></code> 
        </dt>
        <dd>Install Keras</dd>
      </dl><dl><dt>
          
          <code><a href="is_keras_available.html">is_keras_available()</a></code> 
        </dt>
        <dd>Check if Keras is Available</dd>
      </dl><dl><dt>
          
          <code><a href="k_abs.html">k_abs()</a></code> 
        </dt>
        <dd>Shorthand for <code>keras.ops.absolute</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_add.html">k_add()</a></code> 
        </dt>
        <dd>Add arguments element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_all.html">k_all()</a></code> 
        </dt>
        <dd>Test whether all array elements along a given axis evaluate to <code>TRUE</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_amax.html">k_amax()</a></code> 
        </dt>
        <dd>Returns the maximum of a vector or maximum value along an axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_amin.html">k_amin()</a></code> 
        </dt>
        <dd>Returns the minimum of a vector or minimum value along an axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_any.html">k_any()</a></code> 
        </dt>
        <dd>Test whether any array element along a given axis evaluates to <code>TRUE</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_append.html">k_append()</a></code> 
        </dt>
        <dd>Append tensor <code>x2</code> to the end of tensor <code>x1</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_arange.html">k_arange()</a></code> 
        </dt>
        <dd>Return evenly spaced values within a given interval.</dd>
      </dl><dl><dt>
          
          <code><a href="k_arccos.html">k_arccos()</a></code> 
        </dt>
        <dd>Trigonometric inverse cosine, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_arccosh.html">k_arccosh()</a></code> 
        </dt>
        <dd>Inverse hyperbolic cosine, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_arcsin.html">k_arcsin()</a></code> 
        </dt>
        <dd>Inverse sine, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_arcsinh.html">k_arcsinh()</a></code> 
        </dt>
        <dd>Inverse hyperbolic sine, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_arctan.html">k_arctan()</a></code> 
        </dt>
        <dd>Trigonometric inverse tangent, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_arctan2.html">k_arctan2()</a></code> 
        </dt>
        <dd>Element-wise arc tangent of <code>x1/x2</code> choosing the quadrant correctly.</dd>
      </dl><dl><dt>
          
          <code><a href="k_arctanh.html">k_arctanh()</a></code> 
        </dt>
        <dd>Inverse hyperbolic tangent, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_argmax.html">k_argmax()</a></code> 
        </dt>
        <dd>Returns the indices of the maximum values along an axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_argmin.html">k_argmin()</a></code> 
        </dt>
        <dd>Returns the indices of the minimum values along an axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_argsort.html">k_argsort()</a></code> 
        </dt>
        <dd>Returns the indices that would sort a tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_array.html">k_array()</a></code> 
        </dt>
        <dd>Create a tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_average.html">k_average()</a></code> 
        </dt>
        <dd>Compute the weighted average along the specified axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_average_pool.html">k_average_pool()</a></code> 
        </dt>
        <dd>Average pooling operation.</dd>
      </dl><dl><dt>
          
          <code><a href="k_binary_crossentropy.html">k_binary_crossentropy()</a></code> 
        </dt>
        <dd>Computes binary cross-entropy loss between target and output tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_bincount.html">k_bincount()</a></code> 
        </dt>
        <dd>Count the number of occurrences of each value in a tensor of integers.</dd>
      </dl><dl><dt>
          
          <code><a href="k_broadcast_to.html">k_broadcast_to()</a></code> 
        </dt>
        <dd>Broadcast a tensor to a new shape.</dd>
      </dl><dl><dt>
          
          <code><a href="k_cast.html">k_cast()</a></code> 
        </dt>
        <dd>Cast a tensor to the desired dtype.</dd>
      </dl><dl><dt>
          
          <code><a href="k_categorical_crossentropy.html">k_categorical_crossentropy()</a></code> 
        </dt>
        <dd>Computes categorical cross-entropy loss between target and output tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_ceil.html">k_ceil()</a></code> 
        </dt>
        <dd>Return the ceiling of the input, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_clip.html">k_clip()</a></code> 
        </dt>
        <dd>Clip (limit) the values in a tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_concatenate.html">k_concatenate()</a></code> 
        </dt>
        <dd>Join a sequence of tensors along an existing axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_cond.html">k_cond()</a></code> 
        </dt>
        <dd>Conditionally applies <code>true_fn</code> or <code>false_fn</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_conj.html">k_conj()</a></code> 
        </dt>
        <dd>Shorthand for <code>keras.ops.conjugate</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_conjugate.html">k_conjugate()</a></code> 
        </dt>
        <dd>Returns the complex conjugate, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_conv.html">k_conv()</a></code> 
        </dt>
        <dd>General N-D convolution.</dd>
      </dl><dl><dt>
          
          <code><a href="k_conv_transpose.html">k_conv_transpose()</a></code> 
        </dt>
        <dd>General N-D convolution transpose.</dd>
      </dl><dl><dt>
          
          <code><a href="k_convert_to_numpy.html">k_convert_to_numpy()</a></code> 
        </dt>
        <dd>Convert a tensor to a NumPy array.</dd>
      </dl><dl><dt>
          
          <code><a href="k_convert_to_tensor.html">k_convert_to_tensor()</a></code> 
        </dt>
        <dd>Convert an array to a tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_copy.html">k_copy()</a></code> 
        </dt>
        <dd>Returns a copy of <code>x</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_cos.html">k_cos()</a></code> 
        </dt>
        <dd>Cosine, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_cosh.html">k_cosh()</a></code> 
        </dt>
        <dd>Hyperbolic cosine, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_count_nonzero.html">k_count_nonzero()</a></code> 
        </dt>
        <dd>Counts the number of non-zero values in <code>x</code> along the given <code>axis</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_cross.html">k_cross()</a></code> 
        </dt>
        <dd>Returns the cross product of two (arrays of) vectors.</dd>
      </dl><dl><dt>
          
          <code><a href="k_cumprod.html">k_cumprod()</a></code> 
        </dt>
        <dd>Return the cumulative product of elements along a given axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_cumsum.html">k_cumsum()</a></code> 
        </dt>
        <dd>Returns the cumulative sum of elements along a given axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_depthwise_conv.html">k_depthwise_conv()</a></code> 
        </dt>
        <dd>General N-D depthwise convolution.</dd>
      </dl><dl><dt>
          
          <code><a href="k_diag.html">k_diag()</a></code> 
        </dt>
        <dd>Extract a diagonal or construct a diagonal array.</dd>
      </dl><dl><dt>
          
          <code><a href="k_diagonal.html">k_diagonal()</a></code> 
        </dt>
        <dd>Return specified diagonals.</dd>
      </dl><dl><dt>
          
          <code><a href="k_diff.html">k_diff()</a></code> 
        </dt>
        <dd>Calculate the n-th discrete difference along the given axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_digitize.html">k_digitize()</a></code> 
        </dt>
        <dd>Returns the indices of the bins to which each value in <code>x</code> belongs.</dd>
      </dl><dl><dt>
          
          <code><a href="k_divide.html">k_divide()</a></code> 
        </dt>
        <dd>Divide arguments element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_dot.html">k_dot()</a></code> 
        </dt>
        <dd>Dot product of two tensors.</dd>
      </dl><dl><dt>
          
          <code><a href="k_einsum.html">k_einsum()</a></code> 
        </dt>
        <dd>Evaluates the Einstein summation convention on the operands.</dd>
      </dl><dl><dt>
          
          <code><a href="k_elu.html">k_elu()</a></code> 
        </dt>
        <dd>Exponential Linear Unit activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="k_empty.html">k_empty()</a></code> 
        </dt>
        <dd>Return a tensor of given shape and type filled with uninitialized data.</dd>
      </dl><dl><dt>
          
          <code><a href="k_equal.html">k_equal()</a></code> 
        </dt>
        <dd>Returns <code>(x1 == x2)</code> element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_erf.html">k_erf()</a></code> 
        </dt>
        <dd>Computes the error function of <code>x</code>, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_exp.html">k_exp()</a></code> 
        </dt>
        <dd>Calculate the exponential of all elements in the input tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_expand_dims.html">k_expand_dims()</a></code> 
        </dt>
        <dd>Expand the shape of a tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_expm1.html">k_expm1()</a></code> 
        </dt>
        <dd>Calculate <code>exp(x) - 1</code> for all elements in the tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_extract_sequences.html">k_extract_sequences()</a></code> 
        </dt>
        <dd>Expands the dimension of last axis into sequences of <code>sequence_length</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_eye.html">k_eye()</a></code> 
        </dt>
        <dd>Return a 2-D tensor with ones on the diagonal and zeros elsewhere.</dd>
      </dl><dl><dt>
          
          <code><a href="k_fft.html">k_fft()</a></code> 
        </dt>
        <dd>Computes the Fast Fourier Transform along last axis of input.</dd>
      </dl><dl><dt>
          
          <code><a href="k_fft2.html">k_fft2()</a></code> 
        </dt>
        <dd>Computes the 2D Fast Fourier Transform along the last two axes of input.</dd>
      </dl><dl><dt>
          
          <code><a href="k_flip.html">k_flip()</a></code> 
        </dt>
        <dd>Reverse the order of elements in the tensor along the given axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_floatx.html">k_floatx()</a></code> 
        </dt>
        <dd>Return the default float type, as a string.</dd>
      </dl><dl><dt>
          
          <code><a href="k_floor.html">k_floor()</a></code> 
        </dt>
        <dd>Return the floor of the input, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_floor_divide.html">k_floor_divide()</a></code> 
        </dt>
        <dd>Returns the largest integer smaller or equal to the division of inputs.</dd>
      </dl><dl><dt>
          
          <code><a href="k_fori_loop.html">k_fori_loop()</a></code> 
        </dt>
        <dd>For loop implementation.</dd>
      </dl><dl><dt>
          
          <code><a href="k_full.html">k_full()</a></code> 
        </dt>
        <dd>Return a new tensor of given shape and type, filled with <code>fill_value</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_full_like.html">k_full_like()</a></code> 
        </dt>
        <dd>Return a full tensor with the same shape and type as the given tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_gelu.html">k_gelu()</a></code> 
        </dt>
        <dd>Gaussian Error Linear Unit (GELU) activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="k_get_item.html">k_get_item()</a></code> 
        </dt>
        <dd>Return <code>x[key]</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_greater.html">k_greater()</a></code> 
        </dt>
        <dd>Return the truth value of <code>x1 &gt; x2</code> element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_greater_equal.html">k_greater_equal()</a></code> 
        </dt>
        <dd>Return the truth value of <code>x1 &gt;= x2</code> element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_hard_sigmoid.html">k_hard_sigmoid()</a></code> 
        </dt>
        <dd>Hard sigmoid activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="k_hstack.html">k_hstack()</a></code> 
        </dt>
        <dd>Stack tensors in sequence horizontally (column wise).</dd>
      </dl><dl><dt>
          
          <code><a href="k_identity.html">k_identity()</a></code> 
        </dt>
        <dd>Return the identity tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_imag.html">k_imag()</a></code> 
        </dt>
        <dd>Return the imaginary part of the complex argument.</dd>
      </dl><dl><dt>
          
          <code><a href="k_image_affine_transform.html">k_image_affine_transform()</a></code> 
        </dt>
        <dd>Applies the given transform(s) to the image(s).</dd>
      </dl><dl><dt>
          
          <code><a href="k_image_extract_patches.html">k_image_extract_patches()</a></code> 
        </dt>
        <dd>Extracts patches from the image(s).</dd>
      </dl><dl><dt>
          
          <code><a href="k_image_map_coordinates.html">k_image_map_coordinates()</a></code> 
        </dt>
        <dd>Map the input array to new coordinates by interpolation..</dd>
      </dl><dl><dt>
          
          <code><a href="k_image_pad_images.html">k_image_pad_images()</a></code> 
        </dt>
        <dd>Pad <code>images</code> with zeros to the specified <code>height</code> and <code>width</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_image_resize.html">k_image_resize()</a></code> 
        </dt>
        <dd>Resize images to size using the specified interpolation method.</dd>
      </dl><dl><dt>
          
          <code><a href="k_in_top_k.html">k_in_top_k()</a></code> 
        </dt>
        <dd>Checks if the targets are in the top-k predictions.</dd>
      </dl><dl><dt>
          
          <code><a href="k_irfft.html">k_irfft()</a></code> 
        </dt>
        <dd>Inverse real-valued Fast Fourier transform along the last axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_isclose.html">k_isclose()</a></code> 
        </dt>
        <dd>Return whether two tensors are element-wise almost equal.</dd>
      </dl><dl><dt>
          
          <code><a href="k_isfinite.html">k_isfinite()</a></code> 
        </dt>
        <dd>Return whether a tensor is finite, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_isinf.html">k_isinf()</a></code> 
        </dt>
        <dd>Test element-wise for positive or negative infinity.</dd>
      </dl><dl><dt>
          
          <code><a href="k_isnan.html">k_isnan()</a></code> 
        </dt>
        <dd>Test element-wise for NaN and return result as a boolean tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_istft.html">k_istft()</a></code> 
        </dt>
        <dd>Inverse Short-Time Fourier Transform along the last axis of the input.</dd>
      </dl><dl><dt>
          
          <code><a href="k_leaky_relu.html">k_leaky_relu()</a></code> 
        </dt>
        <dd>Leaky version of a Rectified Linear Unit activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="k_less.html">k_less()</a></code> 
        </dt>
        <dd>Return the truth value of <code>x1 &lt; x2</code> element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_less_equal.html">k_less_equal()</a></code> 
        </dt>
        <dd>Return the truth value of <code>x1 &lt;= x2</code> element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_linspace.html">k_linspace()</a></code> 
        </dt>
        <dd>Return evenly spaced numbers over a specified interval.</dd>
      </dl><dl><dt>
          
          <code><a href="k_log.html">k_log()</a></code> 
        </dt>
        <dd>Natural logarithm, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_log10.html">k_log10()</a></code> 
        </dt>
        <dd>Return the base 10 logarithm of the input tensor, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_log1p.html">k_log1p()</a></code> 
        </dt>
        <dd>Returns the natural logarithm of one plus the <code>x</code>, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_log2.html">k_log2()</a></code> 
        </dt>
        <dd>Base-2 logarithm of <code>x</code>, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_log_sigmoid.html">k_log_sigmoid()</a></code> 
        </dt>
        <dd>Logarithm of the sigmoid activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="k_log_softmax.html">k_log_softmax()</a></code> 
        </dt>
        <dd>Log-softmax activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="k_logaddexp.html">k_logaddexp()</a></code> 
        </dt>
        <dd>Logarithm of the sum of exponentiations of the inputs.</dd>
      </dl><dl><dt>
          
          <code><a href="k_logical_and.html">k_logical_and()</a></code> 
        </dt>
        <dd>Computes the element-wise logical AND of the given input tensors.</dd>
      </dl><dl><dt>
          
          <code><a href="k_logical_not.html">k_logical_not()</a></code> 
        </dt>
        <dd>Computes the element-wise NOT of the given input tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_logical_or.html">k_logical_or()</a></code> 
        </dt>
        <dd>Computes the element-wise logical OR of the given input tensors.</dd>
      </dl><dl><dt>
          
          <code><a href="k_logical_xor.html">k_logical_xor()</a></code> 
        </dt>
        <dd>Compute the truth value of <code>x1 XOR x2</code>, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_logspace.html">k_logspace()</a></code> 
        </dt>
        <dd>Returns numbers spaced evenly on a log scale.</dd>
      </dl><dl><dt>
          
          <code><a href="k_logsumexp.html">k_logsumexp()</a></code> 
        </dt>
        <dd>Computes the logarithm of sum of exponentials of elements in a tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_matmul.html">k_matmul()</a></code> 
        </dt>
        <dd>Matrix product of two tensors.</dd>
      </dl><dl><dt>
          
          <code><a href="k_max.html">k_max()</a></code> 
        </dt>
        <dd>Return the maximum of a tensor or maximum along an axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_max_pool.html">k_max_pool()</a></code> 
        </dt>
        <dd>Max pooling operation.</dd>
      </dl><dl><dt>
          
          <code><a href="k_maximum.html">k_maximum()</a></code> 
        </dt>
        <dd>Element-wise maximum of <code>x1</code> and <code>x2</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_mean.html">k_mean()</a></code> 
        </dt>
        <dd>Compute the arithmetic mean along the specified axes.</dd>
      </dl><dl><dt>
          
          <code><a href="k_median.html">k_median()</a></code> 
        </dt>
        <dd>Compute the median along the specified axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_meshgrid.html">k_meshgrid()</a></code> 
        </dt>
        <dd>Creates grids of coordinates from coordinate vectors.</dd>
      </dl><dl><dt>
          
          <code><a href="k_min.html">k_min()</a></code> 
        </dt>
        <dd>Return the minimum of a tensor or minimum along an axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_minimum.html">k_minimum()</a></code> 
        </dt>
        <dd>Element-wise minimum of <code>x1</code> and <code>x2</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_mod.html">k_mod()</a></code> 
        </dt>
        <dd>Returns the element-wise remainder of division.</dd>
      </dl><dl><dt>
          
          <code><a href="k_moments.html">k_moments()</a></code> 
        </dt>
        <dd>Calculates the mean and variance of <code>x</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_moveaxis.html">k_moveaxis()</a></code> 
        </dt>
        <dd>Move axes of a tensor to new positions.</dd>
      </dl><dl><dt>
          
          <code><a href="k_multi_hot.html">k_multi_hot()</a></code> 
        </dt>
        <dd>Encodes integer labels as multi-hot vectors.</dd>
      </dl><dl><dt>
          
          <code><a href="k_multiply.html">k_multiply()</a></code> 
        </dt>
        <dd>Multiply arguments element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_nan_to_num.html">k_nan_to_num()</a></code> 
        </dt>
        <dd>Replace NaN with zero and infinity with large finite numbers.</dd>
      </dl><dl><dt>
          
          <code><a href="k_ndim.html">k_ndim()</a></code> 
        </dt>
        <dd>Return the number of dimensions of a tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_negative.html">k_negative()</a></code> 
        </dt>
        <dd>Numerical negative, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_nonzero.html">k_nonzero()</a></code> 
        </dt>
        <dd>Return the indices of the elements that are non-zero.</dd>
      </dl><dl><dt>
          
          <code><a href="k_not_equal.html">k_not_equal()</a></code> 
        </dt>
        <dd>Return <code>(x1 != x2)</code> element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_one_hot.html">k_one_hot()</a></code> 
        </dt>
        <dd>Converts integer tensor <code>x</code> into a one-hot tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_ones.html">k_ones()</a></code> 
        </dt>
        <dd>Return a new tensor of given shape and type, filled with ones.</dd>
      </dl><dl><dt>
          
          <code><a href="k_ones_like.html">k_ones_like()</a></code> 
        </dt>
        <dd>Return a tensor of ones with the same shape and type of <code>x</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_outer.html">k_outer()</a></code> 
        </dt>
        <dd>Compute the outer product of two vectors.</dd>
      </dl><dl><dt>
          
          <code><a href="k_pad.html">k_pad()</a></code> 
        </dt>
        <dd>Pad a tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_power.html">k_power()</a></code> 
        </dt>
        <dd>First tensor elements raised to powers from second tensor, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_prod.html">k_prod()</a></code> 
        </dt>
        <dd>Return the product of tensor elements over a given axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_qr.html">k_qr()</a></code> 
        </dt>
        <dd>Computes the QR decomposition of a tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_quantile.html">k_quantile()</a></code> 
        </dt>
        <dd>Compute the q-th quantile(s) of the data along the specified axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_ravel.html">k_ravel()</a></code> 
        </dt>
        <dd>Return a contiguous flattened tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_real.html">k_real()</a></code> 
        </dt>
        <dd>Return the real part of the complex argument.</dd>
      </dl><dl><dt>
          
          <code><a href="k_reciprocal.html">k_reciprocal()</a></code> 
        </dt>
        <dd>Return the reciprocal of the argument, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_relu.html">k_relu()</a></code> 
        </dt>
        <dd>Rectified linear unit activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="k_relu6.html">k_relu6()</a></code> 
        </dt>
        <dd>Rectified linear unit activation function with upper bound of 6.</dd>
      </dl><dl><dt>
          
          <code><a href="k_repeat.html">k_repeat()</a></code> 
        </dt>
        <dd>Repeat each element of a tensor after themselves.</dd>
      </dl><dl><dt>
          
          <code><a href="k_reshape.html">k_reshape()</a></code> 
        </dt>
        <dd>Gives a new shape to a tensor without changing its data.</dd>
      </dl><dl><dt>
          
          <code><a href="k_rfft.html">k_rfft()</a></code> 
        </dt>
        <dd>Real-valued Fast Fourier Transform along the last axis of the input.</dd>
      </dl><dl><dt>
          
          <code><a href="k_roll.html">k_roll()</a></code> 
        </dt>
        <dd>Roll tensor elements along a given axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_round.html">k_round()</a></code> 
        </dt>
        <dd>Evenly round to the given number of decimals.</dd>
      </dl><dl><dt>
          
          <code><a href="k_rsqrt.html">k_rsqrt()</a></code> 
        </dt>
        <dd>Computes reciprocal of square root of x element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_scatter.html">k_scatter()</a></code> 
        </dt>
        <dd>Returns a tensor of shape <code>shape</code> where <code>indices</code> are set to <code>values</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_scatter_update.html">k_scatter_update()</a></code> 
        </dt>
        <dd>Update inputs via updates at scattered (sparse) indices.</dd>
      </dl><dl><dt>
          
          <code><a href="k_segment_max.html">k_segment_max()</a></code> 
        </dt>
        <dd>Computes the max of segments in a tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_segment_sum.html">k_segment_sum()</a></code> 
        </dt>
        <dd>Computes the sum of segments in a tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_selu.html">k_selu()</a></code> 
        </dt>
        <dd>Scaled Exponential Linear Unit (SELU) activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="k_separable_conv.html">k_separable_conv()</a></code> 
        </dt>
        <dd>General N-D separable convolution.</dd>
      </dl><dl><dt>
          
          <code><a href="k_shape.html">k_shape()</a></code> 
        </dt>
        <dd>Gets the shape of the tensor input.</dd>
      </dl><dl><dt>
          
          <code><a href="k_sigmoid.html">k_sigmoid()</a></code> 
        </dt>
        <dd>Sigmoid activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="k_sign.html">k_sign()</a></code> 
        </dt>
        <dd>Returns a tensor with the signs of the elements of <code>x</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_silu.html">k_silu()</a></code> 
        </dt>
        <dd>Sigmoid Linear Unit (SiLU) activation function, also known as Swish.</dd>
      </dl><dl><dt>
          
          <code><a href="k_sin.html">k_sin()</a></code> 
        </dt>
        <dd>Trigonomeric sine, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_sinh.html">k_sinh()</a></code> 
        </dt>
        <dd>Hyperbolic sine, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_size.html">k_size()</a></code> 
        </dt>
        <dd>Return the number of elements in a tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_slice.html">k_slice()</a></code> 
        </dt>
        <dd>Return a slice of an input tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_slice_update.html">k_slice_update()</a></code> 
        </dt>
        <dd>Update an input by slicing in a tensor of updated values.</dd>
      </dl><dl><dt>
          
          <code><a href="k_softmax.html">k_softmax()</a></code> 
        </dt>
        <dd>Softmax activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="k_softplus.html">k_softplus()</a></code> 
        </dt>
        <dd>Softplus activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="k_softsign.html">k_softsign()</a></code> 
        </dt>
        <dd>Softsign activation function.</dd>
      </dl><dl><dt>
          
          <code><a href="k_solve.html">k_solve()</a></code> 
        </dt>
        <dd>Solves for <code>x</code> in the equation <code>a * x = b</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_sort.html">k_sort()</a></code> 
        </dt>
        <dd>Sorts the elements of <code>x</code> along a given axis in ascending order.</dd>
      </dl><dl><dt>
          
          <code><a href="k_sparse_categorical_crossentropy.html">k_sparse_categorical_crossentropy()</a></code> 
        </dt>
        <dd>Computes sparse categorical cross-entropy loss.</dd>
      </dl><dl><dt>
          
          <code><a href="k_split.html">k_split()</a></code> 
        </dt>
        <dd>Split a tensor into chunks.</dd>
      </dl><dl><dt>
          
          <code><a href="k_sqrt.html">k_sqrt()</a></code> 
        </dt>
        <dd>Return the non-negative square root of a tensor, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_square.html">k_square()</a></code> 
        </dt>
        <dd>Return the element-wise square of the input.</dd>
      </dl><dl><dt>
          
          <code><a href="k_squeeze.html">k_squeeze()</a></code> 
        </dt>
        <dd>Remove axes of length one from <code>x</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_stack.html">k_stack()</a></code> 
        </dt>
        <dd>Join a sequence of tensors along a new axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_std.html">k_std()</a></code> 
        </dt>
        <dd>Compute the standard deviation along the specified axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_stft.html">k_stft()</a></code> 
        </dt>
        <dd>Short-Time Fourier Transform along the last axis of the input.</dd>
      </dl><dl><dt>
          
          <code><a href="k_stop_gradient.html">k_stop_gradient()</a></code> 
        </dt>
        <dd>Stops gradient computation.</dd>
      </dl><dl><dt>
          
          <code><a href="k_subtract.html">k_subtract()</a></code> 
        </dt>
        <dd>Subtract arguments element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_sum.html">k_sum()</a></code> 
        </dt>
        <dd>Sum of a tensor over the given axes.</dd>
      </dl><dl><dt>
          
          <code><a href="k_swapaxes.html">k_swapaxes()</a></code> 
        </dt>
        <dd>Interchange two axes of a tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_take.html">k_take()</a></code> 
        </dt>
        <dd>Take elements from a tensor along an axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_take_along_axis.html">k_take_along_axis()</a></code> 
        </dt>
        <dd>Select values from <code>x</code> at the 1-D <code>indices</code> along the given axis.</dd>
      </dl><dl><dt>
          
          <code><a href="k_tan.html">k_tan()</a></code> 
        </dt>
        <dd>Compute tangent, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_tanh.html">k_tanh()</a></code> 
        </dt>
        <dd>Hyperbolic tangent, element-wise.</dd>
      </dl><dl><dt>
          
          <code><a href="k_tensordot.html">k_tensordot()</a></code> 
        </dt>
        <dd>Compute the tensor dot product along specified axes.</dd>
      </dl><dl><dt>
          
          <code><a href="k_tile.html">k_tile()</a></code> 
        </dt>
        <dd>Repeat <code>x</code> the number of times given by <code>repeats</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_top_k.html">k_top_k()</a></code> 
        </dt>
        <dd>Finds the top-k values and their indices in a tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_trace.html">k_trace()</a></code> 
        </dt>
        <dd>Return the sum along diagonals of the tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_transpose.html">k_transpose()</a></code> 
        </dt>
        <dd>Returns a tensor with <code>axes</code> transposed.</dd>
      </dl><dl><dt>
          
          <code><a href="k_tri.html">k_tri()</a></code> 
        </dt>
        <dd>Return a tensor with ones at and below a diagonal and zeros elsewhere.</dd>
      </dl><dl><dt>
          
          <code><a href="k_tril.html">k_tril()</a></code> 
        </dt>
        <dd>Return lower triangle of a tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_triu.html">k_triu()</a></code> 
        </dt>
        <dd>Return upper triangle of a tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="k_true_divide.html">k_true_divide()</a></code> 
        </dt>
        <dd>Alias for <code>keras.ops.divide</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_unstack.html">k_unstack()</a></code> 
        </dt>
        <dd>Unpacks the given dimension of a rank-R tensor into rank-(R-1) tensors.</dd>
      </dl><dl><dt>
          
          <code><a href="k_var.html">k_var()</a></code> 
        </dt>
        <dd>Compute the variance along the specified axes.</dd>
      </dl><dl><dt>
          
          <code><a href="k_vdot.html">k_vdot()</a></code> 
        </dt>
        <dd>Return the dot product of two vectors.</dd>
      </dl><dl><dt>
          
          <code><a href="k_vectorized_map.html">k_vectorized_map()</a></code> 
        </dt>
        <dd>Parallel map of <code>function</code> on axis 0 of tensor(s) <code>elements</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_vstack.html">k_vstack()</a></code> 
        </dt>
        <dd>Stack tensors in sequence vertically (row wise).</dd>
      </dl><dl><dt>
          
          <code><a href="k_where.html">k_where()</a></code> 
        </dt>
        <dd>Return elements chosen from <code>x1</code> or <code>x2</code> depending on <code>condition</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="k_while_loop.html">k_while_loop()</a></code> 
        </dt>
        <dd>While loop implementation.</dd>
      </dl><dl><dt>
          
          <code><a href="k_zeros.html">k_zeros()</a></code> 
        </dt>
        <dd>Return a new tensor of given shape and type, filled with zeros.</dd>
      </dl><dl><dt>
          
          <code><a href="k_zeros_like.html">k_zeros_like()</a></code> 
        </dt>
        <dd>Return a tensor of zeros with the same shape and type as <code>x</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="keras-package.html">keras-package</a></code> <code><a href="keras-package.html">_PACKAGE</a></code> 
        </dt>
        <dd>R interface to Keras</dd>
      </dl><dl><dt>
          
          <code><a href="keras.html">keras</a></code> 
        </dt>
        <dd>Main Keras module</dd>
      </dl><dl><dt>
          
          <code><a href="keras_array.html">keras_array()</a></code> 
        </dt>
        <dd>Keras array object</dd>
      </dl><dl><dt>
          
          <code><a href="keras_model.html">keras_model()</a></code> 
        </dt>
        <dd>Keras Model</dd>
      </dl><dl><dt>
          
          <code><a href="keras_model_sequential.html">keras_model_sequential()</a></code> 
        </dt>
        <dd>Keras Model composed of a linear stack of layers</dd>
      </dl><dl><dt>
          
          <code><a href="layer_activation.html">layer_activation()</a></code> 
        </dt>
        <dd>Applies an activation function to an output.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_activation_elu.html">layer_activation_elu()</a></code> 
        </dt>
        <dd>Applies an Exponential Linear Unit function to an output.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_activation_leaky_relu.html">layer_activation_leaky_relu()</a></code> 
        </dt>
        <dd>Leaky version of a Rectified Linear Unit activation layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_activation_parametric_relu.html">layer_activation_parametric_relu()</a></code> 
        </dt>
        <dd>Parametric Rectified Linear Unit activation layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_activation_relu.html">layer_activation_relu()</a></code> 
        </dt>
        <dd>Rectified Linear Unit activation function layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_activation_softmax.html">layer_activation_softmax()</a></code> 
        </dt>
        <dd>Softmax activation layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_activity_regularization.html">layer_activity_regularization()</a></code> 
        </dt>
        <dd>Layer that applies an update to the cost function based input activity.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_add.html">layer_add()</a></code> 
        </dt>
        <dd>Performs elementwise addition operation.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_additive_attention.html">layer_additive_attention()</a></code> 
        </dt>
        <dd>Additive attention layer, a.k.a. Bahdanau-style attention.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_attention.html">layer_attention()</a></code> 
        </dt>
        <dd>Dot-product attention layer, a.k.a. Luong-style attention.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_average.html">layer_average()</a></code> 
        </dt>
        <dd>Averages a list of inputs element-wise..</dd>
      </dl><dl><dt>
          
          <code><a href="layer_average_pooling_1d.html">layer_average_pooling_1d()</a></code> 
        </dt>
        <dd>Average pooling for temporal data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_average_pooling_2d.html">layer_average_pooling_2d()</a></code> 
        </dt>
        <dd>Average pooling operation for 2D spatial data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_average_pooling_3d.html">layer_average_pooling_3d()</a></code> 
        </dt>
        <dd>Average pooling operation for 3D data (spatial or spatio-temporal).</dd>
      </dl><dl><dt>
          
          <code><a href="layer_batch_normalization.html">layer_batch_normalization()</a></code> 
        </dt>
        <dd>Layer that normalizes its inputs.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_bidirectional.html">layer_bidirectional()</a></code> 
        </dt>
        <dd>Bidirectional wrapper for RNNs.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_category_encoding.html">layer_category_encoding()</a></code> 
        </dt>
        <dd>A preprocessing layer which encodes integer features.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_center_crop.html">layer_center_crop()</a></code> 
        </dt>
        <dd>A preprocessing layer which crops images.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_concatenate.html">layer_concatenate()</a></code> 
        </dt>
        <dd>Concatenates a list of inputs.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_conv_1d.html">layer_conv_1d()</a></code> 
        </dt>
        <dd>1D convolution layer (e.g. temporal convolution).</dd>
      </dl><dl><dt>
          
          <code><a href="layer_conv_1d_transpose.html">layer_conv_1d_transpose()</a></code> 
        </dt>
        <dd>1D transposed convolution layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_conv_2d.html">layer_conv_2d()</a></code> 
        </dt>
        <dd>2D convolution layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_conv_2d_transpose.html">layer_conv_2d_transpose()</a></code> 
        </dt>
        <dd>2D transposed convolution layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_conv_3d.html">layer_conv_3d()</a></code> 
        </dt>
        <dd>3D convolution layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_conv_3d_transpose.html">layer_conv_3d_transpose()</a></code> 
        </dt>
        <dd>3D transposed convolution layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_conv_lstm_1d.html">layer_conv_lstm_1d()</a></code> 
        </dt>
        <dd>1D Convolutional LSTM.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_conv_lstm_2d.html">layer_conv_lstm_2d()</a></code> 
        </dt>
        <dd>2D Convolutional LSTM.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_conv_lstm_3d.html">layer_conv_lstm_3d()</a></code> 
        </dt>
        <dd>3D Convolutional LSTM.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_cropping_1d.html">layer_cropping_1d()</a></code> 
        </dt>
        <dd>Cropping layer for 1D input (e.g. temporal sequence).</dd>
      </dl><dl><dt>
          
          <code><a href="layer_cropping_2d.html">layer_cropping_2d()</a></code> 
        </dt>
        <dd>Cropping layer for 2D input (e.g. picture).</dd>
      </dl><dl><dt>
          
          <code><a href="layer_cropping_3d.html">layer_cropping_3d()</a></code> 
        </dt>
        <dd>Cropping layer for 3D data (e.g. spatial or spatio-temporal).</dd>
      </dl><dl><dt>
          
          <code><a href="layer_dense.html">layer_dense()</a></code> 
        </dt>
        <dd>Just your regular densely-connected NN layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_depthwise_conv_1d.html">layer_depthwise_conv_1d()</a></code> 
        </dt>
        <dd>1D depthwise convolution layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_depthwise_conv_2d.html">layer_depthwise_conv_2d()</a></code> 
        </dt>
        <dd>2D depthwise convolution layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_discretization.html">layer_discretization()</a></code> 
        </dt>
        <dd>A preprocessing layer which buckets continuous features by ranges.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_dot.html">layer_dot()</a></code> 
        </dt>
        <dd>Computes element-wise dot product of two tensors.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_dropout.html">layer_dropout()</a></code> 
        </dt>
        <dd>Applies dropout to the input.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_einsum_dense.html">layer_einsum_dense()</a></code> 
        </dt>
        <dd>A layer that uses <code>einsum</code> as the backing computation.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_embedding.html">layer_embedding()</a></code> 
        </dt>
        <dd>Turns positive integers (indexes) into dense vectors of fixed size.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_feature_space.html">layer_feature_space()</a></code> 
        </dt>
        <dd>One-stop utility for preprocessing and encoding structured data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_flatten.html">layer_flatten()</a></code> 
        </dt>
        <dd>Flattens the input. Does not affect the batch size.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_gaussian_dropout.html">layer_gaussian_dropout()</a></code> 
        </dt>
        <dd>Apply multiplicative 1-centered Gaussian noise.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_gaussian_noise.html">layer_gaussian_noise()</a></code> 
        </dt>
        <dd>Apply additive zero-centered Gaussian noise.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_global_average_pooling_1d.html">layer_global_average_pooling_1d()</a></code> 
        </dt>
        <dd>Global average pooling operation for temporal data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_global_average_pooling_2d.html">layer_global_average_pooling_2d()</a></code> 
        </dt>
        <dd>Global average pooling operation for 2D data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_global_average_pooling_3d.html">layer_global_average_pooling_3d()</a></code> 
        </dt>
        <dd>Global average pooling operation for 3D data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_global_max_pooling_1d.html">layer_global_max_pooling_1d()</a></code> 
        </dt>
        <dd>Global max pooling operation for temporal data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_global_max_pooling_2d.html">layer_global_max_pooling_2d()</a></code> 
        </dt>
        <dd>Global max pooling operation for 2D data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_global_max_pooling_3d.html">layer_global_max_pooling_3d()</a></code> 
        </dt>
        <dd>Global max pooling operation for 3D data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_group_normalization.html">layer_group_normalization()</a></code> 
        </dt>
        <dd>Group normalization layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_group_query_attention.html">layer_group_query_attention()</a></code> 
        </dt>
        <dd>Grouped Query Attention layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_gru.html">layer_gru()</a></code> 
        </dt>
        <dd>Gated Recurrent Unit - Cho et al. 2014.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_gru_cell.html">layer_gru_cell()</a></code> 
        </dt>
        <dd>Cell class for the GRU layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_hashed_crossing.html">layer_hashed_crossing()</a></code> 
        </dt>
        <dd>A preprocessing layer which crosses features using the "hashing trick".</dd>
      </dl><dl><dt>
          
          <code><a href="layer_hashing.html">layer_hashing()</a></code> 
        </dt>
        <dd>A preprocessing layer which hashes and bins categorical features.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_identity.html">layer_identity()</a></code> 
        </dt>
        <dd>Identity layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_input.html">layer_input()</a></code> 
        </dt>
        <dd>Used to instantiate a Keras tensor.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_integer_lookup.html">layer_integer_lookup()</a></code> 
        </dt>
        <dd>A preprocessing layer that maps integers to (possibly encoded) indices.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_lambda.html">layer_lambda()</a></code> 
        </dt>
        <dd>Wraps arbitrary expressions as a <code>Layer</code> object.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_layer_normalization.html">layer_layer_normalization()</a></code> 
        </dt>
        <dd>Layer normalization layer (Ba et al., 2016).</dd>
      </dl><dl><dt>
          
          <code><a href="layer_lstm.html">layer_lstm()</a></code> 
        </dt>
        <dd>Long Short-Term Memory layer - Hochreiter 1997.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_lstm_cell.html">layer_lstm_cell()</a></code> 
        </dt>
        <dd>Cell class for the LSTM layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_masking.html">layer_masking()</a></code> 
        </dt>
        <dd>Masks a sequence by using a mask value to skip timesteps.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_max_pooling_1d.html">layer_max_pooling_1d()</a></code> 
        </dt>
        <dd>Max pooling operation for 1D temporal data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_max_pooling_2d.html">layer_max_pooling_2d()</a></code> 
        </dt>
        <dd>Max pooling operation for 2D spatial data.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_max_pooling_3d.html">layer_max_pooling_3d()</a></code> 
        </dt>
        <dd>Max pooling operation for 3D data (spatial or spatio-temporal).</dd>
      </dl><dl><dt>
          
          <code><a href="layer_maximum.html">layer_maximum()</a></code> 
        </dt>
        <dd>Computes element-wise maximum on a list of inputs.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_minimum.html">layer_minimum()</a></code> 
        </dt>
        <dd>Computes elementwise minimum on a list of inputs.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_multi_head_attention.html">layer_multi_head_attention()</a></code> 
        </dt>
        <dd>MultiHeadAttention layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_multiply.html">layer_multiply()</a></code> 
        </dt>
        <dd>Performs elementwise multiplication.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_normalization.html">layer_normalization()</a></code> 
        </dt>
        <dd>A preprocessing layer that normalizes continuous features.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_permute.html">layer_permute()</a></code> 
        </dt>
        <dd>Permutes the dimensions of the input according to a given pattern.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_random_brightness.html">layer_random_brightness()</a></code> 
        </dt>
        <dd>A preprocessing layer which randomly adjusts brightness during training.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_random_contrast.html">layer_random_contrast()</a></code> 
        </dt>
        <dd>A preprocessing layer which randomly adjusts contrast during training.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_random_crop.html">layer_random_crop()</a></code> 
        </dt>
        <dd>A preprocessing layer which randomly crops images during training.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_random_flip.html">layer_random_flip()</a></code> 
        </dt>
        <dd>A preprocessing layer which randomly flips images during training.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_random_rotation.html">layer_random_rotation()</a></code> 
        </dt>
        <dd>A preprocessing layer which randomly rotates images during training.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_random_translation.html">layer_random_translation()</a></code> 
        </dt>
        <dd>A preprocessing layer which randomly translates images during training.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_random_zoom.html">layer_random_zoom()</a></code> 
        </dt>
        <dd>A preprocessing layer which randomly zooms images during training.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_repeat_vector.html">layer_repeat_vector()</a></code> 
        </dt>
        <dd>Repeats the input n times.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_rescaling.html">layer_rescaling()</a></code> 
        </dt>
        <dd>A preprocessing layer which rescales input values to a new range.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_reshape.html">layer_reshape()</a></code> 
        </dt>
        <dd>Layer that reshapes inputs into the given shape.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_resizing.html">layer_resizing()</a></code> 
        </dt>
        <dd>A preprocessing layer which resizes images.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_rnn.html">layer_rnn()</a></code> 
        </dt>
        <dd>Base class for recurrent layers.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_separable_conv_1d.html">layer_separable_conv_1d()</a></code> 
        </dt>
        <dd>1D separable convolution layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_separable_conv_2d.html">layer_separable_conv_2d()</a></code> 
        </dt>
        <dd>2D separable convolution layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_simple_rnn.html">layer_simple_rnn()</a></code> 
        </dt>
        <dd>Fully-connected RNN where the output is to be fed back as the new input.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_simple_rnn_cell.html">layer_simple_rnn_cell()</a></code> 
        </dt>
        <dd>Cell class for SimpleRNN.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_spatial_dropout_1d.html">layer_spatial_dropout_1d()</a></code> 
        </dt>
        <dd>Spatial 1D version of Dropout.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_spatial_dropout_2d.html">layer_spatial_dropout_2d()</a></code> 
        </dt>
        <dd>Spatial 2D version of Dropout.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_spatial_dropout_3d.html">layer_spatial_dropout_3d()</a></code> 
        </dt>
        <dd>Spatial 3D version of Dropout.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_spectral_normalization.html">layer_spectral_normalization()</a></code> 
        </dt>
        <dd>Performs spectral normalization on the weights of a target layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_stacked_rnn_cells.html">layer_stacked_rnn_cells()</a></code> 
        </dt>
        <dd>Wrapper allowing a stack of RNN cells to behave as a single cell.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_string_lookup.html">layer_string_lookup()</a></code> 
        </dt>
        <dd>A preprocessing layer that maps strings to (possibly encoded) indices.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_subtract.html">layer_subtract()</a></code> 
        </dt>
        <dd>Performs elementwise subtraction.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_tfsm.html">layer_tfsm()</a></code> 
        </dt>
        <dd>Reload a Keras model/layer that was saved via SavedModel / ExportArchive.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_time_distributed.html">layer_time_distributed()</a></code> 
        </dt>
        <dd>This wrapper allows to apply a layer to every temporal slice of an input.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_torch_module_wrapper.html">layer_torch_module_wrapper()</a></code> 
        </dt>
        <dd>Torch module wrapper layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_unit_normalization.html">layer_unit_normalization()</a></code> 
        </dt>
        <dd>Unit normalization layer.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_upsampling_1d.html">layer_upsampling_1d()</a></code> 
        </dt>
        <dd>Upsampling layer for 1D inputs.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_upsampling_2d.html">layer_upsampling_2d()</a></code> 
        </dt>
        <dd>Upsampling layer for 2D inputs.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_upsampling_3d.html">layer_upsampling_3d()</a></code> 
        </dt>
        <dd>Upsampling layer for 3D inputs.</dd>
      </dl><dl><dt>
          
          <code><a href="layer_zero_padding_1d.html">layer_zero_padding_1d()</a></code> 
        </dt>
        <dd>Zero-padding layer for 1D input (e.g. temporal sequence).</dd>
      </dl><dl><dt>
          
          <code><a href="layer_zero_padding_2d.html">layer_zero_padding_2d()</a></code> 
        </dt>
        <dd>Zero-padding layer for 2D input (e.g. picture).</dd>
      </dl><dl><dt>
          
          <code><a href="layer_zero_padding_3d.html">layer_zero_padding_3d()</a></code> 
        </dt>
        <dd>Zero-padding layer for 3D data (spatial or spatio-temporal).</dd>
      </dl><dl><dt>
          
          <code><a href="learning_rate_schedule_cosine_decay.html">learning_rate_schedule_cosine_decay()</a></code> <code><a href="learning_rate_schedule_cosine_decay.html">learning_rate_schedule_cosine_decay()</a></code> 
        </dt>
        <dd>A <code>LearningRateSchedule</code> that uses a cosine decay with optional warmup.</dd>
      </dl><dl><dt>
          
          <code><a href="learning_rate_schedule_cosine_decay_restarts.html">learning_rate_schedule_cosine_decay_restarts()</a></code> <code><a href="learning_rate_schedule_cosine_decay_restarts.html">learning_rate_schedule_cosine_decay_restarts()</a></code> 
        </dt>
        <dd>A <code>LearningRateSchedule</code> that uses a cosine decay schedule with restarts.</dd>
      </dl><dl><dt>
          
          <code><a href="learning_rate_schedule_exponential_decay.html">learning_rate_schedule_exponential_decay()</a></code> <code><a href="learning_rate_schedule_exponential_decay.html">learning_rate_schedule_exponential_decay()</a></code> 
        </dt>
        <dd>A <code>LearningRateSchedule</code> that uses an exponential decay schedule.</dd>
      </dl><dl><dt>
          
          <code><a href="learning_rate_schedule_inverse_time_decay.html">learning_rate_schedule_inverse_time_decay()</a></code> <code><a href="learning_rate_schedule_inverse_time_decay.html">learning_rate_schedule_inverse_time_decay()</a></code> 
        </dt>
        <dd>A <code>LearningRateSchedule</code> that uses an inverse time decay schedule.</dd>
      </dl><dl><dt>
          
          <code><a href="learning_rate_schedule_piecewise_constant_decay.html">learning_rate_schedule_piecewise_constant_decay()</a></code> <code><a href="learning_rate_schedule_piecewise_constant_decay.html">learning_rate_schedule_piecewise_constant_decay()</a></code> 
        </dt>
        <dd>A <code>LearningRateSchedule</code> that uses a piecewise constant decay schedule.</dd>
      </dl><dl><dt>
          
          <code><a href="learning_rate_schedule_polynomial_decay.html">learning_rate_schedule_polynomial_decay()</a></code> <code><a href="learning_rate_schedule_polynomial_decay.html">learning_rate_schedule_polynomial_decay()</a></code> 
        </dt>
        <dd>A <code>LearningRateSchedule</code> that uses a polynomial decay schedule.</dd>
      </dl><dl><dt>
          
          <code><a href="loss_binary_crossentropy.html">loss_binary_crossentropy()</a></code> 
        </dt>
        <dd>Computes the cross-entropy loss between true labels and predicted labels.</dd>
      </dl><dl><dt>
          
          <code><a href="loss_binary_focal_crossentropy.html">loss_binary_focal_crossentropy()</a></code> 
        </dt>
        <dd>Computes focal cross-entropy loss between true labels and predictions.</dd>
      </dl><dl><dt>
          
          <code><a href="loss_categorical_crossentropy.html">loss_categorical_crossentropy()</a></code> 
        </dt>
        <dd>Computes the crossentropy loss between the labels and predictions.</dd>
      </dl><dl><dt>
          
          <code><a href="loss_categorical_focal_crossentropy.html">loss_categorical_focal_crossentropy()</a></code> 
        </dt>
        <dd>Computes the alpha balanced focal crossentropy loss.</dd>
      </dl><dl><dt>
          
          <code><a href="loss_categorical_hinge.html">loss_categorical_hinge()</a></code> 
        </dt>
        <dd>Computes the categorical hinge loss between <code>y_true</code> &amp; <code>y_pred</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="loss_cosine_similarity.html">loss_cosine_similarity()</a></code> 
        </dt>
        <dd>Computes the cosine similarity between <code>y_true</code> &amp; <code>y_pred</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="loss_hinge.html">loss_hinge()</a></code> 
        </dt>
        <dd>Computes the hinge loss between <code>y_true</code> &amp; <code>y_pred</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="loss_huber.html">loss_huber()</a></code> 
        </dt>
        <dd>Computes the Huber loss between <code>y_true</code> &amp; <code>y_pred</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="loss_kl_divergence.html">loss_kl_divergence()</a></code> 
        </dt>
        <dd>Computes Kullback-Leibler divergence loss between <code>y_true</code> &amp; <code>y_pred</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="loss_log_cosh.html">loss_log_cosh()</a></code> 
        </dt>
        <dd>Computes the logarithm of the hyperbolic cosine of the prediction error.</dd>
      </dl><dl><dt>
          
          <code><a href="loss_mean_absolute_error.html">loss_mean_absolute_error()</a></code> 
        </dt>
        <dd>Computes the mean of absolute difference between labels and predictions.</dd>
      </dl><dl><dt>
          
          <code><a href="loss_mean_absolute_percentage_error.html">loss_mean_absolute_percentage_error()</a></code> 
        </dt>
        <dd>Computes the mean absolute percentage error between <code>y_true</code> &amp; <code>y_pred</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="loss_mean_squared_error.html">loss_mean_squared_error()</a></code> 
        </dt>
        <dd>Computes the mean of squares of errors between labels and predictions.</dd>
      </dl><dl><dt>
          
          <code><a href="loss_mean_squared_logarithmic_error.html">loss_mean_squared_logarithmic_error()</a></code> 
        </dt>
        <dd>Computes the mean squared logarithmic error between <code>y_true</code> &amp; <code>y_pred</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="loss_poisson.html">loss_poisson()</a></code> 
        </dt>
        <dd>Computes the Poisson loss between <code>y_true</code> &amp; <code>y_pred</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="loss_sparse_categorical_crossentropy.html">loss_sparse_categorical_crossentropy()</a></code> 
        </dt>
        <dd>Computes the crossentropy loss between the labels and predictions.</dd>
      </dl><dl><dt>
          
          <code><a href="loss_squared_hinge.html">loss_squared_hinge()</a></code> 
        </dt>
        <dd>Computes the squared hinge loss between <code>y_true</code> &amp; <code>y_pred</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="save_model_hdf5.html">save_model_hdf5()</a></code> <code><a href="save_model_hdf5.html">load_model_hdf5()</a></code> 
        </dt>
        <dd>Save/Load models using HDF5 files</dd>
      </dl><dl><dt>
          
          <code><a href="save_model_tf.html">save_model_tf()</a></code> <code><a href="save_model_tf.html">load_model_tf()</a></code> 
        </dt>
        <dd>Save/Load models using SavedModel format</dd>
      </dl><dl><dt>
          
          <code><a href="save_model_weights_hdf5.html">save_model_weights_hdf5()</a></code> <code><a href="save_model_weights_hdf5.html">load_model_weights_hdf5()</a></code> 
        </dt>
        <dd>Save/Load model weights using HDF5 files</dd>
      </dl><dl><dt>
          
          <code><a href="save_model_weights_tf.html">save_model_weights_tf()</a></code> <code><a href="save_model_weights_tf.html">load_model_weights_tf()</a></code> 
        </dt>
        <dd>Save model weights in the SavedModel format</dd>
      </dl><dl><dt>
          
          <code><a href="metric_auc.html">metric_auc()</a></code> 
        </dt>
        <dd>Approximates the AUC (Area under the curve) of the ROC or PR curves.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_binary_accuracy.html">metric_binary_accuracy()</a></code> 
        </dt>
        <dd>Calculates how often predictions match binary labels.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_binary_crossentropy.html">metric_binary_crossentropy()</a></code> 
        </dt>
        <dd>Computes the crossentropy metric between the labels and predictions.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_binary_focal_crossentropy.html">metric_binary_focal_crossentropy()</a></code> 
        </dt>
        <dd>Computes the binary focal crossentropy loss.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_binary_iou.html">metric_binary_iou()</a></code> 
        </dt>
        <dd>Computes the Intersection-Over-Union metric for class 0 and/or 1.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_categorical_accuracy.html">metric_categorical_accuracy()</a></code> 
        </dt>
        <dd>Calculates how often predictions match one-hot labels.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_categorical_crossentropy.html">metric_categorical_crossentropy()</a></code> 
        </dt>
        <dd>Computes the crossentropy metric between the labels and predictions.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_categorical_focal_crossentropy.html">metric_categorical_focal_crossentropy()</a></code> 
        </dt>
        <dd>Computes the categorical focal crossentropy loss.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_categorical_hinge.html">metric_categorical_hinge()</a></code> 
        </dt>
        <dd>Computes the categorical hinge metric between <code>y_true</code> and <code>y_pred</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_cosine_similarity.html">metric_cosine_similarity()</a></code> 
        </dt>
        <dd>Computes the cosine similarity between the labels and predictions.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_f1_score.html">metric_f1_score()</a></code> 
        </dt>
        <dd>Computes F-1 Score.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_false_negatives.html">metric_false_negatives()</a></code> 
        </dt>
        <dd>Calculates the number of false negatives.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_false_positives.html">metric_false_positives()</a></code> 
        </dt>
        <dd>Calculates the number of false positives.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_fbeta_score.html">metric_fbeta_score()</a></code> 
        </dt>
        <dd>Computes F-Beta score.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_hinge.html">metric_hinge()</a></code> 
        </dt>
        <dd>Computes the hinge metric between <code>y_true</code> and <code>y_pred</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_huber.html">metric_huber()</a></code> 
        </dt>
        <dd>Computes Huber loss value.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_iou.html">metric_iou()</a></code> 
        </dt>
        <dd>Computes the Intersection-Over-Union metric for specific target classes.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_kl_divergence.html">metric_kl_divergence()</a></code> 
        </dt>
        <dd>Computes Kullback-Leibler divergence metric between <code>y_true</code> and</dd>
      </dl><dl><dt>
          
          <code><a href="metric_log_cosh.html">metric_log_cosh()</a></code> 
        </dt>
        <dd>Logarithm of the hyperbolic cosine of the prediction error.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_log_cosh_error.html">metric_log_cosh_error()</a></code> 
        </dt>
        <dd>Computes the logarithm of the hyperbolic cosine of the prediction error.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_mean.html">metric_mean()</a></code> 
        </dt>
        <dd>Compute the (weighted) mean of the given values.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_mean_absolute_error.html">metric_mean_absolute_error()</a></code> 
        </dt>
        <dd>Computes the mean absolute error between the labels and predictions.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_mean_absolute_percentage_error.html">metric_mean_absolute_percentage_error()</a></code> 
        </dt>
        <dd>Computes mean absolute percentage error between <code>y_true</code> and <code>y_pred</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_mean_iou.html">metric_mean_iou()</a></code> 
        </dt>
        <dd>Computes the mean Intersection-Over-Union metric.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_mean_squared_error.html">metric_mean_squared_error()</a></code> 
        </dt>
        <dd>Computes the mean squared error between <code>y_true</code> and <code>y_pred</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_mean_squared_logarithmic_error.html">metric_mean_squared_logarithmic_error()</a></code> 
        </dt>
        <dd>Computes mean squared logarithmic error between <code>y_true</code> and <code>y_pred</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_mean_wrapper.html">metric_mean_wrapper()</a></code> 
        </dt>
        <dd>Wrap a stateless metric function with the Mean metric.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_one_hot_iou.html">metric_one_hot_iou()</a></code> 
        </dt>
        <dd>Computes the Intersection-Over-Union metric for one-hot encoded labels.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_one_hot_mean_iou.html">metric_one_hot_mean_iou()</a></code> 
        </dt>
        <dd>Computes mean Intersection-Over-Union metric for one-hot encoded labels.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_poisson.html">metric_poisson()</a></code> 
        </dt>
        <dd>Computes the Poisson metric between <code>y_true</code> and <code>y_pred</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_precision.html">metric_precision()</a></code> 
        </dt>
        <dd>Computes the precision of the predictions with respect to the labels.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_precision_at_recall.html">metric_precision_at_recall()</a></code> 
        </dt>
        <dd>Computes best precision where recall is &gt;= specified value.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_r2_score.html">metric_r2_score()</a></code> 
        </dt>
        <dd>Computes R2 score.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_recall.html">metric_recall()</a></code> 
        </dt>
        <dd>Computes the recall of the predictions with respect to the labels.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_recall_at_precision.html">metric_recall_at_precision()</a></code> 
        </dt>
        <dd>Computes best recall where precision is &gt;= specified value.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_root_mean_squared_error.html">metric_root_mean_squared_error()</a></code> 
        </dt>
        <dd>Computes root mean squared error metric between <code>y_true</code> and <code>y_pred</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_sensitivity_at_specificity.html">metric_sensitivity_at_specificity()</a></code> 
        </dt>
        <dd>Computes best sensitivity where specificity is &gt;= specified value.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_sparse_categorical_accuracy.html">metric_sparse_categorical_accuracy()</a></code> 
        </dt>
        <dd>Calculates how often predictions match integer labels.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_sparse_categorical_crossentropy.html">metric_sparse_categorical_crossentropy()</a></code> 
        </dt>
        <dd>Computes the crossentropy metric between the labels and predictions.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_sparse_top_k_categorical_accuracy.html">metric_sparse_top_k_categorical_accuracy()</a></code> 
        </dt>
        <dd>Computes how often integer targets are in the top <code>K</code> predictions.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_specificity_at_sensitivity.html">metric_specificity_at_sensitivity()</a></code> 
        </dt>
        <dd>Computes best specificity where sensitivity is &gt;= specified value.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_squared_hinge.html">metric_squared_hinge()</a></code> 
        </dt>
        <dd>Computes the hinge metric between <code>y_true</code> and <code>y_pred</code>.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_sum.html">metric_sum()</a></code> 
        </dt>
        <dd>Compute the (weighted) sum of the given values.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_top_k_categorical_accuracy.html">metric_top_k_categorical_accuracy()</a></code> 
        </dt>
        <dd>Computes how often targets are in the top <code>K</code> predictions.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_true_negatives.html">metric_true_negatives()</a></code> 
        </dt>
        <dd>Calculates the number of true negatives.</dd>
      </dl><dl><dt>
          
          <code><a href="metric_true_positives.html">metric_true_positives()</a></code> 
        </dt>
        <dd>Calculates the number of true positives.</dd>
      </dl><dl><dt>
          
          <code><a href="model_from_saved_model.html">model_from_saved_model()</a></code> 
        </dt>
        <dd>Load a Keras model from the Saved Model format</dd>
      </dl><dl><dt>
          
          <code><a href="model_to_dot.html">model_to_dot()</a></code> 
        </dt>
        <dd>Convert a Keras model to dot format.</dd>
      </dl><dl><dt>
          
          <code><a href="model_to_json.html">model_to_json()</a></code> <code><a href="model_to_json.html">model_from_json()</a></code> 
        </dt>
        <dd>Model configuration as JSON</dd>
      </dl><dl><dt>
          
          <code><a href="model_to_yaml.html">model_to_yaml()</a></code> <code><a href="model_to_yaml.html">model_from_yaml()</a></code> 
        </dt>
        <dd>Model configuration as YAML</dd>
      </dl><dl><dt>
          
          <code><a href="new-classes.html">new_metric_class()</a></code> <code><a href="new-classes.html">new_loss_class()</a></code> <code><a href="new-classes.html">new_callback_class()</a></code> <code><a href="new-classes.html">new_model_class()</a></code> <code><a href="new-classes.html">new_layer_class()</a></code> <code><a href="new-classes.html">mark_active()</a></code> 
        </dt>
        <dd>Define new keras types</dd>
      </dl><dl><dt>
          
          <code><a href="new_learning_rate_schedule_class.html">new_learning_rate_schedule_class()</a></code> 
        </dt>
        <dd>Create a new learning rate schedule type</dd>
      </dl><dl><dt>
          
          <code><a href="normalize.html">normalize()</a></code> 
        </dt>
        <dd>Normalizes an array.</dd>
      </dl><dl><dt>
          
          <code><a href="optimizer_adadelta.html">optimizer_adadelta()</a></code> 
        </dt>
        <dd>Optimizer that implements the Adadelta algorithm.</dd>
      </dl><dl><dt>
          
          <code><a href="optimizer_adafactor.html">optimizer_adafactor()</a></code> 
        </dt>
        <dd>Optimizer that implements the Adafactor algorithm.</dd>
      </dl><dl><dt>
          
          <code><a href="optimizer_adagrad.html">optimizer_adagrad()</a></code> 
        </dt>
        <dd>Optimizer that implements the Adagrad algorithm.</dd>
      </dl><dl><dt>
          
          <code><a href="optimizer_adam.html">optimizer_adam()</a></code> 
        </dt>
        <dd>Optimizer that implements the Adam algorithm.</dd>
      </dl><dl><dt>
          
          <code><a href="optimizer_adam_w.html">optimizer_adam_w()</a></code> 
        </dt>
        <dd>Optimizer that implements the AdamW algorithm.</dd>
      </dl><dl><dt>
          
          <code><a href="optimizer_adamax.html">optimizer_adamax()</a></code> 
        </dt>
        <dd>Optimizer that implements the Adamax algorithm.</dd>
      </dl><dl><dt>
          
          <code><a href="optimizer_ftrl.html">optimizer_ftrl()</a></code> 
        </dt>
        <dd>Optimizer that implements the FTRL algorithm.</dd>
      </dl><dl><dt>
          
          <code><a href="optimizer_lion.html">optimizer_lion()</a></code> 
        </dt>
        <dd>Optimizer that implements the Lion algorithm.</dd>
      </dl><dl><dt>
          
          <code><a href="optimizer_loss_scale.html">optimizer_loss_scale()</a></code> 
        </dt>
        <dd>An optimizer that dynamically scales the loss to prevent underflow.</dd>
      </dl><dl><dt>
          
          <code><a href="optimizer_nadam.html">optimizer_nadam()</a></code> 
        </dt>
        <dd>Optimizer that implements the Nadam algorithm.</dd>
      </dl><dl><dt>
          
          <code><a href="optimizer_rmsprop.html">optimizer_rmsprop()</a></code> 
        </dt>
        <dd>Optimizer that implements the RMSprop algorithm.</dd>
      </dl><dl><dt>
          
          <code><a href="optimizer_sgd.html">optimizer_sgd()</a></code> 
        </dt>
        <dd>Gradient descent (with momentum) optimizer.</dd>
      </dl><dl><dt>
          
          <code><a href="grapes-py_class-grapes.html">`%py_class%`</a></code> 
        </dt>
        <dd>Make a python class constructor</dd>
      </dl><dl><dt>
          
          <code><a href="pack_x_y_sample_weight.html">pack_x_y_sample_weight()</a></code> 
        </dt>
        <dd>Packs user-provided data into a tuple.</dd>
      </dl><dl><dt>
          
          <code><a href="pad_sequences.html">pad_sequences()</a></code> 
        </dt>
        <dd>Pads sequences to the same length.</dd>
      </dl><dl><dt>
          
          <code><a href="plot.keras.models.model.Model.html">plot(<i>&lt;keras.models.model.Model&gt;</i>)</a></code> 
        </dt>
        <dd>Plot a Keras model</dd>
      </dl><dl><dt>
          
          <code><a href="plot.keras_training_history.html">plot(<i>&lt;keras_training_history&gt;</i>)</a></code> 
        </dt>
        <dd>Plot training history</dd>
      </dl><dl><dt>
          
          <code><a href="pop_layer.html">pop_layer()</a></code> 
        </dt>
        <dd>Remove the last layer in a model</dd>
      </dl><dl><dt>
          
          <code><a href="predict.keras.models.model.Model.html">predict(<i>&lt;keras.models.model.Model&gt;</i>)</a></code> 
        </dt>
        <dd>Generate predictions from a Keras model</dd>
      </dl><dl><dt>
          
          <code><a href="predict_on_batch.html">predict_on_batch()</a></code> 
        </dt>
        <dd>Returns predictions for a single batch of samples.</dd>
      </dl><dl><dt>
          
          <code><a href="random_categorical.html">random_categorical()</a></code> 
        </dt>
        <dd>Draws samples from a categorical distribution.</dd>
      </dl><dl><dt>
          
          <code><a href="random_dropout.html">random_dropout()</a></code> 
        </dt>
        <dd>random dropout</dd>
      </dl><dl><dt>
          
          <code><a href="random_integer.html">random_integer()</a></code> 
        </dt>
        <dd>Draw random integers from a uniform distribution.</dd>
      </dl><dl><dt>
          
          <code><a href="random_normal.html">random_normal()</a></code> 
        </dt>
        <dd>Draw random samples from a normal (Gaussian) distribution.</dd>
      </dl><dl><dt>
          
          <code><a href="random_seed_generator.html">random_seed_generator()</a></code> 
        </dt>
        <dd>Generates variable seeds upon each call to a RNG-using function.</dd>
      </dl><dl><dt>
          
          <code><a href="random_shuffle.html">random_shuffle()</a></code> 
        </dt>
        <dd>Shuffle the elements of a tensor uniformly at random along an axis.</dd>
      </dl><dl><dt>
          
          <code><a href="random_truncated_normal.html">random_truncated_normal()</a></code> 
        </dt>
        <dd>Draw samples from a truncated normal distribution.</dd>
      </dl><dl><dt>
          
          <code><a href="random_uniform.html">random_uniform()</a></code> 
        </dt>
        <dd>Draw samples from a uniform distribution.</dd>
      </dl><dl><dt>
          
          <code><a href="regularizer_l1.html">regularizer_l1()</a></code> 
        </dt>
        <dd>A regularizer that applies a L1 regularization penalty.</dd>
      </dl><dl><dt>
          
          <code><a href="regularizer_l1_l2.html">regularizer_l1_l2()</a></code> 
        </dt>
        <dd>A regularizer that applies both L1 and L2 regularization penalties.</dd>
      </dl><dl><dt>
          
          <code><a href="regularizer_l2.html">regularizer_l2()</a></code> 
        </dt>
        <dd>A regularizer that applies a L2 regularization penalty.</dd>
      </dl><dl><dt>
          
          <code><a href="regularizer_orthogonal.html">regularizer_orthogonal()</a></code> 
        </dt>
        <dd>Regularizer that encourages input vectors to be orthogonal to each other.</dd>
      </dl><dl><dt>
          
          <code><a href="reset_states.html">reset_states()</a></code> 
        </dt>
        <dd>Reset the states for a layer</dd>
      </dl><dl><dt>
          
          <code><a href="serialize_model.html">serialize_model()</a></code> <code><a href="serialize_model.html">unserialize_model()</a></code> 
        </dt>
        <dd>Serialize a model to an R object</dd>
      </dl><dl><dt>
          
          <code><a href="set_random_seed.html">set_random_seed()</a></code> 
        </dt>
        <dd>Sets all random seeds (Python, NumPy, and backend framework, e.g. TF).</dd>
      </dl><dl><dt>
          
          <code><a href="split_dataset.html">split_dataset()</a></code> 
        </dt>
        <dd>Splits a dataset into a left half and a right half (e.g. train / test).</dd>
      </dl><dl><dt>
          
          <code><a href="text_dataset_from_directory.html">text_dataset_from_directory()</a></code> 
        </dt>
        <dd>Generates a <code>tf.data.Dataset</code> from text files in a directory.</dd>
      </dl><dl><dt>
          
          <code><a href="time_distributed.html">time_distributed()</a></code> 
        </dt>
        <dd>This layer wrapper allows to apply a layer to every temporal slice of an input</dd>
      </dl><dl><dt>
          
          <code><a href="timeseries_dataset_from_array.html">timeseries_dataset_from_array()</a></code> 
        </dt>
        <dd>Creates a dataset of sliding windows over a timeseries provided as array.</dd>
      </dl><dl><dt>
          
          <code><a href="timeseries_generator.html">timeseries_generator()</a></code> 
        </dt>
        <dd>Utility function for generating batches of temporal data.</dd>
      </dl><dl><dt>
          
          <code><a href="to_categorical.html">to_categorical()</a></code> 
        </dt>
        <dd>Converts a class vector (integers) to binary class matrix.</dd>
      </dl><dl><dt>
          
          <code><a href="train_on_batch.html">train_on_batch()</a></code> <code><a href="train_on_batch.html">test_on_batch()</a></code> 
        </dt>
        <dd>Single gradient update or model evaluation over one batch of samples.</dd>
      </dl><dl><dt>
          
          <code><a href="unpack_x_y_sample_weight.html">unpack_x_y_sample_weight()</a></code> 
        </dt>
        <dd>Unpacks user-provided data tuple.</dd>
      </dl><dl><dt>
          
          <code><a href="use_implementation.html">use_implementation()</a></code> <code><a href="use_implementation.html">use_backend()</a></code> 
        </dt>
        <dd>Select a Keras implementation and backend</dd>
      </dl><dl><dt>
          
          <code><a href="with_custom_object_scope.html">with_custom_object_scope()</a></code> 
        </dt>
        <dd>Provide a scope with mappings of names to custom objects</dd>
      </dl><dl><dt>
          
          <code><a href="zip_lists.html">zip_lists()</a></code> 
        </dt>
        <dd>zip lists</dd>
      </dl><dl><dt>
          
          <code><a href="Metric.html">Metric</a></code> 
        </dt>
        <dd>Metric</dd>
      </dl></div><div class="section level2">
      <h2 id="deprecated">Deprecated<a class="anchor" aria-label="anchor" href="#deprecated"></a></h2>
      
      

      
    </div><div id="" class="section level2">
      
      
      

      <dl><dt>
          
          <code><a href="KerasLayer.html">KerasLayer</a></code> 
        </dt>
        <dd>(Deprecated) Base R6 class for Keras layers</dd>
      </dl><dl><dt>
          
          <code><a href="adapt.html">adapt()</a></code> 
        </dt>
        <dd>Fits the state of the preprocessing layer to the data being passed</dd>
      </dl><dl><dt>
          
          <code><a href="bidirectional.html">bidirectional()</a></code> 
        </dt>
        <dd>Bidirectional wrapper for RNNs</dd>
      </dl><dl><dt>
          
          <code><a href="keras-package.html">keras-package</a></code> <code><a href="keras-package.html">_PACKAGE</a></code> 
        </dt>
        <dd>R interface to Keras</dd>
      </dl><dl><dt>
          
          <code><a href="time_distributed.html">time_distributed()</a></code> 
        </dt>
        <dd>This layer wrapper allows to apply a layer to every temporal slice of an input</dd>
      </dl></div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p></p><p>Developed by Tomasz Kalinowski, JJ Allaire, FranÃ§ois Chollet, RStudio, Google.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer></div>

  

  

  </body></html>

