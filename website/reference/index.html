<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Function reference â€¢ keras</title><!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png"><link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png"><link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png"><link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png"><link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png"><link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png"><!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous"><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css"><script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet"><script src="../pkgdown.js"></script><link href="../extra.css" rel="stylesheet"><script src="../extra.js"></script><meta property="og:title" content="Function reference"><meta property="og:image" content="/logo.png"><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body data-spy="scroll" data-target="#toc">
    

    <div class="container template-reference-index">
      <header><div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">keras</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">2.13.0.9000</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav"><li>
  <a href="../index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Tutorials
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu"><li>
      <a href="../articles/getting_started.html">Getting Started</a>
    </li>
    <li>
      <a href="../articles/tutorial_basic_classification.html">Basic Classification</a>
    </li>
    <li>
      <a href="../articles/tutorial_basic_text_classification.html">Text Classification</a>
    </li>
    <li>
      <a href="../articles/tutorial_basic_regression.html">Basic Regression</a>
    </li>
    <li>
      <a href="../articles/tutorial_overfit_underfit.html">Overfitting and Underfitting</a>
    </li>
    <li>
      <a href="../articles/tutorial_save_and_restore.html">Save and Restore Models</a>
    </li>
  </ul></li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu"><li class="dropdown-header">Guides (New for TF 2.6)</li>
    <li>
      <a href="../articles/new-guides/python_subclasses.html">Python Subclasses</a>
    </li>
    <li>
      <a href="../articles/new-guides/making_new_layers_and_models_via_subclassing.html">Making New Layers and Models via Subclassing</a>
    </li>
    <li>
      <a href="../articles/new-guides/customizing_what_happens_in_fit.html">Customizing What Happens in Fit</a>
    </li>
    <li>
      <a href="../articles/new-guides/writing_your_own_callbacks.html">Writing Your Own Callbacks</a>
    </li>
    <li>
      <a href="../articles/new-guides/preprocessing_layers.html">Working with Preprocessing Layers</a>
    </li>
    <li>
      <a href="../argicles/new-guides/working_with_rnns.html">Working with RNNs</a>
    </li>
    <li class="divider">
    <li class="dropdown-header">Using Keras</li>
    <li>
      <a href="../articles/guide_keras.html">Guide to Keras Basics</a>
    </li>
    <li>
      <a href="../articles/sequential_model.html">Sequential Model in Depth</a>
    </li>
    <li>
      <a href="../articles/functional_api.html">Functional API in Depth</a>
    </li>
    <li>
      <a href="../articles/about_keras_models.html">About Keras Models</a>
    </li>
    <li>
      <a href="../articles/about_keras_layers.html">About Keras Layers</a>
    </li>
    <li>
      <a href="../articles/training_visualization.html">Training Visualization</a>
    </li>
    <li>
      <a href="../articles/applications.html">Pre-Trained Models</a>
    </li>
    <li>
      <a href="../articles/faq.html">Frequently Asked Questions</a>
    </li>
    <li>
      <a href="../articles/why_use_keras.html">Why Use Keras?</a>
    </li>
    <li class="divider">
    <li class="dropdown-header">Advanced</li>
    <li>
      <a href="../articles/eager_guide.html">Eager Execution</a>
    </li>
    <li>
      <a href="../articles/training_callbacks.html">Training Callbacks</a>
    </li>
    <li>
      <a href="../articles/backend.html">Keras Backend</a>
    </li>
    <li>
      <a href="../articles/custom_layers.html">Custom Layers</a>
    </li>
    <li>
      <a href="../articles/custom_models.html">Custom Models</a>
    </li>
    <li>
      <a href="../articles/saving_serializing.html">Saving and serializing</a>
    </li>
  </ul></li>
<li>
  <a href="../articles/learn.html">Learn</a>
</li>
<li>
  <a href="../articles/tools.html">Tools</a>
</li>
<li>
  <a href="../articles/examples/index.html">Examples</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
      </ul><ul class="nav navbar-nav navbar-right"><li>
  <a href="https://github.com/rstudio/keras/" class="external-link">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul></div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header><div class="row">
  <div class="contents col-md-9">
    <div class="page-header">
      <h1>Reference</h1>
    </div>

    <table class="ref-index"><colgroup><col class="alias"><col class="title"></colgroup><tbody><tr><th colspan="2">
          <h2 id="keras-models">Keras Models <a href="#keras-models" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="keras_model.html">keras_model()</a></code> </p>
        </td>
        <td><p>Keras Model</p></td>
      </tr><tr><td>
          <p><code><a href="keras_model_sequential.html">keras_model_sequential()</a></code> </p>
        </td>
        <td><p>Keras Model composed of a linear stack of layers</p></td>
      </tr><tr><td>
          <p><code><a href="summary.keras.models.model.Model.html">summary(<i>&lt;keras.models.model.Model&gt;</i>)</a></code> <code><a href="summary.keras.models.model.Model.html">format(<i>&lt;keras.models.model.Model&gt;</i>)</a></code> <code><a href="summary.keras.models.model.Model.html">print(<i>&lt;keras.models.model.Model&gt;</i>)</a></code> </p>
        </td>
        <td><p>Print a summary of a Keras model</p></td>
      </tr><tr><td>
          <p><code><a href="compile.keras.models.model.Model.html">compile(<i>&lt;keras.models.model.Model&gt;</i>)</a></code> </p>
        </td>
        <td><p>Configure a Keras model for training</p></td>
      </tr><tr><td>
          <p><code><a href="fit.keras.models.model.Model.html">fit(<i>&lt;keras.models.model.Model&gt;</i>)</a></code> </p>
        </td>
        <td><p>Train a Keras model</p></td>
      </tr><tr><td>
          <p><code><a href="predict.keras.models.model.Model.html">predict(<i>&lt;keras.models.model.Model&gt;</i>)</a></code> </p>
        </td>
        <td><p>Generate predictions from a Keras model</p></td>
      </tr><tr><td>
          <p><code><a href="evaluate.keras.models.model.Model.html">evaluate(<i>&lt;keras.models.model.Model&gt;</i>)</a></code> </p>
        </td>
        <td><p>Evaluate a Keras model</p></td>
      </tr><tr><td>
          <p><code><a href="export_savedmodel.keras.models.model.Model.html">export_savedmodel(<i>&lt;keras.models.model.Model&gt;</i>)</a></code> </p>
        </td>
        <td><p>Export a Saved Model</p></td>
      </tr><tr><td>
          <p><code><a href="train_on_batch.html">train_on_batch()</a></code> <code><a href="train_on_batch.html">test_on_batch()</a></code> </p>
        </td>
        <td><p>Single gradient update or model evaluation over one batch of samples.</p></td>
      </tr><tr><td>
          <p><code><a href="get_layer.html">get_layer()</a></code> </p>
        </td>
        <td><p>Retrieves a layer based on either its name (unique) or index.</p></td>
      </tr><tr><td>
          <p><code><a href="pop_layer.html">pop_layer()</a></code> </p>
        </td>
        <td><p>Remove the last layer in a model</p></td>
      </tr><tr><td>
          <p><code><a href="save_model_hdf5.html">save_model_hdf5()</a></code> <code><a href="save_model_hdf5.html">load_model_hdf5()</a></code> </p>
        </td>
        <td><p>Save/Load models using HDF5 files</p></td>
      </tr><tr><td>
          <p><code><a href="serialize_model.html">serialize_model()</a></code> <code><a href="serialize_model.html">unserialize_model()</a></code> </p>
        </td>
        <td><p>Serialize a model to an R object</p></td>
      </tr><tr><td>
          <p><code><a href="clone_model.html">clone_model()</a></code> </p>
        </td>
        <td><p>Clone a model instance.</p></td>
      </tr><tr><td>
          <p><code><a href="freeze_weights.html">freeze_weights()</a></code> <code><a href="freeze_weights.html">unfreeze_weights()</a></code> </p>
        </td>
        <td><p>Freeze and unfreeze weights</p></td>
      </tr></tbody><tbody><tr><th colspan="2">
          <h2 id="core-layers">Core Layers <a href="#core-layers" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="layer_dense.html">layer_dense()</a></code> </p>
        </td>
        <td><p>Just your regular densely-connected NN layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_einsum_dense.html">layer_einsum_dense()</a></code> </p>
        </td>
        <td><p>A layer that uses <code>einsum</code> as the backing computation.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_embedding.html">layer_embedding()</a></code> </p>
        </td>
        <td><p>Turns positive integers (indexes) into dense vectors of fixed size.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_identity.html">layer_identity()</a></code> </p>
        </td>
        <td><p>Identity layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_lambda.html">layer_lambda()</a></code> </p>
        </td>
        <td><p>Wraps arbitrary expressions as a <code>Layer</code> object.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_masking.html">layer_masking()</a></code> </p>
        </td>
        <td><p>Masks a sequence by using a mask value to skip timesteps.</p></td>
      </tr></tbody><tbody><tr><th colspan="2">
          <h2 id="reshaping-layers">Reshaping Layers <a href="#reshaping-layers" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="layer_cropping_1d.html">layer_cropping_1d()</a></code> </p>
        </td>
        <td><p>Cropping layer for 1D input (e.g. temporal sequence).</p></td>
      </tr><tr><td>
          <p><code><a href="layer_cropping_2d.html">layer_cropping_2d()</a></code> </p>
        </td>
        <td><p>Cropping layer for 2D input (e.g. picture).</p></td>
      </tr><tr><td>
          <p><code><a href="layer_cropping_3d.html">layer_cropping_3d()</a></code> </p>
        </td>
        <td><p>Cropping layer for 3D data (e.g. spatial or spatio-temporal).</p></td>
      </tr><tr><td>
          <p><code><a href="layer_flatten.html">layer_flatten()</a></code> </p>
        </td>
        <td><p>Flattens the input. Does not affect the batch size.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_permute.html">layer_permute()</a></code> </p>
        </td>
        <td><p>Permutes the dimensions of the input according to a given pattern.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_repeat_vector.html">layer_repeat_vector()</a></code> </p>
        </td>
        <td><p>Repeats the input n times.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_reshape.html">layer_reshape()</a></code> </p>
        </td>
        <td><p>Layer that reshapes inputs into the given shape.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_upsampling_1d.html">layer_upsampling_1d()</a></code> </p>
        </td>
        <td><p>Upsampling layer for 1D inputs.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_upsampling_2d.html">layer_upsampling_2d()</a></code> </p>
        </td>
        <td><p>Upsampling layer for 2D inputs.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_upsampling_3d.html">layer_upsampling_3d()</a></code> </p>
        </td>
        <td><p>Upsampling layer for 3D inputs.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_zero_padding_1d.html">layer_zero_padding_1d()</a></code> </p>
        </td>
        <td><p>Zero-padding layer for 1D input (e.g. temporal sequence).</p></td>
      </tr><tr><td>
          <p><code><a href="layer_zero_padding_2d.html">layer_zero_padding_2d()</a></code> </p>
        </td>
        <td><p>Zero-padding layer for 2D input (e.g. picture).</p></td>
      </tr><tr><td>
          <p><code><a href="layer_zero_padding_3d.html">layer_zero_padding_3d()</a></code> </p>
        </td>
        <td><p>Zero-padding layer for 3D data (spatial or spatio-temporal).</p></td>
      </tr></tbody><tbody><tr><th colspan="2">
          <h2 id="convolutional-layers">Convolutional Layers <a href="#convolutional-layers" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="layer_conv_1d.html">layer_conv_1d()</a></code> </p>
        </td>
        <td><p>1D convolution layer (e.g. temporal convolution).</p></td>
      </tr><tr><td>
          <p><code><a href="layer_conv_1d_transpose.html">layer_conv_1d_transpose()</a></code> </p>
        </td>
        <td><p>1D transposed convolution layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_conv_2d.html">layer_conv_2d()</a></code> </p>
        </td>
        <td><p>2D convolution layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_conv_2d_transpose.html">layer_conv_2d_transpose()</a></code> </p>
        </td>
        <td><p>2D transposed convolution layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_conv_3d.html">layer_conv_3d()</a></code> </p>
        </td>
        <td><p>3D convolution layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_conv_3d_transpose.html">layer_conv_3d_transpose()</a></code> </p>
        </td>
        <td><p>3D transposed convolution layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_depthwise_conv_1d.html">layer_depthwise_conv_1d()</a></code> </p>
        </td>
        <td><p>1D depthwise convolution layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_depthwise_conv_2d.html">layer_depthwise_conv_2d()</a></code> </p>
        </td>
        <td><p>2D depthwise convolution layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_separable_conv_1d.html">layer_separable_conv_1d()</a></code> </p>
        </td>
        <td><p>1D separable convolution layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_separable_conv_2d.html">layer_separable_conv_2d()</a></code> </p>
        </td>
        <td><p>2D separable convolution layer.</p></td>
      </tr></tbody><tbody><tr><th colspan="2">
          <h2 id="pooling-layers">Pooling Layers <a href="#pooling-layers" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="layer_average_pooling_1d.html">layer_average_pooling_1d()</a></code> </p>
        </td>
        <td><p>Average pooling for temporal data.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_average_pooling_2d.html">layer_average_pooling_2d()</a></code> </p>
        </td>
        <td><p>Average pooling operation for 2D spatial data.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_average_pooling_3d.html">layer_average_pooling_3d()</a></code> </p>
        </td>
        <td><p>Average pooling operation for 3D data (spatial or spatio-temporal).</p></td>
      </tr><tr><td>
          <p><code><a href="layer_global_average_pooling_1d.html">layer_global_average_pooling_1d()</a></code> </p>
        </td>
        <td><p>Global average pooling operation for temporal data.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_global_average_pooling_2d.html">layer_global_average_pooling_2d()</a></code> </p>
        </td>
        <td><p>Global average pooling operation for 2D data.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_global_average_pooling_3d.html">layer_global_average_pooling_3d()</a></code> </p>
        </td>
        <td><p>Global average pooling operation for 3D data.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_global_max_pooling_1d.html">layer_global_max_pooling_1d()</a></code> </p>
        </td>
        <td><p>Global max pooling operation for temporal data.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_global_max_pooling_2d.html">layer_global_max_pooling_2d()</a></code> </p>
        </td>
        <td><p>Global max pooling operation for 2D data.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_global_max_pooling_3d.html">layer_global_max_pooling_3d()</a></code> </p>
        </td>
        <td><p>Global max pooling operation for 3D data.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_max_pooling_1d.html">layer_max_pooling_1d()</a></code> </p>
        </td>
        <td><p>Max pooling operation for 1D temporal data.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_max_pooling_2d.html">layer_max_pooling_2d()</a></code> </p>
        </td>
        <td><p>Max pooling operation for 2D spatial data.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_max_pooling_3d.html">layer_max_pooling_3d()</a></code> </p>
        </td>
        <td><p>Max pooling operation for 3D data (spatial or spatio-temporal).</p></td>
      </tr></tbody><tbody><tr><th colspan="2">
          <h2 id="activation-layers">Activation Layers <a href="#activation-layers" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="layer_activation.html">layer_activation()</a></code> </p>
        </td>
        <td><p>Applies an activation function to an output.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_activation_elu.html">layer_activation_elu()</a></code> </p>
        </td>
        <td><p>Applies an Exponential Linear Unit function to an output.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_activation_leaky_relu.html">layer_activation_leaky_relu()</a></code> </p>
        </td>
        <td><p>Leaky version of a Rectified Linear Unit activation layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_activation_parametric_relu.html">layer_activation_parametric_relu()</a></code> </p>
        </td>
        <td><p>Parametric Rectified Linear Unit activation layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_activation_relu.html">layer_activation_relu()</a></code> </p>
        </td>
        <td><p>Rectified Linear Unit activation function layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_activation_softmax.html">layer_activation_softmax()</a></code> </p>
        </td>
        <td><p>Softmax activation layer.</p></td>
      </tr></tbody><tbody><tr><th colspan="2">
          <h2 id="recurrent-layers">Recurrent Layers <a href="#recurrent-layers" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="layer_bidirectional.html">layer_bidirectional()</a></code> </p>
        </td>
        <td><p>Bidirectional wrapper for RNNs.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_conv_lstm_1d.html">layer_conv_lstm_1d()</a></code> </p>
        </td>
        <td><p>1D Convolutional LSTM.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_conv_lstm_2d.html">layer_conv_lstm_2d()</a></code> </p>
        </td>
        <td><p>2D Convolutional LSTM.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_conv_lstm_3d.html">layer_conv_lstm_3d()</a></code> </p>
        </td>
        <td><p>3D Convolutional LSTM.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_gru.html">layer_gru()</a></code> </p>
        </td>
        <td><p>Gated Recurrent Unit - Cho et al. 2014.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_gru_cell.html">layer_gru_cell()</a></code> </p>
        </td>
        <td><p>Cell class for the GRU layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_lstm.html">layer_lstm()</a></code> </p>
        </td>
        <td><p>Long Short-Term Memory layer - Hochreiter 1997.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_lstm_cell.html">layer_lstm_cell()</a></code> </p>
        </td>
        <td><p>Cell class for the LSTM layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_rnn.html">layer_rnn()</a></code> </p>
        </td>
        <td><p>Base class for recurrent layers.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_simple_rnn.html">layer_simple_rnn()</a></code> </p>
        </td>
        <td><p>Fully-connected RNN where the output is to be fed back as the new input.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_simple_rnn_cell.html">layer_simple_rnn_cell()</a></code> </p>
        </td>
        <td><p>Cell class for SimpleRNN.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_stacked_rnn_cells.html">layer_stacked_rnn_cells()</a></code> </p>
        </td>
        <td><p>Wrapper allowing a stack of RNN cells to behave as a single cell.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_time_distributed.html">layer_time_distributed()</a></code> </p>
        </td>
        <td><p>This wrapper allows to apply a layer to every temporal slice of an input.</p></td>
      </tr></tbody><tbody><tr><th colspan="2">
          <h2 id="preprocessing-layers">preprocessing Layers <a href="#preprocessing-layers" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="layer_category_encoding.html">layer_category_encoding()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which encodes integer features.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_center_crop.html">layer_center_crop()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which crops images.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_discretization.html">layer_discretization()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which buckets continuous features by ranges.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_feature_space.html">layer_feature_space()</a></code> </p>
        </td>
        <td><p>One-stop utility for preprocessing and encoding structured data.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_hashed_crossing.html">layer_hashed_crossing()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which crosses features using the "hashing trick".</p></td>
      </tr><tr><td>
          <p><code><a href="layer_hashing.html">layer_hashing()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which hashes and bins categorical features.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_integer_lookup.html">layer_integer_lookup()</a></code> </p>
        </td>
        <td><p>A preprocessing layer that maps integers to (possibly encoded) indices.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_normalization.html">layer_normalization()</a></code> </p>
        </td>
        <td><p>A preprocessing layer that normalizes continuous features.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_random_brightness.html">layer_random_brightness()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which randomly adjusts brightness during training.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_random_contrast.html">layer_random_contrast()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which randomly adjusts contrast during training.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_random_crop.html">layer_random_crop()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which randomly crops images during training.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_random_flip.html">layer_random_flip()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which randomly flips images during training.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_random_rotation.html">layer_random_rotation()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which randomly rotates images during training.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_random_translation.html">layer_random_translation()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which randomly translates images during training.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_random_zoom.html">layer_random_zoom()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which randomly zooms images during training.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_rescaling.html">layer_rescaling()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which rescales input values to a new range.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_resizing.html">layer_resizing()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which resizes images.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_string_lookup.html">layer_string_lookup()</a></code> </p>
        </td>
        <td><p>A preprocessing layer that maps strings to (possibly encoded) indices.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_text_vectorization.html">layer_text_vectorization()</a></code> <code><a href="layer_text_vectorization.html">get_vocabulary()</a></code> <code><a href="layer_text_vectorization.html">set_vocabulary()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which maps text features to integer sequences.</p></td>
      </tr></tbody><tbody><tr><th colspan="2">
          <h2 id="attention-layers">Attention Layers <a href="#attention-layers" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="layer_additive_attention.html">layer_additive_attention()</a></code> </p>
        </td>
        <td><p>Additive attention layer, a.k.a. Bahdanau-style attention.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_attention.html">layer_attention()</a></code> </p>
        </td>
        <td><p>Dot-product attention layer, a.k.a. Luong-style attention.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_group_query_attention.html">layer_group_query_attention()</a></code> </p>
        </td>
        <td><p>Grouped Query Attention layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_multi_head_attention.html">layer_multi_head_attention()</a></code> </p>
        </td>
        <td><p>MultiHeadAttention layer.</p></td>
      </tr></tbody><tbody><tr><th colspan="2">
          <h2 id="normalization-layers">Normalization Layers <a href="#normalization-layers" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="layer_batch_normalization.html">layer_batch_normalization()</a></code> </p>
        </td>
        <td><p>Layer that normalizes its inputs.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_group_normalization.html">layer_group_normalization()</a></code> </p>
        </td>
        <td><p>Group normalization layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_layer_normalization.html">layer_layer_normalization()</a></code> </p>
        </td>
        <td><p>Layer normalization layer (Ba et al., 2016).</p></td>
      </tr><tr><td>
          <p><code><a href="layer_spectral_normalization.html">layer_spectral_normalization()</a></code> </p>
        </td>
        <td><p>Performs spectral normalization on the weights of a target layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_unit_normalization.html">layer_unit_normalization()</a></code> </p>
        </td>
        <td><p>Unit normalization layer.</p></td>
      </tr></tbody><tbody><tr><th colspan="2">
          <h2 id="regularization-layers">Regularization Layers <a href="#regularization-layers" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="layer_activity_regularization.html">layer_activity_regularization()</a></code> </p>
        </td>
        <td><p>Layer that applies an update to the cost function based input activity.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_dropout.html">layer_dropout()</a></code> </p>
        </td>
        <td><p>Applies dropout to the input.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_gaussian_dropout.html">layer_gaussian_dropout()</a></code> </p>
        </td>
        <td><p>Apply multiplicative 1-centered Gaussian noise.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_gaussian_noise.html">layer_gaussian_noise()</a></code> </p>
        </td>
        <td><p>Apply additive zero-centered Gaussian noise.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_spatial_dropout_1d.html">layer_spatial_dropout_1d()</a></code> </p>
        </td>
        <td><p>Spatial 1D version of Dropout.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_spatial_dropout_2d.html">layer_spatial_dropout_2d()</a></code> </p>
        </td>
        <td><p>Spatial 2D version of Dropout.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_spatial_dropout_3d.html">layer_spatial_dropout_3d()</a></code> </p>
        </td>
        <td><p>Spatial 3D version of Dropout.</p></td>
      </tr></tbody><tbody><tr><th colspan="2">
          <h2 id="merge-layers">Merge Layers <a href="#merge-layers" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="layer_add.html">layer_add()</a></code> </p>
        </td>
        <td><p>Performs elementwise addition operation.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_average.html">layer_average()</a></code> </p>
        </td>
        <td><p>Averages a list of inputs element-wise..</p></td>
      </tr><tr><td>
          <p><code><a href="layer_concatenate.html">layer_concatenate()</a></code> </p>
        </td>
        <td><p>Concatenates a list of inputs.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_dot.html">layer_dot()</a></code> </p>
        </td>
        <td><p>Computes element-wise dot product of two tensors.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_maximum.html">layer_maximum()</a></code> </p>
        </td>
        <td><p>Computes element-wise maximum on a list of inputs.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_minimum.html">layer_minimum()</a></code> </p>
        </td>
        <td><p>Computes elementwise minimum on a list of inputs.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_multiply.html">layer_multiply()</a></code> </p>
        </td>
        <td><p>Performs elementwise multiplication.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_subtract.html">layer_subtract()</a></code> </p>
        </td>
        <td><p>Performs elementwise subtraction.</p></td>
      </tr></tbody><tbody><tr><th colspan="2">
          <h2 id="layer-methods">Layer Methods <a href="#layer-methods" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="get_config.html">get_config()</a></code> <code><a href="get_config.html">from_config()</a></code> </p>
        </td>
        <td><p>Layer/Model configuration</p></td>
      </tr><tr><td>
          <p><code><a href="get_weights.html">get_weights()</a></code> <code><a href="get_weights.html">set_weights()</a></code> </p>
        </td>
        <td><p>Layer/Model weights as R arrays</p></td>
      </tr><tr><td>
          <p><code><a href="get_input_at.html">get_input_at()</a></code> <code><a href="get_input_at.html">get_output_at()</a></code> <code><a href="get_input_at.html">get_input_shape_at()</a></code> <code><a href="get_input_at.html">get_output_shape_at()</a></code> <code><a href="get_input_at.html">get_input_mask_at()</a></code> <code><a href="get_input_at.html">get_output_mask_at()</a></code> </p>
        </td>
        <td><p>Retrieve tensors for layers with multiple nodes</p></td>
      </tr><tr><td>
          <p><code><a href="count_params.html">count_params()</a></code> </p>
        </td>
        <td><p>Count the total number of scalars composing the weights.</p></td>
      </tr><tr><td>
          <p><code><a href="reset_states.html">reset_states()</a></code> </p>
        </td>
        <td><p>Reset the states for a layer</p></td>
      </tr></tbody><tbody><tr><th colspan="2">
          <h2 id="custom-layers">Custom Layers <a href="#custom-layers" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="grapes-py_class-grapes.html">`%py_class%`</a></code> </p>
        </td>
        <td><p>Make a python class constructor</p></td>
      </tr><tr><td>
          <p><code><a href="Layer.html">Layer()</a></code> </p>
        </td>
        <td><p>(Deprecated) Create a custom Layer</p></td>
      </tr><tr><td>
          <p><code><a href="create_layer_wrapper.html">create_layer_wrapper()</a></code> </p>
        </td>
        <td><p>Create a Keras Layer wrapper</p></td>
      </tr><tr><td>
          <p><code><a href="create_layer.html">create_layer()</a></code> </p>
        </td>
        <td><p>Create a Keras Layer</p></td>
      </tr></tbody><tbody><tr><th colspan="2">
          <h2 id="model-persistence">Model Persistence <a href="#model-persistence" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="save_model_hdf5.html">save_model_hdf5()</a></code> <code><a href="save_model_hdf5.html">load_model_hdf5()</a></code> </p>
        </td>
        <td><p>Save/Load models using HDF5 files</p></td>
      </tr><tr><td>
          <p><code><a href="save_model_weights_hdf5.html">save_model_weights_hdf5()</a></code> <code><a href="save_model_weights_hdf5.html">load_model_weights_hdf5()</a></code> </p>
        </td>
        <td><p>Save/Load model weights using HDF5 files</p></td>
      </tr><tr><td>
          <p><code><a href="serialize_model.html">serialize_model()</a></code> <code><a href="serialize_model.html">unserialize_model()</a></code> </p>
        </td>
        <td><p>Serialize a model to an R object</p></td>
      </tr><tr><td>
          <p><code><a href="get_weights.html">get_weights()</a></code> <code><a href="get_weights.html">set_weights()</a></code> </p>
        </td>
        <td><p>Layer/Model weights as R arrays</p></td>
      </tr><tr><td>
          <p><code><a href="get_config.html">get_config()</a></code> <code><a href="get_config.html">from_config()</a></code> </p>
        </td>
        <td><p>Layer/Model configuration</p></td>
      </tr><tr><td>
          <p><code><a href="model_to_saved_model.html">model_to_saved_model()</a></code> </p>
        </td>
        <td><p>(Deprecated) Export to Saved Model format</p></td>
      </tr><tr><td>
          <p><code><a href="model_from_saved_model.html">model_from_saved_model()</a></code> </p>
        </td>
        <td><p>Load a Keras model from the Saved Model format</p></td>
      </tr><tr><td>
          <p><code><a href="save_model_tf.html">save_model_tf()</a></code> <code><a href="save_model_tf.html">load_model_tf()</a></code> </p>
        </td>
        <td><p>Save/Load models using SavedModel format</p></td>
      </tr><tr><td>
          <p><code><a href="save_model_weights_tf.html">save_model_weights_tf()</a></code> <code><a href="save_model_weights_tf.html">load_model_weights_tf()</a></code> </p>
        </td>
        <td><p>Save model weights in the SavedModel format</p></td>
      </tr><tr><td>
          <p><code><a href="model_to_json.html">model_to_json()</a></code> <code><a href="model_to_json.html">model_from_json()</a></code> </p>
        </td>
        <td><p>Model configuration as JSON</p></td>
      </tr><tr><td>
          <p><code><a href="model_to_yaml.html">model_to_yaml()</a></code> <code><a href="model_to_yaml.html">model_from_yaml()</a></code> </p>
        </td>
        <td><p>Model configuration as YAML</p></td>
      </tr></tbody><tbody><tr><th colspan="2">
          <h2 id="datasets">Datasets <a href="#datasets" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="dataset_boston_housing.html">dataset_boston_housing()</a></code> </p>
        </td>
        <td><p>Boston housing price regression dataset</p></td>
      </tr><tr><td>
          <p><code><a href="dataset_cifar10.html">dataset_cifar10()</a></code> </p>
        </td>
        <td><p>CIFAR10 small image classification</p></td>
      </tr><tr><td>
          <p><code><a href="dataset_cifar100.html">dataset_cifar100()</a></code> </p>
        </td>
        <td><p>CIFAR100 small image classification</p></td>
      </tr><tr><td>
          <p><code><a href="dataset_fashion_mnist.html">dataset_fashion_mnist()</a></code> </p>
        </td>
        <td><p>Fashion-MNIST database of fashion articles</p></td>
      </tr><tr><td>
          <p><code><a href="dataset_imdb.html">dataset_imdb()</a></code> <code><a href="dataset_imdb.html">dataset_imdb_word_index()</a></code> </p>
        </td>
        <td><p>IMDB Movie reviews sentiment classification</p></td>
      </tr><tr><td>
          <p><code><a href="dataset_mnist.html">dataset_mnist()</a></code> </p>
        </td>
        <td><p>MNIST database of handwritten digits</p></td>
      </tr><tr><td>
          <p><code><a href="dataset_reuters.html">dataset_reuters()</a></code> <code><a href="dataset_reuters.html">dataset_reuters_word_index()</a></code> </p>
        </td>
        <td><p>Reuters newswire topics classification</p></td>
      </tr></tbody><tbody><tr><th colspan="2">
          <h2 id="applications">Applications <a href="#applications" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="application_convnext_base.html">application_convnext_base()</a></code> </p>
        </td>
        <td><p>Instantiates the ConvNeXtBase architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_convnext_large.html">application_convnext_large()</a></code> </p>
        </td>
        <td><p>Instantiates the ConvNeXtLarge architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_convnext_small.html">application_convnext_small()</a></code> </p>
        </td>
        <td><p>Instantiates the ConvNeXtSmall architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_convnext_tiny.html">application_convnext_tiny()</a></code> </p>
        </td>
        <td><p>Instantiates the ConvNeXtTiny architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_convnext_xlarge.html">application_convnext_xlarge()</a></code> </p>
        </td>
        <td><p>Instantiates the ConvNeXtXLarge architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_densenet121.html">application_densenet121()</a></code> </p>
        </td>
        <td><p>Instantiates the Densenet121 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_densenet169.html">application_densenet169()</a></code> </p>
        </td>
        <td><p>Instantiates the Densenet169 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_densenet201.html">application_densenet201()</a></code> </p>
        </td>
        <td><p>Instantiates the Densenet201 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_efficientnet_b0.html">application_efficientnet_b0()</a></code> </p>
        </td>
        <td><p>Instantiates the EfficientNetB0 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_efficientnet_b1.html">application_efficientnet_b1()</a></code> </p>
        </td>
        <td><p>Instantiates the EfficientNetB1 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_efficientnet_b2.html">application_efficientnet_b2()</a></code> </p>
        </td>
        <td><p>Instantiates the EfficientNetB2 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_efficientnet_b3.html">application_efficientnet_b3()</a></code> </p>
        </td>
        <td><p>Instantiates the EfficientNetB3 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_efficientnet_b4.html">application_efficientnet_b4()</a></code> </p>
        </td>
        <td><p>Instantiates the EfficientNetB4 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_efficientnet_b5.html">application_efficientnet_b5()</a></code> </p>
        </td>
        <td><p>Instantiates the EfficientNetB5 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_efficientnet_b6.html">application_efficientnet_b6()</a></code> </p>
        </td>
        <td><p>Instantiates the EfficientNetB6 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_efficientnet_b7.html">application_efficientnet_b7()</a></code> </p>
        </td>
        <td><p>Instantiates the EfficientNetB7 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_efficientnet_v2b0.html">application_efficientnet_v2b0()</a></code> </p>
        </td>
        <td><p>Instantiates the EfficientNetV2B0 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_efficientnet_v2b1.html">application_efficientnet_v2b1()</a></code> </p>
        </td>
        <td><p>Instantiates the EfficientNetV2B1 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_efficientnet_v2b2.html">application_efficientnet_v2b2()</a></code> </p>
        </td>
        <td><p>Instantiates the EfficientNetV2B2 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_efficientnet_v2b3.html">application_efficientnet_v2b3()</a></code> </p>
        </td>
        <td><p>Instantiates the EfficientNetV2B3 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_efficientnet_v2l.html">application_efficientnet_v2l()</a></code> </p>
        </td>
        <td><p>Instantiates the EfficientNetV2L architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_efficientnet_v2m.html">application_efficientnet_v2m()</a></code> </p>
        </td>
        <td><p>Instantiates the EfficientNetV2M architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_efficientnet_v2s.html">application_efficientnet_v2s()</a></code> </p>
        </td>
        <td><p>Instantiates the EfficientNetV2S architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_inception_resnet_v2.html">application_inception_resnet_v2()</a></code> </p>
        </td>
        <td><p>Instantiates the Inception-ResNet v2 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_inception_v3.html">application_inception_v3()</a></code> </p>
        </td>
        <td><p>Instantiates the Inception v3 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_mobilenet.html">application_mobilenet()</a></code> </p>
        </td>
        <td><p>Instantiates the MobileNet architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_mobilenet_v2.html">application_mobilenet_v2()</a></code> </p>
        </td>
        <td><p>Instantiates the MobileNetV2 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_mobilenet_v3_large.html">application_mobilenet_v3_large()</a></code> </p>
        </td>
        <td><p>Instantiates the MobileNetV3Large architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_mobilenet_v3_small.html">application_mobilenet_v3_small()</a></code> </p>
        </td>
        <td><p>Instantiates the MobileNetV3Small architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_nasnetlarge.html">application_nasnetlarge()</a></code> </p>
        </td>
        <td><p>Instantiates a NASNet model in ImageNet mode.</p></td>
      </tr><tr><td>
          <p><code><a href="application_nasnetmobile.html">application_nasnetmobile()</a></code> </p>
        </td>
        <td><p>Instantiates a Mobile NASNet model in ImageNet mode.</p></td>
      </tr><tr><td>
          <p><code><a href="application_resnet101.html">application_resnet101()</a></code> </p>
        </td>
        <td><p>Instantiates the ResNet101 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_resnet101_v2.html">application_resnet101_v2()</a></code> </p>
        </td>
        <td><p>Instantiates the ResNet101V2 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_resnet152.html">application_resnet152()</a></code> </p>
        </td>
        <td><p>Instantiates the ResNet152 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_resnet152_v2.html">application_resnet152_v2()</a></code> </p>
        </td>
        <td><p>Instantiates the ResNet152V2 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_resnet50.html">application_resnet50()</a></code> </p>
        </td>
        <td><p>Instantiates the ResNet50 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_resnet50_v2.html">application_resnet50_v2()</a></code> </p>
        </td>
        <td><p>Instantiates the ResNet50V2 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_vgg16.html">application_vgg16()</a></code> </p>
        </td>
        <td><p>Instantiates the VGG16 model.</p></td>
      </tr><tr><td>
          <p><code><a href="application_vgg19.html">application_vgg19()</a></code> </p>
        </td>
        <td><p>Instantiates the VGG19 model.</p></td>
      </tr><tr><td>
          <p><code><a href="application_xception.html">application_xception()</a></code> </p>
        </td>
        <td><p>Instantiates the Xception architecture.</p></td>
      </tr></tbody><tbody><tr><th colspan="2">
          <h2 id="sequence-preprocessing">Sequence Preprocessing <a href="#sequence-preprocessing" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="pad_sequences.html">pad_sequences()</a></code> </p>
        </td>
        <td><p>Pads sequences to the same length.</p></td>
      </tr><tr><td>
          <p><code><a href="timeseries_dataset_from_array.html">timeseries_dataset_from_array()</a></code> </p>
        </td>
        <td><p>Creates a dataset of sliding windows over a timeseries provided as array.</p></td>
      </tr></tbody><tbody><tr><th colspan="2">
          <h2 id="text-preprocessing">Text Preprocessing <a href="#text-preprocessing" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="text_dataset_from_directory.html">text_dataset_from_directory()</a></code> </p>
        </td>
        <td><p>Generates a <code>tf.data.Dataset</code> from text files in a directory.</p></td>
      </tr></tbody><tbody><tr><th colspan="2">
          <h2 id="image-preprocessing">Image Preprocessing <a href="#image-preprocessing" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="image_array_save.html">image_array_save()</a></code> </p>
        </td>
        <td><p>Saves an image stored as a NumPy array to a path or file object.</p></td>
      </tr><tr><td>
          <p><code><a href="image_dataset_from_directory.html">image_dataset_from_directory()</a></code> </p>
        </td>
        <td><p>Generates a <code>tf.data.Dataset</code> from image files in a directory.</p></td>
      </tr><tr><td>
          <p><code><a href="image_from_array.html">image_from_array()</a></code> </p>
        </td>
        <td><p>Converts a 3D array to a PIL Image instance.</p></td>
      </tr><tr><td>
          <p><code><a href="image_load.html">image_load()</a></code> </p>
        </td>
        <td><p>Loads an image into PIL format.</p></td>
      </tr><tr><td>
          <p><code><a href="image_smart_resize.html">image_smart_resize()</a></code> </p>
        </td>
        <td><p>Resize images to a target size without aspect ratio distortion.</p></td>
      </tr><tr><td>
          <p><code><a href="image_to_array.html">image_to_array()</a></code> </p>
        </td>
        <td><p>Converts a PIL Image instance to a matrix.</p></td>
      </tr><tr><td>
          <p><code><a href="k_image_affine_transform.html">k_image_affine_transform()</a></code> </p>
        </td>
        <td><p>Applies the given transform(s) to the image(s).</p></td>
      </tr><tr><td>
          <p><code><a href="k_image_extract_patches.html">k_image_extract_patches()</a></code> </p>
        </td>
        <td><p>Extracts patches from the image(s).</p></td>
      </tr><tr><td>
          <p><code><a href="k_image_map_coordinates.html">k_image_map_coordinates()</a></code> </p>
        </td>
        <td><p>Map the input array to new coordinates by interpolation..</p></td>
      </tr><tr><td>
          <p><code><a href="k_image_pad_images.html">k_image_pad_images()</a></code> </p>
        </td>
        <td><p>Pad <code>images</code> with zeros to the specified <code>height</code> and <code>width</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_image_resize.html">k_image_resize()</a></code> </p>
        </td>
        <td><p>Resize images to size using the specified interpolation method.</p></td>
      </tr></tbody><tbody><tr><th colspan="2">
          <h2 id="optimizers">Optimizers <a href="#optimizers" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="optimizer_adadelta.html">optimizer_adadelta()</a></code> </p>
        </td>
        <td><p>Optimizer that implements the Adadelta algorithm.</p></td>
      </tr><tr><td>
          <p><code><a href="optimizer_adafactor.html">optimizer_adafactor()</a></code> </p>
        </td>
        <td><p>Optimizer that implements the Adafactor algorithm.</p></td>
      </tr><tr><td>
          <p><code><a href="optimizer_adagrad.html">optimizer_adagrad()</a></code> </p>
        </td>
        <td><p>Optimizer that implements the Adagrad algorithm.</p></td>
      </tr><tr><td>
          <p><code><a href="optimizer_adam.html">optimizer_adam()</a></code> </p>
        </td>
        <td><p>Optimizer that implements the Adam algorithm.</p></td>
      </tr><tr><td>
          <p><code><a href="optimizer_adam_w.html">optimizer_adam_w()</a></code> </p>
        </td>
        <td><p>Optimizer that implements the AdamW algorithm.</p></td>
      </tr><tr><td>
          <p><code><a href="optimizer_adamax.html">optimizer_adamax()</a></code> </p>
        </td>
        <td><p>Optimizer that implements the Adamax algorithm.</p></td>
      </tr><tr><td>
          <p><code><a href="optimizer_ftrl.html">optimizer_ftrl()</a></code> </p>
        </td>
        <td><p>Optimizer that implements the FTRL algorithm.</p></td>
      </tr><tr><td>
          <p><code><a href="optimizer_lion.html">optimizer_lion()</a></code> </p>
        </td>
        <td><p>Optimizer that implements the Lion algorithm.</p></td>
      </tr><tr><td>
          <p><code><a href="optimizer_loss_scale.html">optimizer_loss_scale()</a></code> </p>
        </td>
        <td><p>An optimizer that dynamically scales the loss to prevent underflow.</p></td>
      </tr><tr><td>
          <p><code><a href="optimizer_nadam.html">optimizer_nadam()</a></code> </p>
        </td>
        <td><p>Optimizer that implements the Nadam algorithm.</p></td>
      </tr><tr><td>
          <p><code><a href="optimizer_rmsprop.html">optimizer_rmsprop()</a></code> </p>
        </td>
        <td><p>Optimizer that implements the RMSprop algorithm.</p></td>
      </tr><tr><td>
          <p><code><a href="optimizer_sgd.html">optimizer_sgd()</a></code> </p>
        </td>
        <td><p>Gradient descent (with momentum) optimizer.</p></td>
      </tr></tbody><tbody><tr><th colspan="2">
          <h2 id="learning-rate-schedules">Learning Rate Schedules <a href="#learning-rate-schedules" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="learning_rate_schedule_cosine_decay.html">learning_rate_schedule_cosine_decay()</a></code> <code><a href="learning_rate_schedule_cosine_decay.html">learning_rate_schedule_cosine_decay()</a></code> </p>
        </td>
        <td><p>A <code>LearningRateSchedule</code> that uses a cosine decay with optional warmup.</p></td>
      </tr><tr><td>
          <p><code><a href="learning_rate_schedule_cosine_decay_restarts.html">learning_rate_schedule_cosine_decay_restarts()</a></code> <code><a href="learning_rate_schedule_cosine_decay_restarts.html">learning_rate_schedule_cosine_decay_restarts()</a></code> </p>
        </td>
        <td><p>A <code>LearningRateSchedule</code> that uses a cosine decay schedule with restarts.</p></td>
      </tr><tr><td>
          <p><code><a href="learning_rate_schedule_exponential_decay.html">learning_rate_schedule_exponential_decay()</a></code> <code><a href="learning_rate_schedule_exponential_decay.html">learning_rate_schedule_exponential_decay()</a></code> </p>
        </td>
        <td><p>A <code>LearningRateSchedule</code> that uses an exponential decay schedule.</p></td>
      </tr><tr><td>
          <p><code><a href="learning_rate_schedule_inverse_time_decay.html">learning_rate_schedule_inverse_time_decay()</a></code> <code><a href="learning_rate_schedule_inverse_time_decay.html">learning_rate_schedule_inverse_time_decay()</a></code> </p>
        </td>
        <td><p>A <code>LearningRateSchedule</code> that uses an inverse time decay schedule.</p></td>
      </tr><tr><td>
          <p><code><a href="learning_rate_schedule_piecewise_constant_decay.html">learning_rate_schedule_piecewise_constant_decay()</a></code> <code><a href="learning_rate_schedule_piecewise_constant_decay.html">learning_rate_schedule_piecewise_constant_decay()</a></code> </p>
        </td>
        <td><p>A <code>LearningRateSchedule</code> that uses a piecewise constant decay schedule.</p></td>
      </tr><tr><td>
          <p><code><a href="learning_rate_schedule_polynomial_decay.html">learning_rate_schedule_polynomial_decay()</a></code> <code><a href="learning_rate_schedule_polynomial_decay.html">learning_rate_schedule_polynomial_decay()</a></code> </p>
        </td>
        <td><p>A <code>LearningRateSchedule</code> that uses a polynomial decay schedule.</p></td>
      </tr><tr><td>
          <p><code><a href="new_learning_rate_schedule_class.html">new_learning_rate_schedule_class()</a></code> </p>
        </td>
        <td><p>Create a new learning rate schedule type</p></td>
      </tr></tbody><tbody><tr><th colspan="2">
          <h2 id="callbacks">Callbacks <a href="#callbacks" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="callback_backup_and_restore.html">callback_backup_and_restore()</a></code> </p>
        </td>
        <td><p>Callback to back up and restore the training state.</p></td>
      </tr><tr><td>
          <p><code><a href="callback_csv_logger.html">callback_csv_logger()</a></code> </p>
        </td>
        <td><p>Callback that streams epoch results to a CSV file.</p></td>
      </tr><tr><td>
          <p><code><a href="callback_early_stopping.html">callback_early_stopping()</a></code> </p>
        </td>
        <td><p>Stop training when a monitored metric has stopped improving.</p></td>
      </tr><tr><td>
          <p><code><a href="callback_lambda.html">callback_lambda()</a></code> </p>
        </td>
        <td><p>Callback for creating simple, custom callbacks on-the-fly.</p></td>
      </tr><tr><td>
          <p><code><a href="callback_learning_rate_scheduler.html">callback_learning_rate_scheduler()</a></code> </p>
        </td>
        <td><p>Learning rate scheduler.</p></td>
      </tr><tr><td>
          <p><code><a href="callback_model_checkpoint.html">callback_model_checkpoint()</a></code> </p>
        </td>
        <td><p>Callback to save the Keras model or model weights at some frequency.
@description
<code><a href="../reference/callback_model_checkpoint.html">callback_model_checkpoint()</a></code> is used in conjunction with training using
<code>model |&gt; fit()</code> to save a model or weights (in a checkpoint file) at some
interval, so the model or weights can be loaded later to continue the
training from the state saved.</p></td>
      </tr><tr><td>
          <p><code><a href="callback_progbar_logger.html">callback_progbar_logger()</a></code> </p>
        </td>
        <td><p>Callback that prints metrics to stdout.</p></td>
      </tr><tr><td>
          <p><code><a href="callback_reduce_lr_on_plateau.html">callback_reduce_lr_on_plateau()</a></code> </p>
        </td>
        <td><p>Reduce learning rate when a metric has stopped improving.</p></td>
      </tr><tr><td>
          <p><code><a href="callback_remote_monitor.html">callback_remote_monitor()</a></code> </p>
        </td>
        <td><p>Callback used to stream events to a server.</p></td>
      </tr><tr><td>
          <p><code><a href="callback_tensorboard.html">callback_tensorboard()</a></code> </p>
        </td>
        <td><p>Enable visualizations for TensorBoard.</p></td>
      </tr><tr><td>
          <p><code><a href="callback_terminate_on_nan.html">callback_terminate_on_nan()</a></code> </p>
        </td>
        <td><p>Callback that terminates training when a NaN loss is encountered.</p></td>
      </tr><tr><td>
          <p><code><a href="KerasCallback.html">KerasCallback</a></code> </p>
        </td>
        <td><p>(Deprecated) Base R6 class for Keras callbacks</p></td>
      </tr></tbody><tbody><tr><th colspan="2">
          <h2 id="initializers">Initializers <a href="#initializers" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="initializer_constant.html">initializer_constant()</a></code> </p>
        </td>
        <td><p>Initializer that generates tensors with constant values.</p></td>
      </tr><tr><td>
          <p><code><a href="initializer_glorot_normal.html">initializer_glorot_normal()</a></code> </p>
        </td>
        <td><p>The Glorot normal initializer, also called Xavier normal initializer.</p></td>
      </tr><tr><td>
          <p><code><a href="initializer_glorot_uniform.html">initializer_glorot_uniform()</a></code> </p>
        </td>
        <td><p>The Glorot uniform initializer, also called Xavier uniform initializer.</p></td>
      </tr><tr><td>
          <p><code><a href="initializer_he_normal.html">initializer_he_normal()</a></code> </p>
        </td>
        <td><p>He normal initializer.</p></td>
      </tr><tr><td>
          <p><code><a href="initializer_he_uniform.html">initializer_he_uniform()</a></code> </p>
        </td>
        <td><p>He uniform variance scaling initializer.</p></td>
      </tr><tr><td>
          <p><code><a href="initializer_identity.html">initializer_identity()</a></code> </p>
        </td>
        <td><p>Initializer that generates the identity matrix.</p></td>
      </tr><tr><td>
          <p><code><a href="initializer_lecun_normal.html">initializer_lecun_normal()</a></code> </p>
        </td>
        <td><p>Lecun normal initializer.</p></td>
      </tr><tr><td>
          <p><code><a href="initializer_lecun_uniform.html">initializer_lecun_uniform()</a></code> </p>
        </td>
        <td><p>Lecun uniform initializer.</p></td>
      </tr><tr><td>
          <p><code><a href="initializer_ones.html">initializer_ones()</a></code> </p>
        </td>
        <td><p>Initializer that generates tensors initialized to 1.</p></td>
      </tr><tr><td>
          <p><code><a href="initializer_orthogonal.html">initializer_orthogonal()</a></code> </p>
        </td>
        <td><p>Initializer that generates an orthogonal matrix.</p></td>
      </tr><tr><td>
          <p><code><a href="initializer_random_normal.html">initializer_random_normal()</a></code> </p>
        </td>
        <td><p>Random normal initializer.</p></td>
      </tr><tr><td>
          <p><code><a href="initializer_random_uniform.html">initializer_random_uniform()</a></code> </p>
        </td>
        <td><p>Random uniform initializer.</p></td>
      </tr><tr><td>
          <p><code><a href="initializer_truncated_normal.html">initializer_truncated_normal()</a></code> </p>
        </td>
        <td><p>Initializer that generates a truncated normal distribution.</p></td>
      </tr><tr><td>
          <p><code><a href="initializer_variance_scaling.html">initializer_variance_scaling()</a></code> </p>
        </td>
        <td><p>Initializer that adapts its scale to the shape of its input tensors.</p></td>
      </tr><tr><td>
          <p><code><a href="initializer_zeros.html">initializer_zeros()</a></code> </p>
        </td>
        <td><p>Initializer that generates tensors initialized to 0.</p></td>
      </tr></tbody><tbody><tr><th colspan="2">
          <h2 id="constraints">Constraints <a href="#constraints" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="constraint_maxnorm.html">constraint_maxnorm()</a></code> </p>
        </td>
        <td><p>MaxNorm weight constraint.</p></td>
      </tr><tr><td>
          <p><code><a href="constraint_minmaxnorm.html">constraint_minmaxnorm()</a></code> </p>
        </td>
        <td><p>MinMaxNorm weight constraint.</p></td>
      </tr><tr><td>
          <p><code><a href="constraint_nonneg.html">constraint_nonneg()</a></code> </p>
        </td>
        <td><p>Constrains the weights to be non-negative.</p></td>
      </tr><tr><td>
          <p><code><a href="constraint_unitnorm.html">constraint_unitnorm()</a></code> </p>
        </td>
        <td><p>Constrains the weights incident to each hidden unit to have unit norm.</p></td>
      </tr><tr><td>
          <p><code><a href="KerasConstraint.html">KerasConstraint</a></code> </p>
        </td>
        <td><p>(Deprecated) Base R6 class for Keras constraints</p></td>
      </tr></tbody><tbody><tr><th colspan="2">
          <h2 id="utils">Utils <a href="#utils" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="audio_dataset_from_directory.html">audio_dataset_from_directory()</a></code> </p>
        </td>
        <td><p>Generates a <code>tf.data.Dataset</code> from audio files in a directory.</p></td>
      </tr><tr><td>
          <p><code><a href="clear_session.html">clear_session()</a></code> </p>
        </td>
        <td><p>Resets all state generated by Keras.</p></td>
      </tr><tr><td>
          <p><code><a href="get_custom_objects.html">get_custom_objects()</a></code> </p>
        </td>
        <td><p>Retrieves a live reference to the global dictionary of custom objects.</p></td>
      </tr><tr><td>
          <p><code><a href="get_file.html">get_file()</a></code> </p>
        </td>
        <td><p>Downloads a file from a URL if it not already in the cache.</p></td>
      </tr><tr><td>
          <p><code><a href="get_registered_name.html">get_registered_name()</a></code> </p>
        </td>
        <td><p>Returns the name registered to an object within the Keras framework.</p></td>
      </tr><tr><td>
          <p><code><a href="get_registered_object.html">get_registered_object()</a></code> </p>
        </td>
        <td><p>Returns the class associated with <code>name</code> if it is registered with Keras.</p></td>
      </tr><tr><td>
          <p><code><a href="get_source_inputs.html">get_source_inputs()</a></code> </p>
        </td>
        <td><p>Returns the list of input tensors necessary to compute <code>tensor</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="image_array_save.html">image_array_save()</a></code> </p>
        </td>
        <td><p>Saves an image stored as a NumPy array to a path or file object.</p></td>
      </tr><tr><td>
          <p><code><a href="image_dataset_from_directory.html">image_dataset_from_directory()</a></code> </p>
        </td>
        <td><p>Generates a <code>tf.data.Dataset</code> from image files in a directory.</p></td>
      </tr><tr><td>
          <p><code><a href="image_from_array.html">image_from_array()</a></code> </p>
        </td>
        <td><p>Converts a 3D array to a PIL Image instance.</p></td>
      </tr><tr><td>
          <p><code><a href="image_load.html">image_load()</a></code> </p>
        </td>
        <td><p>Loads an image into PIL format.</p></td>
      </tr><tr><td>
          <p><code><a href="image_to_array.html">image_to_array()</a></code> </p>
        </td>
        <td><p>Converts a PIL Image instance to a matrix.</p></td>
      </tr><tr><td>
          <p><code><a href="model_to_dot.html">model_to_dot()</a></code> </p>
        </td>
        <td><p>Convert a Keras model to dot format.</p></td>
      </tr><tr><td>
          <p><code><a href="normalize.html">normalize()</a></code> </p>
        </td>
        <td><p>Normalizes an array.</p></td>
      </tr><tr><td>
          <p><code><a href="pack_x_y_sample_weight.html">pack_x_y_sample_weight()</a></code> </p>
        </td>
        <td><p>Packs user-provided data into a tuple.</p></td>
      </tr><tr><td>
          <p><code><a href="pad_sequences.html">pad_sequences()</a></code> </p>
        </td>
        <td><p>Pads sequences to the same length.</p></td>
      </tr><tr><td>
          <p><code><a href="set_random_seed.html">set_random_seed()</a></code> </p>
        </td>
        <td><p>Sets all random seeds (Python, NumPy, and backend framework, e.g. TF).</p></td>
      </tr><tr><td>
          <p><code><a href="split_dataset.html">split_dataset()</a></code> </p>
        </td>
        <td><p>Splits a dataset into a left half and a right half (e.g. train / test).</p></td>
      </tr><tr><td>
          <p><code><a href="text_dataset_from_directory.html">text_dataset_from_directory()</a></code> </p>
        </td>
        <td><p>Generates a <code>tf.data.Dataset</code> from text files in a directory.</p></td>
      </tr><tr><td>
          <p><code><a href="timeseries_dataset_from_array.html">timeseries_dataset_from_array()</a></code> </p>
        </td>
        <td><p>Creates a dataset of sliding windows over a timeseries provided as array.</p></td>
      </tr><tr><td>
          <p><code><a href="to_categorical.html">to_categorical()</a></code> </p>
        </td>
        <td><p>Converts a class vector (integers) to binary class matrix.</p></td>
      </tr><tr><td>
          <p><code><a href="unpack_x_y_sample_weight.html">unpack_x_y_sample_weight()</a></code> </p>
        </td>
        <td><p>Unpacks user-provided data tuple.</p></td>
      </tr><tr><td>
          <p><code><a href="plot.keras_training_history.html">plot(<i>&lt;keras_training_history&gt;</i>)</a></code> </p>
        </td>
        <td><p>Plot training history</p></td>
      </tr><tr><td>
          <p><code><a href="plot.keras.models.model.Model.html">plot(<i>&lt;keras.models.model.Model&gt;</i>)</a></code> </p>
        </td>
        <td><p>Plot a Keras model</p></td>
      </tr><tr><td>
          <p><code><a href="zip_lists.html">zip_lists()</a></code> </p>
        </td>
        <td><p>zip lists</p></td>
      </tr><tr><td>
          <p><code><a href="new-classes.html">new_metric_class()</a></code> <code><a href="new-classes.html">new_loss_class()</a></code> <code><a href="new-classes.html">new_callback_class()</a></code> <code><a href="new-classes.html">new_model_class()</a></code> <code><a href="new-classes.html">new_layer_class()</a></code> <code><a href="new-classes.html">mark_active()</a></code> </p>
        </td>
        <td><p>Define new keras types</p></td>
      </tr><tr><td>
          <p><code><a href="timeseries_generator.html">timeseries_generator()</a></code> </p>
        </td>
        <td><p>Utility function for generating batches of temporal data.</p></td>
      </tr><tr><td>
          <p><code><a href="with_custom_object_scope.html">with_custom_object_scope()</a></code> </p>
        </td>
        <td><p>Provide a scope with mappings of names to custom objects</p></td>
      </tr><tr><td>
          <p><code><a href="keras_array.html">keras_array()</a></code> </p>
        </td>
        <td><p>Keras array object</p></td>
      </tr><tr><td>
          <p><code><a href="install_keras.html">install_keras()</a></code> </p>
        </td>
        <td><p>Install Keras</p></td>
      </tr><tr><td>
          <p><code><a href="is_keras_available.html">is_keras_available()</a></code> </p>
        </td>
        <td><p>Check if Keras is Available</p></td>
      </tr><tr><td>
          <p><code><a href="backend.html">backend()</a></code> </p>
        </td>
        <td><p>Keras backend tensor engine</p></td>
      </tr><tr><td>
          <p><code><a href="implementation.html">implementation()</a></code> </p>
        </td>
        <td><p>Keras implementation</p></td>
      </tr><tr><td>
          <p><code><a href="use_implementation.html">use_implementation()</a></code> <code><a href="use_implementation.html">use_backend()</a></code> </p>
        </td>
        <td><p>Select a Keras implementation and backend</p></td>
      </tr></tbody><tbody><tr><th colspan="2">
          <h2 id="losses">Losses <a href="#losses" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="loss_mean_squared_error.html">loss_mean_squared_error()</a></code> </p>
        </td>
        <td><p>Computes the mean of squares of errors between labels and predictions.</p></td>
      </tr><tr><td>
          <p><code><a href="loss_binary_crossentropy.html">loss_binary_crossentropy()</a></code> </p>
        </td>
        <td><p>Computes the cross-entropy loss between true labels and predicted labels.</p></td>
      </tr><tr><td>
          <p><code><a href="loss_binary_focal_crossentropy.html">loss_binary_focal_crossentropy()</a></code> </p>
        </td>
        <td><p>Computes focal cross-entropy loss between true labels and predictions.</p></td>
      </tr><tr><td>
          <p><code><a href="loss_categorical_crossentropy.html">loss_categorical_crossentropy()</a></code> </p>
        </td>
        <td><p>Computes the crossentropy loss between the labels and predictions.</p></td>
      </tr><tr><td>
          <p><code><a href="loss_categorical_focal_crossentropy.html">loss_categorical_focal_crossentropy()</a></code> </p>
        </td>
        <td><p>Computes the alpha balanced focal crossentropy loss.</p></td>
      </tr><tr><td>
          <p><code><a href="loss_categorical_hinge.html">loss_categorical_hinge()</a></code> </p>
        </td>
        <td><p>Computes the categorical hinge loss between <code>y_true</code> &amp; <code>y_pred</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="loss_cosine_similarity.html">loss_cosine_similarity()</a></code> </p>
        </td>
        <td><p>Computes the cosine similarity between <code>y_true</code> &amp; <code>y_pred</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="loss_hinge.html">loss_hinge()</a></code> </p>
        </td>
        <td><p>Computes the hinge loss between <code>y_true</code> &amp; <code>y_pred</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="loss_huber.html">loss_huber()</a></code> </p>
        </td>
        <td><p>Computes the Huber loss between <code>y_true</code> &amp; <code>y_pred</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="loss_kl_divergence.html">loss_kl_divergence()</a></code> </p>
        </td>
        <td><p>Computes Kullback-Leibler divergence loss between <code>y_true</code> &amp; <code>y_pred</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="loss_log_cosh.html">loss_log_cosh()</a></code> </p>
        </td>
        <td><p>Computes the logarithm of the hyperbolic cosine of the prediction error.</p></td>
      </tr><tr><td>
          <p><code><a href="loss_mean_absolute_error.html">loss_mean_absolute_error()</a></code> </p>
        </td>
        <td><p>Computes the mean of absolute difference between labels and predictions.</p></td>
      </tr><tr><td>
          <p><code><a href="loss_mean_absolute_percentage_error.html">loss_mean_absolute_percentage_error()</a></code> </p>
        </td>
        <td><p>Computes the mean absolute percentage error between <code>y_true</code> &amp; <code>y_pred</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="loss_mean_squared_logarithmic_error.html">loss_mean_squared_logarithmic_error()</a></code> </p>
        </td>
        <td><p>Computes the mean squared logarithmic error between <code>y_true</code> &amp; <code>y_pred</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="loss_poisson.html">loss_poisson()</a></code> </p>
        </td>
        <td><p>Computes the Poisson loss between <code>y_true</code> &amp; <code>y_pred</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="loss_sparse_categorical_crossentropy.html">loss_sparse_categorical_crossentropy()</a></code> </p>
        </td>
        <td><p>Computes the crossentropy loss between the labels and predictions.</p></td>
      </tr><tr><td>
          <p><code><a href="loss_squared_hinge.html">loss_squared_hinge()</a></code> </p>
        </td>
        <td><p>Computes the squared hinge loss between <code>y_true</code> &amp; <code>y_pred</code>.</p></td>
      </tr></tbody><tbody><tr><th colspan="2">
          <h2 id="metrics">Metrics <a href="#metrics" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="Metric.html">Metric</a></code> </p>
        </td>
        <td><p>Metric</p></td>
      </tr><tr><td>
          <p><code><a href="metric_auc.html">metric_auc()</a></code> </p>
        </td>
        <td><p>Approximates the AUC (Area under the curve) of the ROC or PR curves.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_binary_accuracy.html">metric_binary_accuracy()</a></code> </p>
        </td>
        <td><p>Calculates how often predictions match binary labels.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_binary_crossentropy.html">metric_binary_crossentropy()</a></code> </p>
        </td>
        <td><p>Computes the crossentropy metric between the labels and predictions.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_binary_focal_crossentropy.html">metric_binary_focal_crossentropy()</a></code> </p>
        </td>
        <td><p>Computes the binary focal crossentropy loss.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_binary_iou.html">metric_binary_iou()</a></code> </p>
        </td>
        <td><p>Computes the Intersection-Over-Union metric for class 0 and/or 1.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_categorical_accuracy.html">metric_categorical_accuracy()</a></code> </p>
        </td>
        <td><p>Calculates how often predictions match one-hot labels.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_categorical_crossentropy.html">metric_categorical_crossentropy()</a></code> </p>
        </td>
        <td><p>Computes the crossentropy metric between the labels and predictions.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_categorical_focal_crossentropy.html">metric_categorical_focal_crossentropy()</a></code> </p>
        </td>
        <td><p>Computes the categorical focal crossentropy loss.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_categorical_hinge.html">metric_categorical_hinge()</a></code> </p>
        </td>
        <td><p>Computes the categorical hinge metric between <code>y_true</code> and <code>y_pred</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_cosine_similarity.html">metric_cosine_similarity()</a></code> </p>
        </td>
        <td><p>Computes the cosine similarity between the labels and predictions.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_f1_score.html">metric_f1_score()</a></code> </p>
        </td>
        <td><p>Computes F-1 Score.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_false_negatives.html">metric_false_negatives()</a></code> </p>
        </td>
        <td><p>Calculates the number of false negatives.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_false_positives.html">metric_false_positives()</a></code> </p>
        </td>
        <td><p>Calculates the number of false positives.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_fbeta_score.html">metric_fbeta_score()</a></code> </p>
        </td>
        <td><p>Computes F-Beta score.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_hinge.html">metric_hinge()</a></code> </p>
        </td>
        <td><p>Computes the hinge metric between <code>y_true</code> and <code>y_pred</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_huber.html">metric_huber()</a></code> </p>
        </td>
        <td><p>Computes Huber loss value.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_iou.html">metric_iou()</a></code> </p>
        </td>
        <td><p>Computes the Intersection-Over-Union metric for specific target classes.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_kl_divergence.html">metric_kl_divergence()</a></code> </p>
        </td>
        <td><p>Computes Kullback-Leibler divergence metric between <code>y_true</code> and</p></td>
      </tr><tr><td>
          <p><code><a href="metric_log_cosh.html">metric_log_cosh()</a></code> </p>
        </td>
        <td><p>Logarithm of the hyperbolic cosine of the prediction error.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_log_cosh_error.html">metric_log_cosh_error()</a></code> </p>
        </td>
        <td><p>Computes the logarithm of the hyperbolic cosine of the prediction error.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_mean.html">metric_mean()</a></code> </p>
        </td>
        <td><p>Compute the (weighted) mean of the given values.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_mean_absolute_error.html">metric_mean_absolute_error()</a></code> </p>
        </td>
        <td><p>Computes the mean absolute error between the labels and predictions.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_mean_absolute_percentage_error.html">metric_mean_absolute_percentage_error()</a></code> </p>
        </td>
        <td><p>Computes mean absolute percentage error between <code>y_true</code> and <code>y_pred</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_mean_iou.html">metric_mean_iou()</a></code> </p>
        </td>
        <td><p>Computes the mean Intersection-Over-Union metric.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_mean_squared_error.html">metric_mean_squared_error()</a></code> </p>
        </td>
        <td><p>Computes the mean squared error between <code>y_true</code> and <code>y_pred</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_mean_squared_logarithmic_error.html">metric_mean_squared_logarithmic_error()</a></code> </p>
        </td>
        <td><p>Computes mean squared logarithmic error between <code>y_true</code> and <code>y_pred</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_mean_wrapper.html">metric_mean_wrapper()</a></code> </p>
        </td>
        <td><p>Wrap a stateless metric function with the Mean metric.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_one_hot_iou.html">metric_one_hot_iou()</a></code> </p>
        </td>
        <td><p>Computes the Intersection-Over-Union metric for one-hot encoded labels.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_one_hot_mean_iou.html">metric_one_hot_mean_iou()</a></code> </p>
        </td>
        <td><p>Computes mean Intersection-Over-Union metric for one-hot encoded labels.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_poisson.html">metric_poisson()</a></code> </p>
        </td>
        <td><p>Computes the Poisson metric between <code>y_true</code> and <code>y_pred</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_precision.html">metric_precision()</a></code> </p>
        </td>
        <td><p>Computes the precision of the predictions with respect to the labels.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_precision_at_recall.html">metric_precision_at_recall()</a></code> </p>
        </td>
        <td><p>Computes best precision where recall is &gt;= specified value.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_r2_score.html">metric_r2_score()</a></code> </p>
        </td>
        <td><p>Computes R2 score.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_recall.html">metric_recall()</a></code> </p>
        </td>
        <td><p>Computes the recall of the predictions with respect to the labels.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_recall_at_precision.html">metric_recall_at_precision()</a></code> </p>
        </td>
        <td><p>Computes best recall where precision is &gt;= specified value.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_root_mean_squared_error.html">metric_root_mean_squared_error()</a></code> </p>
        </td>
        <td><p>Computes root mean squared error metric between <code>y_true</code> and <code>y_pred</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_sensitivity_at_specificity.html">metric_sensitivity_at_specificity()</a></code> </p>
        </td>
        <td><p>Computes best sensitivity where specificity is &gt;= specified value.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_sparse_categorical_accuracy.html">metric_sparse_categorical_accuracy()</a></code> </p>
        </td>
        <td><p>Calculates how often predictions match integer labels.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_sparse_categorical_crossentropy.html">metric_sparse_categorical_crossentropy()</a></code> </p>
        </td>
        <td><p>Computes the crossentropy metric between the labels and predictions.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_sparse_top_k_categorical_accuracy.html">metric_sparse_top_k_categorical_accuracy()</a></code> </p>
        </td>
        <td><p>Computes how often integer targets are in the top <code>K</code> predictions.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_specificity_at_sensitivity.html">metric_specificity_at_sensitivity()</a></code> </p>
        </td>
        <td><p>Computes best specificity where sensitivity is &gt;= specified value.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_squared_hinge.html">metric_squared_hinge()</a></code> </p>
        </td>
        <td><p>Computes the hinge metric between <code>y_true</code> and <code>y_pred</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_sum.html">metric_sum()</a></code> </p>
        </td>
        <td><p>Compute the (weighted) sum of the given values.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_top_k_categorical_accuracy.html">metric_top_k_categorical_accuracy()</a></code> </p>
        </td>
        <td><p>Computes how often targets are in the top <code>K</code> predictions.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_true_negatives.html">metric_true_negatives()</a></code> </p>
        </td>
        <td><p>Calculates the number of true negatives.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_true_positives.html">metric_true_positives()</a></code> </p>
        </td>
        <td><p>Calculates the number of true positives.</p></td>
      </tr><tr><td>
          <p><code><a href="custom_metric.html">custom_metric()</a></code> </p>
        </td>
        <td><p>Custom metric function</p></td>
      </tr></tbody><tbody><tr><th colspan="2">
          <h2 id="regularizers">Regularizers <a href="#regularizers" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="regularizer_l1.html">regularizer_l1()</a></code> </p>
        </td>
        <td><p>A regularizer that applies a L1 regularization penalty.</p></td>
      </tr><tr><td>
          <p><code><a href="regularizer_l1_l2.html">regularizer_l1_l2()</a></code> </p>
        </td>
        <td><p>A regularizer that applies both L1 and L2 regularization penalties.</p></td>
      </tr><tr><td>
          <p><code><a href="regularizer_l2.html">regularizer_l2()</a></code> </p>
        </td>
        <td><p>A regularizer that applies a L2 regularization penalty.</p></td>
      </tr><tr><td>
          <p><code><a href="regularizer_orthogonal.html">regularizer_orthogonal()</a></code> </p>
        </td>
        <td><p>Regularizer that encourages input vectors to be orthogonal to each other.</p></td>
      </tr></tbody><tbody><tr><th colspan="2">
          <h2 id="activations">Activations <a href="#activations" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="activation_elu.html">activation_elu()</a></code> </p>
        </td>
        <td><p>Exponential Linear Unit.</p></td>
      </tr><tr><td>
          <p><code><a href="activation_exponential.html">activation_exponential()</a></code> </p>
        </td>
        <td><p>Exponential activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="activation_gelu.html">activation_gelu()</a></code> </p>
        </td>
        <td><p>Gaussian error linear unit (GELU) activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="activation_hard_sigmoid.html">activation_hard_sigmoid()</a></code> </p>
        </td>
        <td><p>Hard sigmoid activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="activation_leaky_relu.html">activation_leaky_relu()</a></code> </p>
        </td>
        <td><p>Leaky relu activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="activation_linear.html">activation_linear()</a></code> </p>
        </td>
        <td><p>Linear activation function (pass-through).</p></td>
      </tr><tr><td>
          <p><code><a href="activation_log_softmax.html">activation_log_softmax()</a></code> </p>
        </td>
        <td><p>Log-Softmax activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="activation_mish.html">activation_mish()</a></code> </p>
        </td>
        <td><p>Mish activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="activation_relu.html">activation_relu()</a></code> </p>
        </td>
        <td><p>Applies the rectified linear unit activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="activation_relu6.html">activation_relu6()</a></code> </p>
        </td>
        <td><p>Relu6 activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="activation_selu.html">activation_selu()</a></code> </p>
        </td>
        <td><p>Scaled Exponential Linear Unit (SELU).</p></td>
      </tr><tr><td>
          <p><code><a href="activation_sigmoid.html">activation_sigmoid()</a></code> </p>
        </td>
        <td><p>Sigmoid activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="activation_silu.html">activation_silu()</a></code> </p>
        </td>
        <td><p>Swish (or Silu) activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="activation_softmax.html">activation_softmax()</a></code> </p>
        </td>
        <td><p>Softmax converts a vector of values to a probability distribution.</p></td>
      </tr><tr><td>
          <p><code><a href="activation_softplus.html">activation_softplus()</a></code> </p>
        </td>
        <td><p>Softplus activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="activation_softsign.html">activation_softsign()</a></code> </p>
        </td>
        <td><p>Softsign activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="activation_tanh.html">activation_tanh()</a></code> </p>
        </td>
        <td><p>Hyperbolic tangent activation function.</p></td>
      </tr></tbody><tbody><tr><th colspan="2">
          <h2 id="misc-other-layers">Misc other layers <a href="#misc-other-layers" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="layer_activation.html">layer_activation()</a></code> </p>
        </td>
        <td><p>Applies an activation function to an output.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_activation_elu.html">layer_activation_elu()</a></code> </p>
        </td>
        <td><p>Applies an Exponential Linear Unit function to an output.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_activation_leaky_relu.html">layer_activation_leaky_relu()</a></code> </p>
        </td>
        <td><p>Leaky version of a Rectified Linear Unit activation layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_activation_parametric_relu.html">layer_activation_parametric_relu()</a></code> </p>
        </td>
        <td><p>Parametric Rectified Linear Unit activation layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_activation_relu.html">layer_activation_relu()</a></code> </p>
        </td>
        <td><p>Rectified Linear Unit activation function layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_activation_softmax.html">layer_activation_softmax()</a></code> </p>
        </td>
        <td><p>Softmax activation layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_activity_regularization.html">layer_activity_regularization()</a></code> </p>
        </td>
        <td><p>Layer that applies an update to the cost function based input activity.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_add.html">layer_add()</a></code> </p>
        </td>
        <td><p>Performs elementwise addition operation.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_additive_attention.html">layer_additive_attention()</a></code> </p>
        </td>
        <td><p>Additive attention layer, a.k.a. Bahdanau-style attention.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_attention.html">layer_attention()</a></code> </p>
        </td>
        <td><p>Dot-product attention layer, a.k.a. Luong-style attention.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_average.html">layer_average()</a></code> </p>
        </td>
        <td><p>Averages a list of inputs element-wise..</p></td>
      </tr><tr><td>
          <p><code><a href="layer_average_pooling_1d.html">layer_average_pooling_1d()</a></code> </p>
        </td>
        <td><p>Average pooling for temporal data.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_average_pooling_2d.html">layer_average_pooling_2d()</a></code> </p>
        </td>
        <td><p>Average pooling operation for 2D spatial data.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_average_pooling_3d.html">layer_average_pooling_3d()</a></code> </p>
        </td>
        <td><p>Average pooling operation for 3D data (spatial or spatio-temporal).</p></td>
      </tr><tr><td>
          <p><code><a href="layer_batch_normalization.html">layer_batch_normalization()</a></code> </p>
        </td>
        <td><p>Layer that normalizes its inputs.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_bidirectional.html">layer_bidirectional()</a></code> </p>
        </td>
        <td><p>Bidirectional wrapper for RNNs.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_category_encoding.html">layer_category_encoding()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which encodes integer features.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_center_crop.html">layer_center_crop()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which crops images.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_concatenate.html">layer_concatenate()</a></code> </p>
        </td>
        <td><p>Concatenates a list of inputs.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_conv_1d.html">layer_conv_1d()</a></code> </p>
        </td>
        <td><p>1D convolution layer (e.g. temporal convolution).</p></td>
      </tr><tr><td>
          <p><code><a href="layer_conv_1d_transpose.html">layer_conv_1d_transpose()</a></code> </p>
        </td>
        <td><p>1D transposed convolution layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_conv_2d.html">layer_conv_2d()</a></code> </p>
        </td>
        <td><p>2D convolution layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_conv_2d_transpose.html">layer_conv_2d_transpose()</a></code> </p>
        </td>
        <td><p>2D transposed convolution layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_conv_3d.html">layer_conv_3d()</a></code> </p>
        </td>
        <td><p>3D convolution layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_conv_3d_transpose.html">layer_conv_3d_transpose()</a></code> </p>
        </td>
        <td><p>3D transposed convolution layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_conv_lstm_1d.html">layer_conv_lstm_1d()</a></code> </p>
        </td>
        <td><p>1D Convolutional LSTM.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_conv_lstm_2d.html">layer_conv_lstm_2d()</a></code> </p>
        </td>
        <td><p>2D Convolutional LSTM.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_conv_lstm_3d.html">layer_conv_lstm_3d()</a></code> </p>
        </td>
        <td><p>3D Convolutional LSTM.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_cropping_1d.html">layer_cropping_1d()</a></code> </p>
        </td>
        <td><p>Cropping layer for 1D input (e.g. temporal sequence).</p></td>
      </tr><tr><td>
          <p><code><a href="layer_cropping_2d.html">layer_cropping_2d()</a></code> </p>
        </td>
        <td><p>Cropping layer for 2D input (e.g. picture).</p></td>
      </tr><tr><td>
          <p><code><a href="layer_cropping_3d.html">layer_cropping_3d()</a></code> </p>
        </td>
        <td><p>Cropping layer for 3D data (e.g. spatial or spatio-temporal).</p></td>
      </tr><tr><td>
          <p><code><a href="layer_dense.html">layer_dense()</a></code> </p>
        </td>
        <td><p>Just your regular densely-connected NN layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_depthwise_conv_1d.html">layer_depthwise_conv_1d()</a></code> </p>
        </td>
        <td><p>1D depthwise convolution layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_depthwise_conv_2d.html">layer_depthwise_conv_2d()</a></code> </p>
        </td>
        <td><p>2D depthwise convolution layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_discretization.html">layer_discretization()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which buckets continuous features by ranges.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_dot.html">layer_dot()</a></code> </p>
        </td>
        <td><p>Computes element-wise dot product of two tensors.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_dropout.html">layer_dropout()</a></code> </p>
        </td>
        <td><p>Applies dropout to the input.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_einsum_dense.html">layer_einsum_dense()</a></code> </p>
        </td>
        <td><p>A layer that uses <code>einsum</code> as the backing computation.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_embedding.html">layer_embedding()</a></code> </p>
        </td>
        <td><p>Turns positive integers (indexes) into dense vectors of fixed size.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_feature_space.html">layer_feature_space()</a></code> </p>
        </td>
        <td><p>One-stop utility for preprocessing and encoding structured data.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_flatten.html">layer_flatten()</a></code> </p>
        </td>
        <td><p>Flattens the input. Does not affect the batch size.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_gaussian_dropout.html">layer_gaussian_dropout()</a></code> </p>
        </td>
        <td><p>Apply multiplicative 1-centered Gaussian noise.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_gaussian_noise.html">layer_gaussian_noise()</a></code> </p>
        </td>
        <td><p>Apply additive zero-centered Gaussian noise.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_global_average_pooling_1d.html">layer_global_average_pooling_1d()</a></code> </p>
        </td>
        <td><p>Global average pooling operation for temporal data.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_global_average_pooling_2d.html">layer_global_average_pooling_2d()</a></code> </p>
        </td>
        <td><p>Global average pooling operation for 2D data.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_global_average_pooling_3d.html">layer_global_average_pooling_3d()</a></code> </p>
        </td>
        <td><p>Global average pooling operation for 3D data.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_global_max_pooling_1d.html">layer_global_max_pooling_1d()</a></code> </p>
        </td>
        <td><p>Global max pooling operation for temporal data.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_global_max_pooling_2d.html">layer_global_max_pooling_2d()</a></code> </p>
        </td>
        <td><p>Global max pooling operation for 2D data.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_global_max_pooling_3d.html">layer_global_max_pooling_3d()</a></code> </p>
        </td>
        <td><p>Global max pooling operation for 3D data.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_group_normalization.html">layer_group_normalization()</a></code> </p>
        </td>
        <td><p>Group normalization layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_group_query_attention.html">layer_group_query_attention()</a></code> </p>
        </td>
        <td><p>Grouped Query Attention layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_gru.html">layer_gru()</a></code> </p>
        </td>
        <td><p>Gated Recurrent Unit - Cho et al. 2014.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_gru_cell.html">layer_gru_cell()</a></code> </p>
        </td>
        <td><p>Cell class for the GRU layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_hashed_crossing.html">layer_hashed_crossing()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which crosses features using the "hashing trick".</p></td>
      </tr><tr><td>
          <p><code><a href="layer_hashing.html">layer_hashing()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which hashes and bins categorical features.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_identity.html">layer_identity()</a></code> </p>
        </td>
        <td><p>Identity layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_input.html">layer_input()</a></code> </p>
        </td>
        <td><p>Used to instantiate a Keras tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_integer_lookup.html">layer_integer_lookup()</a></code> </p>
        </td>
        <td><p>A preprocessing layer that maps integers to (possibly encoded) indices.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_lambda.html">layer_lambda()</a></code> </p>
        </td>
        <td><p>Wraps arbitrary expressions as a <code>Layer</code> object.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_layer_normalization.html">layer_layer_normalization()</a></code> </p>
        </td>
        <td><p>Layer normalization layer (Ba et al., 2016).</p></td>
      </tr><tr><td>
          <p><code><a href="layer_lstm.html">layer_lstm()</a></code> </p>
        </td>
        <td><p>Long Short-Term Memory layer - Hochreiter 1997.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_lstm_cell.html">layer_lstm_cell()</a></code> </p>
        </td>
        <td><p>Cell class for the LSTM layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_masking.html">layer_masking()</a></code> </p>
        </td>
        <td><p>Masks a sequence by using a mask value to skip timesteps.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_max_pooling_1d.html">layer_max_pooling_1d()</a></code> </p>
        </td>
        <td><p>Max pooling operation for 1D temporal data.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_max_pooling_2d.html">layer_max_pooling_2d()</a></code> </p>
        </td>
        <td><p>Max pooling operation for 2D spatial data.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_max_pooling_3d.html">layer_max_pooling_3d()</a></code> </p>
        </td>
        <td><p>Max pooling operation for 3D data (spatial or spatio-temporal).</p></td>
      </tr><tr><td>
          <p><code><a href="layer_maximum.html">layer_maximum()</a></code> </p>
        </td>
        <td><p>Computes element-wise maximum on a list of inputs.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_minimum.html">layer_minimum()</a></code> </p>
        </td>
        <td><p>Computes elementwise minimum on a list of inputs.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_multi_head_attention.html">layer_multi_head_attention()</a></code> </p>
        </td>
        <td><p>MultiHeadAttention layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_multiply.html">layer_multiply()</a></code> </p>
        </td>
        <td><p>Performs elementwise multiplication.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_normalization.html">layer_normalization()</a></code> </p>
        </td>
        <td><p>A preprocessing layer that normalizes continuous features.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_permute.html">layer_permute()</a></code> </p>
        </td>
        <td><p>Permutes the dimensions of the input according to a given pattern.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_random_brightness.html">layer_random_brightness()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which randomly adjusts brightness during training.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_random_contrast.html">layer_random_contrast()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which randomly adjusts contrast during training.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_random_crop.html">layer_random_crop()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which randomly crops images during training.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_random_flip.html">layer_random_flip()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which randomly flips images during training.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_random_rotation.html">layer_random_rotation()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which randomly rotates images during training.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_random_translation.html">layer_random_translation()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which randomly translates images during training.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_random_zoom.html">layer_random_zoom()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which randomly zooms images during training.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_repeat_vector.html">layer_repeat_vector()</a></code> </p>
        </td>
        <td><p>Repeats the input n times.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_rescaling.html">layer_rescaling()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which rescales input values to a new range.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_reshape.html">layer_reshape()</a></code> </p>
        </td>
        <td><p>Layer that reshapes inputs into the given shape.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_resizing.html">layer_resizing()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which resizes images.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_rnn.html">layer_rnn()</a></code> </p>
        </td>
        <td><p>Base class for recurrent layers.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_separable_conv_1d.html">layer_separable_conv_1d()</a></code> </p>
        </td>
        <td><p>1D separable convolution layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_separable_conv_2d.html">layer_separable_conv_2d()</a></code> </p>
        </td>
        <td><p>2D separable convolution layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_simple_rnn.html">layer_simple_rnn()</a></code> </p>
        </td>
        <td><p>Fully-connected RNN where the output is to be fed back as the new input.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_simple_rnn_cell.html">layer_simple_rnn_cell()</a></code> </p>
        </td>
        <td><p>Cell class for SimpleRNN.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_spatial_dropout_1d.html">layer_spatial_dropout_1d()</a></code> </p>
        </td>
        <td><p>Spatial 1D version of Dropout.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_spatial_dropout_2d.html">layer_spatial_dropout_2d()</a></code> </p>
        </td>
        <td><p>Spatial 2D version of Dropout.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_spatial_dropout_3d.html">layer_spatial_dropout_3d()</a></code> </p>
        </td>
        <td><p>Spatial 3D version of Dropout.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_spectral_normalization.html">layer_spectral_normalization()</a></code> </p>
        </td>
        <td><p>Performs spectral normalization on the weights of a target layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_stacked_rnn_cells.html">layer_stacked_rnn_cells()</a></code> </p>
        </td>
        <td><p>Wrapper allowing a stack of RNN cells to behave as a single cell.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_string_lookup.html">layer_string_lookup()</a></code> </p>
        </td>
        <td><p>A preprocessing layer that maps strings to (possibly encoded) indices.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_subtract.html">layer_subtract()</a></code> </p>
        </td>
        <td><p>Performs elementwise subtraction.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_text_vectorization.html">layer_text_vectorization()</a></code> <code><a href="layer_text_vectorization.html">get_vocabulary()</a></code> <code><a href="layer_text_vectorization.html">set_vocabulary()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which maps text features to integer sequences.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_tfsm.html">layer_tfsm()</a></code> </p>
        </td>
        <td><p>Reload a Keras model/layer that was saved via SavedModel / ExportArchive.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_time_distributed.html">layer_time_distributed()</a></code> </p>
        </td>
        <td><p>This wrapper allows to apply a layer to every temporal slice of an input.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_torch_module_wrapper.html">layer_torch_module_wrapper()</a></code> </p>
        </td>
        <td><p>Torch module wrapper layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_unit_normalization.html">layer_unit_normalization()</a></code> </p>
        </td>
        <td><p>Unit normalization layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_upsampling_1d.html">layer_upsampling_1d()</a></code> </p>
        </td>
        <td><p>Upsampling layer for 1D inputs.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_upsampling_2d.html">layer_upsampling_2d()</a></code> </p>
        </td>
        <td><p>Upsampling layer for 2D inputs.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_upsampling_3d.html">layer_upsampling_3d()</a></code> </p>
        </td>
        <td><p>Upsampling layer for 3D inputs.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_zero_padding_1d.html">layer_zero_padding_1d()</a></code> </p>
        </td>
        <td><p>Zero-padding layer for 1D input (e.g. temporal sequence).</p></td>
      </tr><tr><td>
          <p><code><a href="layer_zero_padding_2d.html">layer_zero_padding_2d()</a></code> </p>
        </td>
        <td><p>Zero-padding layer for 2D input (e.g. picture).</p></td>
      </tr><tr><td>
          <p><code><a href="layer_zero_padding_3d.html">layer_zero_padding_3d()</a></code> </p>
        </td>
        <td><p>Zero-padding layer for 3D data (spatial or spatio-temporal).</p></td>
      </tr></tbody><tbody><tr><th colspan="2">
          <h2 id="random-tensor-generators">Random Tensor Generators <a href="#random-tensor-generators" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="random_categorical.html">random_categorical()</a></code> </p>
        </td>
        <td><p>Draws samples from a categorical distribution.</p></td>
      </tr><tr><td>
          <p><code><a href="random_dropout.html">random_dropout()</a></code> </p>
        </td>
        <td><p>random dropout</p></td>
      </tr><tr><td>
          <p><code><a href="random_integer.html">random_integer()</a></code> </p>
        </td>
        <td><p>Draw random integers from a uniform distribution.</p></td>
      </tr><tr><td>
          <p><code><a href="random_normal.html">random_normal()</a></code> </p>
        </td>
        <td><p>Draw random samples from a normal (Gaussian) distribution.</p></td>
      </tr><tr><td>
          <p><code><a href="random_seed_generator.html">random_seed_generator()</a></code> </p>
        </td>
        <td><p>Generates variable seeds upon each call to a RNG-using function.</p></td>
      </tr><tr><td>
          <p><code><a href="random_shuffle.html">random_shuffle()</a></code> </p>
        </td>
        <td><p>Shuffle the elements of a tensor uniformly at random along an axis.</p></td>
      </tr><tr><td>
          <p><code><a href="random_truncated_normal.html">random_truncated_normal()</a></code> </p>
        </td>
        <td><p>Draw samples from a truncated normal distribution.</p></td>
      </tr><tr><td>
          <p><code><a href="random_uniform.html">random_uniform()</a></code> </p>
        </td>
        <td><p>Draw samples from a uniform distribution.</p></td>
      </tr></tbody><tbody><tr><th colspan="2">
          <h2 id="operations">Operations <a href="#operations" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="k_abs.html">k_abs()</a></code> </p>
        </td>
        <td><p>Shorthand for <code>keras.ops.absolute</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_add.html">k_add()</a></code> </p>
        </td>
        <td><p>Add arguments element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_all.html">k_all()</a></code> </p>
        </td>
        <td><p>Test whether all array elements along a given axis evaluate to <code>TRUE</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_amax.html">k_amax()</a></code> </p>
        </td>
        <td><p>Returns the maximum of a vector or maximum value along an axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_amin.html">k_amin()</a></code> </p>
        </td>
        <td><p>Returns the minimum of a vector or minimum value along an axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_any.html">k_any()</a></code> </p>
        </td>
        <td><p>Test whether any array element along a given axis evaluates to <code>TRUE</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_append.html">k_append()</a></code> </p>
        </td>
        <td><p>Append tensor <code>x2</code> to the end of tensor <code>x1</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_arange.html">k_arange()</a></code> </p>
        </td>
        <td><p>Return evenly spaced values within a given interval.</p></td>
      </tr><tr><td>
          <p><code><a href="k_arccos.html">k_arccos()</a></code> </p>
        </td>
        <td><p>Trigonometric inverse cosine, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_arccosh.html">k_arccosh()</a></code> </p>
        </td>
        <td><p>Inverse hyperbolic cosine, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_arcsin.html">k_arcsin()</a></code> </p>
        </td>
        <td><p>Inverse sine, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_arcsinh.html">k_arcsinh()</a></code> </p>
        </td>
        <td><p>Inverse hyperbolic sine, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_arctan.html">k_arctan()</a></code> </p>
        </td>
        <td><p>Trigonometric inverse tangent, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_arctan2.html">k_arctan2()</a></code> </p>
        </td>
        <td><p>Element-wise arc tangent of <code>x1/x2</code> choosing the quadrant correctly.</p></td>
      </tr><tr><td>
          <p><code><a href="k_arctanh.html">k_arctanh()</a></code> </p>
        </td>
        <td><p>Inverse hyperbolic tangent, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_argmax.html">k_argmax()</a></code> </p>
        </td>
        <td><p>Returns the indices of the maximum values along an axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_argmin.html">k_argmin()</a></code> </p>
        </td>
        <td><p>Returns the indices of the minimum values along an axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_argsort.html">k_argsort()</a></code> </p>
        </td>
        <td><p>Returns the indices that would sort a tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_array.html">k_array()</a></code> </p>
        </td>
        <td><p>Create a tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_average.html">k_average()</a></code> </p>
        </td>
        <td><p>Compute the weighted average along the specified axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_average_pool.html">k_average_pool()</a></code> </p>
        </td>
        <td><p>Average pooling operation.</p></td>
      </tr><tr><td>
          <p><code><a href="k_binary_crossentropy.html">k_binary_crossentropy()</a></code> </p>
        </td>
        <td><p>Computes binary cross-entropy loss between target and output tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_bincount.html">k_bincount()</a></code> </p>
        </td>
        <td><p>Count the number of occurrences of each value in a tensor of integers.</p></td>
      </tr><tr><td>
          <p><code><a href="k_broadcast_to.html">k_broadcast_to()</a></code> </p>
        </td>
        <td><p>Broadcast a tensor to a new shape.</p></td>
      </tr><tr><td>
          <p><code><a href="k_cast.html">k_cast()</a></code> </p>
        </td>
        <td><p>Cast a tensor to the desired dtype.</p></td>
      </tr><tr><td>
          <p><code><a href="k_categorical_crossentropy.html">k_categorical_crossentropy()</a></code> </p>
        </td>
        <td><p>Computes categorical cross-entropy loss between target and output tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_ceil.html">k_ceil()</a></code> </p>
        </td>
        <td><p>Return the ceiling of the input, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_clip.html">k_clip()</a></code> </p>
        </td>
        <td><p>Clip (limit) the values in a tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_concatenate.html">k_concatenate()</a></code> </p>
        </td>
        <td><p>Join a sequence of tensors along an existing axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_cond.html">k_cond()</a></code> </p>
        </td>
        <td><p>Conditionally applies <code>true_fn</code> or <code>false_fn</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_conj.html">k_conj()</a></code> </p>
        </td>
        <td><p>Shorthand for <code>keras.ops.conjugate</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_conjugate.html">k_conjugate()</a></code> </p>
        </td>
        <td><p>Returns the complex conjugate, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_conv.html">k_conv()</a></code> </p>
        </td>
        <td><p>General N-D convolution.</p></td>
      </tr><tr><td>
          <p><code><a href="k_conv_transpose.html">k_conv_transpose()</a></code> </p>
        </td>
        <td><p>General N-D convolution transpose.</p></td>
      </tr><tr><td>
          <p><code><a href="k_convert_to_numpy.html">k_convert_to_numpy()</a></code> </p>
        </td>
        <td><p>Convert a tensor to a NumPy array.</p></td>
      </tr><tr><td>
          <p><code><a href="k_convert_to_tensor.html">k_convert_to_tensor()</a></code> </p>
        </td>
        <td><p>Convert an array to a tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_copy.html">k_copy()</a></code> </p>
        </td>
        <td><p>Returns a copy of <code>x</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_cos.html">k_cos()</a></code> </p>
        </td>
        <td><p>Cosine, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_cosh.html">k_cosh()</a></code> </p>
        </td>
        <td><p>Hyperbolic cosine, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_count_nonzero.html">k_count_nonzero()</a></code> </p>
        </td>
        <td><p>Counts the number of non-zero values in <code>x</code> along the given <code>axis</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_cross.html">k_cross()</a></code> </p>
        </td>
        <td><p>Returns the cross product of two (arrays of) vectors.</p></td>
      </tr><tr><td>
          <p><code><a href="k_cumprod.html">k_cumprod()</a></code> </p>
        </td>
        <td><p>Return the cumulative product of elements along a given axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_cumsum.html">k_cumsum()</a></code> </p>
        </td>
        <td><p>Returns the cumulative sum of elements along a given axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_depthwise_conv.html">k_depthwise_conv()</a></code> </p>
        </td>
        <td><p>General N-D depthwise convolution.</p></td>
      </tr><tr><td>
          <p><code><a href="k_diag.html">k_diag()</a></code> </p>
        </td>
        <td><p>Extract a diagonal or construct a diagonal array.</p></td>
      </tr><tr><td>
          <p><code><a href="k_diagonal.html">k_diagonal()</a></code> </p>
        </td>
        <td><p>Return specified diagonals.</p></td>
      </tr><tr><td>
          <p><code><a href="k_diff.html">k_diff()</a></code> </p>
        </td>
        <td><p>Calculate the n-th discrete difference along the given axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_digitize.html">k_digitize()</a></code> </p>
        </td>
        <td><p>Returns the indices of the bins to which each value in <code>x</code> belongs.</p></td>
      </tr><tr><td>
          <p><code><a href="k_divide.html">k_divide()</a></code> </p>
        </td>
        <td><p>Divide arguments element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_dot.html">k_dot()</a></code> </p>
        </td>
        <td><p>Dot product of two tensors.</p></td>
      </tr><tr><td>
          <p><code><a href="k_einsum.html">k_einsum()</a></code> </p>
        </td>
        <td><p>Evaluates the Einstein summation convention on the operands.</p></td>
      </tr><tr><td>
          <p><code><a href="k_elu.html">k_elu()</a></code> </p>
        </td>
        <td><p>Exponential Linear Unit activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="k_empty.html">k_empty()</a></code> </p>
        </td>
        <td><p>Return a tensor of given shape and type filled with uninitialized data.</p></td>
      </tr><tr><td>
          <p><code><a href="k_equal.html">k_equal()</a></code> </p>
        </td>
        <td><p>Returns <code>(x1 == x2)</code> element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_erf.html">k_erf()</a></code> </p>
        </td>
        <td><p>Computes the error function of <code>x</code>, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_exp.html">k_exp()</a></code> </p>
        </td>
        <td><p>Calculate the exponential of all elements in the input tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_expand_dims.html">k_expand_dims()</a></code> </p>
        </td>
        <td><p>Expand the shape of a tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_expm1.html">k_expm1()</a></code> </p>
        </td>
        <td><p>Calculate <code>exp(x) - 1</code> for all elements in the tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_extract_sequences.html">k_extract_sequences()</a></code> </p>
        </td>
        <td><p>Expands the dimension of last axis into sequences of <code>sequence_length</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_eye.html">k_eye()</a></code> </p>
        </td>
        <td><p>Return a 2-D tensor with ones on the diagonal and zeros elsewhere.</p></td>
      </tr><tr><td>
          <p><code><a href="k_fft.html">k_fft()</a></code> </p>
        </td>
        <td><p>Computes the Fast Fourier Transform along last axis of input.</p></td>
      </tr><tr><td>
          <p><code><a href="k_fft2.html">k_fft2()</a></code> </p>
        </td>
        <td><p>Computes the 2D Fast Fourier Transform along the last two axes of input.</p></td>
      </tr><tr><td>
          <p><code><a href="k_flip.html">k_flip()</a></code> </p>
        </td>
        <td><p>Reverse the order of elements in the tensor along the given axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_floatx.html">k_floatx()</a></code> </p>
        </td>
        <td><p>Return the default float type, as a string.</p></td>
      </tr><tr><td>
          <p><code><a href="k_floor.html">k_floor()</a></code> </p>
        </td>
        <td><p>Return the floor of the input, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_floor_divide.html">k_floor_divide()</a></code> </p>
        </td>
        <td><p>Returns the largest integer smaller or equal to the division of inputs.</p></td>
      </tr><tr><td>
          <p><code><a href="k_fori_loop.html">k_fori_loop()</a></code> </p>
        </td>
        <td><p>For loop implementation.</p></td>
      </tr><tr><td>
          <p><code><a href="k_full.html">k_full()</a></code> </p>
        </td>
        <td><p>Return a new tensor of given shape and type, filled with <code>fill_value</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_full_like.html">k_full_like()</a></code> </p>
        </td>
        <td><p>Return a full tensor with the same shape and type as the given tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_gelu.html">k_gelu()</a></code> </p>
        </td>
        <td><p>Gaussian Error Linear Unit (GELU) activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="k_get_item.html">k_get_item()</a></code> </p>
        </td>
        <td><p>Return <code>x[key]</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_greater.html">k_greater()</a></code> </p>
        </td>
        <td><p>Return the truth value of <code>x1 &gt; x2</code> element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_greater_equal.html">k_greater_equal()</a></code> </p>
        </td>
        <td><p>Return the truth value of <code>x1 &gt;= x2</code> element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_hard_sigmoid.html">k_hard_sigmoid()</a></code> </p>
        </td>
        <td><p>Hard sigmoid activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="k_hstack.html">k_hstack()</a></code> </p>
        </td>
        <td><p>Stack tensors in sequence horizontally (column wise).</p></td>
      </tr><tr><td>
          <p><code><a href="k_identity.html">k_identity()</a></code> </p>
        </td>
        <td><p>Return the identity tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_imag.html">k_imag()</a></code> </p>
        </td>
        <td><p>Return the imaginary part of the complex argument.</p></td>
      </tr><tr><td>
          <p><code><a href="k_image_affine_transform.html">k_image_affine_transform()</a></code> </p>
        </td>
        <td><p>Applies the given transform(s) to the image(s).</p></td>
      </tr><tr><td>
          <p><code><a href="k_image_extract_patches.html">k_image_extract_patches()</a></code> </p>
        </td>
        <td><p>Extracts patches from the image(s).</p></td>
      </tr><tr><td>
          <p><code><a href="k_image_map_coordinates.html">k_image_map_coordinates()</a></code> </p>
        </td>
        <td><p>Map the input array to new coordinates by interpolation..</p></td>
      </tr><tr><td>
          <p><code><a href="k_image_pad_images.html">k_image_pad_images()</a></code> </p>
        </td>
        <td><p>Pad <code>images</code> with zeros to the specified <code>height</code> and <code>width</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_image_resize.html">k_image_resize()</a></code> </p>
        </td>
        <td><p>Resize images to size using the specified interpolation method.</p></td>
      </tr><tr><td>
          <p><code><a href="k_in_top_k.html">k_in_top_k()</a></code> </p>
        </td>
        <td><p>Checks if the targets are in the top-k predictions.</p></td>
      </tr><tr><td>
          <p><code><a href="k_irfft.html">k_irfft()</a></code> </p>
        </td>
        <td><p>Inverse real-valued Fast Fourier transform along the last axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_isclose.html">k_isclose()</a></code> </p>
        </td>
        <td><p>Return whether two tensors are element-wise almost equal.</p></td>
      </tr><tr><td>
          <p><code><a href="k_isfinite.html">k_isfinite()</a></code> </p>
        </td>
        <td><p>Return whether a tensor is finite, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_isinf.html">k_isinf()</a></code> </p>
        </td>
        <td><p>Test element-wise for positive or negative infinity.</p></td>
      </tr><tr><td>
          <p><code><a href="k_isnan.html">k_isnan()</a></code> </p>
        </td>
        <td><p>Test element-wise for NaN and return result as a boolean tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_istft.html">k_istft()</a></code> </p>
        </td>
        <td><p>Inverse Short-Time Fourier Transform along the last axis of the input.</p></td>
      </tr><tr><td>
          <p><code><a href="k_leaky_relu.html">k_leaky_relu()</a></code> </p>
        </td>
        <td><p>Leaky version of a Rectified Linear Unit activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="k_less.html">k_less()</a></code> </p>
        </td>
        <td><p>Return the truth value of <code>x1 &lt; x2</code> element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_less_equal.html">k_less_equal()</a></code> </p>
        </td>
        <td><p>Return the truth value of <code>x1 &lt;= x2</code> element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_linspace.html">k_linspace()</a></code> </p>
        </td>
        <td><p>Return evenly spaced numbers over a specified interval.</p></td>
      </tr><tr><td>
          <p><code><a href="k_log.html">k_log()</a></code> </p>
        </td>
        <td><p>Natural logarithm, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_log10.html">k_log10()</a></code> </p>
        </td>
        <td><p>Return the base 10 logarithm of the input tensor, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_log1p.html">k_log1p()</a></code> </p>
        </td>
        <td><p>Returns the natural logarithm of one plus the <code>x</code>, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_log2.html">k_log2()</a></code> </p>
        </td>
        <td><p>Base-2 logarithm of <code>x</code>, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_log_sigmoid.html">k_log_sigmoid()</a></code> </p>
        </td>
        <td><p>Logarithm of the sigmoid activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="k_log_softmax.html">k_log_softmax()</a></code> </p>
        </td>
        <td><p>Log-softmax activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="k_logaddexp.html">k_logaddexp()</a></code> </p>
        </td>
        <td><p>Logarithm of the sum of exponentiations of the inputs.</p></td>
      </tr><tr><td>
          <p><code><a href="k_logical_and.html">k_logical_and()</a></code> </p>
        </td>
        <td><p>Computes the element-wise logical AND of the given input tensors.</p></td>
      </tr><tr><td>
          <p><code><a href="k_logical_not.html">k_logical_not()</a></code> </p>
        </td>
        <td><p>Computes the element-wise NOT of the given input tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_logical_or.html">k_logical_or()</a></code> </p>
        </td>
        <td><p>Computes the element-wise logical OR of the given input tensors.</p></td>
      </tr><tr><td>
          <p><code><a href="k_logical_xor.html">k_logical_xor()</a></code> </p>
        </td>
        <td><p>Compute the truth value of <code>x1 XOR x2</code>, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_logspace.html">k_logspace()</a></code> </p>
        </td>
        <td><p>Returns numbers spaced evenly on a log scale.</p></td>
      </tr><tr><td>
          <p><code><a href="k_logsumexp.html">k_logsumexp()</a></code> </p>
        </td>
        <td><p>Computes the logarithm of sum of exponentials of elements in a tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_matmul.html">k_matmul()</a></code> </p>
        </td>
        <td><p>Matrix product of two tensors.</p></td>
      </tr><tr><td>
          <p><code><a href="k_max.html">k_max()</a></code> </p>
        </td>
        <td><p>Return the maximum of a tensor or maximum along an axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_max_pool.html">k_max_pool()</a></code> </p>
        </td>
        <td><p>Max pooling operation.</p></td>
      </tr><tr><td>
          <p><code><a href="k_maximum.html">k_maximum()</a></code> </p>
        </td>
        <td><p>Element-wise maximum of <code>x1</code> and <code>x2</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_mean.html">k_mean()</a></code> </p>
        </td>
        <td><p>Compute the arithmetic mean along the specified axes.</p></td>
      </tr><tr><td>
          <p><code><a href="k_median.html">k_median()</a></code> </p>
        </td>
        <td><p>Compute the median along the specified axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_meshgrid.html">k_meshgrid()</a></code> </p>
        </td>
        <td><p>Creates grids of coordinates from coordinate vectors.</p></td>
      </tr><tr><td>
          <p><code><a href="k_min.html">k_min()</a></code> </p>
        </td>
        <td><p>Return the minimum of a tensor or minimum along an axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_minimum.html">k_minimum()</a></code> </p>
        </td>
        <td><p>Element-wise minimum of <code>x1</code> and <code>x2</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_mod.html">k_mod()</a></code> </p>
        </td>
        <td><p>Returns the element-wise remainder of division.</p></td>
      </tr><tr><td>
          <p><code><a href="k_moments.html">k_moments()</a></code> </p>
        </td>
        <td><p>Calculates the mean and variance of <code>x</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_moveaxis.html">k_moveaxis()</a></code> </p>
        </td>
        <td><p>Move axes of a tensor to new positions.</p></td>
      </tr><tr><td>
          <p><code><a href="k_multi_hot.html">k_multi_hot()</a></code> </p>
        </td>
        <td><p>Encodes integer labels as multi-hot vectors.</p></td>
      </tr><tr><td>
          <p><code><a href="k_multiply.html">k_multiply()</a></code> </p>
        </td>
        <td><p>Multiply arguments element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_nan_to_num.html">k_nan_to_num()</a></code> </p>
        </td>
        <td><p>Replace NaN with zero and infinity with large finite numbers.</p></td>
      </tr><tr><td>
          <p><code><a href="k_ndim.html">k_ndim()</a></code> </p>
        </td>
        <td><p>Return the number of dimensions of a tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_negative.html">k_negative()</a></code> </p>
        </td>
        <td><p>Numerical negative, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_nonzero.html">k_nonzero()</a></code> </p>
        </td>
        <td><p>Return the indices of the elements that are non-zero.</p></td>
      </tr><tr><td>
          <p><code><a href="k_not_equal.html">k_not_equal()</a></code> </p>
        </td>
        <td><p>Return <code>(x1 != x2)</code> element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_one_hot.html">k_one_hot()</a></code> </p>
        </td>
        <td><p>Converts integer tensor <code>x</code> into a one-hot tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_ones.html">k_ones()</a></code> </p>
        </td>
        <td><p>Return a new tensor of given shape and type, filled with ones.</p></td>
      </tr><tr><td>
          <p><code><a href="k_ones_like.html">k_ones_like()</a></code> </p>
        </td>
        <td><p>Return a tensor of ones with the same shape and type of <code>x</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_outer.html">k_outer()</a></code> </p>
        </td>
        <td><p>Compute the outer product of two vectors.</p></td>
      </tr><tr><td>
          <p><code><a href="k_pad.html">k_pad()</a></code> </p>
        </td>
        <td><p>Pad a tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_power.html">k_power()</a></code> </p>
        </td>
        <td><p>First tensor elements raised to powers from second tensor, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_prod.html">k_prod()</a></code> </p>
        </td>
        <td><p>Return the product of tensor elements over a given axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_qr.html">k_qr()</a></code> </p>
        </td>
        <td><p>Computes the QR decomposition of a tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_quantile.html">k_quantile()</a></code> </p>
        </td>
        <td><p>Compute the q-th quantile(s) of the data along the specified axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_ravel.html">k_ravel()</a></code> </p>
        </td>
        <td><p>Return a contiguous flattened tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_real.html">k_real()</a></code> </p>
        </td>
        <td><p>Return the real part of the complex argument.</p></td>
      </tr><tr><td>
          <p><code><a href="k_reciprocal.html">k_reciprocal()</a></code> </p>
        </td>
        <td><p>Return the reciprocal of the argument, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_relu.html">k_relu()</a></code> </p>
        </td>
        <td><p>Rectified linear unit activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="k_relu6.html">k_relu6()</a></code> </p>
        </td>
        <td><p>Rectified linear unit activation function with upper bound of 6.</p></td>
      </tr><tr><td>
          <p><code><a href="k_repeat.html">k_repeat()</a></code> </p>
        </td>
        <td><p>Repeat each element of a tensor after themselves.</p></td>
      </tr><tr><td>
          <p><code><a href="k_reshape.html">k_reshape()</a></code> </p>
        </td>
        <td><p>Gives a new shape to a tensor without changing its data.</p></td>
      </tr><tr><td>
          <p><code><a href="k_rfft.html">k_rfft()</a></code> </p>
        </td>
        <td><p>Real-valued Fast Fourier Transform along the last axis of the input.</p></td>
      </tr><tr><td>
          <p><code><a href="k_roll.html">k_roll()</a></code> </p>
        </td>
        <td><p>Roll tensor elements along a given axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_round.html">k_round()</a></code> </p>
        </td>
        <td><p>Evenly round to the given number of decimals.</p></td>
      </tr><tr><td>
          <p><code><a href="k_rsqrt.html">k_rsqrt()</a></code> </p>
        </td>
        <td><p>Computes reciprocal of square root of x element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_scatter.html">k_scatter()</a></code> </p>
        </td>
        <td><p>Returns a tensor of shape <code>shape</code> where <code>indices</code> are set to <code>values</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_scatter_update.html">k_scatter_update()</a></code> </p>
        </td>
        <td><p>Update inputs via updates at scattered (sparse) indices.</p></td>
      </tr><tr><td>
          <p><code><a href="k_segment_max.html">k_segment_max()</a></code> </p>
        </td>
        <td><p>Computes the max of segments in a tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_segment_sum.html">k_segment_sum()</a></code> </p>
        </td>
        <td><p>Computes the sum of segments in a tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_selu.html">k_selu()</a></code> </p>
        </td>
        <td><p>Scaled Exponential Linear Unit (SELU) activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="k_separable_conv.html">k_separable_conv()</a></code> </p>
        </td>
        <td><p>General N-D separable convolution.</p></td>
      </tr><tr><td>
          <p><code><a href="k_shape.html">k_shape()</a></code> </p>
        </td>
        <td><p>Gets the shape of the tensor input.</p></td>
      </tr><tr><td>
          <p><code><a href="k_sigmoid.html">k_sigmoid()</a></code> </p>
        </td>
        <td><p>Sigmoid activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="k_sign.html">k_sign()</a></code> </p>
        </td>
        <td><p>Returns a tensor with the signs of the elements of <code>x</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_silu.html">k_silu()</a></code> </p>
        </td>
        <td><p>Sigmoid Linear Unit (SiLU) activation function, also known as Swish.</p></td>
      </tr><tr><td>
          <p><code><a href="k_sin.html">k_sin()</a></code> </p>
        </td>
        <td><p>Trigonomeric sine, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_sinh.html">k_sinh()</a></code> </p>
        </td>
        <td><p>Hyperbolic sine, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_size.html">k_size()</a></code> </p>
        </td>
        <td><p>Return the number of elements in a tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_slice.html">k_slice()</a></code> </p>
        </td>
        <td><p>Return a slice of an input tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_slice_update.html">k_slice_update()</a></code> </p>
        </td>
        <td><p>Update an input by slicing in a tensor of updated values.</p></td>
      </tr><tr><td>
          <p><code><a href="k_softmax.html">k_softmax()</a></code> </p>
        </td>
        <td><p>Softmax activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="k_softplus.html">k_softplus()</a></code> </p>
        </td>
        <td><p>Softplus activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="k_softsign.html">k_softsign()</a></code> </p>
        </td>
        <td><p>Softsign activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="k_solve.html">k_solve()</a></code> </p>
        </td>
        <td><p>Solves for <code>x</code> in the equation <code>a * x = b</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_sort.html">k_sort()</a></code> </p>
        </td>
        <td><p>Sorts the elements of <code>x</code> along a given axis in ascending order.</p></td>
      </tr><tr><td>
          <p><code><a href="k_sparse_categorical_crossentropy.html">k_sparse_categorical_crossentropy()</a></code> </p>
        </td>
        <td><p>Computes sparse categorical cross-entropy loss.</p></td>
      </tr><tr><td>
          <p><code><a href="k_split.html">k_split()</a></code> </p>
        </td>
        <td><p>Split a tensor into chunks.</p></td>
      </tr><tr><td>
          <p><code><a href="k_sqrt.html">k_sqrt()</a></code> </p>
        </td>
        <td><p>Return the non-negative square root of a tensor, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_square.html">k_square()</a></code> </p>
        </td>
        <td><p>Return the element-wise square of the input.</p></td>
      </tr><tr><td>
          <p><code><a href="k_squeeze.html">k_squeeze()</a></code> </p>
        </td>
        <td><p>Remove axes of length one from <code>x</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_stack.html">k_stack()</a></code> </p>
        </td>
        <td><p>Join a sequence of tensors along a new axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_std.html">k_std()</a></code> </p>
        </td>
        <td><p>Compute the standard deviation along the specified axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_stft.html">k_stft()</a></code> </p>
        </td>
        <td><p>Short-Time Fourier Transform along the last axis of the input.</p></td>
      </tr><tr><td>
          <p><code><a href="k_stop_gradient.html">k_stop_gradient()</a></code> </p>
        </td>
        <td><p>Stops gradient computation.</p></td>
      </tr><tr><td>
          <p><code><a href="k_subtract.html">k_subtract()</a></code> </p>
        </td>
        <td><p>Subtract arguments element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_sum.html">k_sum()</a></code> </p>
        </td>
        <td><p>Sum of a tensor over the given axes.</p></td>
      </tr><tr><td>
          <p><code><a href="k_swapaxes.html">k_swapaxes()</a></code> </p>
        </td>
        <td><p>Interchange two axes of a tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_take.html">k_take()</a></code> </p>
        </td>
        <td><p>Take elements from a tensor along an axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_take_along_axis.html">k_take_along_axis()</a></code> </p>
        </td>
        <td><p>Select values from <code>x</code> at the 1-D <code>indices</code> along the given axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_tan.html">k_tan()</a></code> </p>
        </td>
        <td><p>Compute tangent, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_tanh.html">k_tanh()</a></code> </p>
        </td>
        <td><p>Hyperbolic tangent, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_tensordot.html">k_tensordot()</a></code> </p>
        </td>
        <td><p>Compute the tensor dot product along specified axes.</p></td>
      </tr><tr><td>
          <p><code><a href="k_tile.html">k_tile()</a></code> </p>
        </td>
        <td><p>Repeat <code>x</code> the number of times given by <code>repeats</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_top_k.html">k_top_k()</a></code> </p>
        </td>
        <td><p>Finds the top-k values and their indices in a tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_trace.html">k_trace()</a></code> </p>
        </td>
        <td><p>Return the sum along diagonals of the tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_transpose.html">k_transpose()</a></code> </p>
        </td>
        <td><p>Returns a tensor with <code>axes</code> transposed.</p></td>
      </tr><tr><td>
          <p><code><a href="k_tri.html">k_tri()</a></code> </p>
        </td>
        <td><p>Return a tensor with ones at and below a diagonal and zeros elsewhere.</p></td>
      </tr><tr><td>
          <p><code><a href="k_tril.html">k_tril()</a></code> </p>
        </td>
        <td><p>Return lower triangle of a tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_triu.html">k_triu()</a></code> </p>
        </td>
        <td><p>Return upper triangle of a tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_true_divide.html">k_true_divide()</a></code> </p>
        </td>
        <td><p>Alias for <code>keras.ops.divide</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_unstack.html">k_unstack()</a></code> </p>
        </td>
        <td><p>Unpacks the given dimension of a rank-R tensor into rank-(R-1) tensors.</p></td>
      </tr><tr><td>
          <p><code><a href="k_var.html">k_var()</a></code> </p>
        </td>
        <td><p>Compute the variance along the specified axes.</p></td>
      </tr><tr><td>
          <p><code><a href="k_vdot.html">k_vdot()</a></code> </p>
        </td>
        <td><p>Return the dot product of two vectors.</p></td>
      </tr><tr><td>
          <p><code><a href="k_vectorized_map.html">k_vectorized_map()</a></code> </p>
        </td>
        <td><p>Parallel map of <code>function</code> on axis 0 of tensor(s) <code>elements</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_vstack.html">k_vstack()</a></code> </p>
        </td>
        <td><p>Stack tensors in sequence vertically (row wise).</p></td>
      </tr><tr><td>
          <p><code><a href="k_where.html">k_where()</a></code> </p>
        </td>
        <td><p>Return elements chosen from <code>x1</code> or <code>x2</code> depending on <code>condition</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_while_loop.html">k_while_loop()</a></code> </p>
        </td>
        <td><p>While loop implementation.</p></td>
      </tr><tr><td>
          <p><code><a href="k_zeros.html">k_zeros()</a></code> </p>
        </td>
        <td><p>Return a new tensor of given shape and type, filled with zeros.</p></td>
      </tr><tr><td>
          <p><code><a href="k_zeros_like.html">k_zeros_like()</a></code> </p>
        </td>
        <td><p>Return a tensor of zeros with the same shape and type as <code>x</code>.</p></td>
      </tr></tbody><tbody><tr><th colspan="2">
          <h2 id="configuration">Configuration <a href="#configuration" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="config_backend.html">config_backend()</a></code> </p>
        </td>
        <td><p>Publicly accessible method for determining the current backend.</p></td>
      </tr><tr><td>
          <p><code><a href="config_disable_interactive_logging.html">config_disable_interactive_logging()</a></code> </p>
        </td>
        <td><p>Turn off interactive logging.</p></td>
      </tr><tr><td>
          <p><code><a href="config_disable_traceback_filtering.html">config_disable_traceback_filtering()</a></code> </p>
        </td>
        <td><p>Turn off traceback filtering.</p></td>
      </tr><tr><td>
          <p><code><a href="config_enable_interactive_logging.html">config_enable_interactive_logging()</a></code> </p>
        </td>
        <td><p>Turn on interactive logging.</p></td>
      </tr><tr><td>
          <p><code><a href="config_enable_traceback_filtering.html">config_enable_traceback_filtering()</a></code> </p>
        </td>
        <td><p>Turn on traceback filtering.</p></td>
      </tr><tr><td>
          <p><code><a href="config_enable_unsafe_deserialization.html">config_enable_unsafe_deserialization()</a></code> </p>
        </td>
        <td><p>Disables safe mode globally, allowing deserialization of lambdas.</p></td>
      </tr><tr><td>
          <p><code><a href="config_epsilon.html">config_epsilon()</a></code> </p>
        </td>
        <td><p>Return the value of the fuzz factor used in numeric expressions.</p></td>
      </tr><tr><td>
          <p><code><a href="config_floatx.html">config_floatx()</a></code> </p>
        </td>
        <td><p>Return the default float type, as a string.</p></td>
      </tr><tr><td>
          <p><code><a href="config_image_data_format.html">config_image_data_format()</a></code> </p>
        </td>
        <td><p>Return the default image data format convention.</p></td>
      </tr><tr><td>
          <p><code><a href="config_is_interactive_logging_enabled.html">config_is_interactive_logging_enabled()</a></code> </p>
        </td>
        <td><p>Check if interactive logging is enabled.</p></td>
      </tr><tr><td>
          <p><code><a href="config_is_traceback_filtering_enabled.html">config_is_traceback_filtering_enabled()</a></code> </p>
        </td>
        <td><p>Check if traceback filtering is enabled.</p></td>
      </tr><tr><td>
          <p><code><a href="config_set_epsilon.html">config_set_epsilon()</a></code> </p>
        </td>
        <td><p>Set the value of the fuzz factor used in numeric expressions.</p></td>
      </tr><tr><td>
          <p><code><a href="config_set_floatx.html">config_set_floatx()</a></code> </p>
        </td>
        <td><p>Set the default float dtype.</p></td>
      </tr><tr><td>
          <p><code><a href="config_set_image_data_format.html">config_set_image_data_format()</a></code> </p>
        </td>
        <td><p>Set the value of the image data format convention.</p></td>
      </tr></tbody><tbody><tr><th colspan="2">
          <h2 id="python">Python <a href="#python" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="keras.html">keras</a></code> </p>
        </td>
        <td><p>Main Keras module</p></td>
      </tr><tr><td>
          <p><code><a href="grapes-py_class-grapes.html">`%py_class%`</a></code> </p>
        </td>
        <td><p>Make a python class constructor</p></td>
      </tr><tr><td>
          <p><code><a href="grapes-set-active-grapes.html">`%&lt;-active%`</a></code> </p>
        </td>
        <td><p>Make an Active Binding</p></td>
      </tr></tbody><tbody><tr><th colspan="2">
          <h2 id="catchall">Catchall <a href="#catchall" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="activation_elu.html">activation_elu()</a></code> </p>
        </td>
        <td><p>Exponential Linear Unit.</p></td>
      </tr><tr><td>
          <p><code><a href="activation_exponential.html">activation_exponential()</a></code> </p>
        </td>
        <td><p>Exponential activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="activation_gelu.html">activation_gelu()</a></code> </p>
        </td>
        <td><p>Gaussian error linear unit (GELU) activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="activation_hard_sigmoid.html">activation_hard_sigmoid()</a></code> </p>
        </td>
        <td><p>Hard sigmoid activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="activation_leaky_relu.html">activation_leaky_relu()</a></code> </p>
        </td>
        <td><p>Leaky relu activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="activation_linear.html">activation_linear()</a></code> </p>
        </td>
        <td><p>Linear activation function (pass-through).</p></td>
      </tr><tr><td>
          <p><code><a href="activation_log_softmax.html">activation_log_softmax()</a></code> </p>
        </td>
        <td><p>Log-Softmax activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="activation_mish.html">activation_mish()</a></code> </p>
        </td>
        <td><p>Mish activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="activation_relu.html">activation_relu()</a></code> </p>
        </td>
        <td><p>Applies the rectified linear unit activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="activation_relu6.html">activation_relu6()</a></code> </p>
        </td>
        <td><p>Relu6 activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="activation_selu.html">activation_selu()</a></code> </p>
        </td>
        <td><p>Scaled Exponential Linear Unit (SELU).</p></td>
      </tr><tr><td>
          <p><code><a href="activation_sigmoid.html">activation_sigmoid()</a></code> </p>
        </td>
        <td><p>Sigmoid activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="activation_silu.html">activation_silu()</a></code> </p>
        </td>
        <td><p>Swish (or Silu) activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="activation_softmax.html">activation_softmax()</a></code> </p>
        </td>
        <td><p>Softmax converts a vector of values to a probability distribution.</p></td>
      </tr><tr><td>
          <p><code><a href="activation_softplus.html">activation_softplus()</a></code> </p>
        </td>
        <td><p>Softplus activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="activation_softsign.html">activation_softsign()</a></code> </p>
        </td>
        <td><p>Softsign activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="activation_tanh.html">activation_tanh()</a></code> </p>
        </td>
        <td><p>Hyperbolic tangent activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="adapt.html">adapt()</a></code> </p>
        </td>
        <td><p>Fits the state of the preprocessing layer to the data being passed</p></td>
      </tr><tr><td>
          <p><code><a href="application_convnext_base.html">application_convnext_base()</a></code> </p>
        </td>
        <td><p>Instantiates the ConvNeXtBase architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_convnext_large.html">application_convnext_large()</a></code> </p>
        </td>
        <td><p>Instantiates the ConvNeXtLarge architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_convnext_small.html">application_convnext_small()</a></code> </p>
        </td>
        <td><p>Instantiates the ConvNeXtSmall architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_convnext_tiny.html">application_convnext_tiny()</a></code> </p>
        </td>
        <td><p>Instantiates the ConvNeXtTiny architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_convnext_xlarge.html">application_convnext_xlarge()</a></code> </p>
        </td>
        <td><p>Instantiates the ConvNeXtXLarge architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_densenet121.html">application_densenet121()</a></code> </p>
        </td>
        <td><p>Instantiates the Densenet121 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_densenet169.html">application_densenet169()</a></code> </p>
        </td>
        <td><p>Instantiates the Densenet169 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_densenet201.html">application_densenet201()</a></code> </p>
        </td>
        <td><p>Instantiates the Densenet201 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_efficientnet_b0.html">application_efficientnet_b0()</a></code> </p>
        </td>
        <td><p>Instantiates the EfficientNetB0 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_efficientnet_b1.html">application_efficientnet_b1()</a></code> </p>
        </td>
        <td><p>Instantiates the EfficientNetB1 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_efficientnet_b2.html">application_efficientnet_b2()</a></code> </p>
        </td>
        <td><p>Instantiates the EfficientNetB2 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_efficientnet_b3.html">application_efficientnet_b3()</a></code> </p>
        </td>
        <td><p>Instantiates the EfficientNetB3 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_efficientnet_b4.html">application_efficientnet_b4()</a></code> </p>
        </td>
        <td><p>Instantiates the EfficientNetB4 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_efficientnet_b5.html">application_efficientnet_b5()</a></code> </p>
        </td>
        <td><p>Instantiates the EfficientNetB5 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_efficientnet_b6.html">application_efficientnet_b6()</a></code> </p>
        </td>
        <td><p>Instantiates the EfficientNetB6 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_efficientnet_b7.html">application_efficientnet_b7()</a></code> </p>
        </td>
        <td><p>Instantiates the EfficientNetB7 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_efficientnet_v2b0.html">application_efficientnet_v2b0()</a></code> </p>
        </td>
        <td><p>Instantiates the EfficientNetV2B0 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_efficientnet_v2b1.html">application_efficientnet_v2b1()</a></code> </p>
        </td>
        <td><p>Instantiates the EfficientNetV2B1 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_efficientnet_v2b2.html">application_efficientnet_v2b2()</a></code> </p>
        </td>
        <td><p>Instantiates the EfficientNetV2B2 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_efficientnet_v2b3.html">application_efficientnet_v2b3()</a></code> </p>
        </td>
        <td><p>Instantiates the EfficientNetV2B3 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_efficientnet_v2l.html">application_efficientnet_v2l()</a></code> </p>
        </td>
        <td><p>Instantiates the EfficientNetV2L architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_efficientnet_v2m.html">application_efficientnet_v2m()</a></code> </p>
        </td>
        <td><p>Instantiates the EfficientNetV2M architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_efficientnet_v2s.html">application_efficientnet_v2s()</a></code> </p>
        </td>
        <td><p>Instantiates the EfficientNetV2S architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_inception_resnet_v2.html">application_inception_resnet_v2()</a></code> </p>
        </td>
        <td><p>Instantiates the Inception-ResNet v2 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_inception_v3.html">application_inception_v3()</a></code> </p>
        </td>
        <td><p>Instantiates the Inception v3 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_mobilenet.html">application_mobilenet()</a></code> </p>
        </td>
        <td><p>Instantiates the MobileNet architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_mobilenet_v2.html">application_mobilenet_v2()</a></code> </p>
        </td>
        <td><p>Instantiates the MobileNetV2 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_mobilenet_v3_large.html">application_mobilenet_v3_large()</a></code> </p>
        </td>
        <td><p>Instantiates the MobileNetV3Large architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_mobilenet_v3_small.html">application_mobilenet_v3_small()</a></code> </p>
        </td>
        <td><p>Instantiates the MobileNetV3Small architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_nasnetlarge.html">application_nasnetlarge()</a></code> </p>
        </td>
        <td><p>Instantiates a NASNet model in ImageNet mode.</p></td>
      </tr><tr><td>
          <p><code><a href="application_nasnetmobile.html">application_nasnetmobile()</a></code> </p>
        </td>
        <td><p>Instantiates a Mobile NASNet model in ImageNet mode.</p></td>
      </tr><tr><td>
          <p><code><a href="application_resnet101.html">application_resnet101()</a></code> </p>
        </td>
        <td><p>Instantiates the ResNet101 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_resnet101_v2.html">application_resnet101_v2()</a></code> </p>
        </td>
        <td><p>Instantiates the ResNet101V2 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_resnet152.html">application_resnet152()</a></code> </p>
        </td>
        <td><p>Instantiates the ResNet152 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_resnet152_v2.html">application_resnet152_v2()</a></code> </p>
        </td>
        <td><p>Instantiates the ResNet152V2 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_resnet50.html">application_resnet50()</a></code> </p>
        </td>
        <td><p>Instantiates the ResNet50 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_resnet50_v2.html">application_resnet50_v2()</a></code> </p>
        </td>
        <td><p>Instantiates the ResNet50V2 architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="application_vgg16.html">application_vgg16()</a></code> </p>
        </td>
        <td><p>Instantiates the VGG16 model.</p></td>
      </tr><tr><td>
          <p><code><a href="application_vgg19.html">application_vgg19()</a></code> </p>
        </td>
        <td><p>Instantiates the VGG19 model.</p></td>
      </tr><tr><td>
          <p><code><a href="application_xception.html">application_xception()</a></code> </p>
        </td>
        <td><p>Instantiates the Xception architecture.</p></td>
      </tr><tr><td>
          <p><code><a href="audio_dataset_from_directory.html">audio_dataset_from_directory()</a></code> </p>
        </td>
        <td><p>Generates a <code>tf.data.Dataset</code> from audio files in a directory.</p></td>
      </tr><tr><td>
          <p><code><a href="backend.html">backend()</a></code> </p>
        </td>
        <td><p>Keras backend tensor engine</p></td>
      </tr><tr><td>
          <p><code><a href="bidirectional.html">bidirectional()</a></code> </p>
        </td>
        <td><p>Bidirectional wrapper for RNNs</p></td>
      </tr><tr><td>
          <p><code><a href="callback_backup_and_restore.html">callback_backup_and_restore()</a></code> </p>
        </td>
        <td><p>Callback to back up and restore the training state.</p></td>
      </tr><tr><td>
          <p><code><a href="callback_csv_logger.html">callback_csv_logger()</a></code> </p>
        </td>
        <td><p>Callback that streams epoch results to a CSV file.</p></td>
      </tr><tr><td>
          <p><code><a href="callback_early_stopping.html">callback_early_stopping()</a></code> </p>
        </td>
        <td><p>Stop training when a monitored metric has stopped improving.</p></td>
      </tr><tr><td>
          <p><code><a href="callback_lambda.html">callback_lambda()</a></code> </p>
        </td>
        <td><p>Callback for creating simple, custom callbacks on-the-fly.</p></td>
      </tr><tr><td>
          <p><code><a href="callback_learning_rate_scheduler.html">callback_learning_rate_scheduler()</a></code> </p>
        </td>
        <td><p>Learning rate scheduler.</p></td>
      </tr><tr><td>
          <p><code><a href="callback_model_checkpoint.html">callback_model_checkpoint()</a></code> </p>
        </td>
        <td><p>Callback to save the Keras model or model weights at some frequency.
@description
<code><a href="../reference/callback_model_checkpoint.html">callback_model_checkpoint()</a></code> is used in conjunction with training using
<code>model |&gt; fit()</code> to save a model or weights (in a checkpoint file) at some
interval, so the model or weights can be loaded later to continue the
training from the state saved.</p></td>
      </tr><tr><td>
          <p><code><a href="callback_progbar_logger.html">callback_progbar_logger()</a></code> </p>
        </td>
        <td><p>Callback that prints metrics to stdout.</p></td>
      </tr><tr><td>
          <p><code><a href="callback_reduce_lr_on_plateau.html">callback_reduce_lr_on_plateau()</a></code> </p>
        </td>
        <td><p>Reduce learning rate when a metric has stopped improving.</p></td>
      </tr><tr><td>
          <p><code><a href="callback_remote_monitor.html">callback_remote_monitor()</a></code> </p>
        </td>
        <td><p>Callback used to stream events to a server.</p></td>
      </tr><tr><td>
          <p><code><a href="callback_tensorboard.html">callback_tensorboard()</a></code> </p>
        </td>
        <td><p>Enable visualizations for TensorBoard.</p></td>
      </tr><tr><td>
          <p><code><a href="callback_terminate_on_nan.html">callback_terminate_on_nan()</a></code> </p>
        </td>
        <td><p>Callback that terminates training when a NaN loss is encountered.</p></td>
      </tr><tr><td>
          <p><code><a href="clear_session.html">clear_session()</a></code> </p>
        </td>
        <td><p>Resets all state generated by Keras.</p></td>
      </tr><tr><td>
          <p><code><a href="clone_model.html">clone_model()</a></code> </p>
        </td>
        <td><p>Clone a model instance.</p></td>
      </tr><tr><td>
          <p><code><a href="compile.keras.models.model.Model.html">compile(<i>&lt;keras.models.model.Model&gt;</i>)</a></code> </p>
        </td>
        <td><p>Configure a Keras model for training</p></td>
      </tr><tr><td>
          <p><code><a href="config_backend.html">config_backend()</a></code> </p>
        </td>
        <td><p>Publicly accessible method for determining the current backend.</p></td>
      </tr><tr><td>
          <p><code><a href="config_disable_interactive_logging.html">config_disable_interactive_logging()</a></code> </p>
        </td>
        <td><p>Turn off interactive logging.</p></td>
      </tr><tr><td>
          <p><code><a href="config_disable_traceback_filtering.html">config_disable_traceback_filtering()</a></code> </p>
        </td>
        <td><p>Turn off traceback filtering.</p></td>
      </tr><tr><td>
          <p><code><a href="config_enable_interactive_logging.html">config_enable_interactive_logging()</a></code> </p>
        </td>
        <td><p>Turn on interactive logging.</p></td>
      </tr><tr><td>
          <p><code><a href="config_enable_traceback_filtering.html">config_enable_traceback_filtering()</a></code> </p>
        </td>
        <td><p>Turn on traceback filtering.</p></td>
      </tr><tr><td>
          <p><code><a href="config_enable_unsafe_deserialization.html">config_enable_unsafe_deserialization()</a></code> </p>
        </td>
        <td><p>Disables safe mode globally, allowing deserialization of lambdas.</p></td>
      </tr><tr><td>
          <p><code><a href="config_epsilon.html">config_epsilon()</a></code> </p>
        </td>
        <td><p>Return the value of the fuzz factor used in numeric expressions.</p></td>
      </tr><tr><td>
          <p><code><a href="config_floatx.html">config_floatx()</a></code> </p>
        </td>
        <td><p>Return the default float type, as a string.</p></td>
      </tr><tr><td>
          <p><code><a href="config_image_data_format.html">config_image_data_format()</a></code> </p>
        </td>
        <td><p>Return the default image data format convention.</p></td>
      </tr><tr><td>
          <p><code><a href="config_is_interactive_logging_enabled.html">config_is_interactive_logging_enabled()</a></code> </p>
        </td>
        <td><p>Check if interactive logging is enabled.</p></td>
      </tr><tr><td>
          <p><code><a href="config_is_traceback_filtering_enabled.html">config_is_traceback_filtering_enabled()</a></code> </p>
        </td>
        <td><p>Check if traceback filtering is enabled.</p></td>
      </tr><tr><td>
          <p><code><a href="config_set_epsilon.html">config_set_epsilon()</a></code> </p>
        </td>
        <td><p>Set the value of the fuzz factor used in numeric expressions.</p></td>
      </tr><tr><td>
          <p><code><a href="config_set_floatx.html">config_set_floatx()</a></code> </p>
        </td>
        <td><p>Set the default float dtype.</p></td>
      </tr><tr><td>
          <p><code><a href="config_set_image_data_format.html">config_set_image_data_format()</a></code> </p>
        </td>
        <td><p>Set the value of the image data format convention.</p></td>
      </tr><tr><td>
          <p><code><a href="constraint_maxnorm.html">constraint_maxnorm()</a></code> </p>
        </td>
        <td><p>MaxNorm weight constraint.</p></td>
      </tr><tr><td>
          <p><code><a href="constraint_minmaxnorm.html">constraint_minmaxnorm()</a></code> </p>
        </td>
        <td><p>MinMaxNorm weight constraint.</p></td>
      </tr><tr><td>
          <p><code><a href="constraint_nonneg.html">constraint_nonneg()</a></code> </p>
        </td>
        <td><p>Constrains the weights to be non-negative.</p></td>
      </tr><tr><td>
          <p><code><a href="constraint_unitnorm.html">constraint_unitnorm()</a></code> </p>
        </td>
        <td><p>Constrains the weights incident to each hidden unit to have unit norm.</p></td>
      </tr><tr><td>
          <p><code><a href="count_params.html">count_params()</a></code> </p>
        </td>
        <td><p>Count the total number of scalars composing the weights.</p></td>
      </tr><tr><td>
          <p><code><a href="create_layer.html">create_layer()</a></code> </p>
        </td>
        <td><p>Create a Keras Layer</p></td>
      </tr><tr><td>
          <p><code><a href="create_layer_wrapper.html">create_layer_wrapper()</a></code> </p>
        </td>
        <td><p>Create a Keras Layer wrapper</p></td>
      </tr><tr><td>
          <p><code><a href="custom_metric.html">custom_metric()</a></code> </p>
        </td>
        <td><p>Custom metric function</p></td>
      </tr><tr><td>
          <p><code><a href="dataset_boston_housing.html">dataset_boston_housing()</a></code> </p>
        </td>
        <td><p>Boston housing price regression dataset</p></td>
      </tr><tr><td>
          <p><code><a href="dataset_cifar10.html">dataset_cifar10()</a></code> </p>
        </td>
        <td><p>CIFAR10 small image classification</p></td>
      </tr><tr><td>
          <p><code><a href="dataset_cifar100.html">dataset_cifar100()</a></code> </p>
        </td>
        <td><p>CIFAR100 small image classification</p></td>
      </tr><tr><td>
          <p><code><a href="dataset_fashion_mnist.html">dataset_fashion_mnist()</a></code> </p>
        </td>
        <td><p>Fashion-MNIST database of fashion articles</p></td>
      </tr><tr><td>
          <p><code><a href="dataset_imdb.html">dataset_imdb()</a></code> <code><a href="dataset_imdb.html">dataset_imdb_word_index()</a></code> </p>
        </td>
        <td><p>IMDB Movie reviews sentiment classification</p></td>
      </tr><tr><td>
          <p><code><a href="dataset_mnist.html">dataset_mnist()</a></code> </p>
        </td>
        <td><p>MNIST database of handwritten digits</p></td>
      </tr><tr><td>
          <p><code><a href="dataset_reuters.html">dataset_reuters()</a></code> <code><a href="dataset_reuters.html">dataset_reuters_word_index()</a></code> </p>
        </td>
        <td><p>Reuters newswire topics classification</p></td>
      </tr><tr><td>
          <p><code><a href="evaluate.keras.models.model.Model.html">evaluate(<i>&lt;keras.models.model.Model&gt;</i>)</a></code> </p>
        </td>
        <td><p>Evaluate a Keras model</p></td>
      </tr><tr><td>
          <p><code><a href="export_savedmodel.keras.models.model.Model.html">export_savedmodel(<i>&lt;keras.models.model.Model&gt;</i>)</a></code> </p>
        </td>
        <td><p>Export a Saved Model</p></td>
      </tr><tr><td>
          <p><code><a href="fit.keras.models.model.Model.html">fit(<i>&lt;keras.models.model.Model&gt;</i>)</a></code> </p>
        </td>
        <td><p>Train a Keras model</p></td>
      </tr><tr><td>
          <p><code><a href="freeze_weights.html">freeze_weights()</a></code> <code><a href="freeze_weights.html">unfreeze_weights()</a></code> </p>
        </td>
        <td><p>Freeze and unfreeze weights</p></td>
      </tr><tr><td>
          <p><code><a href="get_config.html">get_config()</a></code> <code><a href="get_config.html">from_config()</a></code> </p>
        </td>
        <td><p>Layer/Model configuration</p></td>
      </tr><tr><td>
          <p><code><a href="summary.keras.models.model.Model.html">summary(<i>&lt;keras.models.model.Model&gt;</i>)</a></code> <code><a href="summary.keras.models.model.Model.html">format(<i>&lt;keras.models.model.Model&gt;</i>)</a></code> <code><a href="summary.keras.models.model.Model.html">print(<i>&lt;keras.models.model.Model&gt;</i>)</a></code> </p>
        </td>
        <td><p>Print a summary of a Keras model</p></td>
      </tr><tr><td>
          <p><code><a href="get_custom_objects.html">get_custom_objects()</a></code> </p>
        </td>
        <td><p>Retrieves a live reference to the global dictionary of custom objects.</p></td>
      </tr><tr><td>
          <p><code><a href="get_file.html">get_file()</a></code> </p>
        </td>
        <td><p>Downloads a file from a URL if it not already in the cache.</p></td>
      </tr><tr><td>
          <p><code><a href="get_input_at.html">get_input_at()</a></code> <code><a href="get_input_at.html">get_output_at()</a></code> <code><a href="get_input_at.html">get_input_shape_at()</a></code> <code><a href="get_input_at.html">get_output_shape_at()</a></code> <code><a href="get_input_at.html">get_input_mask_at()</a></code> <code><a href="get_input_at.html">get_output_mask_at()</a></code> </p>
        </td>
        <td><p>Retrieve tensors for layers with multiple nodes</p></td>
      </tr><tr><td>
          <p><code><a href="get_layer.html">get_layer()</a></code> </p>
        </td>
        <td><p>Retrieves a layer based on either its name (unique) or index.</p></td>
      </tr><tr><td>
          <p><code><a href="get_registered_name.html">get_registered_name()</a></code> </p>
        </td>
        <td><p>Returns the name registered to an object within the Keras framework.</p></td>
      </tr><tr><td>
          <p><code><a href="get_registered_object.html">get_registered_object()</a></code> </p>
        </td>
        <td><p>Returns the class associated with <code>name</code> if it is registered with Keras.</p></td>
      </tr><tr><td>
          <p><code><a href="get_source_inputs.html">get_source_inputs()</a></code> </p>
        </td>
        <td><p>Returns the list of input tensors necessary to compute <code>tensor</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="get_weights.html">get_weights()</a></code> <code><a href="get_weights.html">set_weights()</a></code> </p>
        </td>
        <td><p>Layer/Model weights as R arrays</p></td>
      </tr><tr><td>
          <p><code><a href="layer_text_vectorization.html">layer_text_vectorization()</a></code> <code><a href="layer_text_vectorization.html">get_vocabulary()</a></code> <code><a href="layer_text_vectorization.html">set_vocabulary()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which maps text features to integer sequences.</p></td>
      </tr><tr><td>
          <p><code><a href="image_array_save.html">image_array_save()</a></code> </p>
        </td>
        <td><p>Saves an image stored as a NumPy array to a path or file object.</p></td>
      </tr><tr><td>
          <p><code><a href="image_dataset_from_directory.html">image_dataset_from_directory()</a></code> </p>
        </td>
        <td><p>Generates a <code>tf.data.Dataset</code> from image files in a directory.</p></td>
      </tr><tr><td>
          <p><code><a href="image_from_array.html">image_from_array()</a></code> </p>
        </td>
        <td><p>Converts a 3D array to a PIL Image instance.</p></td>
      </tr><tr><td>
          <p><code><a href="image_load.html">image_load()</a></code> </p>
        </td>
        <td><p>Loads an image into PIL format.</p></td>
      </tr><tr><td>
          <p><code><a href="image_smart_resize.html">image_smart_resize()</a></code> </p>
        </td>
        <td><p>Resize images to a target size without aspect ratio distortion.</p></td>
      </tr><tr><td>
          <p><code><a href="image_to_array.html">image_to_array()</a></code> </p>
        </td>
        <td><p>Converts a PIL Image instance to a matrix.</p></td>
      </tr><tr><td>
          <p><code><a href="implementation.html">implementation()</a></code> </p>
        </td>
        <td><p>Keras implementation</p></td>
      </tr><tr><td>
          <p><code><a href="initializer_constant.html">initializer_constant()</a></code> </p>
        </td>
        <td><p>Initializer that generates tensors with constant values.</p></td>
      </tr><tr><td>
          <p><code><a href="initializer_glorot_normal.html">initializer_glorot_normal()</a></code> </p>
        </td>
        <td><p>The Glorot normal initializer, also called Xavier normal initializer.</p></td>
      </tr><tr><td>
          <p><code><a href="initializer_glorot_uniform.html">initializer_glorot_uniform()</a></code> </p>
        </td>
        <td><p>The Glorot uniform initializer, also called Xavier uniform initializer.</p></td>
      </tr><tr><td>
          <p><code><a href="initializer_he_normal.html">initializer_he_normal()</a></code> </p>
        </td>
        <td><p>He normal initializer.</p></td>
      </tr><tr><td>
          <p><code><a href="initializer_he_uniform.html">initializer_he_uniform()</a></code> </p>
        </td>
        <td><p>He uniform variance scaling initializer.</p></td>
      </tr><tr><td>
          <p><code><a href="initializer_identity.html">initializer_identity()</a></code> </p>
        </td>
        <td><p>Initializer that generates the identity matrix.</p></td>
      </tr><tr><td>
          <p><code><a href="initializer_lecun_normal.html">initializer_lecun_normal()</a></code> </p>
        </td>
        <td><p>Lecun normal initializer.</p></td>
      </tr><tr><td>
          <p><code><a href="initializer_lecun_uniform.html">initializer_lecun_uniform()</a></code> </p>
        </td>
        <td><p>Lecun uniform initializer.</p></td>
      </tr><tr><td>
          <p><code><a href="initializer_ones.html">initializer_ones()</a></code> </p>
        </td>
        <td><p>Initializer that generates tensors initialized to 1.</p></td>
      </tr><tr><td>
          <p><code><a href="initializer_orthogonal.html">initializer_orthogonal()</a></code> </p>
        </td>
        <td><p>Initializer that generates an orthogonal matrix.</p></td>
      </tr><tr><td>
          <p><code><a href="initializer_random_normal.html">initializer_random_normal()</a></code> </p>
        </td>
        <td><p>Random normal initializer.</p></td>
      </tr><tr><td>
          <p><code><a href="initializer_random_uniform.html">initializer_random_uniform()</a></code> </p>
        </td>
        <td><p>Random uniform initializer.</p></td>
      </tr><tr><td>
          <p><code><a href="initializer_truncated_normal.html">initializer_truncated_normal()</a></code> </p>
        </td>
        <td><p>Initializer that generates a truncated normal distribution.</p></td>
      </tr><tr><td>
          <p><code><a href="initializer_variance_scaling.html">initializer_variance_scaling()</a></code> </p>
        </td>
        <td><p>Initializer that adapts its scale to the shape of its input tensors.</p></td>
      </tr><tr><td>
          <p><code><a href="initializer_zeros.html">initializer_zeros()</a></code> </p>
        </td>
        <td><p>Initializer that generates tensors initialized to 0.</p></td>
      </tr><tr><td>
          <p><code><a href="install_keras.html">install_keras()</a></code> </p>
        </td>
        <td><p>Install Keras</p></td>
      </tr><tr><td>
          <p><code><a href="is_keras_available.html">is_keras_available()</a></code> </p>
        </td>
        <td><p>Check if Keras is Available</p></td>
      </tr><tr><td>
          <p><code><a href="k_abs.html">k_abs()</a></code> </p>
        </td>
        <td><p>Shorthand for <code>keras.ops.absolute</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_add.html">k_add()</a></code> </p>
        </td>
        <td><p>Add arguments element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_all.html">k_all()</a></code> </p>
        </td>
        <td><p>Test whether all array elements along a given axis evaluate to <code>TRUE</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_amax.html">k_amax()</a></code> </p>
        </td>
        <td><p>Returns the maximum of a vector or maximum value along an axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_amin.html">k_amin()</a></code> </p>
        </td>
        <td><p>Returns the minimum of a vector or minimum value along an axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_any.html">k_any()</a></code> </p>
        </td>
        <td><p>Test whether any array element along a given axis evaluates to <code>TRUE</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_append.html">k_append()</a></code> </p>
        </td>
        <td><p>Append tensor <code>x2</code> to the end of tensor <code>x1</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_arange.html">k_arange()</a></code> </p>
        </td>
        <td><p>Return evenly spaced values within a given interval.</p></td>
      </tr><tr><td>
          <p><code><a href="k_arccos.html">k_arccos()</a></code> </p>
        </td>
        <td><p>Trigonometric inverse cosine, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_arccosh.html">k_arccosh()</a></code> </p>
        </td>
        <td><p>Inverse hyperbolic cosine, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_arcsin.html">k_arcsin()</a></code> </p>
        </td>
        <td><p>Inverse sine, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_arcsinh.html">k_arcsinh()</a></code> </p>
        </td>
        <td><p>Inverse hyperbolic sine, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_arctan.html">k_arctan()</a></code> </p>
        </td>
        <td><p>Trigonometric inverse tangent, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_arctan2.html">k_arctan2()</a></code> </p>
        </td>
        <td><p>Element-wise arc tangent of <code>x1/x2</code> choosing the quadrant correctly.</p></td>
      </tr><tr><td>
          <p><code><a href="k_arctanh.html">k_arctanh()</a></code> </p>
        </td>
        <td><p>Inverse hyperbolic tangent, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_argmax.html">k_argmax()</a></code> </p>
        </td>
        <td><p>Returns the indices of the maximum values along an axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_argmin.html">k_argmin()</a></code> </p>
        </td>
        <td><p>Returns the indices of the minimum values along an axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_argsort.html">k_argsort()</a></code> </p>
        </td>
        <td><p>Returns the indices that would sort a tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_array.html">k_array()</a></code> </p>
        </td>
        <td><p>Create a tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_average.html">k_average()</a></code> </p>
        </td>
        <td><p>Compute the weighted average along the specified axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_average_pool.html">k_average_pool()</a></code> </p>
        </td>
        <td><p>Average pooling operation.</p></td>
      </tr><tr><td>
          <p><code><a href="k_binary_crossentropy.html">k_binary_crossentropy()</a></code> </p>
        </td>
        <td><p>Computes binary cross-entropy loss between target and output tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_bincount.html">k_bincount()</a></code> </p>
        </td>
        <td><p>Count the number of occurrences of each value in a tensor of integers.</p></td>
      </tr><tr><td>
          <p><code><a href="k_broadcast_to.html">k_broadcast_to()</a></code> </p>
        </td>
        <td><p>Broadcast a tensor to a new shape.</p></td>
      </tr><tr><td>
          <p><code><a href="k_cast.html">k_cast()</a></code> </p>
        </td>
        <td><p>Cast a tensor to the desired dtype.</p></td>
      </tr><tr><td>
          <p><code><a href="k_categorical_crossentropy.html">k_categorical_crossentropy()</a></code> </p>
        </td>
        <td><p>Computes categorical cross-entropy loss between target and output tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_ceil.html">k_ceil()</a></code> </p>
        </td>
        <td><p>Return the ceiling of the input, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_clip.html">k_clip()</a></code> </p>
        </td>
        <td><p>Clip (limit) the values in a tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_concatenate.html">k_concatenate()</a></code> </p>
        </td>
        <td><p>Join a sequence of tensors along an existing axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_cond.html">k_cond()</a></code> </p>
        </td>
        <td><p>Conditionally applies <code>true_fn</code> or <code>false_fn</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_conj.html">k_conj()</a></code> </p>
        </td>
        <td><p>Shorthand for <code>keras.ops.conjugate</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_conjugate.html">k_conjugate()</a></code> </p>
        </td>
        <td><p>Returns the complex conjugate, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_conv.html">k_conv()</a></code> </p>
        </td>
        <td><p>General N-D convolution.</p></td>
      </tr><tr><td>
          <p><code><a href="k_conv_transpose.html">k_conv_transpose()</a></code> </p>
        </td>
        <td><p>General N-D convolution transpose.</p></td>
      </tr><tr><td>
          <p><code><a href="k_convert_to_numpy.html">k_convert_to_numpy()</a></code> </p>
        </td>
        <td><p>Convert a tensor to a NumPy array.</p></td>
      </tr><tr><td>
          <p><code><a href="k_convert_to_tensor.html">k_convert_to_tensor()</a></code> </p>
        </td>
        <td><p>Convert an array to a tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_copy.html">k_copy()</a></code> </p>
        </td>
        <td><p>Returns a copy of <code>x</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_cos.html">k_cos()</a></code> </p>
        </td>
        <td><p>Cosine, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_cosh.html">k_cosh()</a></code> </p>
        </td>
        <td><p>Hyperbolic cosine, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_count_nonzero.html">k_count_nonzero()</a></code> </p>
        </td>
        <td><p>Counts the number of non-zero values in <code>x</code> along the given <code>axis</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_cross.html">k_cross()</a></code> </p>
        </td>
        <td><p>Returns the cross product of two (arrays of) vectors.</p></td>
      </tr><tr><td>
          <p><code><a href="k_cumprod.html">k_cumprod()</a></code> </p>
        </td>
        <td><p>Return the cumulative product of elements along a given axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_cumsum.html">k_cumsum()</a></code> </p>
        </td>
        <td><p>Returns the cumulative sum of elements along a given axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_depthwise_conv.html">k_depthwise_conv()</a></code> </p>
        </td>
        <td><p>General N-D depthwise convolution.</p></td>
      </tr><tr><td>
          <p><code><a href="k_diag.html">k_diag()</a></code> </p>
        </td>
        <td><p>Extract a diagonal or construct a diagonal array.</p></td>
      </tr><tr><td>
          <p><code><a href="k_diagonal.html">k_diagonal()</a></code> </p>
        </td>
        <td><p>Return specified diagonals.</p></td>
      </tr><tr><td>
          <p><code><a href="k_diff.html">k_diff()</a></code> </p>
        </td>
        <td><p>Calculate the n-th discrete difference along the given axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_digitize.html">k_digitize()</a></code> </p>
        </td>
        <td><p>Returns the indices of the bins to which each value in <code>x</code> belongs.</p></td>
      </tr><tr><td>
          <p><code><a href="k_divide.html">k_divide()</a></code> </p>
        </td>
        <td><p>Divide arguments element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_dot.html">k_dot()</a></code> </p>
        </td>
        <td><p>Dot product of two tensors.</p></td>
      </tr><tr><td>
          <p><code><a href="k_einsum.html">k_einsum()</a></code> </p>
        </td>
        <td><p>Evaluates the Einstein summation convention on the operands.</p></td>
      </tr><tr><td>
          <p><code><a href="k_elu.html">k_elu()</a></code> </p>
        </td>
        <td><p>Exponential Linear Unit activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="k_empty.html">k_empty()</a></code> </p>
        </td>
        <td><p>Return a tensor of given shape and type filled with uninitialized data.</p></td>
      </tr><tr><td>
          <p><code><a href="k_equal.html">k_equal()</a></code> </p>
        </td>
        <td><p>Returns <code>(x1 == x2)</code> element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_erf.html">k_erf()</a></code> </p>
        </td>
        <td><p>Computes the error function of <code>x</code>, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_exp.html">k_exp()</a></code> </p>
        </td>
        <td><p>Calculate the exponential of all elements in the input tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_expand_dims.html">k_expand_dims()</a></code> </p>
        </td>
        <td><p>Expand the shape of a tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_expm1.html">k_expm1()</a></code> </p>
        </td>
        <td><p>Calculate <code>exp(x) - 1</code> for all elements in the tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_extract_sequences.html">k_extract_sequences()</a></code> </p>
        </td>
        <td><p>Expands the dimension of last axis into sequences of <code>sequence_length</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_eye.html">k_eye()</a></code> </p>
        </td>
        <td><p>Return a 2-D tensor with ones on the diagonal and zeros elsewhere.</p></td>
      </tr><tr><td>
          <p><code><a href="k_fft.html">k_fft()</a></code> </p>
        </td>
        <td><p>Computes the Fast Fourier Transform along last axis of input.</p></td>
      </tr><tr><td>
          <p><code><a href="k_fft2.html">k_fft2()</a></code> </p>
        </td>
        <td><p>Computes the 2D Fast Fourier Transform along the last two axes of input.</p></td>
      </tr><tr><td>
          <p><code><a href="k_flip.html">k_flip()</a></code> </p>
        </td>
        <td><p>Reverse the order of elements in the tensor along the given axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_floatx.html">k_floatx()</a></code> </p>
        </td>
        <td><p>Return the default float type, as a string.</p></td>
      </tr><tr><td>
          <p><code><a href="k_floor.html">k_floor()</a></code> </p>
        </td>
        <td><p>Return the floor of the input, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_floor_divide.html">k_floor_divide()</a></code> </p>
        </td>
        <td><p>Returns the largest integer smaller or equal to the division of inputs.</p></td>
      </tr><tr><td>
          <p><code><a href="k_fori_loop.html">k_fori_loop()</a></code> </p>
        </td>
        <td><p>For loop implementation.</p></td>
      </tr><tr><td>
          <p><code><a href="k_full.html">k_full()</a></code> </p>
        </td>
        <td><p>Return a new tensor of given shape and type, filled with <code>fill_value</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_full_like.html">k_full_like()</a></code> </p>
        </td>
        <td><p>Return a full tensor with the same shape and type as the given tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_gelu.html">k_gelu()</a></code> </p>
        </td>
        <td><p>Gaussian Error Linear Unit (GELU) activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="k_get_item.html">k_get_item()</a></code> </p>
        </td>
        <td><p>Return <code>x[key]</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_greater.html">k_greater()</a></code> </p>
        </td>
        <td><p>Return the truth value of <code>x1 &gt; x2</code> element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_greater_equal.html">k_greater_equal()</a></code> </p>
        </td>
        <td><p>Return the truth value of <code>x1 &gt;= x2</code> element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_hard_sigmoid.html">k_hard_sigmoid()</a></code> </p>
        </td>
        <td><p>Hard sigmoid activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="k_hstack.html">k_hstack()</a></code> </p>
        </td>
        <td><p>Stack tensors in sequence horizontally (column wise).</p></td>
      </tr><tr><td>
          <p><code><a href="k_identity.html">k_identity()</a></code> </p>
        </td>
        <td><p>Return the identity tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_imag.html">k_imag()</a></code> </p>
        </td>
        <td><p>Return the imaginary part of the complex argument.</p></td>
      </tr><tr><td>
          <p><code><a href="k_image_affine_transform.html">k_image_affine_transform()</a></code> </p>
        </td>
        <td><p>Applies the given transform(s) to the image(s).</p></td>
      </tr><tr><td>
          <p><code><a href="k_image_extract_patches.html">k_image_extract_patches()</a></code> </p>
        </td>
        <td><p>Extracts patches from the image(s).</p></td>
      </tr><tr><td>
          <p><code><a href="k_image_map_coordinates.html">k_image_map_coordinates()</a></code> </p>
        </td>
        <td><p>Map the input array to new coordinates by interpolation..</p></td>
      </tr><tr><td>
          <p><code><a href="k_image_pad_images.html">k_image_pad_images()</a></code> </p>
        </td>
        <td><p>Pad <code>images</code> with zeros to the specified <code>height</code> and <code>width</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_image_resize.html">k_image_resize()</a></code> </p>
        </td>
        <td><p>Resize images to size using the specified interpolation method.</p></td>
      </tr><tr><td>
          <p><code><a href="k_in_top_k.html">k_in_top_k()</a></code> </p>
        </td>
        <td><p>Checks if the targets are in the top-k predictions.</p></td>
      </tr><tr><td>
          <p><code><a href="k_irfft.html">k_irfft()</a></code> </p>
        </td>
        <td><p>Inverse real-valued Fast Fourier transform along the last axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_isclose.html">k_isclose()</a></code> </p>
        </td>
        <td><p>Return whether two tensors are element-wise almost equal.</p></td>
      </tr><tr><td>
          <p><code><a href="k_isfinite.html">k_isfinite()</a></code> </p>
        </td>
        <td><p>Return whether a tensor is finite, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_isinf.html">k_isinf()</a></code> </p>
        </td>
        <td><p>Test element-wise for positive or negative infinity.</p></td>
      </tr><tr><td>
          <p><code><a href="k_isnan.html">k_isnan()</a></code> </p>
        </td>
        <td><p>Test element-wise for NaN and return result as a boolean tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_istft.html">k_istft()</a></code> </p>
        </td>
        <td><p>Inverse Short-Time Fourier Transform along the last axis of the input.</p></td>
      </tr><tr><td>
          <p><code><a href="k_leaky_relu.html">k_leaky_relu()</a></code> </p>
        </td>
        <td><p>Leaky version of a Rectified Linear Unit activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="k_less.html">k_less()</a></code> </p>
        </td>
        <td><p>Return the truth value of <code>x1 &lt; x2</code> element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_less_equal.html">k_less_equal()</a></code> </p>
        </td>
        <td><p>Return the truth value of <code>x1 &lt;= x2</code> element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_linspace.html">k_linspace()</a></code> </p>
        </td>
        <td><p>Return evenly spaced numbers over a specified interval.</p></td>
      </tr><tr><td>
          <p><code><a href="k_log.html">k_log()</a></code> </p>
        </td>
        <td><p>Natural logarithm, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_log10.html">k_log10()</a></code> </p>
        </td>
        <td><p>Return the base 10 logarithm of the input tensor, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_log1p.html">k_log1p()</a></code> </p>
        </td>
        <td><p>Returns the natural logarithm of one plus the <code>x</code>, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_log2.html">k_log2()</a></code> </p>
        </td>
        <td><p>Base-2 logarithm of <code>x</code>, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_log_sigmoid.html">k_log_sigmoid()</a></code> </p>
        </td>
        <td><p>Logarithm of the sigmoid activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="k_log_softmax.html">k_log_softmax()</a></code> </p>
        </td>
        <td><p>Log-softmax activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="k_logaddexp.html">k_logaddexp()</a></code> </p>
        </td>
        <td><p>Logarithm of the sum of exponentiations of the inputs.</p></td>
      </tr><tr><td>
          <p><code><a href="k_logical_and.html">k_logical_and()</a></code> </p>
        </td>
        <td><p>Computes the element-wise logical AND of the given input tensors.</p></td>
      </tr><tr><td>
          <p><code><a href="k_logical_not.html">k_logical_not()</a></code> </p>
        </td>
        <td><p>Computes the element-wise NOT of the given input tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_logical_or.html">k_logical_or()</a></code> </p>
        </td>
        <td><p>Computes the element-wise logical OR of the given input tensors.</p></td>
      </tr><tr><td>
          <p><code><a href="k_logical_xor.html">k_logical_xor()</a></code> </p>
        </td>
        <td><p>Compute the truth value of <code>x1 XOR x2</code>, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_logspace.html">k_logspace()</a></code> </p>
        </td>
        <td><p>Returns numbers spaced evenly on a log scale.</p></td>
      </tr><tr><td>
          <p><code><a href="k_logsumexp.html">k_logsumexp()</a></code> </p>
        </td>
        <td><p>Computes the logarithm of sum of exponentials of elements in a tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_matmul.html">k_matmul()</a></code> </p>
        </td>
        <td><p>Matrix product of two tensors.</p></td>
      </tr><tr><td>
          <p><code><a href="k_max.html">k_max()</a></code> </p>
        </td>
        <td><p>Return the maximum of a tensor or maximum along an axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_max_pool.html">k_max_pool()</a></code> </p>
        </td>
        <td><p>Max pooling operation.</p></td>
      </tr><tr><td>
          <p><code><a href="k_maximum.html">k_maximum()</a></code> </p>
        </td>
        <td><p>Element-wise maximum of <code>x1</code> and <code>x2</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_mean.html">k_mean()</a></code> </p>
        </td>
        <td><p>Compute the arithmetic mean along the specified axes.</p></td>
      </tr><tr><td>
          <p><code><a href="k_median.html">k_median()</a></code> </p>
        </td>
        <td><p>Compute the median along the specified axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_meshgrid.html">k_meshgrid()</a></code> </p>
        </td>
        <td><p>Creates grids of coordinates from coordinate vectors.</p></td>
      </tr><tr><td>
          <p><code><a href="k_min.html">k_min()</a></code> </p>
        </td>
        <td><p>Return the minimum of a tensor or minimum along an axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_minimum.html">k_minimum()</a></code> </p>
        </td>
        <td><p>Element-wise minimum of <code>x1</code> and <code>x2</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_mod.html">k_mod()</a></code> </p>
        </td>
        <td><p>Returns the element-wise remainder of division.</p></td>
      </tr><tr><td>
          <p><code><a href="k_moments.html">k_moments()</a></code> </p>
        </td>
        <td><p>Calculates the mean and variance of <code>x</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_moveaxis.html">k_moveaxis()</a></code> </p>
        </td>
        <td><p>Move axes of a tensor to new positions.</p></td>
      </tr><tr><td>
          <p><code><a href="k_multi_hot.html">k_multi_hot()</a></code> </p>
        </td>
        <td><p>Encodes integer labels as multi-hot vectors.</p></td>
      </tr><tr><td>
          <p><code><a href="k_multiply.html">k_multiply()</a></code> </p>
        </td>
        <td><p>Multiply arguments element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_nan_to_num.html">k_nan_to_num()</a></code> </p>
        </td>
        <td><p>Replace NaN with zero and infinity with large finite numbers.</p></td>
      </tr><tr><td>
          <p><code><a href="k_ndim.html">k_ndim()</a></code> </p>
        </td>
        <td><p>Return the number of dimensions of a tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_negative.html">k_negative()</a></code> </p>
        </td>
        <td><p>Numerical negative, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_nonzero.html">k_nonzero()</a></code> </p>
        </td>
        <td><p>Return the indices of the elements that are non-zero.</p></td>
      </tr><tr><td>
          <p><code><a href="k_not_equal.html">k_not_equal()</a></code> </p>
        </td>
        <td><p>Return <code>(x1 != x2)</code> element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_one_hot.html">k_one_hot()</a></code> </p>
        </td>
        <td><p>Converts integer tensor <code>x</code> into a one-hot tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_ones.html">k_ones()</a></code> </p>
        </td>
        <td><p>Return a new tensor of given shape and type, filled with ones.</p></td>
      </tr><tr><td>
          <p><code><a href="k_ones_like.html">k_ones_like()</a></code> </p>
        </td>
        <td><p>Return a tensor of ones with the same shape and type of <code>x</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_outer.html">k_outer()</a></code> </p>
        </td>
        <td><p>Compute the outer product of two vectors.</p></td>
      </tr><tr><td>
          <p><code><a href="k_pad.html">k_pad()</a></code> </p>
        </td>
        <td><p>Pad a tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_power.html">k_power()</a></code> </p>
        </td>
        <td><p>First tensor elements raised to powers from second tensor, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_prod.html">k_prod()</a></code> </p>
        </td>
        <td><p>Return the product of tensor elements over a given axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_qr.html">k_qr()</a></code> </p>
        </td>
        <td><p>Computes the QR decomposition of a tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_quantile.html">k_quantile()</a></code> </p>
        </td>
        <td><p>Compute the q-th quantile(s) of the data along the specified axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_ravel.html">k_ravel()</a></code> </p>
        </td>
        <td><p>Return a contiguous flattened tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_real.html">k_real()</a></code> </p>
        </td>
        <td><p>Return the real part of the complex argument.</p></td>
      </tr><tr><td>
          <p><code><a href="k_reciprocal.html">k_reciprocal()</a></code> </p>
        </td>
        <td><p>Return the reciprocal of the argument, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_relu.html">k_relu()</a></code> </p>
        </td>
        <td><p>Rectified linear unit activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="k_relu6.html">k_relu6()</a></code> </p>
        </td>
        <td><p>Rectified linear unit activation function with upper bound of 6.</p></td>
      </tr><tr><td>
          <p><code><a href="k_repeat.html">k_repeat()</a></code> </p>
        </td>
        <td><p>Repeat each element of a tensor after themselves.</p></td>
      </tr><tr><td>
          <p><code><a href="k_reshape.html">k_reshape()</a></code> </p>
        </td>
        <td><p>Gives a new shape to a tensor without changing its data.</p></td>
      </tr><tr><td>
          <p><code><a href="k_rfft.html">k_rfft()</a></code> </p>
        </td>
        <td><p>Real-valued Fast Fourier Transform along the last axis of the input.</p></td>
      </tr><tr><td>
          <p><code><a href="k_roll.html">k_roll()</a></code> </p>
        </td>
        <td><p>Roll tensor elements along a given axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_round.html">k_round()</a></code> </p>
        </td>
        <td><p>Evenly round to the given number of decimals.</p></td>
      </tr><tr><td>
          <p><code><a href="k_rsqrt.html">k_rsqrt()</a></code> </p>
        </td>
        <td><p>Computes reciprocal of square root of x element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_scatter.html">k_scatter()</a></code> </p>
        </td>
        <td><p>Returns a tensor of shape <code>shape</code> where <code>indices</code> are set to <code>values</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_scatter_update.html">k_scatter_update()</a></code> </p>
        </td>
        <td><p>Update inputs via updates at scattered (sparse) indices.</p></td>
      </tr><tr><td>
          <p><code><a href="k_segment_max.html">k_segment_max()</a></code> </p>
        </td>
        <td><p>Computes the max of segments in a tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_segment_sum.html">k_segment_sum()</a></code> </p>
        </td>
        <td><p>Computes the sum of segments in a tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_selu.html">k_selu()</a></code> </p>
        </td>
        <td><p>Scaled Exponential Linear Unit (SELU) activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="k_separable_conv.html">k_separable_conv()</a></code> </p>
        </td>
        <td><p>General N-D separable convolution.</p></td>
      </tr><tr><td>
          <p><code><a href="k_shape.html">k_shape()</a></code> </p>
        </td>
        <td><p>Gets the shape of the tensor input.</p></td>
      </tr><tr><td>
          <p><code><a href="k_sigmoid.html">k_sigmoid()</a></code> </p>
        </td>
        <td><p>Sigmoid activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="k_sign.html">k_sign()</a></code> </p>
        </td>
        <td><p>Returns a tensor with the signs of the elements of <code>x</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_silu.html">k_silu()</a></code> </p>
        </td>
        <td><p>Sigmoid Linear Unit (SiLU) activation function, also known as Swish.</p></td>
      </tr><tr><td>
          <p><code><a href="k_sin.html">k_sin()</a></code> </p>
        </td>
        <td><p>Trigonomeric sine, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_sinh.html">k_sinh()</a></code> </p>
        </td>
        <td><p>Hyperbolic sine, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_size.html">k_size()</a></code> </p>
        </td>
        <td><p>Return the number of elements in a tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_slice.html">k_slice()</a></code> </p>
        </td>
        <td><p>Return a slice of an input tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_slice_update.html">k_slice_update()</a></code> </p>
        </td>
        <td><p>Update an input by slicing in a tensor of updated values.</p></td>
      </tr><tr><td>
          <p><code><a href="k_softmax.html">k_softmax()</a></code> </p>
        </td>
        <td><p>Softmax activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="k_softplus.html">k_softplus()</a></code> </p>
        </td>
        <td><p>Softplus activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="k_softsign.html">k_softsign()</a></code> </p>
        </td>
        <td><p>Softsign activation function.</p></td>
      </tr><tr><td>
          <p><code><a href="k_solve.html">k_solve()</a></code> </p>
        </td>
        <td><p>Solves for <code>x</code> in the equation <code>a * x = b</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_sort.html">k_sort()</a></code> </p>
        </td>
        <td><p>Sorts the elements of <code>x</code> along a given axis in ascending order.</p></td>
      </tr><tr><td>
          <p><code><a href="k_sparse_categorical_crossentropy.html">k_sparse_categorical_crossentropy()</a></code> </p>
        </td>
        <td><p>Computes sparse categorical cross-entropy loss.</p></td>
      </tr><tr><td>
          <p><code><a href="k_split.html">k_split()</a></code> </p>
        </td>
        <td><p>Split a tensor into chunks.</p></td>
      </tr><tr><td>
          <p><code><a href="k_sqrt.html">k_sqrt()</a></code> </p>
        </td>
        <td><p>Return the non-negative square root of a tensor, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_square.html">k_square()</a></code> </p>
        </td>
        <td><p>Return the element-wise square of the input.</p></td>
      </tr><tr><td>
          <p><code><a href="k_squeeze.html">k_squeeze()</a></code> </p>
        </td>
        <td><p>Remove axes of length one from <code>x</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_stack.html">k_stack()</a></code> </p>
        </td>
        <td><p>Join a sequence of tensors along a new axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_std.html">k_std()</a></code> </p>
        </td>
        <td><p>Compute the standard deviation along the specified axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_stft.html">k_stft()</a></code> </p>
        </td>
        <td><p>Short-Time Fourier Transform along the last axis of the input.</p></td>
      </tr><tr><td>
          <p><code><a href="k_stop_gradient.html">k_stop_gradient()</a></code> </p>
        </td>
        <td><p>Stops gradient computation.</p></td>
      </tr><tr><td>
          <p><code><a href="k_subtract.html">k_subtract()</a></code> </p>
        </td>
        <td><p>Subtract arguments element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_sum.html">k_sum()</a></code> </p>
        </td>
        <td><p>Sum of a tensor over the given axes.</p></td>
      </tr><tr><td>
          <p><code><a href="k_swapaxes.html">k_swapaxes()</a></code> </p>
        </td>
        <td><p>Interchange two axes of a tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_take.html">k_take()</a></code> </p>
        </td>
        <td><p>Take elements from a tensor along an axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_take_along_axis.html">k_take_along_axis()</a></code> </p>
        </td>
        <td><p>Select values from <code>x</code> at the 1-D <code>indices</code> along the given axis.</p></td>
      </tr><tr><td>
          <p><code><a href="k_tan.html">k_tan()</a></code> </p>
        </td>
        <td><p>Compute tangent, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_tanh.html">k_tanh()</a></code> </p>
        </td>
        <td><p>Hyperbolic tangent, element-wise.</p></td>
      </tr><tr><td>
          <p><code><a href="k_tensordot.html">k_tensordot()</a></code> </p>
        </td>
        <td><p>Compute the tensor dot product along specified axes.</p></td>
      </tr><tr><td>
          <p><code><a href="k_tile.html">k_tile()</a></code> </p>
        </td>
        <td><p>Repeat <code>x</code> the number of times given by <code>repeats</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_top_k.html">k_top_k()</a></code> </p>
        </td>
        <td><p>Finds the top-k values and their indices in a tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_trace.html">k_trace()</a></code> </p>
        </td>
        <td><p>Return the sum along diagonals of the tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_transpose.html">k_transpose()</a></code> </p>
        </td>
        <td><p>Returns a tensor with <code>axes</code> transposed.</p></td>
      </tr><tr><td>
          <p><code><a href="k_tri.html">k_tri()</a></code> </p>
        </td>
        <td><p>Return a tensor with ones at and below a diagonal and zeros elsewhere.</p></td>
      </tr><tr><td>
          <p><code><a href="k_tril.html">k_tril()</a></code> </p>
        </td>
        <td><p>Return lower triangle of a tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_triu.html">k_triu()</a></code> </p>
        </td>
        <td><p>Return upper triangle of a tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="k_true_divide.html">k_true_divide()</a></code> </p>
        </td>
        <td><p>Alias for <code>keras.ops.divide</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_unstack.html">k_unstack()</a></code> </p>
        </td>
        <td><p>Unpacks the given dimension of a rank-R tensor into rank-(R-1) tensors.</p></td>
      </tr><tr><td>
          <p><code><a href="k_var.html">k_var()</a></code> </p>
        </td>
        <td><p>Compute the variance along the specified axes.</p></td>
      </tr><tr><td>
          <p><code><a href="k_vdot.html">k_vdot()</a></code> </p>
        </td>
        <td><p>Return the dot product of two vectors.</p></td>
      </tr><tr><td>
          <p><code><a href="k_vectorized_map.html">k_vectorized_map()</a></code> </p>
        </td>
        <td><p>Parallel map of <code>function</code> on axis 0 of tensor(s) <code>elements</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_vstack.html">k_vstack()</a></code> </p>
        </td>
        <td><p>Stack tensors in sequence vertically (row wise).</p></td>
      </tr><tr><td>
          <p><code><a href="k_where.html">k_where()</a></code> </p>
        </td>
        <td><p>Return elements chosen from <code>x1</code> or <code>x2</code> depending on <code>condition</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="k_while_loop.html">k_while_loop()</a></code> </p>
        </td>
        <td><p>While loop implementation.</p></td>
      </tr><tr><td>
          <p><code><a href="k_zeros.html">k_zeros()</a></code> </p>
        </td>
        <td><p>Return a new tensor of given shape and type, filled with zeros.</p></td>
      </tr><tr><td>
          <p><code><a href="k_zeros_like.html">k_zeros_like()</a></code> </p>
        </td>
        <td><p>Return a tensor of zeros with the same shape and type as <code>x</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="keras-package.html">keras-package</a></code> <code><a href="keras-package.html">_PACKAGE</a></code> </p>
        </td>
        <td><p>R interface to Keras</p></td>
      </tr><tr><td>
          <p><code><a href="keras.html">keras</a></code> </p>
        </td>
        <td><p>Main Keras module</p></td>
      </tr><tr><td>
          <p><code><a href="keras_array.html">keras_array()</a></code> </p>
        </td>
        <td><p>Keras array object</p></td>
      </tr><tr><td>
          <p><code><a href="keras_model.html">keras_model()</a></code> </p>
        </td>
        <td><p>Keras Model</p></td>
      </tr><tr><td>
          <p><code><a href="keras_model_sequential.html">keras_model_sequential()</a></code> </p>
        </td>
        <td><p>Keras Model composed of a linear stack of layers</p></td>
      </tr><tr><td>
          <p><code><a href="layer_activation.html">layer_activation()</a></code> </p>
        </td>
        <td><p>Applies an activation function to an output.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_activation_elu.html">layer_activation_elu()</a></code> </p>
        </td>
        <td><p>Applies an Exponential Linear Unit function to an output.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_activation_leaky_relu.html">layer_activation_leaky_relu()</a></code> </p>
        </td>
        <td><p>Leaky version of a Rectified Linear Unit activation layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_activation_parametric_relu.html">layer_activation_parametric_relu()</a></code> </p>
        </td>
        <td><p>Parametric Rectified Linear Unit activation layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_activation_relu.html">layer_activation_relu()</a></code> </p>
        </td>
        <td><p>Rectified Linear Unit activation function layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_activation_softmax.html">layer_activation_softmax()</a></code> </p>
        </td>
        <td><p>Softmax activation layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_activity_regularization.html">layer_activity_regularization()</a></code> </p>
        </td>
        <td><p>Layer that applies an update to the cost function based input activity.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_add.html">layer_add()</a></code> </p>
        </td>
        <td><p>Performs elementwise addition operation.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_additive_attention.html">layer_additive_attention()</a></code> </p>
        </td>
        <td><p>Additive attention layer, a.k.a. Bahdanau-style attention.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_attention.html">layer_attention()</a></code> </p>
        </td>
        <td><p>Dot-product attention layer, a.k.a. Luong-style attention.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_average.html">layer_average()</a></code> </p>
        </td>
        <td><p>Averages a list of inputs element-wise..</p></td>
      </tr><tr><td>
          <p><code><a href="layer_average_pooling_1d.html">layer_average_pooling_1d()</a></code> </p>
        </td>
        <td><p>Average pooling for temporal data.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_average_pooling_2d.html">layer_average_pooling_2d()</a></code> </p>
        </td>
        <td><p>Average pooling operation for 2D spatial data.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_average_pooling_3d.html">layer_average_pooling_3d()</a></code> </p>
        </td>
        <td><p>Average pooling operation for 3D data (spatial or spatio-temporal).</p></td>
      </tr><tr><td>
          <p><code><a href="layer_batch_normalization.html">layer_batch_normalization()</a></code> </p>
        </td>
        <td><p>Layer that normalizes its inputs.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_bidirectional.html">layer_bidirectional()</a></code> </p>
        </td>
        <td><p>Bidirectional wrapper for RNNs.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_category_encoding.html">layer_category_encoding()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which encodes integer features.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_center_crop.html">layer_center_crop()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which crops images.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_concatenate.html">layer_concatenate()</a></code> </p>
        </td>
        <td><p>Concatenates a list of inputs.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_conv_1d.html">layer_conv_1d()</a></code> </p>
        </td>
        <td><p>1D convolution layer (e.g. temporal convolution).</p></td>
      </tr><tr><td>
          <p><code><a href="layer_conv_1d_transpose.html">layer_conv_1d_transpose()</a></code> </p>
        </td>
        <td><p>1D transposed convolution layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_conv_2d.html">layer_conv_2d()</a></code> </p>
        </td>
        <td><p>2D convolution layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_conv_2d_transpose.html">layer_conv_2d_transpose()</a></code> </p>
        </td>
        <td><p>2D transposed convolution layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_conv_3d.html">layer_conv_3d()</a></code> </p>
        </td>
        <td><p>3D convolution layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_conv_3d_transpose.html">layer_conv_3d_transpose()</a></code> </p>
        </td>
        <td><p>3D transposed convolution layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_conv_lstm_1d.html">layer_conv_lstm_1d()</a></code> </p>
        </td>
        <td><p>1D Convolutional LSTM.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_conv_lstm_2d.html">layer_conv_lstm_2d()</a></code> </p>
        </td>
        <td><p>2D Convolutional LSTM.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_conv_lstm_3d.html">layer_conv_lstm_3d()</a></code> </p>
        </td>
        <td><p>3D Convolutional LSTM.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_cropping_1d.html">layer_cropping_1d()</a></code> </p>
        </td>
        <td><p>Cropping layer for 1D input (e.g. temporal sequence).</p></td>
      </tr><tr><td>
          <p><code><a href="layer_cropping_2d.html">layer_cropping_2d()</a></code> </p>
        </td>
        <td><p>Cropping layer for 2D input (e.g. picture).</p></td>
      </tr><tr><td>
          <p><code><a href="layer_cropping_3d.html">layer_cropping_3d()</a></code> </p>
        </td>
        <td><p>Cropping layer for 3D data (e.g. spatial or spatio-temporal).</p></td>
      </tr><tr><td>
          <p><code><a href="layer_dense.html">layer_dense()</a></code> </p>
        </td>
        <td><p>Just your regular densely-connected NN layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_depthwise_conv_1d.html">layer_depthwise_conv_1d()</a></code> </p>
        </td>
        <td><p>1D depthwise convolution layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_depthwise_conv_2d.html">layer_depthwise_conv_2d()</a></code> </p>
        </td>
        <td><p>2D depthwise convolution layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_discretization.html">layer_discretization()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which buckets continuous features by ranges.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_dot.html">layer_dot()</a></code> </p>
        </td>
        <td><p>Computes element-wise dot product of two tensors.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_dropout.html">layer_dropout()</a></code> </p>
        </td>
        <td><p>Applies dropout to the input.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_einsum_dense.html">layer_einsum_dense()</a></code> </p>
        </td>
        <td><p>A layer that uses <code>einsum</code> as the backing computation.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_embedding.html">layer_embedding()</a></code> </p>
        </td>
        <td><p>Turns positive integers (indexes) into dense vectors of fixed size.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_feature_space.html">layer_feature_space()</a></code> </p>
        </td>
        <td><p>One-stop utility for preprocessing and encoding structured data.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_flatten.html">layer_flatten()</a></code> </p>
        </td>
        <td><p>Flattens the input. Does not affect the batch size.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_gaussian_dropout.html">layer_gaussian_dropout()</a></code> </p>
        </td>
        <td><p>Apply multiplicative 1-centered Gaussian noise.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_gaussian_noise.html">layer_gaussian_noise()</a></code> </p>
        </td>
        <td><p>Apply additive zero-centered Gaussian noise.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_global_average_pooling_1d.html">layer_global_average_pooling_1d()</a></code> </p>
        </td>
        <td><p>Global average pooling operation for temporal data.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_global_average_pooling_2d.html">layer_global_average_pooling_2d()</a></code> </p>
        </td>
        <td><p>Global average pooling operation for 2D data.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_global_average_pooling_3d.html">layer_global_average_pooling_3d()</a></code> </p>
        </td>
        <td><p>Global average pooling operation for 3D data.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_global_max_pooling_1d.html">layer_global_max_pooling_1d()</a></code> </p>
        </td>
        <td><p>Global max pooling operation for temporal data.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_global_max_pooling_2d.html">layer_global_max_pooling_2d()</a></code> </p>
        </td>
        <td><p>Global max pooling operation for 2D data.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_global_max_pooling_3d.html">layer_global_max_pooling_3d()</a></code> </p>
        </td>
        <td><p>Global max pooling operation for 3D data.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_group_normalization.html">layer_group_normalization()</a></code> </p>
        </td>
        <td><p>Group normalization layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_group_query_attention.html">layer_group_query_attention()</a></code> </p>
        </td>
        <td><p>Grouped Query Attention layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_gru.html">layer_gru()</a></code> </p>
        </td>
        <td><p>Gated Recurrent Unit - Cho et al. 2014.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_gru_cell.html">layer_gru_cell()</a></code> </p>
        </td>
        <td><p>Cell class for the GRU layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_hashed_crossing.html">layer_hashed_crossing()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which crosses features using the "hashing trick".</p></td>
      </tr><tr><td>
          <p><code><a href="layer_hashing.html">layer_hashing()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which hashes and bins categorical features.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_identity.html">layer_identity()</a></code> </p>
        </td>
        <td><p>Identity layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_input.html">layer_input()</a></code> </p>
        </td>
        <td><p>Used to instantiate a Keras tensor.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_integer_lookup.html">layer_integer_lookup()</a></code> </p>
        </td>
        <td><p>A preprocessing layer that maps integers to (possibly encoded) indices.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_lambda.html">layer_lambda()</a></code> </p>
        </td>
        <td><p>Wraps arbitrary expressions as a <code>Layer</code> object.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_layer_normalization.html">layer_layer_normalization()</a></code> </p>
        </td>
        <td><p>Layer normalization layer (Ba et al., 2016).</p></td>
      </tr><tr><td>
          <p><code><a href="layer_lstm.html">layer_lstm()</a></code> </p>
        </td>
        <td><p>Long Short-Term Memory layer - Hochreiter 1997.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_lstm_cell.html">layer_lstm_cell()</a></code> </p>
        </td>
        <td><p>Cell class for the LSTM layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_masking.html">layer_masking()</a></code> </p>
        </td>
        <td><p>Masks a sequence by using a mask value to skip timesteps.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_max_pooling_1d.html">layer_max_pooling_1d()</a></code> </p>
        </td>
        <td><p>Max pooling operation for 1D temporal data.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_max_pooling_2d.html">layer_max_pooling_2d()</a></code> </p>
        </td>
        <td><p>Max pooling operation for 2D spatial data.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_max_pooling_3d.html">layer_max_pooling_3d()</a></code> </p>
        </td>
        <td><p>Max pooling operation for 3D data (spatial or spatio-temporal).</p></td>
      </tr><tr><td>
          <p><code><a href="layer_maximum.html">layer_maximum()</a></code> </p>
        </td>
        <td><p>Computes element-wise maximum on a list of inputs.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_minimum.html">layer_minimum()</a></code> </p>
        </td>
        <td><p>Computes elementwise minimum on a list of inputs.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_multi_head_attention.html">layer_multi_head_attention()</a></code> </p>
        </td>
        <td><p>MultiHeadAttention layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_multiply.html">layer_multiply()</a></code> </p>
        </td>
        <td><p>Performs elementwise multiplication.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_normalization.html">layer_normalization()</a></code> </p>
        </td>
        <td><p>A preprocessing layer that normalizes continuous features.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_permute.html">layer_permute()</a></code> </p>
        </td>
        <td><p>Permutes the dimensions of the input according to a given pattern.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_random_brightness.html">layer_random_brightness()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which randomly adjusts brightness during training.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_random_contrast.html">layer_random_contrast()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which randomly adjusts contrast during training.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_random_crop.html">layer_random_crop()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which randomly crops images during training.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_random_flip.html">layer_random_flip()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which randomly flips images during training.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_random_rotation.html">layer_random_rotation()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which randomly rotates images during training.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_random_translation.html">layer_random_translation()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which randomly translates images during training.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_random_zoom.html">layer_random_zoom()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which randomly zooms images during training.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_repeat_vector.html">layer_repeat_vector()</a></code> </p>
        </td>
        <td><p>Repeats the input n times.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_rescaling.html">layer_rescaling()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which rescales input values to a new range.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_reshape.html">layer_reshape()</a></code> </p>
        </td>
        <td><p>Layer that reshapes inputs into the given shape.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_resizing.html">layer_resizing()</a></code> </p>
        </td>
        <td><p>A preprocessing layer which resizes images.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_rnn.html">layer_rnn()</a></code> </p>
        </td>
        <td><p>Base class for recurrent layers.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_separable_conv_1d.html">layer_separable_conv_1d()</a></code> </p>
        </td>
        <td><p>1D separable convolution layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_separable_conv_2d.html">layer_separable_conv_2d()</a></code> </p>
        </td>
        <td><p>2D separable convolution layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_simple_rnn.html">layer_simple_rnn()</a></code> </p>
        </td>
        <td><p>Fully-connected RNN where the output is to be fed back as the new input.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_simple_rnn_cell.html">layer_simple_rnn_cell()</a></code> </p>
        </td>
        <td><p>Cell class for SimpleRNN.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_spatial_dropout_1d.html">layer_spatial_dropout_1d()</a></code> </p>
        </td>
        <td><p>Spatial 1D version of Dropout.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_spatial_dropout_2d.html">layer_spatial_dropout_2d()</a></code> </p>
        </td>
        <td><p>Spatial 2D version of Dropout.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_spatial_dropout_3d.html">layer_spatial_dropout_3d()</a></code> </p>
        </td>
        <td><p>Spatial 3D version of Dropout.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_spectral_normalization.html">layer_spectral_normalization()</a></code> </p>
        </td>
        <td><p>Performs spectral normalization on the weights of a target layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_stacked_rnn_cells.html">layer_stacked_rnn_cells()</a></code> </p>
        </td>
        <td><p>Wrapper allowing a stack of RNN cells to behave as a single cell.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_string_lookup.html">layer_string_lookup()</a></code> </p>
        </td>
        <td><p>A preprocessing layer that maps strings to (possibly encoded) indices.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_subtract.html">layer_subtract()</a></code> </p>
        </td>
        <td><p>Performs elementwise subtraction.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_tfsm.html">layer_tfsm()</a></code> </p>
        </td>
        <td><p>Reload a Keras model/layer that was saved via SavedModel / ExportArchive.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_time_distributed.html">layer_time_distributed()</a></code> </p>
        </td>
        <td><p>This wrapper allows to apply a layer to every temporal slice of an input.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_torch_module_wrapper.html">layer_torch_module_wrapper()</a></code> </p>
        </td>
        <td><p>Torch module wrapper layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_unit_normalization.html">layer_unit_normalization()</a></code> </p>
        </td>
        <td><p>Unit normalization layer.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_upsampling_1d.html">layer_upsampling_1d()</a></code> </p>
        </td>
        <td><p>Upsampling layer for 1D inputs.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_upsampling_2d.html">layer_upsampling_2d()</a></code> </p>
        </td>
        <td><p>Upsampling layer for 2D inputs.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_upsampling_3d.html">layer_upsampling_3d()</a></code> </p>
        </td>
        <td><p>Upsampling layer for 3D inputs.</p></td>
      </tr><tr><td>
          <p><code><a href="layer_zero_padding_1d.html">layer_zero_padding_1d()</a></code> </p>
        </td>
        <td><p>Zero-padding layer for 1D input (e.g. temporal sequence).</p></td>
      </tr><tr><td>
          <p><code><a href="layer_zero_padding_2d.html">layer_zero_padding_2d()</a></code> </p>
        </td>
        <td><p>Zero-padding layer for 2D input (e.g. picture).</p></td>
      </tr><tr><td>
          <p><code><a href="layer_zero_padding_3d.html">layer_zero_padding_3d()</a></code> </p>
        </td>
        <td><p>Zero-padding layer for 3D data (spatial or spatio-temporal).</p></td>
      </tr><tr><td>
          <p><code><a href="learning_rate_schedule_cosine_decay.html">learning_rate_schedule_cosine_decay()</a></code> <code><a href="learning_rate_schedule_cosine_decay.html">learning_rate_schedule_cosine_decay()</a></code> </p>
        </td>
        <td><p>A <code>LearningRateSchedule</code> that uses a cosine decay with optional warmup.</p></td>
      </tr><tr><td>
          <p><code><a href="learning_rate_schedule_cosine_decay_restarts.html">learning_rate_schedule_cosine_decay_restarts()</a></code> <code><a href="learning_rate_schedule_cosine_decay_restarts.html">learning_rate_schedule_cosine_decay_restarts()</a></code> </p>
        </td>
        <td><p>A <code>LearningRateSchedule</code> that uses a cosine decay schedule with restarts.</p></td>
      </tr><tr><td>
          <p><code><a href="learning_rate_schedule_exponential_decay.html">learning_rate_schedule_exponential_decay()</a></code> <code><a href="learning_rate_schedule_exponential_decay.html">learning_rate_schedule_exponential_decay()</a></code> </p>
        </td>
        <td><p>A <code>LearningRateSchedule</code> that uses an exponential decay schedule.</p></td>
      </tr><tr><td>
          <p><code><a href="learning_rate_schedule_inverse_time_decay.html">learning_rate_schedule_inverse_time_decay()</a></code> <code><a href="learning_rate_schedule_inverse_time_decay.html">learning_rate_schedule_inverse_time_decay()</a></code> </p>
        </td>
        <td><p>A <code>LearningRateSchedule</code> that uses an inverse time decay schedule.</p></td>
      </tr><tr><td>
          <p><code><a href="learning_rate_schedule_piecewise_constant_decay.html">learning_rate_schedule_piecewise_constant_decay()</a></code> <code><a href="learning_rate_schedule_piecewise_constant_decay.html">learning_rate_schedule_piecewise_constant_decay()</a></code> </p>
        </td>
        <td><p>A <code>LearningRateSchedule</code> that uses a piecewise constant decay schedule.</p></td>
      </tr><tr><td>
          <p><code><a href="learning_rate_schedule_polynomial_decay.html">learning_rate_schedule_polynomial_decay()</a></code> <code><a href="learning_rate_schedule_polynomial_decay.html">learning_rate_schedule_polynomial_decay()</a></code> </p>
        </td>
        <td><p>A <code>LearningRateSchedule</code> that uses a polynomial decay schedule.</p></td>
      </tr><tr><td>
          <p><code><a href="loss_binary_crossentropy.html">loss_binary_crossentropy()</a></code> </p>
        </td>
        <td><p>Computes the cross-entropy loss between true labels and predicted labels.</p></td>
      </tr><tr><td>
          <p><code><a href="loss_binary_focal_crossentropy.html">loss_binary_focal_crossentropy()</a></code> </p>
        </td>
        <td><p>Computes focal cross-entropy loss between true labels and predictions.</p></td>
      </tr><tr><td>
          <p><code><a href="loss_categorical_crossentropy.html">loss_categorical_crossentropy()</a></code> </p>
        </td>
        <td><p>Computes the crossentropy loss between the labels and predictions.</p></td>
      </tr><tr><td>
          <p><code><a href="loss_categorical_focal_crossentropy.html">loss_categorical_focal_crossentropy()</a></code> </p>
        </td>
        <td><p>Computes the alpha balanced focal crossentropy loss.</p></td>
      </tr><tr><td>
          <p><code><a href="loss_categorical_hinge.html">loss_categorical_hinge()</a></code> </p>
        </td>
        <td><p>Computes the categorical hinge loss between <code>y_true</code> &amp; <code>y_pred</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="loss_cosine_similarity.html">loss_cosine_similarity()</a></code> </p>
        </td>
        <td><p>Computes the cosine similarity between <code>y_true</code> &amp; <code>y_pred</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="loss_hinge.html">loss_hinge()</a></code> </p>
        </td>
        <td><p>Computes the hinge loss between <code>y_true</code> &amp; <code>y_pred</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="loss_huber.html">loss_huber()</a></code> </p>
        </td>
        <td><p>Computes the Huber loss between <code>y_true</code> &amp; <code>y_pred</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="loss_kl_divergence.html">loss_kl_divergence()</a></code> </p>
        </td>
        <td><p>Computes Kullback-Leibler divergence loss between <code>y_true</code> &amp; <code>y_pred</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="loss_log_cosh.html">loss_log_cosh()</a></code> </p>
        </td>
        <td><p>Computes the logarithm of the hyperbolic cosine of the prediction error.</p></td>
      </tr><tr><td>
          <p><code><a href="loss_mean_absolute_error.html">loss_mean_absolute_error()</a></code> </p>
        </td>
        <td><p>Computes the mean of absolute difference between labels and predictions.</p></td>
      </tr><tr><td>
          <p><code><a href="loss_mean_absolute_percentage_error.html">loss_mean_absolute_percentage_error()</a></code> </p>
        </td>
        <td><p>Computes the mean absolute percentage error between <code>y_true</code> &amp; <code>y_pred</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="loss_mean_squared_error.html">loss_mean_squared_error()</a></code> </p>
        </td>
        <td><p>Computes the mean of squares of errors between labels and predictions.</p></td>
      </tr><tr><td>
          <p><code><a href="loss_mean_squared_logarithmic_error.html">loss_mean_squared_logarithmic_error()</a></code> </p>
        </td>
        <td><p>Computes the mean squared logarithmic error between <code>y_true</code> &amp; <code>y_pred</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="loss_poisson.html">loss_poisson()</a></code> </p>
        </td>
        <td><p>Computes the Poisson loss between <code>y_true</code> &amp; <code>y_pred</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="loss_sparse_categorical_crossentropy.html">loss_sparse_categorical_crossentropy()</a></code> </p>
        </td>
        <td><p>Computes the crossentropy loss between the labels and predictions.</p></td>
      </tr><tr><td>
          <p><code><a href="loss_squared_hinge.html">loss_squared_hinge()</a></code> </p>
        </td>
        <td><p>Computes the squared hinge loss between <code>y_true</code> &amp; <code>y_pred</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="save_model_hdf5.html">save_model_hdf5()</a></code> <code><a href="save_model_hdf5.html">load_model_hdf5()</a></code> </p>
        </td>
        <td><p>Save/Load models using HDF5 files</p></td>
      </tr><tr><td>
          <p><code><a href="save_model_tf.html">save_model_tf()</a></code> <code><a href="save_model_tf.html">load_model_tf()</a></code> </p>
        </td>
        <td><p>Save/Load models using SavedModel format</p></td>
      </tr><tr><td>
          <p><code><a href="save_model_weights_hdf5.html">save_model_weights_hdf5()</a></code> <code><a href="save_model_weights_hdf5.html">load_model_weights_hdf5()</a></code> </p>
        </td>
        <td><p>Save/Load model weights using HDF5 files</p></td>
      </tr><tr><td>
          <p><code><a href="save_model_weights_tf.html">save_model_weights_tf()</a></code> <code><a href="save_model_weights_tf.html">load_model_weights_tf()</a></code> </p>
        </td>
        <td><p>Save model weights in the SavedModel format</p></td>
      </tr><tr><td>
          <p><code><a href="metric_auc.html">metric_auc()</a></code> </p>
        </td>
        <td><p>Approximates the AUC (Area under the curve) of the ROC or PR curves.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_binary_accuracy.html">metric_binary_accuracy()</a></code> </p>
        </td>
        <td><p>Calculates how often predictions match binary labels.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_binary_crossentropy.html">metric_binary_crossentropy()</a></code> </p>
        </td>
        <td><p>Computes the crossentropy metric between the labels and predictions.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_binary_focal_crossentropy.html">metric_binary_focal_crossentropy()</a></code> </p>
        </td>
        <td><p>Computes the binary focal crossentropy loss.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_binary_iou.html">metric_binary_iou()</a></code> </p>
        </td>
        <td><p>Computes the Intersection-Over-Union metric for class 0 and/or 1.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_categorical_accuracy.html">metric_categorical_accuracy()</a></code> </p>
        </td>
        <td><p>Calculates how often predictions match one-hot labels.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_categorical_crossentropy.html">metric_categorical_crossentropy()</a></code> </p>
        </td>
        <td><p>Computes the crossentropy metric between the labels and predictions.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_categorical_focal_crossentropy.html">metric_categorical_focal_crossentropy()</a></code> </p>
        </td>
        <td><p>Computes the categorical focal crossentropy loss.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_categorical_hinge.html">metric_categorical_hinge()</a></code> </p>
        </td>
        <td><p>Computes the categorical hinge metric between <code>y_true</code> and <code>y_pred</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_cosine_similarity.html">metric_cosine_similarity()</a></code> </p>
        </td>
        <td><p>Computes the cosine similarity between the labels and predictions.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_f1_score.html">metric_f1_score()</a></code> </p>
        </td>
        <td><p>Computes F-1 Score.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_false_negatives.html">metric_false_negatives()</a></code> </p>
        </td>
        <td><p>Calculates the number of false negatives.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_false_positives.html">metric_false_positives()</a></code> </p>
        </td>
        <td><p>Calculates the number of false positives.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_fbeta_score.html">metric_fbeta_score()</a></code> </p>
        </td>
        <td><p>Computes F-Beta score.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_hinge.html">metric_hinge()</a></code> </p>
        </td>
        <td><p>Computes the hinge metric between <code>y_true</code> and <code>y_pred</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_huber.html">metric_huber()</a></code> </p>
        </td>
        <td><p>Computes Huber loss value.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_iou.html">metric_iou()</a></code> </p>
        </td>
        <td><p>Computes the Intersection-Over-Union metric for specific target classes.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_kl_divergence.html">metric_kl_divergence()</a></code> </p>
        </td>
        <td><p>Computes Kullback-Leibler divergence metric between <code>y_true</code> and</p></td>
      </tr><tr><td>
          <p><code><a href="metric_log_cosh.html">metric_log_cosh()</a></code> </p>
        </td>
        <td><p>Logarithm of the hyperbolic cosine of the prediction error.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_log_cosh_error.html">metric_log_cosh_error()</a></code> </p>
        </td>
        <td><p>Computes the logarithm of the hyperbolic cosine of the prediction error.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_mean.html">metric_mean()</a></code> </p>
        </td>
        <td><p>Compute the (weighted) mean of the given values.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_mean_absolute_error.html">metric_mean_absolute_error()</a></code> </p>
        </td>
        <td><p>Computes the mean absolute error between the labels and predictions.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_mean_absolute_percentage_error.html">metric_mean_absolute_percentage_error()</a></code> </p>
        </td>
        <td><p>Computes mean absolute percentage error between <code>y_true</code> and <code>y_pred</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_mean_iou.html">metric_mean_iou()</a></code> </p>
        </td>
        <td><p>Computes the mean Intersection-Over-Union metric.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_mean_squared_error.html">metric_mean_squared_error()</a></code> </p>
        </td>
        <td><p>Computes the mean squared error between <code>y_true</code> and <code>y_pred</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_mean_squared_logarithmic_error.html">metric_mean_squared_logarithmic_error()</a></code> </p>
        </td>
        <td><p>Computes mean squared logarithmic error between <code>y_true</code> and <code>y_pred</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_mean_wrapper.html">metric_mean_wrapper()</a></code> </p>
        </td>
        <td><p>Wrap a stateless metric function with the Mean metric.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_one_hot_iou.html">metric_one_hot_iou()</a></code> </p>
        </td>
        <td><p>Computes the Intersection-Over-Union metric for one-hot encoded labels.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_one_hot_mean_iou.html">metric_one_hot_mean_iou()</a></code> </p>
        </td>
        <td><p>Computes mean Intersection-Over-Union metric for one-hot encoded labels.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_poisson.html">metric_poisson()</a></code> </p>
        </td>
        <td><p>Computes the Poisson metric between <code>y_true</code> and <code>y_pred</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_precision.html">metric_precision()</a></code> </p>
        </td>
        <td><p>Computes the precision of the predictions with respect to the labels.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_precision_at_recall.html">metric_precision_at_recall()</a></code> </p>
        </td>
        <td><p>Computes best precision where recall is &gt;= specified value.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_r2_score.html">metric_r2_score()</a></code> </p>
        </td>
        <td><p>Computes R2 score.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_recall.html">metric_recall()</a></code> </p>
        </td>
        <td><p>Computes the recall of the predictions with respect to the labels.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_recall_at_precision.html">metric_recall_at_precision()</a></code> </p>
        </td>
        <td><p>Computes best recall where precision is &gt;= specified value.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_root_mean_squared_error.html">metric_root_mean_squared_error()</a></code> </p>
        </td>
        <td><p>Computes root mean squared error metric between <code>y_true</code> and <code>y_pred</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_sensitivity_at_specificity.html">metric_sensitivity_at_specificity()</a></code> </p>
        </td>
        <td><p>Computes best sensitivity where specificity is &gt;= specified value.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_sparse_categorical_accuracy.html">metric_sparse_categorical_accuracy()</a></code> </p>
        </td>
        <td><p>Calculates how often predictions match integer labels.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_sparse_categorical_crossentropy.html">metric_sparse_categorical_crossentropy()</a></code> </p>
        </td>
        <td><p>Computes the crossentropy metric between the labels and predictions.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_sparse_top_k_categorical_accuracy.html">metric_sparse_top_k_categorical_accuracy()</a></code> </p>
        </td>
        <td><p>Computes how often integer targets are in the top <code>K</code> predictions.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_specificity_at_sensitivity.html">metric_specificity_at_sensitivity()</a></code> </p>
        </td>
        <td><p>Computes best specificity where sensitivity is &gt;= specified value.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_squared_hinge.html">metric_squared_hinge()</a></code> </p>
        </td>
        <td><p>Computes the hinge metric between <code>y_true</code> and <code>y_pred</code>.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_sum.html">metric_sum()</a></code> </p>
        </td>
        <td><p>Compute the (weighted) sum of the given values.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_top_k_categorical_accuracy.html">metric_top_k_categorical_accuracy()</a></code> </p>
        </td>
        <td><p>Computes how often targets are in the top <code>K</code> predictions.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_true_negatives.html">metric_true_negatives()</a></code> </p>
        </td>
        <td><p>Calculates the number of true negatives.</p></td>
      </tr><tr><td>
          <p><code><a href="metric_true_positives.html">metric_true_positives()</a></code> </p>
        </td>
        <td><p>Calculates the number of true positives.</p></td>
      </tr><tr><td>
          <p><code><a href="model_from_saved_model.html">model_from_saved_model()</a></code> </p>
        </td>
        <td><p>Load a Keras model from the Saved Model format</p></td>
      </tr><tr><td>
          <p><code><a href="model_to_dot.html">model_to_dot()</a></code> </p>
        </td>
        <td><p>Convert a Keras model to dot format.</p></td>
      </tr><tr><td>
          <p><code><a href="model_to_json.html">model_to_json()</a></code> <code><a href="model_to_json.html">model_from_json()</a></code> </p>
        </td>
        <td><p>Model configuration as JSON</p></td>
      </tr><tr><td>
          <p><code><a href="model_to_yaml.html">model_to_yaml()</a></code> <code><a href="model_to_yaml.html">model_from_yaml()</a></code> </p>
        </td>
        <td><p>Model configuration as YAML</p></td>
      </tr><tr><td>
          <p><code><a href="new-classes.html">new_metric_class()</a></code> <code><a href="new-classes.html">new_loss_class()</a></code> <code><a href="new-classes.html">new_callback_class()</a></code> <code><a href="new-classes.html">new_model_class()</a></code> <code><a href="new-classes.html">new_layer_class()</a></code> <code><a href="new-classes.html">mark_active()</a></code> </p>
        </td>
        <td><p>Define new keras types</p></td>
      </tr><tr><td>
          <p><code><a href="new_learning_rate_schedule_class.html">new_learning_rate_schedule_class()</a></code> </p>
        </td>
        <td><p>Create a new learning rate schedule type</p></td>
      </tr><tr><td>
          <p><code><a href="normalize.html">normalize()</a></code> </p>
        </td>
        <td><p>Normalizes an array.</p></td>
      </tr><tr><td>
          <p><code><a href="optimizer_adadelta.html">optimizer_adadelta()</a></code> </p>
        </td>
        <td><p>Optimizer that implements the Adadelta algorithm.</p></td>
      </tr><tr><td>
          <p><code><a href="optimizer_adafactor.html">optimizer_adafactor()</a></code> </p>
        </td>
        <td><p>Optimizer that implements the Adafactor algorithm.</p></td>
      </tr><tr><td>
          <p><code><a href="optimizer_adagrad.html">optimizer_adagrad()</a></code> </p>
        </td>
        <td><p>Optimizer that implements the Adagrad algorithm.</p></td>
      </tr><tr><td>
          <p><code><a href="optimizer_adam.html">optimizer_adam()</a></code> </p>
        </td>
        <td><p>Optimizer that implements the Adam algorithm.</p></td>
      </tr><tr><td>
          <p><code><a href="optimizer_adam_w.html">optimizer_adam_w()</a></code> </p>
        </td>
        <td><p>Optimizer that implements the AdamW algorithm.</p></td>
      </tr><tr><td>
          <p><code><a href="optimizer_adamax.html">optimizer_adamax()</a></code> </p>
        </td>
        <td><p>Optimizer that implements the Adamax algorithm.</p></td>
      </tr><tr><td>
          <p><code><a href="optimizer_ftrl.html">optimizer_ftrl()</a></code> </p>
        </td>
        <td><p>Optimizer that implements the FTRL algorithm.</p></td>
      </tr><tr><td>
          <p><code><a href="optimizer_lion.html">optimizer_lion()</a></code> </p>
        </td>
        <td><p>Optimizer that implements the Lion algorithm.</p></td>
      </tr><tr><td>
          <p><code><a href="optimizer_loss_scale.html">optimizer_loss_scale()</a></code> </p>
        </td>
        <td><p>An optimizer that dynamically scales the loss to prevent underflow.</p></td>
      </tr><tr><td>
          <p><code><a href="optimizer_nadam.html">optimizer_nadam()</a></code> </p>
        </td>
        <td><p>Optimizer that implements the Nadam algorithm.</p></td>
      </tr><tr><td>
          <p><code><a href="optimizer_rmsprop.html">optimizer_rmsprop()</a></code> </p>
        </td>
        <td><p>Optimizer that implements the RMSprop algorithm.</p></td>
      </tr><tr><td>
          <p><code><a href="optimizer_sgd.html">optimizer_sgd()</a></code> </p>
        </td>
        <td><p>Gradient descent (with momentum) optimizer.</p></td>
      </tr><tr><td>
          <p><code><a href="grapes-py_class-grapes.html">`%py_class%`</a></code> </p>
        </td>
        <td><p>Make a python class constructor</p></td>
      </tr><tr><td>
          <p><code><a href="pack_x_y_sample_weight.html">pack_x_y_sample_weight()</a></code> </p>
        </td>
        <td><p>Packs user-provided data into a tuple.</p></td>
      </tr><tr><td>
          <p><code><a href="pad_sequences.html">pad_sequences()</a></code> </p>
        </td>
        <td><p>Pads sequences to the same length.</p></td>
      </tr><tr><td>
          <p><code><a href="plot.keras.models.model.Model.html">plot(<i>&lt;keras.models.model.Model&gt;</i>)</a></code> </p>
        </td>
        <td><p>Plot a Keras model</p></td>
      </tr><tr><td>
          <p><code><a href="plot.keras_training_history.html">plot(<i>&lt;keras_training_history&gt;</i>)</a></code> </p>
        </td>
        <td><p>Plot training history</p></td>
      </tr><tr><td>
          <p><code><a href="pop_layer.html">pop_layer()</a></code> </p>
        </td>
        <td><p>Remove the last layer in a model</p></td>
      </tr><tr><td>
          <p><code><a href="predict.keras.models.model.Model.html">predict(<i>&lt;keras.models.model.Model&gt;</i>)</a></code> </p>
        </td>
        <td><p>Generate predictions from a Keras model</p></td>
      </tr><tr><td>
          <p><code><a href="predict_on_batch.html">predict_on_batch()</a></code> </p>
        </td>
        <td><p>Returns predictions for a single batch of samples.</p></td>
      </tr><tr><td>
          <p><code><a href="random_categorical.html">random_categorical()</a></code> </p>
        </td>
        <td><p>Draws samples from a categorical distribution.</p></td>
      </tr><tr><td>
          <p><code><a href="random_dropout.html">random_dropout()</a></code> </p>
        </td>
        <td><p>random dropout</p></td>
      </tr><tr><td>
          <p><code><a href="random_integer.html">random_integer()</a></code> </p>
        </td>
        <td><p>Draw random integers from a uniform distribution.</p></td>
      </tr><tr><td>
          <p><code><a href="random_normal.html">random_normal()</a></code> </p>
        </td>
        <td><p>Draw random samples from a normal (Gaussian) distribution.</p></td>
      </tr><tr><td>
          <p><code><a href="random_seed_generator.html">random_seed_generator()</a></code> </p>
        </td>
        <td><p>Generates variable seeds upon each call to a RNG-using function.</p></td>
      </tr><tr><td>
          <p><code><a href="random_shuffle.html">random_shuffle()</a></code> </p>
        </td>
        <td><p>Shuffle the elements of a tensor uniformly at random along an axis.</p></td>
      </tr><tr><td>
          <p><code><a href="random_truncated_normal.html">random_truncated_normal()</a></code> </p>
        </td>
        <td><p>Draw samples from a truncated normal distribution.</p></td>
      </tr><tr><td>
          <p><code><a href="random_uniform.html">random_uniform()</a></code> </p>
        </td>
        <td><p>Draw samples from a uniform distribution.</p></td>
      </tr><tr><td>
          <p><code><a href="regularizer_l1.html">regularizer_l1()</a></code> </p>
        </td>
        <td><p>A regularizer that applies a L1 regularization penalty.</p></td>
      </tr><tr><td>
          <p><code><a href="regularizer_l1_l2.html">regularizer_l1_l2()</a></code> </p>
        </td>
        <td><p>A regularizer that applies both L1 and L2 regularization penalties.</p></td>
      </tr><tr><td>
          <p><code><a href="regularizer_l2.html">regularizer_l2()</a></code> </p>
        </td>
        <td><p>A regularizer that applies a L2 regularization penalty.</p></td>
      </tr><tr><td>
          <p><code><a href="regularizer_orthogonal.html">regularizer_orthogonal()</a></code> </p>
        </td>
        <td><p>Regularizer that encourages input vectors to be orthogonal to each other.</p></td>
      </tr><tr><td>
          <p><code><a href="reset_states.html">reset_states()</a></code> </p>
        </td>
        <td><p>Reset the states for a layer</p></td>
      </tr><tr><td>
          <p><code><a href="serialize_model.html">serialize_model()</a></code> <code><a href="serialize_model.html">unserialize_model()</a></code> </p>
        </td>
        <td><p>Serialize a model to an R object</p></td>
      </tr><tr><td>
          <p><code><a href="set_random_seed.html">set_random_seed()</a></code> </p>
        </td>
        <td><p>Sets all random seeds (Python, NumPy, and backend framework, e.g. TF).</p></td>
      </tr><tr><td>
          <p><code><a href="split_dataset.html">split_dataset()</a></code> </p>
        </td>
        <td><p>Splits a dataset into a left half and a right half (e.g. train / test).</p></td>
      </tr><tr><td>
          <p><code><a href="text_dataset_from_directory.html">text_dataset_from_directory()</a></code> </p>
        </td>
        <td><p>Generates a <code>tf.data.Dataset</code> from text files in a directory.</p></td>
      </tr><tr><td>
          <p><code><a href="time_distributed.html">time_distributed()</a></code> </p>
        </td>
        <td><p>This layer wrapper allows to apply a layer to every temporal slice of an input</p></td>
      </tr><tr><td>
          <p><code><a href="timeseries_dataset_from_array.html">timeseries_dataset_from_array()</a></code> </p>
        </td>
        <td><p>Creates a dataset of sliding windows over a timeseries provided as array.</p></td>
      </tr><tr><td>
          <p><code><a href="timeseries_generator.html">timeseries_generator()</a></code> </p>
        </td>
        <td><p>Utility function for generating batches of temporal data.</p></td>
      </tr><tr><td>
          <p><code><a href="to_categorical.html">to_categorical()</a></code> </p>
        </td>
        <td><p>Converts a class vector (integers) to binary class matrix.</p></td>
      </tr><tr><td>
          <p><code><a href="train_on_batch.html">train_on_batch()</a></code> <code><a href="train_on_batch.html">test_on_batch()</a></code> </p>
        </td>
        <td><p>Single gradient update or model evaluation over one batch of samples.</p></td>
      </tr><tr><td>
          <p><code><a href="unpack_x_y_sample_weight.html">unpack_x_y_sample_weight()</a></code> </p>
        </td>
        <td><p>Unpacks user-provided data tuple.</p></td>
      </tr><tr><td>
          <p><code><a href="use_implementation.html">use_implementation()</a></code> <code><a href="use_implementation.html">use_backend()</a></code> </p>
        </td>
        <td><p>Select a Keras implementation and backend</p></td>
      </tr><tr><td>
          <p><code><a href="with_custom_object_scope.html">with_custom_object_scope()</a></code> </p>
        </td>
        <td><p>Provide a scope with mappings of names to custom objects</p></td>
      </tr><tr><td>
          <p><code><a href="zip_lists.html">zip_lists()</a></code> </p>
        </td>
        <td><p>zip lists</p></td>
      </tr><tr><td>
          <p><code><a href="Metric.html">Metric</a></code> </p>
        </td>
        <td><p>Metric</p></td>
      </tr></tbody><tbody><tr><th colspan="2">
          <h2 id="deprecated">Deprecated <a href="#deprecated" class="anchor" aria-hidden="true"></a></h2>
          <p class="section-desc"></p>
        </th>
      </tr></tbody><tbody><tr><td>
          <p><code><a href="KerasLayer.html">KerasLayer</a></code> </p>
        </td>
        <td><p>(Deprecated) Base R6 class for Keras layers</p></td>
      </tr><tr><td>
          <p><code><a href="adapt.html">adapt()</a></code> </p>
        </td>
        <td><p>Fits the state of the preprocessing layer to the data being passed</p></td>
      </tr><tr><td>
          <p><code><a href="bidirectional.html">bidirectional()</a></code> </p>
        </td>
        <td><p>Bidirectional wrapper for RNNs</p></td>
      </tr><tr><td>
          <p><code><a href="keras-package.html">keras-package</a></code> <code><a href="keras-package.html">_PACKAGE</a></code> </p>
        </td>
        <td><p>R interface to Keras</p></td>
      </tr><tr><td>
          <p><code><a href="time_distributed.html">time_distributed()</a></code> </p>
        </td>
        <td><p>This layer wrapper allows to apply a layer to every temporal slice of an input</p></td>
      </tr></tbody></table></div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top"><h2 data-toc-skip>Contents</h2>
    </nav></div>
</div>


      <footer><div class="copyright">
  <p></p><p>Developed by Tomasz Kalinowski, JJ Allaire, FranÃ§ois Chollet, RStudio, Google.</p>
</div>

<div class="pkgdown">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

      </footer></div>

  


  

  </body></html>

