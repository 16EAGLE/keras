<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="Training a timeseries classifier from scratch on the FordA dataset from the UCR/UEA archive.">
<title>Timeseries classification from scratch • keras3</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../../../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../../../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../../../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../../../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../../../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../../../apple-touch-icon-60x60.png">
<script src="../../../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../../../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../../../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../../../deps/Fira_Mono-0.4.9/font.css" rel="stylesheet">
<!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../../../pkgdown.js"></script><meta property="og:title" content="Timeseries classification from scratch">
<meta property="og:description" content="Training a timeseries classifier from scratch on the FordA dataset from the UCR/UEA archive.">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-inverse navbar-expand-lg bg-primary"><div class="container">
    
    <a class="navbar-brand me-2" href="../../../index.html">keras3</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.0.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../../../articles/getting_started.html">Getting Started</a>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-guides">Guides</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-guides">
    <h6 class="dropdown-header" data-toc-skip>Model definition</h6>
    <a class="dropdown-item" href="../../../articles/sequential_model.html">Sequential Model</a>
    <a class="dropdown-item" href="../../../articles/functional_api.html">Functional API</a>
    <h6 class="dropdown-header" data-toc-skip>Extending and customizing</h6>
    <a class="dropdown-item" href="../../../articles/training_with_built_in_methods.html">Training &amp; evaluation with the built-in methods</a>
    <a class="dropdown-item" href="../../../articles/custom_train_step_in_tensorflow.html">Customizing `fit()` with Tensorflow</a>
    <a class="dropdown-item" href="../../../articles/writing_your_own_callbacks.html">Writing your own callbacks</a>
    <a class="dropdown-item" href="../../../articles/making_new_layers_and_models_via_subclassing.html">Making new layers and models via subclassing</a>
    <a class="dropdown-item" href="../../../articles/writing_a_custom_training_loop_in_tensorflow.html">Writing a training loop from scratch in TensorFlow</a>
    <a class="dropdown-item" href="../../../articles/serialization_and_saving.html">Serialization and Saving</a>
    <h6 class="dropdown-header" data-toc-skip>Other topics</h6>
    <a class="dropdown-item" href="../../../articles/transfer_learning.html">Transfer learning and fine tuning</a>
    <a class="dropdown-item" href="../../../articles/distributed_training_with_tensorflow.html">Distributed training with TensorFlow</a>
    <a class="dropdown-item" href="../../../articles/distribution.html">Distributed training with Jax</a>
  </div>
</li>
<li class="active nav-item">
  <a class="nav-link" href="../../../articles/examples/index.html">Examples</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../../reference/index.html">Reference</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../../../news/index.html">News</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../../../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/rstudio/keras/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Timeseries classification from scratch</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/rstudio/keras/blob/HEAD/vignettes/examples/timeseries/timeseries_classification_from_scratch.Rmd" class="external-link"><code>vignettes/examples/timeseries/timeseries_classification_from_scratch.Rmd</code></a></small>
      <div class="d-none name"><code>timeseries_classification_from_scratch.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>This example shows how to do timeseries classification from scratch,
starting from raw CSV timeseries files on disk. We demonstrate the
workflow on the FordA dataset from the <a href="https://www.cs.ucr.edu/%7Eeamonn/time_series_data_2018/" class="external-link">UCR/UEA
archive</a>.</p>
</div>
<div class="section level2">
<h2 id="setup">Setup<a class="anchor" aria-label="anchor" href="#setup"></a>
</h2>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://keras.posit.co/">keras3</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="../../../reference/use_backend.html">use_backend</a></span><span class="op">(</span><span class="st">"jax"</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="load-the-data-the-forda-dataset">Load the data: the FordA dataset<a class="anchor" aria-label="anchor" href="#load-the-data-the-forda-dataset"></a>
</h2>
<div class="section level3">
<h3 id="dataset-description">Dataset description<a class="anchor" aria-label="anchor" href="#dataset-description"></a>
</h3>
<p>The dataset we are using here is called FordA. The data comes from
the UCR archive. The dataset contains 3601 training instances and
another 1320 testing instances. Each timeseries corresponds to a
measurement of engine noise captured by a motor sensor. For this task,
the goal is to automatically detect the presence of a specific issue
with the engine. The problem is a balanced binary classification task.
The full description of this dataset can be found <a href="http://www.j-wichard.de/publications/FordPaper.pdf" class="external-link">here</a>.</p>
</div>
<div class="section level3">
<h3 id="read-the-tsv-data">Read the TSV data<a class="anchor" aria-label="anchor" href="#read-the-tsv-data"></a>
</h3>
<p>We will use the <code>FordA_TRAIN</code> file for training and the
<code>FordA_TEST</code> file for testing. The simplicity of this dataset
allows us to demonstrate effectively how to use ConvNets for timeseries
classification. In this file, the first column corresponds to the
label.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">get_data</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">path</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="kw">if</span><span class="op">(</span><span class="va">path</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/base/startsWith.html" class="external-link">startsWith</a></span><span class="op">(</span><span class="st">"https://"</span><span class="op">)</span><span class="op">)</span></span>
<span>    <span class="va">path</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../../reference/get_file.html">get_file</a></span><span class="op">(</span>origin <span class="op">=</span> <span class="va">path</span><span class="op">)</span>  <span class="co"># cache file locally</span></span>
<span></span>
<span>  <span class="va">data</span> <span class="op">&lt;-</span> <span class="fu">readr</span><span class="fu">::</span><span class="fu"><a href="https://readr.tidyverse.org/reference/read_delim.html" class="external-link">read_tsv</a></span><span class="op">(</span></span>
<span>    <span class="va">path</span>, col_names <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>    <span class="co"># Each row is: one integer (the label),</span></span>
<span>    <span class="co"># followed by 500 doubles (the timeseries)</span></span>
<span>    col_types <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="st">"i"</span>, <span class="fu"><a href="https://rdrr.io/r/base/strrep.html" class="external-link">strrep</a></span><span class="op">(</span><span class="st">"d"</span>, <span class="fl">500</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span></span>
<span>  <span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">data</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">)</span></span>
<span>  <span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">data</span><span class="op">[</span>,<span class="op">-</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/dimnames.html" class="external-link">dimnames</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/dimnames.html" class="external-link">dimnames</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="cn">NULL</span></span>
<span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">root_url</span> <span class="op">&lt;-</span> <span class="st">"https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/"</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">x_train</span>, <span class="va">y_train</span><span class="op">)</span> <span class="op"><a href="../../../reference/multi-assign.html">%&lt;-%</a></span> <span class="fu">get_data</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="va">root_url</span>, <span class="st">"FordA_TRAIN.tsv"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">x_test</span>, <span class="va">y_test</span><span class="op">)</span> <span class="op"><a href="../../../reference/multi-assign.html">%&lt;-%</a></span> <span class="fu">get_data</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="va">root_url</span>, <span class="st">"FordA_TEST.tsv"</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="fu">keras3</span><span class="fu">:::</span><span class="fu">named_list</span><span class="op">(</span></span>
<span>  <span class="va">x_train</span>, <span class="va">y_train</span>,</span>
<span>  <span class="va">x_test</span>, <span class="va">y_test</span></span>
<span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## List of 4</span></span>
<span><span class="co">##  $ x_train: num [1:3601, 1:500] -0.797 0.805 0.728 -0.234 -0.171 ...</span></span>
<span><span class="co">##  $ y_train: int [1:3601, 1] -1 1 -1 -1 -1 1 1 1 1 1 ...</span></span>
<span><span class="co">##  $ x_test : num [1:1320, 1:500] -0.14 0.334 0.717 1.24 -1.159 ...</span></span>
<span><span class="co">##  $ y_test : int [1:1320, 1] -1 -1 -1 1 -1 1 -1 -1 1 1 ...</span></span></code></pre>
</div>
</div>
<div class="section level2">
<h2 id="visualize-the-data">Visualize the data<a class="anchor" aria-label="anchor" href="#visualize-the-data"></a>
</h2>
<p>Here we visualize one timeseries example for each class in the
dataset.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="cn">NULL</span>, main <span class="op">=</span> <span class="st">"Timeseries Data"</span>,</span>
<span>     xlab <span class="op">=</span> <span class="st">"Timepoints"</span>,  ylab <span class="op">=</span> <span class="st">"Values"</span>,</span>
<span>     xlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">x_test</span><span class="op">)</span><span class="op">)</span>,</span>
<span>     ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/range.html" class="external-link">range</a></span><span class="op">(</span><span class="va">x_test</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/grid.html" class="external-link">grid</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span><span class="va">x_test</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/match.html" class="external-link">match</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>, <span class="va">y_test</span><span class="op">)</span>, <span class="op">]</span>, col <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span><span class="va">x_test</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/match.html" class="external-link">match</a></span><span class="op">(</span> <span class="fl">1</span>, <span class="va">y_test</span><span class="op">)</span>, <span class="op">]</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/legend.html" class="external-link">legend</a></span><span class="op">(</span><span class="st">"topright"</span>, legend<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"label -1"</span>, <span class="st">"label 1"</span><span class="op">)</span>, col<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"blue"</span>, <span class="st">"red"</span><span class="op">)</span>, lty<span class="op">=</span><span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="timeseries_classification_from_scratch/unnamed-chunk-3-1.png" alt="plot of chunk unnamed-chunk-3"><div class="figcaption">plot of chunk unnamed-chunk-3</div>
</div>
</div>
<div class="section level2">
<h2 id="standardize-the-data">Standardize the data<a class="anchor" aria-label="anchor" href="#standardize-the-data"></a>
</h2>
<p>Our timeseries are already in a single length (500). However, their
values are usually in various ranges. This is not ideal for a neural
network; in general we should seek to make the input values normalized.
For this specific dataset, the data is already z-normalized: each
timeseries sample has a mean equal to zero and a standard deviation
equal to one. This type of normalization is very common for timeseries
classification problems, see <a href="https://link.springer.com/article/10.1007/s10618-016-0483-9" class="external-link">Bagnall
et al. (2016)</a>.</p>
<p>Note that the timeseries data used here are univariate, meaning we
only have one channel per timeseries example. We will therefore
transform the timeseries into a multivariate one with one channel using
a simple reshaping via numpy. This will allow us to construct a model
that is easily applicable to multivariate time series.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">x_train</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">x_train</span><span class="op">)</span>, <span class="fl">1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">x_test</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">x_test</span><span class="op">)</span>, <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<p>Finally, in order to use
<code>sparse_categorical_crossentropy</code>, we will have to count the
number of classes beforehand.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">num_classes</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/unique.html" class="external-link">unique</a></span><span class="op">(</span><span class="va">y_train</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>Now we shuffle the training set because we will be using the
<code>validation_split</code> option later when training.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">x_train</span>, <span class="va">y_train</span><span class="op">)</span> <span class="op"><a href="../../../reference/multi-assign.html">%&lt;-%</a></span> <span class="fu">listarrays</span><span class="fu">::</span><span class="fu"><a href="https://t-kalinowski.github.io/listarrays/reference/shuffle_rows.html" class="external-link">shuffle_rows</a></span><span class="op">(</span><span class="va">x_train</span>, <span class="va">y_train</span><span class="op">)</span></span>
<span><span class="co"># idx &lt;- sample.int(nrow(x_train))</span></span>
<span><span class="co"># x_train %&lt;&gt;% .[idx,, ,drop = FALSE]</span></span>
<span><span class="co"># y_train %&lt;&gt;% .[idx,  ,drop = FALSE]</span></span></code></pre></div>
<p>Standardize the labels to positive integers. The expected labels will
then be 0 and 1.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">y_train</span><span class="op">[</span><span class="va">y_train</span> <span class="op">==</span> <span class="op">-</span><span class="fl">1L</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fl">0L</span></span>
<span><span class="va">y_test</span><span class="op">[</span><span class="va">y_test</span> <span class="op">==</span> <span class="op">-</span><span class="fl">1L</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fl">0L</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="build-a-model">Build a model<a class="anchor" aria-label="anchor" href="#build-a-model"></a>
</h2>
<p>We build a Fully Convolutional Neural Network originally proposed in
<a href="https://arxiv.org/abs/1611.06455" class="external-link">this paper</a>. The
implementation is based on the TF 2 version provided <a href="https://github.com/hfawaz/dl-4-tsc/" class="external-link">here</a>. The following
hyperparameters (kernel_size, filters, the usage of BatchNorm) were
found via random search using <a href="https://github.com/keras-team/keras-tuner" class="external-link">KerasTuner</a>.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">make_model</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">input_shape</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">inputs</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../../reference/keras_input.html">keras_input</a></span><span class="op">(</span><span class="va">input_shape</span><span class="op">)</span></span>
<span></span>
<span>  <span class="va">outputs</span> <span class="op">&lt;-</span> <span class="va">inputs</span> <span class="op">|&gt;</span></span>
<span>    <span class="co"># conv1</span></span>
<span>    <span class="fu"><a href="../../../reference/layer_conv_1d.html">layer_conv_1d</a></span><span class="op">(</span>filters <span class="op">=</span> <span class="fl">64</span>, kernel_size <span class="op">=</span> <span class="fl">3</span>, padding <span class="op">=</span> <span class="st">"same"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="../../../reference/layer_batch_normalization.html">layer_batch_normalization</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="../../../reference/layer_activation_relu.html">layer_activation_relu</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="co"># conv2</span></span>
<span>    <span class="fu"><a href="../../../reference/layer_conv_1d.html">layer_conv_1d</a></span><span class="op">(</span>filters <span class="op">=</span> <span class="fl">64</span>, kernel_size <span class="op">=</span> <span class="fl">3</span>, padding <span class="op">=</span> <span class="st">"same"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="../../../reference/layer_batch_normalization.html">layer_batch_normalization</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="../../../reference/layer_activation_relu.html">layer_activation_relu</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="co"># conv3</span></span>
<span>    <span class="fu"><a href="../../../reference/layer_conv_1d.html">layer_conv_1d</a></span><span class="op">(</span>filters <span class="op">=</span> <span class="fl">64</span>, kernel_size <span class="op">=</span> <span class="fl">3</span>, padding <span class="op">=</span> <span class="st">"same"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="../../../reference/layer_batch_normalization.html">layer_batch_normalization</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="../../../reference/layer_activation_relu.html">layer_activation_relu</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="co"># pooling</span></span>
<span>    <span class="fu"><a href="../../../reference/layer_global_average_pooling_1d.html">layer_global_average_pooling_1d</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="co"># final output</span></span>
<span>    <span class="fu"><a href="../../../reference/layer_dense.html">layer_dense</a></span><span class="op">(</span><span class="va">num_classes</span>, activation <span class="op">=</span> <span class="st">"softmax"</span><span class="op">)</span></span>
<span></span>
<span>  <span class="fu"><a href="../../../reference/keras_model.html">keras_model</a></span><span class="op">(</span><span class="va">inputs</span>, <span class="va">outputs</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu">make_model</span><span class="op">(</span>input_shape <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">x_train</span><span class="op">)</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model</span></span></code></pre></div>
<pre><code><span><span class="co">## <span style="font-weight: bold;">Model: "functional_1"</span></span></span>
<span><span class="co">## ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━┓</span></span>
<span><span class="co">## ┃<span style="font-weight: bold;"> Layer (type)                </span>┃<span style="font-weight: bold;"> Output Shape          </span>┃<span style="font-weight: bold;">    Param # </span>┃<span style="font-weight: bold;"> Trai… </span>┃</span></span>
<span><span class="co">## ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━┩</span></span>
<span><span class="co">## │ input_layer (<span style="color: #0087FF;">InputLayer</span>)    │ (<span style="color: #00D7FF;">None</span>, <span style="color: #00AF00;">500</span>, <span style="color: #00AF00;">1</span>)        │          <span style="color: #00AF00;">0</span> │   <span style="font-weight: bold;">-</span>   │</span></span>
<span><span class="co">## ├─────────────────────────────┼───────────────────────┼────────────┼───────┤</span></span>
<span><span class="co">## │ conv1d_2 (<span style="color: #0087FF;">Conv1D</span>)           │ (<span style="color: #00D7FF;">None</span>, <span style="color: #00AF00;">500</span>, <span style="color: #00AF00;">64</span>)       │        <span style="color: #00AF00;">256</span> │   <span style="color: #00AF00; font-weight: bold;">Y</span>   │</span></span>
<span><span class="co">## ├─────────────────────────────┼───────────────────────┼────────────┼───────┤</span></span>
<span><span class="co">## │ batch_normalization_2       │ (<span style="color: #00D7FF;">None</span>, <span style="color: #00AF00;">500</span>, <span style="color: #00AF00;">64</span>)       │        <span style="color: #00AF00;">256</span> │   <span style="color: #00AF00; font-weight: bold;">Y</span>   │</span></span>
<span><span class="co">## │ (<span style="color: #0087FF;">BatchNormalization</span>)        │                       │            │       │</span></span>
<span><span class="co">## ├─────────────────────────────┼───────────────────────┼────────────┼───────┤</span></span>
<span><span class="co">## │ re_lu_2 (<span style="color: #0087FF;">ReLU</span>)              │ (<span style="color: #00D7FF;">None</span>, <span style="color: #00AF00;">500</span>, <span style="color: #00AF00;">64</span>)       │          <span style="color: #00AF00;">0</span> │   <span style="font-weight: bold;">-</span>   │</span></span>
<span><span class="co">## ├─────────────────────────────┼───────────────────────┼────────────┼───────┤</span></span>
<span><span class="co">## │ conv1d_1 (<span style="color: #0087FF;">Conv1D</span>)           │ (<span style="color: #00D7FF;">None</span>, <span style="color: #00AF00;">500</span>, <span style="color: #00AF00;">64</span>)       │     <span style="color: #00AF00;">12,352</span> │   <span style="color: #00AF00; font-weight: bold;">Y</span>   │</span></span>
<span><span class="co">## ├─────────────────────────────┼───────────────────────┼────────────┼───────┤</span></span>
<span><span class="co">## │ batch_normalization_1       │ (<span style="color: #00D7FF;">None</span>, <span style="color: #00AF00;">500</span>, <span style="color: #00AF00;">64</span>)       │        <span style="color: #00AF00;">256</span> │   <span style="color: #00AF00; font-weight: bold;">Y</span>   │</span></span>
<span><span class="co">## │ (<span style="color: #0087FF;">BatchNormalization</span>)        │                       │            │       │</span></span>
<span><span class="co">## ├─────────────────────────────┼───────────────────────┼────────────┼───────┤</span></span>
<span><span class="co">## │ re_lu_1 (<span style="color: #0087FF;">ReLU</span>)              │ (<span style="color: #00D7FF;">None</span>, <span style="color: #00AF00;">500</span>, <span style="color: #00AF00;">64</span>)       │          <span style="color: #00AF00;">0</span> │   <span style="font-weight: bold;">-</span>   │</span></span>
<span><span class="co">## ├─────────────────────────────┼───────────────────────┼────────────┼───────┤</span></span>
<span><span class="co">## │ conv1d (<span style="color: #0087FF;">Conv1D</span>)             │ (<span style="color: #00D7FF;">None</span>, <span style="color: #00AF00;">500</span>, <span style="color: #00AF00;">64</span>)       │     <span style="color: #00AF00;">12,352</span> │   <span style="color: #00AF00; font-weight: bold;">Y</span>   │</span></span>
<span><span class="co">## ├─────────────────────────────┼───────────────────────┼────────────┼───────┤</span></span>
<span><span class="co">## │ batch_normalization         │ (<span style="color: #00D7FF;">None</span>, <span style="color: #00AF00;">500</span>, <span style="color: #00AF00;">64</span>)       │        <span style="color: #00AF00;">256</span> │   <span style="color: #00AF00; font-weight: bold;">Y</span>   │</span></span>
<span><span class="co">## │ (<span style="color: #0087FF;">BatchNormalization</span>)        │                       │            │       │</span></span>
<span><span class="co">## ├─────────────────────────────┼───────────────────────┼────────────┼───────┤</span></span>
<span><span class="co">## │ re_lu (<span style="color: #0087FF;">ReLU</span>)                │ (<span style="color: #00D7FF;">None</span>, <span style="color: #00AF00;">500</span>, <span style="color: #00AF00;">64</span>)       │          <span style="color: #00AF00;">0</span> │   <span style="font-weight: bold;">-</span>   │</span></span>
<span><span class="co">## ├─────────────────────────────┼───────────────────────┼────────────┼───────┤</span></span>
<span><span class="co">## │ global_average_pooling1d    │ (<span style="color: #00D7FF;">None</span>, <span style="color: #00AF00;">64</span>)            │          <span style="color: #00AF00;">0</span> │   <span style="font-weight: bold;">-</span>   │</span></span>
<span><span class="co">## │ (<span style="color: #0087FF;">GlobalAveragePooling1D</span>)    │                       │            │       │</span></span>
<span><span class="co">## ├─────────────────────────────┼───────────────────────┼────────────┼───────┤</span></span>
<span><span class="co">## │ dense (<span style="color: #0087FF;">Dense</span>)               │ (<span style="color: #00D7FF;">None</span>, <span style="color: #00AF00;">2</span>)             │        <span style="color: #00AF00;">130</span> │   <span style="color: #00AF00; font-weight: bold;">Y</span>   │</span></span>
<span><span class="co">## └─────────────────────────────┴───────────────────────┴────────────┴───────┘</span></span>
<span><span class="co">## <span style="font-weight: bold;"> Total params: </span><span style="color: #00AF00;">25,858</span> (101.01 KB)</span></span>
<span><span class="co">## <span style="font-weight: bold;"> Trainable params: </span><span style="color: #00AF00;">25,474</span> (99.51 KB)</span></span>
<span><span class="co">## <span style="font-weight: bold;"> Non-trainable params: </span><span style="color: #00AF00;">384</span> (1.50 KB)</span></span></code></pre>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">model</span>, show_shapes <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code></pre></div>
<div class="figure">
<img src="timeseries_classification_from_scratch/unnamed-chunk-9-1.png" alt="plot of chunk unnamed-chunk-9" width="480"><p class="caption">
plot of chunk unnamed-chunk-9
</p>
</div>
</div>
<div class="section level2">
<h2 id="train-the-model">Train the model<a class="anchor" aria-label="anchor" href="#train-the-model"></a>
</h2>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">epochs</span> <span class="op">&lt;-</span> <span class="fl">500</span></span>
<span><span class="va">batch_size</span> <span class="op">&lt;-</span> <span class="fl">32</span></span>
<span></span>
<span><span class="va">callbacks</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span></span>
<span>  <span class="fu"><a href="../../../reference/callback_model_checkpoint.html">callback_model_checkpoint</a></span><span class="op">(</span></span>
<span>    <span class="st">"best_model.keras"</span>, save_best_only <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>    monitor <span class="op">=</span> <span class="st">"val_loss"</span></span>
<span>  <span class="op">)</span>,</span>
<span>  <span class="fu"><a href="../../../reference/callback_reduce_lr_on_plateau.html">callback_reduce_lr_on_plateau</a></span><span class="op">(</span></span>
<span>    monitor <span class="op">=</span> <span class="st">"val_loss"</span>, factor <span class="op">=</span> <span class="fl">0.5</span>,</span>
<span>    patience <span class="op">=</span> <span class="fl">20</span>, min_lr <span class="op">=</span> <span class="fl">0.0001</span></span>
<span>  <span class="op">)</span>,</span>
<span>  <span class="fu"><a href="../../../reference/callback_early_stopping.html">callback_early_stopping</a></span><span class="op">(</span></span>
<span>    monitor <span class="op">=</span> <span class="st">"val_loss"</span>, patience <span class="op">=</span> <span class="fl">50</span>,</span>
<span>    verbose <span class="op">=</span> <span class="fl">1</span></span>
<span>  <span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span></span>
<span><span class="va">model</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://generics.r-lib.org/reference/compile.html" class="external-link">compile</a></span><span class="op">(</span></span>
<span>  optimizer <span class="op">=</span> <span class="st">"adam"</span>,</span>
<span>  loss <span class="op">=</span> <span class="st">"sparse_categorical_crossentropy"</span>,</span>
<span>  metrics <span class="op">=</span> <span class="st">"sparse_categorical_accuracy"</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">history</span> <span class="op">&lt;-</span> <span class="va">model</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span></span>
<span>  <span class="va">x_train</span>, <span class="va">y_train</span>,</span>
<span>  batch_size <span class="op">=</span> <span class="va">batch_size</span>,</span>
<span>  epochs <span class="op">=</span> <span class="va">epochs</span>,</span>
<span>  callbacks <span class="op">=</span> <span class="va">callbacks</span>,</span>
<span>  validation_split <span class="op">=</span> <span class="fl">0.2</span></span>
<span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Epoch 1/500</span></span>
<span><span class="co">## 90/90 - 2s - 20ms/step - loss: 0.5699 - sparse_categorical_accuracy: 0.6958 - val_loss: 0.7534 - val_sparse_categorical_accuracy: 0.4896 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 2/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.4916 - sparse_categorical_accuracy: 0.7552 - val_loss: 0.7851 - val_sparse_categorical_accuracy: 0.4896 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 3/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.4628 - sparse_categorical_accuracy: 0.7670 - val_loss: 0.7018 - val_sparse_categorical_accuracy: 0.5645 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 4/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.4168 - sparse_categorical_accuracy: 0.7917 - val_loss: 0.6447 - val_sparse_categorical_accuracy: 0.6713 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 5/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.4194 - sparse_categorical_accuracy: 0.7920 - val_loss: 0.5328 - val_sparse_categorical_accuracy: 0.7323 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 6/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.4026 - sparse_categorical_accuracy: 0.8052 - val_loss: 0.4502 - val_sparse_categorical_accuracy: 0.8239 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 7/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.3974 - sparse_categorical_accuracy: 0.8059 - val_loss: 1.1050 - val_sparse_categorical_accuracy: 0.6227 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 8/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.3852 - sparse_categorical_accuracy: 0.8101 - val_loss: 0.3881 - val_sparse_categorical_accuracy: 0.8183 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 9/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.3827 - sparse_categorical_accuracy: 0.8153 - val_loss: 0.4226 - val_sparse_categorical_accuracy: 0.7892 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 10/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.3802 - sparse_categorical_accuracy: 0.8156 - val_loss: 0.3901 - val_sparse_categorical_accuracy: 0.8225 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 11/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.3727 - sparse_categorical_accuracy: 0.8174 - val_loss: 0.6322 - val_sparse_categorical_accuracy: 0.6741 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 12/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.3656 - sparse_categorical_accuracy: 0.8253 - val_loss: 0.3699 - val_sparse_categorical_accuracy: 0.8308 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 13/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.3524 - sparse_categorical_accuracy: 0.8385 - val_loss: 0.4632 - val_sparse_categorical_accuracy: 0.7642 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 14/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.3553 - sparse_categorical_accuracy: 0.8306 - val_loss: 0.4022 - val_sparse_categorical_accuracy: 0.7795 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 15/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.3404 - sparse_categorical_accuracy: 0.8444 - val_loss: 0.5106 - val_sparse_categorical_accuracy: 0.7240 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 16/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.3394 - sparse_categorical_accuracy: 0.8497 - val_loss: 0.3802 - val_sparse_categorical_accuracy: 0.8169 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 17/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.3282 - sparse_categorical_accuracy: 0.8559 - val_loss: 0.3894 - val_sparse_categorical_accuracy: 0.8086 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 18/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.3183 - sparse_categorical_accuracy: 0.8566 - val_loss: 0.3239 - val_sparse_categorical_accuracy: 0.8558 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 19/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.3146 - sparse_categorical_accuracy: 0.8642 - val_loss: 0.4493 - val_sparse_categorical_accuracy: 0.7725 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 20/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.3107 - sparse_categorical_accuracy: 0.8656 - val_loss: 0.7768 - val_sparse_categorical_accuracy: 0.6214 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 21/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.2951 - sparse_categorical_accuracy: 0.8760 - val_loss: 0.3365 - val_sparse_categorical_accuracy: 0.8516 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 22/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.2946 - sparse_categorical_accuracy: 0.8764 - val_loss: 0.3139 - val_sparse_categorical_accuracy: 0.8544 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 23/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.2847 - sparse_categorical_accuracy: 0.8858 - val_loss: 0.8195 - val_sparse_categorical_accuracy: 0.5714 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 24/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.2788 - sparse_categorical_accuracy: 0.8861 - val_loss: 0.6453 - val_sparse_categorical_accuracy: 0.6616 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 25/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.2819 - sparse_categorical_accuracy: 0.8809 - val_loss: 1.8959 - val_sparse_categorical_accuracy: 0.5104 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 26/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.3038 - sparse_categorical_accuracy: 0.8625 - val_loss: 1.0902 - val_sparse_categorical_accuracy: 0.5811 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 27/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.2678 - sparse_categorical_accuracy: 0.8917 - val_loss: 0.9476 - val_sparse_categorical_accuracy: 0.6297 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 28/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.2883 - sparse_categorical_accuracy: 0.8760 - val_loss: 2.6088 - val_sparse_categorical_accuracy: 0.5368 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 29/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.2730 - sparse_categorical_accuracy: 0.8795 - val_loss: 0.8953 - val_sparse_categorical_accuracy: 0.6227 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 30/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.2686 - sparse_categorical_accuracy: 0.8875 - val_loss: 0.4891 - val_sparse_categorical_accuracy: 0.7739 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 31/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.2662 - sparse_categorical_accuracy: 0.8878 - val_loss: 0.3040 - val_sparse_categorical_accuracy: 0.8710 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 32/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.2629 - sparse_categorical_accuracy: 0.8896 - val_loss: 0.3474 - val_sparse_categorical_accuracy: 0.8363 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 33/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.2515 - sparse_categorical_accuracy: 0.8969 - val_loss: 0.4071 - val_sparse_categorical_accuracy: 0.7961 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 34/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.2420 - sparse_categorical_accuracy: 0.8997 - val_loss: 1.1083 - val_sparse_categorical_accuracy: 0.5229 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 35/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.2657 - sparse_categorical_accuracy: 0.8872 - val_loss: 1.1045 - val_sparse_categorical_accuracy: 0.5465 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 36/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.2502 - sparse_categorical_accuracy: 0.8997 - val_loss: 0.5667 - val_sparse_categorical_accuracy: 0.7143 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 37/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.2487 - sparse_categorical_accuracy: 0.8931 - val_loss: 0.5075 - val_sparse_categorical_accuracy: 0.7448 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 38/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.2533 - sparse_categorical_accuracy: 0.8962 - val_loss: 2.2239 - val_sparse_categorical_accuracy: 0.6019 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 39/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.2472 - sparse_categorical_accuracy: 0.8997 - val_loss: 0.7943 - val_sparse_categorical_accuracy: 0.6630 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 40/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.2465 - sparse_categorical_accuracy: 0.8983 - val_loss: 0.3195 - val_sparse_categorical_accuracy: 0.8516 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 41/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.2316 - sparse_categorical_accuracy: 0.9038 - val_loss: 0.3884 - val_sparse_categorical_accuracy: 0.8031 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 42/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.2270 - sparse_categorical_accuracy: 0.9118 - val_loss: 0.4865 - val_sparse_categorical_accuracy: 0.7739 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 43/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.2431 - sparse_categorical_accuracy: 0.8993 - val_loss: 0.2912 - val_sparse_categorical_accuracy: 0.8752 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 44/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.2297 - sparse_categorical_accuracy: 0.9087 - val_loss: 1.2659 - val_sparse_categorical_accuracy: 0.6338 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 45/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.2300 - sparse_categorical_accuracy: 0.9104 - val_loss: 0.2956 - val_sparse_categorical_accuracy: 0.8724 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 46/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.2330 - sparse_categorical_accuracy: 0.9062 - val_loss: 0.7793 - val_sparse_categorical_accuracy: 0.6796 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 47/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.2155 - sparse_categorical_accuracy: 0.9146 - val_loss: 0.9919 - val_sparse_categorical_accuracy: 0.6436 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 48/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.2166 - sparse_categorical_accuracy: 0.9135 - val_loss: 0.2972 - val_sparse_categorical_accuracy: 0.8627 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 49/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.2163 - sparse_categorical_accuracy: 0.9125 - val_loss: 1.2487 - val_sparse_categorical_accuracy: 0.7101 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 50/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.2082 - sparse_categorical_accuracy: 0.9184 - val_loss: 0.2427 - val_sparse_categorical_accuracy: 0.8974 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 51/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.2137 - sparse_categorical_accuracy: 0.9135 - val_loss: 1.0448 - val_sparse_categorical_accuracy: 0.6644 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 52/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.2035 - sparse_categorical_accuracy: 0.9208 - val_loss: 3.2190 - val_sparse_categorical_accuracy: 0.5090 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 53/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.1939 - sparse_categorical_accuracy: 0.9257 - val_loss: 3.7529 - val_sparse_categorical_accuracy: 0.5562 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 54/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.1866 - sparse_categorical_accuracy: 0.9253 - val_loss: 2.3514 - val_sparse_categorical_accuracy: 0.6089 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 55/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.1748 - sparse_categorical_accuracy: 0.9347 - val_loss: 1.5064 - val_sparse_categorical_accuracy: 0.6533 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 56/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.1562 - sparse_categorical_accuracy: 0.9472 - val_loss: 1.7046 - val_sparse_categorical_accuracy: 0.6158 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 57/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.1536 - sparse_categorical_accuracy: 0.9497 - val_loss: 0.2666 - val_sparse_categorical_accuracy: 0.8752 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 58/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.1457 - sparse_categorical_accuracy: 0.9500 - val_loss: 0.1585 - val_sparse_categorical_accuracy: 0.9348 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 59/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.1512 - sparse_categorical_accuracy: 0.9483 - val_loss: 0.9663 - val_sparse_categorical_accuracy: 0.6546 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 60/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.1355 - sparse_categorical_accuracy: 0.9597 - val_loss: 4.1886 - val_sparse_categorical_accuracy: 0.5950 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 61/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.1319 - sparse_categorical_accuracy: 0.9542 - val_loss: 1.8469 - val_sparse_categorical_accuracy: 0.6893 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 62/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.1378 - sparse_categorical_accuracy: 0.9549 - val_loss: 0.4279 - val_sparse_categorical_accuracy: 0.7933 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 63/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.1392 - sparse_categorical_accuracy: 0.9465 - val_loss: 0.2616 - val_sparse_categorical_accuracy: 0.8696 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 64/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.1395 - sparse_categorical_accuracy: 0.9559 - val_loss: 0.3086 - val_sparse_categorical_accuracy: 0.8363 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 65/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.1229 - sparse_categorical_accuracy: 0.9608 - val_loss: 0.1658 - val_sparse_categorical_accuracy: 0.9376 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 66/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.1188 - sparse_categorical_accuracy: 0.9639 - val_loss: 0.1924 - val_sparse_categorical_accuracy: 0.9168 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 67/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.1255 - sparse_categorical_accuracy: 0.9566 - val_loss: 0.2742 - val_sparse_categorical_accuracy: 0.9001 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 68/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.1191 - sparse_categorical_accuracy: 0.9615 - val_loss: 0.2514 - val_sparse_categorical_accuracy: 0.9001 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 69/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.1306 - sparse_categorical_accuracy: 0.9552 - val_loss: 0.4682 - val_sparse_categorical_accuracy: 0.7684 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 70/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.1244 - sparse_categorical_accuracy: 0.9608 - val_loss: 0.2919 - val_sparse_categorical_accuracy: 0.8627 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 71/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.1212 - sparse_categorical_accuracy: 0.9608 - val_loss: 1.0799 - val_sparse_categorical_accuracy: 0.7240 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 72/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.1249 - sparse_categorical_accuracy: 0.9587 - val_loss: 1.2666 - val_sparse_categorical_accuracy: 0.7143 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 73/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.1066 - sparse_categorical_accuracy: 0.9670 - val_loss: 1.9443 - val_sparse_categorical_accuracy: 0.6963 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 74/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.1071 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.1345 - val_sparse_categorical_accuracy: 0.9487 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 75/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.1250 - sparse_categorical_accuracy: 0.9594 - val_loss: 0.2415 - val_sparse_categorical_accuracy: 0.9140 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 76/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.1168 - sparse_categorical_accuracy: 0.9622 - val_loss: 0.2679 - val_sparse_categorical_accuracy: 0.9071 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 77/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.1060 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.1445 - val_sparse_categorical_accuracy: 0.9417 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 78/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.1151 - sparse_categorical_accuracy: 0.9649 - val_loss: 0.1520 - val_sparse_categorical_accuracy: 0.9376 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 79/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.1134 - sparse_categorical_accuracy: 0.9642 - val_loss: 0.2077 - val_sparse_categorical_accuracy: 0.9029 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 80/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.1108 - sparse_categorical_accuracy: 0.9653 - val_loss: 2.8488 - val_sparse_categorical_accuracy: 0.6935 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 81/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.1139 - sparse_categorical_accuracy: 0.9639 - val_loss: 2.7853 - val_sparse_categorical_accuracy: 0.6602 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 82/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.1031 - sparse_categorical_accuracy: 0.9656 - val_loss: 0.3471 - val_sparse_categorical_accuracy: 0.8155 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 83/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.1164 - sparse_categorical_accuracy: 0.9611 - val_loss: 0.1823 - val_sparse_categorical_accuracy: 0.9279 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 84/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.1065 - sparse_categorical_accuracy: 0.9646 - val_loss: 0.1702 - val_sparse_categorical_accuracy: 0.9487 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 85/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.1066 - sparse_categorical_accuracy: 0.9646 - val_loss: 0.8909 - val_sparse_categorical_accuracy: 0.7559 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 86/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.1007 - sparse_categorical_accuracy: 0.9642 - val_loss: 0.1385 - val_sparse_categorical_accuracy: 0.9445 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 87/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.1053 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.1473 - val_sparse_categorical_accuracy: 0.9542 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 88/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0986 - sparse_categorical_accuracy: 0.9674 - val_loss: 0.2733 - val_sparse_categorical_accuracy: 0.8890 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 89/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.1016 - sparse_categorical_accuracy: 0.9625 - val_loss: 1.0660 - val_sparse_categorical_accuracy: 0.7379 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 90/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0987 - sparse_categorical_accuracy: 0.9688 - val_loss: 1.0865 - val_sparse_categorical_accuracy: 0.7393 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 91/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.1262 - sparse_categorical_accuracy: 0.9583 - val_loss: 0.1782 - val_sparse_categorical_accuracy: 0.9237 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 92/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.1020 - sparse_categorical_accuracy: 0.9674 - val_loss: 0.5247 - val_sparse_categorical_accuracy: 0.8003 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 93/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.1002 - sparse_categorical_accuracy: 0.9663 - val_loss: 1.4023 - val_sparse_categorical_accuracy: 0.7323 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 94/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0959 - sparse_categorical_accuracy: 0.9670 - val_loss: 0.4220 - val_sparse_categorical_accuracy: 0.8280 - learning_rate: 0.0010</span></span>
<span><span class="co">## Epoch 95/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0874 - sparse_categorical_accuracy: 0.9712 - val_loss: 0.1210 - val_sparse_categorical_accuracy: 0.9445 - learning_rate: 5.0000e-04</span></span>
<span><span class="co">## Epoch 96/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0923 - sparse_categorical_accuracy: 0.9698 - val_loss: 0.1591 - val_sparse_categorical_accuracy: 0.9320 - learning_rate: 5.0000e-04</span></span>
<span><span class="co">## Epoch 97/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0865 - sparse_categorical_accuracy: 0.9708 - val_loss: 0.1229 - val_sparse_categorical_accuracy: 0.9459 - learning_rate: 5.0000e-04</span></span>
<span><span class="co">## Epoch 98/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0831 - sparse_categorical_accuracy: 0.9733 - val_loss: 0.1150 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 5.0000e-04</span></span>
<span><span class="co">## Epoch 99/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0843 - sparse_categorical_accuracy: 0.9729 - val_loss: 0.1212 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 5.0000e-04</span></span>
<span><span class="co">## Epoch 100/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0852 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.1309 - val_sparse_categorical_accuracy: 0.9473 - learning_rate: 5.0000e-04</span></span>
<span><span class="co">## Epoch 101/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0818 - sparse_categorical_accuracy: 0.9743 - val_loss: 0.2148 - val_sparse_categorical_accuracy: 0.9015 - learning_rate: 5.0000e-04</span></span>
<span><span class="co">## Epoch 102/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0925 - sparse_categorical_accuracy: 0.9677 - val_loss: 0.2271 - val_sparse_categorical_accuracy: 0.9001 - learning_rate: 5.0000e-04</span></span>
<span><span class="co">## Epoch 103/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0862 - sparse_categorical_accuracy: 0.9722 - val_loss: 0.1130 - val_sparse_categorical_accuracy: 0.9528 - learning_rate: 5.0000e-04</span></span>
<span><span class="co">## Epoch 104/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0857 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.1257 - val_sparse_categorical_accuracy: 0.9556 - learning_rate: 5.0000e-04</span></span>
<span><span class="co">## Epoch 105/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0838 - sparse_categorical_accuracy: 0.9726 - val_loss: 0.2272 - val_sparse_categorical_accuracy: 0.9126 - learning_rate: 5.0000e-04</span></span>
<span><span class="co">## Epoch 106/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0835 - sparse_categorical_accuracy: 0.9736 - val_loss: 0.2501 - val_sparse_categorical_accuracy: 0.9168 - learning_rate: 5.0000e-04</span></span>
<span><span class="co">## Epoch 107/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0856 - sparse_categorical_accuracy: 0.9694 - val_loss: 0.1464 - val_sparse_categorical_accuracy: 0.9459 - learning_rate: 5.0000e-04</span></span>
<span><span class="co">## Epoch 108/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0816 - sparse_categorical_accuracy: 0.9736 - val_loss: 0.1954 - val_sparse_categorical_accuracy: 0.9223 - learning_rate: 5.0000e-04</span></span>
<span><span class="co">## Epoch 109/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0850 - sparse_categorical_accuracy: 0.9747 - val_loss: 0.3662 - val_sparse_categorical_accuracy: 0.8696 - learning_rate: 5.0000e-04</span></span>
<span><span class="co">## Epoch 110/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0871 - sparse_categorical_accuracy: 0.9712 - val_loss: 0.1478 - val_sparse_categorical_accuracy: 0.9334 - learning_rate: 5.0000e-04</span></span>
<span><span class="co">## Epoch 111/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0802 - sparse_categorical_accuracy: 0.9736 - val_loss: 0.1419 - val_sparse_categorical_accuracy: 0.9473 - learning_rate: 5.0000e-04</span></span>
<span><span class="co">## Epoch 112/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0818 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.2088 - val_sparse_categorical_accuracy: 0.9001 - learning_rate: 5.0000e-04</span></span>
<span><span class="co">## Epoch 113/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0767 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.2227 - val_sparse_categorical_accuracy: 0.9029 - learning_rate: 5.0000e-04</span></span>
<span><span class="co">## Epoch 114/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0923 - sparse_categorical_accuracy: 0.9694 - val_loss: 0.2138 - val_sparse_categorical_accuracy: 0.8932 - learning_rate: 5.0000e-04</span></span>
<span><span class="co">## Epoch 115/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0753 - sparse_categorical_accuracy: 0.9764 - val_loss: 0.2368 - val_sparse_categorical_accuracy: 0.9015 - learning_rate: 5.0000e-04</span></span>
<span><span class="co">## Epoch 116/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0816 - sparse_categorical_accuracy: 0.9753 - val_loss: 0.1174 - val_sparse_categorical_accuracy: 0.9584 - learning_rate: 5.0000e-04</span></span>
<span><span class="co">## Epoch 117/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0795 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.1728 - val_sparse_categorical_accuracy: 0.9501 - learning_rate: 5.0000e-04</span></span>
<span><span class="co">## Epoch 118/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0822 - sparse_categorical_accuracy: 0.9712 - val_loss: 0.1200 - val_sparse_categorical_accuracy: 0.9501 - learning_rate: 5.0000e-04</span></span>
<span><span class="co">## Epoch 119/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0838 - sparse_categorical_accuracy: 0.9747 - val_loss: 0.1758 - val_sparse_categorical_accuracy: 0.9279 - learning_rate: 5.0000e-04</span></span>
<span><span class="co">## Epoch 120/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0830 - sparse_categorical_accuracy: 0.9722 - val_loss: 0.1413 - val_sparse_categorical_accuracy: 0.9556 - learning_rate: 5.0000e-04</span></span>
<span><span class="co">## Epoch 121/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0806 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.1463 - val_sparse_categorical_accuracy: 0.9348 - learning_rate: 5.0000e-04</span></span>
<span><span class="co">## Epoch 122/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0806 - sparse_categorical_accuracy: 0.9736 - val_loss: 0.1244 - val_sparse_categorical_accuracy: 0.9598 - learning_rate: 5.0000e-04</span></span>
<span><span class="co">## Epoch 123/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0822 - sparse_categorical_accuracy: 0.9736 - val_loss: 0.1682 - val_sparse_categorical_accuracy: 0.9376 - learning_rate: 5.0000e-04</span></span>
<span><span class="co">## Epoch 124/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0799 - sparse_categorical_accuracy: 0.9729 - val_loss: 0.1143 - val_sparse_categorical_accuracy: 0.9487 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 125/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0766 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.1146 - val_sparse_categorical_accuracy: 0.9542 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 126/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0735 - sparse_categorical_accuracy: 0.9781 - val_loss: 0.1217 - val_sparse_categorical_accuracy: 0.9501 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 127/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0743 - sparse_categorical_accuracy: 0.9778 - val_loss: 0.1158 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 128/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0741 - sparse_categorical_accuracy: 0.9736 - val_loss: 0.1538 - val_sparse_categorical_accuracy: 0.9334 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 129/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0717 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.1121 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 130/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0805 - sparse_categorical_accuracy: 0.9757 - val_loss: 0.1289 - val_sparse_categorical_accuracy: 0.9459 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 131/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0684 - sparse_categorical_accuracy: 0.9788 - val_loss: 0.1122 - val_sparse_categorical_accuracy: 0.9556 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 132/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0685 - sparse_categorical_accuracy: 0.9788 - val_loss: 0.1418 - val_sparse_categorical_accuracy: 0.9348 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 133/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0645 - sparse_categorical_accuracy: 0.9809 - val_loss: 0.1114 - val_sparse_categorical_accuracy: 0.9598 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 134/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0719 - sparse_categorical_accuracy: 0.9764 - val_loss: 0.1259 - val_sparse_categorical_accuracy: 0.9584 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 135/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0718 - sparse_categorical_accuracy: 0.9771 - val_loss: 0.1154 - val_sparse_categorical_accuracy: 0.9598 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 136/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0742 - sparse_categorical_accuracy: 0.9743 - val_loss: 0.1163 - val_sparse_categorical_accuracy: 0.9598 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 137/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0773 - sparse_categorical_accuracy: 0.9726 - val_loss: 0.1444 - val_sparse_categorical_accuracy: 0.9404 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 138/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0700 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.1133 - val_sparse_categorical_accuracy: 0.9528 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 139/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0789 - sparse_categorical_accuracy: 0.9726 - val_loss: 0.1315 - val_sparse_categorical_accuracy: 0.9598 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 140/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0703 - sparse_categorical_accuracy: 0.9781 - val_loss: 0.2403 - val_sparse_categorical_accuracy: 0.9085 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 141/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0698 - sparse_categorical_accuracy: 0.9764 - val_loss: 0.1141 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 142/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0670 - sparse_categorical_accuracy: 0.9819 - val_loss: 0.1130 - val_sparse_categorical_accuracy: 0.9515 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 143/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0708 - sparse_categorical_accuracy: 0.9778 - val_loss: 0.1443 - val_sparse_categorical_accuracy: 0.9542 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 144/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0628 - sparse_categorical_accuracy: 0.9802 - val_loss: 0.1368 - val_sparse_categorical_accuracy: 0.9431 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 145/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0661 - sparse_categorical_accuracy: 0.9771 - val_loss: 0.1226 - val_sparse_categorical_accuracy: 0.9501 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 146/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0677 - sparse_categorical_accuracy: 0.9781 - val_loss: 0.1898 - val_sparse_categorical_accuracy: 0.9223 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 147/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0740 - sparse_categorical_accuracy: 0.9764 - val_loss: 0.1139 - val_sparse_categorical_accuracy: 0.9501 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 148/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0786 - sparse_categorical_accuracy: 0.9722 - val_loss: 0.1119 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 149/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0689 - sparse_categorical_accuracy: 0.9774 - val_loss: 0.1021 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 150/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0723 - sparse_categorical_accuracy: 0.9764 - val_loss: 0.1411 - val_sparse_categorical_accuracy: 0.9556 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 151/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0687 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.1100 - val_sparse_categorical_accuracy: 0.9653 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 152/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0741 - sparse_categorical_accuracy: 0.9733 - val_loss: 0.2827 - val_sparse_categorical_accuracy: 0.8946 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 153/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0701 - sparse_categorical_accuracy: 0.9778 - val_loss: 0.1050 - val_sparse_categorical_accuracy: 0.9598 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 154/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0654 - sparse_categorical_accuracy: 0.9785 - val_loss: 0.1110 - val_sparse_categorical_accuracy: 0.9598 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 155/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0688 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.1171 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 156/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0710 - sparse_categorical_accuracy: 0.9764 - val_loss: 0.1373 - val_sparse_categorical_accuracy: 0.9431 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 157/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0706 - sparse_categorical_accuracy: 0.9733 - val_loss: 0.1091 - val_sparse_categorical_accuracy: 0.9598 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 158/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0690 - sparse_categorical_accuracy: 0.9771 - val_loss: 0.5644 - val_sparse_categorical_accuracy: 0.8280 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 159/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0677 - sparse_categorical_accuracy: 0.9736 - val_loss: 0.1018 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 160/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0689 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.1114 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 161/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0701 - sparse_categorical_accuracy: 0.9785 - val_loss: 0.1200 - val_sparse_categorical_accuracy: 0.9598 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 162/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0643 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.1382 - val_sparse_categorical_accuracy: 0.9542 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 163/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0605 - sparse_categorical_accuracy: 0.9830 - val_loss: 0.1175 - val_sparse_categorical_accuracy: 0.9487 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 164/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0655 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.1251 - val_sparse_categorical_accuracy: 0.9515 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 165/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0625 - sparse_categorical_accuracy: 0.9809 - val_loss: 0.1051 - val_sparse_categorical_accuracy: 0.9528 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 166/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0623 - sparse_categorical_accuracy: 0.9785 - val_loss: 0.1921 - val_sparse_categorical_accuracy: 0.9223 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 167/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0643 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.1396 - val_sparse_categorical_accuracy: 0.9459 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 168/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0755 - sparse_categorical_accuracy: 0.9736 - val_loss: 0.3494 - val_sparse_categorical_accuracy: 0.8807 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 169/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0654 - sparse_categorical_accuracy: 0.9781 - val_loss: 0.1077 - val_sparse_categorical_accuracy: 0.9584 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 170/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0670 - sparse_categorical_accuracy: 0.9826 - val_loss: 0.2135 - val_sparse_categorical_accuracy: 0.9154 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 171/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0617 - sparse_categorical_accuracy: 0.9806 - val_loss: 0.1792 - val_sparse_categorical_accuracy: 0.9390 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 172/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0648 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.2222 - val_sparse_categorical_accuracy: 0.9126 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 173/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0630 - sparse_categorical_accuracy: 0.9809 - val_loss: 0.1139 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 174/500</span></span>
<span><span class="co">## 90/90 - 0s - 3ms/step - loss: 0.0677 - sparse_categorical_accuracy: 0.9778 - val_loss: 0.1053 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 175/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0666 - sparse_categorical_accuracy: 0.9764 - val_loss: 0.2025 - val_sparse_categorical_accuracy: 0.9209 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 176/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0649 - sparse_categorical_accuracy: 0.9778 - val_loss: 0.5486 - val_sparse_categorical_accuracy: 0.8405 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 177/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0639 - sparse_categorical_accuracy: 0.9826 - val_loss: 0.1643 - val_sparse_categorical_accuracy: 0.9404 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 178/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0618 - sparse_categorical_accuracy: 0.9806 - val_loss: 0.1540 - val_sparse_categorical_accuracy: 0.9417 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 179/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0626 - sparse_categorical_accuracy: 0.9802 - val_loss: 0.1096 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 2.5000e-04</span></span>
<span><span class="co">## Epoch 180/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0611 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.1349 - val_sparse_categorical_accuracy: 0.9570 - learning_rate: 1.2500e-04</span></span>
<span><span class="co">## Epoch 181/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0643 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.1554 - val_sparse_categorical_accuracy: 0.9501 - learning_rate: 1.2500e-04</span></span>
<span><span class="co">## Epoch 182/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0605 - sparse_categorical_accuracy: 0.9816 - val_loss: 0.1344 - val_sparse_categorical_accuracy: 0.9570 - learning_rate: 1.2500e-04</span></span>
<span><span class="co">## Epoch 183/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0614 - sparse_categorical_accuracy: 0.9778 - val_loss: 0.1123 - val_sparse_categorical_accuracy: 0.9639 - learning_rate: 1.2500e-04</span></span>
<span><span class="co">## Epoch 184/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0575 - sparse_categorical_accuracy: 0.9826 - val_loss: 0.1557 - val_sparse_categorical_accuracy: 0.9515 - learning_rate: 1.2500e-04</span></span>
<span><span class="co">## Epoch 185/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0582 - sparse_categorical_accuracy: 0.9830 - val_loss: 0.1147 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.2500e-04</span></span>
<span><span class="co">## Epoch 186/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0633 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.1537 - val_sparse_categorical_accuracy: 0.9445 - learning_rate: 1.2500e-04</span></span>
<span><span class="co">## Epoch 187/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0591 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.1106 - val_sparse_categorical_accuracy: 0.9612 - learning_rate: 1.2500e-04</span></span>
<span><span class="co">## Epoch 188/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0593 - sparse_categorical_accuracy: 0.9830 - val_loss: 0.1444 - val_sparse_categorical_accuracy: 0.9515 - learning_rate: 1.2500e-04</span></span>
<span><span class="co">## Epoch 189/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0555 - sparse_categorical_accuracy: 0.9837 - val_loss: 0.1516 - val_sparse_categorical_accuracy: 0.9528 - learning_rate: 1.2500e-04</span></span>
<span><span class="co">## Epoch 190/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0638 - sparse_categorical_accuracy: 0.9809 - val_loss: 0.1198 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.2500e-04</span></span>
<span><span class="co">## Epoch 191/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0576 - sparse_categorical_accuracy: 0.9799 - val_loss: 0.1348 - val_sparse_categorical_accuracy: 0.9542 - learning_rate: 1.2500e-04</span></span>
<span><span class="co">## Epoch 192/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0647 - sparse_categorical_accuracy: 0.9788 - val_loss: 0.1879 - val_sparse_categorical_accuracy: 0.9293 - learning_rate: 1.2500e-04</span></span>
<span><span class="co">## Epoch 193/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0592 - sparse_categorical_accuracy: 0.9819 - val_loss: 0.1514 - val_sparse_categorical_accuracy: 0.9570 - learning_rate: 1.2500e-04</span></span>
<span><span class="co">## Epoch 194/500</span></span>
<span><span class="co">## 90/90 - 0s - 3ms/step - loss: 0.0588 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.1164 - val_sparse_categorical_accuracy: 0.9501 - learning_rate: 1.2500e-04</span></span>
<span><span class="co">## Epoch 195/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0594 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.1167 - val_sparse_categorical_accuracy: 0.9487 - learning_rate: 1.2500e-04</span></span>
<span><span class="co">## Epoch 196/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0619 - sparse_categorical_accuracy: 0.9785 - val_loss: 0.1196 - val_sparse_categorical_accuracy: 0.9584 - learning_rate: 1.2500e-04</span></span>
<span><span class="co">## Epoch 197/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0589 - sparse_categorical_accuracy: 0.9819 - val_loss: 0.1153 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.2500e-04</span></span>
<span><span class="co">## Epoch 198/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0592 - sparse_categorical_accuracy: 0.9826 - val_loss: 0.1679 - val_sparse_categorical_accuracy: 0.9417 - learning_rate: 1.2500e-04</span></span>
<span><span class="co">## Epoch 199/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0637 - sparse_categorical_accuracy: 0.9792 - val_loss: 0.1127 - val_sparse_categorical_accuracy: 0.9598 - learning_rate: 1.2500e-04</span></span>
<span><span class="co">## Epoch 200/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0582 - sparse_categorical_accuracy: 0.9830 - val_loss: 0.1089 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.0000e-04</span></span>
<span><span class="co">## Epoch 201/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0569 - sparse_categorical_accuracy: 0.9840 - val_loss: 0.1133 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.0000e-04</span></span>
<span><span class="co">## Epoch 202/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0567 - sparse_categorical_accuracy: 0.9826 - val_loss: 0.1110 - val_sparse_categorical_accuracy: 0.9528 - learning_rate: 1.0000e-04</span></span>
<span><span class="co">## Epoch 203/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0606 - sparse_categorical_accuracy: 0.9819 - val_loss: 0.1028 - val_sparse_categorical_accuracy: 0.9584 - learning_rate: 1.0000e-04</span></span>
<span><span class="co">## Epoch 204/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0539 - sparse_categorical_accuracy: 0.9847 - val_loss: 0.1057 - val_sparse_categorical_accuracy: 0.9556 - learning_rate: 1.0000e-04</span></span>
<span><span class="co">## Epoch 205/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0574 - sparse_categorical_accuracy: 0.9802 - val_loss: 0.1037 - val_sparse_categorical_accuracy: 0.9639 - learning_rate: 1.0000e-04</span></span>
<span><span class="co">## Epoch 206/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0585 - sparse_categorical_accuracy: 0.9819 - val_loss: 0.1385 - val_sparse_categorical_accuracy: 0.9598 - learning_rate: 1.0000e-04</span></span>
<span><span class="co">## Epoch 207/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0611 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.1147 - val_sparse_categorical_accuracy: 0.9556 - learning_rate: 1.0000e-04</span></span>
<span><span class="co">## Epoch 208/500</span></span>
<span><span class="co">## 90/90 - 0s - 1ms/step - loss: 0.0584 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.1185 - val_sparse_categorical_accuracy: 0.9639 - learning_rate: 1.0000e-04</span></span>
<span><span class="co">## Epoch 209/500</span></span>
<span><span class="co">## 90/90 - 0s - 2ms/step - loss: 0.0563 - sparse_categorical_accuracy: 0.9813 - val_loss: 0.1127 - val_sparse_categorical_accuracy: 0.9626 - learning_rate: 1.0000e-04</span></span>
<span><span class="co">## Epoch 209: early stopping</span></span></code></pre>
</div>
<div class="section level2">
<h2 id="evaluate-model-on-test-data">Evaluate model on test data<a class="anchor" aria-label="anchor" href="#evaluate-model-on-test-data"></a>
</h2>
<div class="sourceCode" id="cb15"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a>model <span class="op">=</span> keras.models.load_model(<span class="st">"best_model.keras"</span>)</span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a>test_loss, test_acc <span class="op">=</span> model.evaluate(x_test, y_test)</span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test accuracy"</span>, test_acc)</span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test loss"</span>, test_loss)</span></code></pre></div>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../../../reference/load_model.html">load_model</a></span><span class="op">(</span><span class="st">"best_model.keras"</span><span class="op">)</span></span>
<span></span>
<span><span class="va">results</span> <span class="op">&lt;-</span> <span class="va">model</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/pkg/tensorflow/man/evaluate.html" class="external-link">evaluate</a></span><span class="op">(</span><span class="va">x_test</span>, <span class="va">y_test</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## 42/42 - 0s - 10ms/step - loss: 0.0893 - sparse_categorical_accuracy: 0.9697</span></span></code></pre>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">results</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## List of 2</span></span>
<span><span class="co">##  $ loss                       : num 0.0893</span></span>
<span><span class="co">##  $ sparse_categorical_accuracy: num 0.97</span></span></code></pre>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span></span>
<span>  <span class="st">"Test accuracy: "</span>, <span class="va">results</span><span class="op">$</span><span class="va">sparse_categorical_accuracy</span>, <span class="st">"\n"</span>,</span>
<span>  <span class="st">"Test loss: "</span>, <span class="va">results</span><span class="op">$</span><span class="va">loss</span>, <span class="st">"\n"</span>,</span>
<span>  sep <span class="op">=</span> <span class="st">""</span></span>
<span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Test accuracy: 0.969697</span></span>
<span><span class="co">## Test loss: 0.08933648</span></span></code></pre>
</div>
<div class="section level2">
<h2 id="plot-the-models-training-history">Plot the model’s training history<a class="anchor" aria-label="anchor" href="#plot-the-models-training-history"></a>
</h2>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">history</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="timeseries_classification_from_scratch/unnamed-chunk-12-1.png" alt="plot of chunk unnamed-chunk-12"><div class="figcaption">plot of chunk unnamed-chunk-12</div>
</div>
<p>Plot just the training and validation accuracy:</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">history</span>, metric <span class="op">=</span> <span class="st">"sparse_categorical_accuracy"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="co"># scale x axis to actual number of epochs run before early stopping</span></span>
<span>  <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/lims.html" class="external-link">xlim</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">history</span><span class="op">$</span><span class="va">metrics</span><span class="op">$</span><span class="va">loss</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="timeseries_classification_from_scratch/unnamed-chunk-13-1.png" alt="plot of chunk unnamed-chunk-13"><div class="figcaption">plot of chunk unnamed-chunk-13</div>
</div>
<p>We can see how the training accuracy reaches almost 0.95 after 100
epochs. However, by observing the validation accuracy we can see how the
network still needs training until it reaches almost 0.97 for both the
validation and the training accuracy after 200 epochs. Beyond the 200th
epoch, if we continue on training, the validation accuracy will start
decreasing while the training accuracy will continue on increasing: the
model starts overfitting.</p>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Tomasz Kalinowski, JJ Allaire, François Chollet, Posit Software, PBC, Google.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
