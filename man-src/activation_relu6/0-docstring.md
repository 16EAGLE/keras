Relu6 activation function.

It's the ReLU function, but truncated to a maximum value of 6.

Args:
    x: Input tensor.
