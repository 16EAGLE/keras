diff --git a/man-src/callback_reduce_lr_on_plateau/roxygen.Rmd b/man-src/callback_reduce_lr_on_plateau/roxygen.Rmd
index 63296454..77f7a3db 100644
--- a/man-src/callback_reduce_lr_on_plateau/roxygen.Rmd
+++ b/man-src/callback_reduce_lr_on_plateau/roxygen.Rmd
@@ -9,6 +9,6 @@ of epochs, the learning rate is reduced.
 # Examples
-```python
-reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,
-                              patience=5, min_lr=0.001)
-model.fit(x_train, y_train, callbacks=[reduce_lr])
+```{r}
+reduce_lr <- callback_reduce_lr_on_plateau(monitor = 'val_loss', factor = 0.2,
+                                           patience = 5, min_lr = 0.001)
+model %>% fit(x_train, y_train, callbacks = list(reduce_lr))
 ```
@@ -16,3 +16,3 @@ model.fit(x_train, y_train, callbacks=[reduce_lr])
 @param monitor String. Quantity to be monitored.
-@param factor Float. Factor by which the learning rate will be reduced.
+@param factor Numeric. Factor by which the learning rate will be reduced.
     `new_lr = lr * factor`.
@@ -27,3 +27,3 @@ model.fit(x_train, y_train, callbacks=[reduce_lr])
     of the monitored quantity.
-@param min_delta Float. Threshold for measuring the new optimum, to only focus
+@param min_delta Numeric. Threshold for measuring the new optimum, to only focus
     on significant changes.
@@ -31,4 +31,4 @@ model.fit(x_train, y_train, callbacks=[reduce_lr])
     operation after the learning rate has been reduced.
-@param min_lr Float. Lower bound on the learning rate.
-@param ... Passed on to the Python callable
+@param min_lr Numeric. Lower bound on the learning rate.
+@param ... For forward/backward compatability.
 
