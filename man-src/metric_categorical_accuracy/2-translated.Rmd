---
knit: ({source(here::here("tools/knit.R")); knit_man_src})
---
Calculates how often predictions match one-hot labels.

@description
You can provide logits of classes as `y_pred`, since argmax of
logits and probabilities are same.

This metric creates two local variables, `total` and `count` that are used
to compute the frequency with which `y_pred` matches `y_true`. This
frequency is ultimately returned as `categorical accuracy`: an idempotent
operation that simply divides `total` by `count`.

`y_pred` and `y_true` should be passed in as vectors of probabilities,
rather than as labels. If necessary, use `k_one_hot` to expand `y_true` as
a vector.

If `sample_weight` is `NULL`, weights default to 1.
Use `sample_weight` of 0 to mask values.

# Usage
Standalone usage:

```{r}
m <- metric_categorical_accuracy()
m$update_state(rbind(c(0, 0, 1), c(0, 1, 0)), rbind(c(0.1, 0.9, 0.8),
                c(0.05, 0.95, 0)))
m$result()
```

```{r}
m$reset_state()
m$update_state(rbind(c(0, 0, 1), c(0, 1, 0)), rbind(c(0.1, 0.9, 0.8),
               c(0.05, 0.95, 0)),
               sample_weight = c(0.7, 0.3))
m$result()
# 0.3
```

Usage with `compile()` API:

```{r, eval = FALSE}
model %>% compile(optimizer = 'sgd',
                  loss = 'categorical_crossentropy',
                  metrics = list(metric_categorical_accuracy()))
```

@param name
(Optional) string name of the metric instance.

@param dtype
(Optional) data type of the metric result.

@param y_true
Tensor of true targets.

@param y_pred
Tensor of predicted targets.

@param ...
Passed on to the Python callable

@export
@family metric
@seealso
+ <https:/keras.io/api/metrics/accuracy_metrics#categoricalaccuracy-class>
+ <https://www.tensorflow.org/api_docs/python/tf/keras/metrics/CategoricalAccuracy>

