## Autogenerated. Do not modify manually.


# keras$layers$CategoryEncoding
# keras_core.src.layers.preprocessing.category_encoding.CategoryEncoding
r"-(A preprocessing layer which encodes integer features.

    This layer provides options for condensing data into a categorical encoding
    when the total number of tokens are known in advance. It accepts integer
    values as inputs, and it outputs a dense or sparse representation of those
    inputs. For integer inputs where the total number of tokens is not known,
    use `keras.layers.IntegerLookup` instead.

    **Note:** This layer is safe to use inside a `tf.data` pipeline
    (independently of which backend you're using).

    Examples:

    **One-hot encoding data**

    >>> layer = keras.layers.CategoryEncoding(
    ...           num_tokens=4, output_mode="one_hot")
    >>> layer([3, 2, 0, 1])
    array([[0., 0., 0., 1.],
            [0., 0., 1., 0.],
            [1., 0., 0., 0.],
            [0., 1., 0., 0.]]>

    **Multi-hot encoding data**

    >>> layer = keras.layers.CategoryEncoding(
    ...           num_tokens=4, output_mode="multi_hot")
    >>> layer([[0, 1], [0, 0], [1, 2], [3, 1]])
    array([[1., 1., 0., 0.],
            [1., 0., 0., 0.],
            [0., 1., 1., 0.],
            [0., 1., 0., 1.]]>

    **Using weighted inputs in `"count"` mode**

    >>> layer = keras.layers.CategoryEncoding(
    ...           num_tokens=4, output_mode="count")
    >>> count_weights = np.array([[.1, .2], [.1, .1], [.2, .3], [.4, .2]])
    >>> layer([[0, 1], [0, 0], [1, 2], [3, 1]], count_weights=count_weights)
      array([[0.1, 0.2, 0. , 0. ],
             [0.2, 0. , 0. , 0. ],
             [0. , 0.2, 0.3, 0. ],
             [0. , 0.2, 0. , 0.4]]>

    Args:
        num_tokens: The total number of tokens the layer should support. All
            inputs to the layer must integers in the range `0 <= value <
            num_tokens`, or an error will be thrown.
        output_mode: Specification for the output of the layer.
            Values can be `"one_hot"`, `"multi_hot"` or `"count"`,
            configuring the layer as follows:
                - `"one_hot"`: Encodes each individual element in the input
                    into an array of `num_tokens` size, containing a 1 at the
                    element index. If the last dimension is size 1, will encode
                    on that dimension. If the last dimension is not size 1,
                    will append a new dimension for the encoded output.
                - `"multi_hot"`: Encodes each sample in the input into a single
                    array of `num_tokens` size, containing a 1 for each
                    vocabulary term present in the sample. Treats the last
                    dimension as the sample dimension, if input shape is
                    `(..., sample_length)`, output shape will be
                    `(..., num_tokens)`.
                - `"count"`: Like `"multi_hot"`, but the int array contains a
                    count of the number of times the token at that index
                    appeared in the sample.
            For all output modes, currently only output up to rank 2 is
            supported.
            Defaults to `"multi_hot"`.

    Call arguments:
        inputs: A 1D or 2D tensor of integer inputs.
        count_weights: A tensor in the same shape as `inputs` indicating the
            weight for each sample value when summing up in `count` mode.
            Not used in `"multi_hot"` or `"one_hot"` modes.
    )-"


# keras_core.src.layers.preprocessing.category_encoding.CategoryEncoding
#' A preprocessing layer which encodes integer features.
#'
#' @description
#' This layer provides options for condensing data into a categorical encoding
#' when the total number of tokens are known in advance. It accepts integer
#' values as inputs, and it outputs a dense or sparse representation of those
#' inputs. For integer inputs where the total number of tokens is not known,
#' use `keras.layers.IntegerLookup` instead.
#'
#' **Note:** This layer is safe to use inside a `tf.data` pipeline
#' (independently of which backend you're using).
#'
#' # Examples
#' **One-hot encoding data**
#'
#' ```python
#' layer = keras.layers.CategoryEncoding(
#'           num_tokens=4, output_mode="one_hot")
#' layer([3, 2, 0, 1])
#' # array([[0., 0., 0., 1.],
#' #         [0., 0., 1., 0.],
#' #         [1., 0., 0., 0.],
#' #         [0., 1., 0., 0.]]>
#' ```
#'
#' **Multi-hot encoding data**
#'
#' ```python
#' layer = keras.layers.CategoryEncoding(
#'           num_tokens=4, output_mode="multi_hot")
#' layer([[0, 1], [0, 0], [1, 2], [3, 1]])
#' # array([[1., 1., 0., 0.],
#' #         [1., 0., 0., 0.],
#' #         [0., 1., 1., 0.],
#' #         [0., 1., 0., 1.]]>
#' ```
#'
#' **Using weighted inputs in `"count"` mode**
#'
#' ```python
#' layer = keras.layers.CategoryEncoding(
#'           num_tokens=4, output_mode="count")
#' count_weights = np.array([[.1, .2], [.1, .1], [.2, .3], [.4, .2]])
#' layer([[0, 1], [0, 0], [1, 2], [3, 1]], count_weights=count_weights)
#' #   array([[0.1, 0.2, 0. , 0. ],
#' #          [0.2, 0. , 0. , 0. ],
#' #          [0. , 0.2, 0.3, 0. ],
#' #          [0. , 0.2, 0. , 0.4]]>
#' ```
#'
#' # Call Arguments
#' - `inputs`: A 1D or 2D tensor of integer inputs.
#' - `count_weights`: A tensor in the same shape as `inputs` indicating the
#'     weight for each sample value when summing up in `count` mode.
#'     Not used in `"multi_hot"` or `"one_hot"` modes.
#'
#' @param num_tokens The total number of tokens the layer should support. All
#'     inputs to the layer must integers in the range `0 <= value <
#'     num_tokens`, or an error will be thrown.
#' @param output_mode Specification for the output of the layer.
#'     Values can be `"one_hot"`, `"multi_hot"` or `"count"`,
#'     configuring the layer as follows:
#'         - `"one_hot"`: Encodes each individual element in the input
#'             into an array of `num_tokens` size, containing a 1 at the
#'             element index. If the last dimension is size 1, will encode
#'             on that dimension. If the last dimension is not size 1,
#'             will append a new dimension for the encoded output.
#'         - `"multi_hot"`: Encodes each sample in the input into a single
#'             array of `num_tokens` size, containing a 1 for each
#'             vocabulary term present in the sample. Treats the last
#'             dimension as the sample dimension, if input shape is
#'             `(..., sample_length)`, output shape will be
#'             `(..., num_tokens)`.
#'         - `"count"`: Like `"multi_hot"`, but the int array contains a
#'             count of the number of times the token at that index
#'             appeared in the sample.
#'     For all output modes, currently only output up to rank 2 is
#'     supported.
#'     Defaults to `"multi_hot"`.
#' @param object Object to compose the layer with. A tensor, array, or sequential model.
#' @param ... Passed on to the Python callable
#'
#' @export
#' @family preprocessing layers
#' @seealso
#' + <https://www.tensorflow.org/api_docs/python/tf/keras/layers/CategoryEncoding>
layer_category_encoding <-
function (object, num_tokens = NULL, output_mode = "multi_hot",
    ...)
{
    args <- capture_args2(list(output_mode = as_integer, input_shape = normalize_shape,
        batch_size = as_integer, batch_input_shape = normalize_shape,
        num_tokens = as_integer), ignore = "object")
    create_layer(keras$layers$CategoryEncoding, object, args)
}


# keras$layers$CenterCrop
# keras_core.src.layers.preprocessing.center_crop.CenterCrop
r"-(A preprocessing layer which crops images.

    This layers crops the central portion of the images to a target size. If an
    image is smaller than the target size, it will be resized and cropped
    so as to return the largest possible window in the image that matches
    the target aspect ratio.

    Input pixel values can be of any range (e.g. `[0., 1.)` or `[0, 255]`).

    Input shape:
        3D (unbatched) or 4D (batched) tensor with shape:
        `(..., height, width, channels)`, in `"channels_last"` format,
        or `(..., channels, height, width)`, in `"channels_first"` format.

    Output shape:
        3D (unbatched) or 4D (batched) tensor with shape:
        `(..., target_height, target_width, channels)`,
        or `(..., channels, target_height, target_width)`,
        in `"channels_first"` format.

    If the input height/width is even and the target height/width is odd (or
    inversely), the input image is left-padded by 1 pixel.

    **Note:** This layer is safe to use inside a `tf.data` pipeline
    (independently of which backend you're using).

    Args:
        height: Integer, the height of the output shape.
        width: Integer, the width of the output shape.
        data_format: string, either `"channels_last"` or `"channels_first"`.
            The ordering of the dimensions in the inputs. `"channels_last"`
            corresponds to inputs with shape `(batch, height, width, channels)`
            while `"channels_first"` corresponds to inputs with shape
            `(batch, channels, height, width)`. It defaults to the
            `image_data_format` value found in your Keras config file at
            `~/.keras/keras.json`. If you never set it, then it will be
            `"channels_last"`.
    )-"


# keras_core.src.layers.preprocessing.center_crop.CenterCrop
#' A preprocessing layer which crops images.
#'
#' @description
#' This layers crops the central portion of the images to a target size. If an
#' image is smaller than the target size, it will be resized and cropped
#' so as to return the largest possible window in the image that matches
#' the target aspect ratio.
#'
#' Input pixel values can be of any range (e.g. `[0., 1.)` or `[0, 255]`).
#'
#' # Input Shape
#' 3D (unbatched) or 4D (batched) tensor with shape:
#' `(..., height, width, channels)`, in `"channels_last"` format,
#' or `(..., channels, height, width)`, in `"channels_first"` format.
#'
#' # Output Shape
#' 3D (unbatched) or 4D (batched) tensor with shape:
#'     `(..., target_height, target_width, channels)`,
#'     or `(..., channels, target_height, target_width)`,
#'     in `"channels_first"` format.
#'
#' If the input height/width is even and the target height/width is odd (or
#' inversely), the input image is left-padded by 1 pixel.
#'
#' **Note:** This layer is safe to use inside a `tf.data` pipeline
#' (independently of which backend you're using).
#'
#' @param height Integer, the height of the output shape.
#' @param width Integer, the width of the output shape.
#' @param data_format string, either `"channels_last"` or `"channels_first"`.
#'     The ordering of the dimensions in the inputs. `"channels_last"`
#'     corresponds to inputs with shape `(batch, height, width, channels)`
#'     while `"channels_first"` corresponds to inputs with shape
#'     `(batch, channels, height, width)`. It defaults to the
#'     `image_data_format` value found in your Keras config file at
#'     `~/.keras/keras.json`. If you never set it, then it will be
#'     `"channels_last"`.
#' @param object Object to compose the layer with. A tensor, array, or sequential model.
#' @param ... Passed on to the Python callable
#'
#' @export
#' @family preprocessing layers
#' @seealso
#' + <https://www.tensorflow.org/api_docs/python/tf/keras/layers/CenterCrop>
layer_center_crop <-
function (object, height, width, data_format = NULL, ...)
{
    args <- capture_args2(list(height = as_integer, width = as_integer,
        input_shape = normalize_shape, batch_size = as_integer,
        batch_input_shape = normalize_shape), ignore = "object")
    create_layer(keras$layers$CenterCrop, object, args)
}


# keras$layers$Discretization
# keras_core.src.layers.preprocessing.discretization.Discretization
r"-(A preprocessing layer which buckets continuous features by ranges.

    This layer will place each element of its input data into one of several
    contiguous ranges and output an integer index indicating which range each
    element was placed in.

    **Note:** This layer is safe to use inside a `tf.data` pipeline
    (independently of which backend you're using).

    Input shape:
        Any array of dimension 2 or higher.

    Output shape:
        Same as input shape.

    Arguments:
        bin_boundaries: A list of bin boundaries.
            The leftmost and rightmost bins
            will always extend to `-inf` and `inf`,
            so `bin_boundaries=[0., 1., 2.]`
            generates bins `(-inf, 0.)`, `[0., 1.)`, `[1., 2.)`,
            and `[2., +inf)`.
            If this option is set, `adapt()` should not be called.
        num_bins: The integer number of bins to compute.
            If this option is set,
            `adapt()` should be called to learn the bin boundaries.
        epsilon: Error tolerance, typically a small fraction
            close to zero (e.g. 0.01). Higher values of epsilon increase
            the quantile approximation, and hence result in more
            unequal buckets, but could improve performance
            and resource consumption.
        output_mode: Specification for the output of the layer.
            Values can be `"int"`, `"one_hot"`, `"multi_hot"`, or
            `"count"` configuring the layer as follows:
            - `"int"`: Return the discretized bin indices directly.
            - `"one_hot"`: Encodes each individual element in the
                input into an array the same size as `num_bins`,
                containing a 1 at the input's bin
                index. If the last dimension is size 1, will encode on that
                dimension.  If the last dimension is not size 1,
                will append a new dimension for the encoded output.
            - `"multi_hot"`: Encodes each sample in the input into a
                single array the same size as `num_bins`,
                containing a 1 for each bin index
                index present in the sample.
                Treats the last dimension as the sample
                dimension, if input shape is `(..., sample_length)`,
                output shape will be `(..., num_tokens)`.
            - `"count"`: As `"multi_hot"`, but the int array contains
                a count of the number of times the bin index appeared
                in the sample.
            Defaults to `"int"`.
        sparse: Boolean. Only applicable to `"one_hot"`, `"multi_hot"`,
            and `"count"` output modes. Only supported with TensorFlow
            backend. If `True`, returns a `SparseTensor` instead of
            a dense `Tensor`. Defaults to `False`.

    Examples:

    Discretize float values based on provided buckets.
    >>> input = np.array([[-1.5, 1.0, 3.4, .5], [0.0, 3.0, 1.3, 0.0]])
    >>> layer = Discretization(bin_boundaries=[0., 1., 2.])
    >>> layer(input)
    array([[0, 2, 3, 1],
           [1, 3, 2, 1]])

    Discretize float values based on a number of buckets to compute.
    >>> input = np.array([[-1.5, 1.0, 3.4, .5], [0.0, 3.0, 1.3, 0.0]])
    >>> layer = Discretization(num_bins=4, epsilon=0.01)
    >>> layer.adapt(input)
    >>> layer(input)
    array([[0, 2, 3, 2],
           [1, 3, 3, 1]])
    )-"


# keras_core.src.layers.preprocessing.discretization.Discretization
#' A preprocessing layer which buckets continuous features by ranges.
#'
#' @description
#' This layer will place each element of its input data into one of several
#' contiguous ranges and output an integer index indicating which range each
#' element was placed in.
#'
#' **Note:** This layer is safe to use inside a `tf.data` pipeline
#' (independently of which backend you're using).
#'
#' # Input Shape
#' Any array of dimension 2 or higher.
#'
#' # Output Shape
#' Same as input shape.
#'
#' # Examples
#' Discretize float values based on provided buckets.
#' ```python
#' input = np.array([[-1.5, 1.0, 3.4, .5], [0.0, 3.0, 1.3, 0.0]])
#' layer = Discretization(bin_boundaries=[0., 1., 2.])
#' layer(input)
#' # array([[0, 2, 3, 1],
#' #        [1, 3, 2, 1]])
#' ```
#'
#' Discretize float values based on a number of buckets to compute.
#' ```python
#' input = np.array([[-1.5, 1.0, 3.4, .5], [0.0, 3.0, 1.3, 0.0]])
#' layer = Discretization(num_bins=4, epsilon=0.01)
#' layer.adapt(input)
#' layer(input)
#' # array([[0, 2, 3, 2],
#' #        [1, 3, 3, 1]])
#' ```
#'
#' @param bin_boundaries A list of bin boundaries.
#'     The leftmost and rightmost bins
#'     will always extend to `-inf` and `inf`,
#'     so `bin_boundaries=[0., 1., 2.]`
#'     generates bins `(-inf, 0.)`, `[0., 1.)`, `[1., 2.)`,
#'     and `[2., +inf)`.
#'     If this option is set, `adapt()` should not be called.
#' @param num_bins The integer number of bins to compute.
#'     If this option is set,
#'     `adapt()` should be called to learn the bin boundaries.
#' @param epsilon Error tolerance, typically a small fraction
#'     close to zero (e.g. 0.01). Higher values of epsilon increase
#'     the quantile approximation, and hence result in more
#'     unequal buckets, but could improve performance
#'     and resource consumption.
#' @param output_mode Specification for the output of the layer.
#'     Values can be `"int"`, `"one_hot"`, `"multi_hot"`, or
#'     `"count"` configuring the layer as follows:
#'     - `"int"`: Return the discretized bin indices directly.
#'     - `"one_hot"`: Encodes each individual element in the
#'         input into an array the same size as `num_bins`,
#'         containing a 1 at the input's bin
#'         index. If the last dimension is size 1, will encode on that
#'         dimension.  If the last dimension is not size 1,
#'         will append a new dimension for the encoded output.
#'     - `"multi_hot"`: Encodes each sample in the input into a
#'         single array the same size as `num_bins`,
#'         containing a 1 for each bin index
#'         index present in the sample.
#'         Treats the last dimension as the sample
#'         dimension, if input shape is `(..., sample_length)`,
#'         output shape will be `(..., num_tokens)`.
#'     - `"count"`: As `"multi_hot"`, but the int array contains
#'         a count of the number of times the bin index appeared
#'         in the sample.
#'     Defaults to `"int"`.
#' @param sparse Boolean. Only applicable to `"one_hot"`, `"multi_hot"`,
#'     and `"count"` output modes. Only supported with TensorFlow
#'     backend. If `True`, returns a `SparseTensor` instead of
#'     a dense `Tensor`. Defaults to `False`.
#' @param object Object to compose the layer with. A tensor, array, or sequential model.
#' @param name name for the layer
#' @param dtype datatype (e.g., `"float32"`)
#'
#' @export
#' @family preprocessing layers
#' @seealso
#' + <https://www.tensorflow.org/api_docs/python/tf/keras/layers/Discretization>
layer_discretization <-
function (object, bin_boundaries = NULL, num_bins = NULL, epsilon = 0.01,
    output_mode = "int", sparse = FALSE, dtype = NULL, name = NULL)
{
    args <- capture_args2(list(num_bins = as_integer, output_mode = as_integer,
        input_shape = normalize_shape, batch_size = as_integer,
        batch_input_shape = normalize_shape), ignore = "object")
    create_layer(keras$layers$Discretization, object, args)
}


# keras$layers$HashedCrossing
# keras_core.src.layers.preprocessing.hashed_crossing.HashedCrossing
r"-(A preprocessing layer which crosses features using the "hashing trick".

    This layer performs crosses of categorical features using the "hashing
    trick". Conceptually, the transformation can be thought of as:
    `hash(concatenate(features)) % num_bins.

    This layer currently only performs crosses of scalar inputs and batches of
    scalar inputs. Valid input shapes are `(batch_size, 1)`, `(batch_size,)` and
    `()`.

    **Note:** This layer wraps `tf.keras.layers.HashedCrossing`. It cannot
    be used as part of the compiled computation graph of a model with
    any backend other than TensorFlow.
    It can however be used with any backend when running eagerly.
    It can also always be used as part of an input preprocessing pipeline
    with any backend (outside the model itself), which is how we recommend
    to use this layer.

    **Note:** This layer is safe to use inside a `tf.data` pipeline
    (independently of which backend you're using).

    Args:
        num_bins: Number of hash bins.
        output_mode: Specification for the output of the layer. Values can be
            `"int"`, or `"one_hot"` configuring the layer as follows:
            - `"int"`: Return the integer bin indices directly.
            - `"one_hot"`: Encodes each individual element in the input into an
                array the same size as `num_bins`, containing a 1 at the input's
                bin index. Defaults to `"int"`.
        sparse: Boolean. Only applicable to `"one_hot"` mode and only valid
            when using the TensorFlow backend. If `True`, returns
            a `SparseTensor` instead of a dense `Tensor`. Defaults to `False`.
        **kwargs: Keyword arguments to construct a layer.

    Examples:

    **Crossing two scalar features.**

    >>> layer = keras.layers.HashedCrossing(
    ...     num_bins=5)
    >>> feat1 = np.array(['A', 'B', 'A', 'B', 'A'])
    >>> feat2 = np.array([101, 101, 101, 102, 102])
    >>> layer((feat1, feat2))
    array([1, 4, 1, 1, 3])

    **Crossing and one-hotting two scalar features.**

    >>> layer = keras.layers.HashedCrossing(
    ...     num_bins=5, output_mode='one_hot')
    >>> feat1 = np.array(['A', 'B', 'A', 'B', 'A'])
    >>> feat2 = np.array([101, 101, 101, 102, 102])
    >>> layer((feat1, feat2))
    array([[0., 1., 0., 0., 0.],
            [0., 0., 0., 0., 1.],
            [0., 1., 0., 0., 0.],
            [0., 1., 0., 0., 0.],
            [0., 0., 0., 1., 0.]], dtype=float32)
    )-"


# keras_core.src.layers.preprocessing.hashed_crossing.HashedCrossing
#' A preprocessing layer which crosses features using the "hashing trick".
#'
#' @description
#' This layer performs crosses of categorical features using the "hashing
#' trick". Conceptually, the transformation can be thought of as:
#' `hash(concatenate(features)) % num_bins.
#'
#' This layer currently only performs crosses of scalar inputs and batches of
#' scalar inputs. Valid input shapes are `(batch_size, 1)`, `(batch_size,)` and
#' `()`.
#'
#' **Note:** This layer wraps `tf.keras.layers.HashedCrossing`. It cannot
#' be used as part of the compiled computation graph of a model with
#' any backend other than TensorFlow.
#' It can however be used with any backend when running eagerly.
#' It can also always be used as part of an input preprocessing pipeline
#' with any backend (outside the model itself), which is how we recommend
#' to use this layer.
#'
#' **Note:** This layer is safe to use inside a `tf.data` pipeline
#' (independently of which backend you're using).
#'
#' # Examples
#' **Crossing two scalar features.**
#'
#' ```python
#' layer = keras.layers.HashedCrossing(
#'     num_bins=5)
#' feat1 = np.array(['A', 'B', 'A', 'B', 'A'])
#' feat2 = np.array([101, 101, 101, 102, 102])
#' layer((feat1, feat2))
#' # array([1, 4, 1, 1, 3])
#' ```
#'
#' **Crossing and one-hotting two scalar features.**
#'
#' ```python
#' layer = keras.layers.HashedCrossing(
#'     num_bins=5, output_mode='one_hot')
#' feat1 = np.array(['A', 'B', 'A', 'B', 'A'])
#' feat2 = np.array([101, 101, 101, 102, 102])
#' layer((feat1, feat2))
#' # array([[0., 1., 0., 0., 0.],
#' #         [0., 0., 0., 0., 1.],
#' #         [0., 1., 0., 0., 0.],
#' #         [0., 1., 0., 0., 0.],
#' #         [0., 0., 0., 1., 0.]], dtype=float32)
#' ```
#'
#' @param num_bins Number of hash bins.
#' @param output_mode Specification for the output of the layer. Values can be
#'     `"int"`, or `"one_hot"` configuring the layer as follows:
#'     - `"int"`: Return the integer bin indices directly.
#'     - `"one_hot"`: Encodes each individual element in the input into an
#'         array the same size as `num_bins`, containing a 1 at the input's
#'         bin index. Defaults to `"int"`.
#' @param sparse Boolean. Only applicable to `"one_hot"` mode and only valid
#'     when using the TensorFlow backend. If `True`, returns
#'     a `SparseTensor` instead of a dense `Tensor`. Defaults to `False`.
#' @param ... Keyword arguments to construct a layer.
#' @param object Object to compose the layer with. A tensor, array, or sequential model.
#' @param name name for the layer
#' @param dtype datatype (e.g., `"float32"`)
#'
#' @export
#' @family preprocessing layers
#' @seealso
#' + <https://www.tensorflow.org/api_docs/python/tf/keras/layers/HashedCrossing>
layer_hashed_crossing <-
function (object, num_bins, output_mode = "int", sparse = FALSE,
    name = NULL, dtype = NULL, ...)
{
    args <- capture_args2(list(output_mode = as_integer, input_shape = normalize_shape,
        batch_size = as_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$HashedCrossing, object, args)
}


# keras$layers$Hashing
# keras_core.src.layers.preprocessing.hashing.Hashing
r"-(A preprocessing layer which hashes and bins categorical features.

    This layer transforms categorical inputs to hashed output. It element-wise
    converts a ints or strings to ints in a fixed range. The stable hash
    function uses `tensorflow::ops::Fingerprint` to produce the same output
    consistently across all platforms.

    This layer uses [FarmHash64](https://github.com/google/farmhash) by default,
    which provides a consistent hashed output across different platforms and is
    stable across invocations, regardless of device and context, by mixing the
    input bits thoroughly.

    If you want to obfuscate the hashed output, you can also pass a random
    `salt` argument in the constructor. In that case, the layer will use the
    [SipHash64](https://github.com/google/highwayhash) hash function, with
    the `salt` value serving as additional input to the hash function.

    **Note:** This layer internally uses TensorFlow. It cannot
    be used as part of the compiled computation graph of a model with
    any backend other than TensorFlow.
    It can however be used with any backend when running eagerly.
    It can also always be used as part of an input preprocessing pipeline
    with any backend (outside the model itself), which is how we recommend
    to use this layer.

    **Note:** This layer is safe to use inside a `tf.data` pipeline
    (independently of which backend you're using).

    **Example (FarmHash64)**

    >>> layer = keras.layers.Hashing(num_bins=3)
    >>> inp = [['A'], ['B'], ['C'], ['D'], ['E']]
    >>> layer(inp)
    array([[1],
            [0],
            [1],
            [1],
            [2]])>

    **Example (FarmHash64) with a mask value**

    >>> layer = keras.layers.Hashing(num_bins=3, mask_value='')
    >>> inp = [['A'], ['B'], [''], ['C'], ['D']]
    >>> layer(inp)
    array([[1],
            [1],
            [0],
            [2],
            [2]])

    **Example (SipHash64)**

    >>> layer = keras.layers.Hashing(num_bins=3, salt=[133, 137])
    >>> inp = [['A'], ['B'], ['C'], ['D'], ['E']]
    >>> layer(inp)
    array([[1],
            [2],
            [1],
            [0],
            [2]])

    **Example (Siphash64 with a single integer, same as `salt=[133, 133]`)**

    >>> layer = keras.layers.Hashing(num_bins=3, salt=133)
    >>> inp = [['A'], ['B'], ['C'], ['D'], ['E']]
    >>> layer(inp)
    array([[0],
            [0],
            [2],
            [1],
            [0]])

    Args:
        num_bins: Number of hash bins. Note that this includes the `mask_value`
            bin, so the effective number of bins is `(num_bins - 1)`
            if `mask_value` is set.
        mask_value: A value that represents masked inputs, which are mapped to
            index 0. `None` means no mask term will be added and the
            hashing will start at index 0. Defaults to `None`.
        salt: A single unsigned integer or None.
            If passed, the hash function used will be SipHash64,
            with these values used as an additional input
            (known as a "salt" in cryptography).
            These should be non-zero. If `None`, uses the FarmHash64 hash
            function. It also supports tuple/list of 2 unsigned
            integer numbers, see reference paper for details.
            Defaults to `None`.
        output_mode: Specification for the output of the layer. Values can be
            `"int"`, `"one_hot"`, `"multi_hot"`, or
            `"count"` configuring the layer as follows:
            - `"int"`: Return the integer bin indices directly.
            - `"one_hot"`: Encodes each individual element in the input into an
                array the same size as `num_bins`, containing a 1
                at the input's bin index. If the last dimension is size 1,
                will encode on that dimension.
                If the last dimension is not size 1, will append a new
                dimension for the encoded output.
            - `"multi_hot"`: Encodes each sample in the input into a
                single array the same size as `num_bins`,
                containing a 1 for each bin index
                index present in the sample. Treats the last dimension
                as the sample dimension, if input shape is
                `(..., sample_length)`, output shape will be
                `(..., num_tokens)`.
            - `"count"`: As `"multi_hot"`, but the int array contains a count of
                the number of times the bin index appeared in the sample.
            Defaults to `"int"`.
        sparse: Boolean. Only applicable to `"one_hot"`, `"multi_hot"`,
            and `"count"` output modes. Only supported with TensorFlow
            backend. If `True`, returns a `SparseTensor` instead of
            a dense `Tensor`. Defaults to `False`.
        **kwargs: Keyword arguments to construct a layer.

    Input shape:
        A single string, a list of strings, or an `int32` or `int64` tensor
        of shape `(batch_size, ...,)`.

    Output shape:
        An `int32` tensor of shape `(batch_size, ...)`.

    Reference:

    - [SipHash with salt](https://www.131002.net/siphash/siphash.pdf)
    )-"


# keras_core.src.layers.preprocessing.hashing.Hashing
#' A preprocessing layer which hashes and bins categorical features.
#'
#' @description
#' This layer transforms categorical inputs to hashed output. It element-wise
#' converts a ints or strings to ints in a fixed range. The stable hash
#' function uses `tensorflow::ops::Fingerprint` to produce the same output
#' consistently across all platforms.
#'
#' This layer uses [FarmHash64](https://github.com/google/farmhash) by default,
#' which provides a consistent hashed output across different platforms and is
#' stable across invocations, regardless of device and context, by mixing the
#' input bits thoroughly.
#'
#' If you want to obfuscate the hashed output, you can also pass a random
#' `salt` argument in the constructor. In that case, the layer will use the
#' [SipHash64](https://github.com/google/highwayhash) hash function, with
#' the `salt` value serving as additional input to the hash function.
#'
#' **Note:** This layer internally uses TensorFlow. It cannot
#' be used as part of the compiled computation graph of a model with
#' any backend other than TensorFlow.
#' It can however be used with any backend when running eagerly.
#' It can also always be used as part of an input preprocessing pipeline
#' with any backend (outside the model itself), which is how we recommend
#' to use this layer.
#'
#' **Note:** This layer is safe to use inside a `tf.data` pipeline
#' (independently of which backend you're using).
#'
#' **Example (FarmHash64)**
#'
#' ```python
#' layer = keras.layers.Hashing(num_bins=3)
#' inp = [['A'], ['B'], ['C'], ['D'], ['E']]
#' layer(inp)
#' # array([[1],
#' #         [0],
#' #         [1],
#' #         [1],
#' #         [2]])>
#' ```
#'
#' **Example (FarmHash64) with a mask value**
#'
#' ```python
#' layer = keras.layers.Hashing(num_bins=3, mask_value='')
#' inp = [['A'], ['B'], [''], ['C'], ['D']]
#' layer(inp)
#' # array([[1],
#' #         [1],
#' #         [0],
#' #         [2],
#' #         [2]])
#' ```
#'
#' **Example (SipHash64)**
#'
#' ```python
#' layer = keras.layers.Hashing(num_bins=3, salt=[133, 137])
#' inp = [['A'], ['B'], ['C'], ['D'], ['E']]
#' layer(inp)
#' # array([[1],
#' #         [2],
#' #         [1],
#' #         [0],
#' #         [2]])
#' ```
#'
#' **Example (Siphash64 with a single integer, same as `salt=[133, 133]`)**
#'
#' ```python
#' layer = keras.layers.Hashing(num_bins=3, salt=133)
#' inp = [['A'], ['B'], ['C'], ['D'], ['E']]
#' layer(inp)
#' # array([[0],
#' #         [0],
#' #         [2],
#' #         [1],
#' #         [0]])
#' ```
#'
#' # Input Shape
#' A single string, a list of strings, or an `int32` or `int64` tensor
#' of shape `(batch_size, ...,)`.
#'
#' # Output Shape
#' An `int32` tensor of shape `(batch_size, ...)`.
#'
#' # Reference
#' - [SipHash with salt](https://www.131002.net/siphash/siphash.pdf)
#'
#' @param num_bins Number of hash bins. Note that this includes the `mask_value`
#'     bin, so the effective number of bins is `(num_bins - 1)`
#'     if `mask_value` is set.
#' @param mask_value A value that represents masked inputs, which are mapped to
#'     index 0. `None` means no mask term will be added and the
#'     hashing will start at index 0. Defaults to `None`.
#' @param salt A single unsigned integer or None.
#'     If passed, the hash function used will be SipHash64,
#'     with these values used as an additional input
#'     (known as a "salt" in cryptography).
#'     These should be non-zero. If `None`, uses the FarmHash64 hash
#'     function. It also supports tuple/list of 2 unsigned
#'     integer numbers, see reference paper for details.
#'     Defaults to `None`.
#' @param output_mode Specification for the output of the layer. Values can be
#'     `"int"`, `"one_hot"`, `"multi_hot"`, or
#'     `"count"` configuring the layer as follows:
#'     - `"int"`: Return the integer bin indices directly.
#'     - `"one_hot"`: Encodes each individual element in the input into an
#'         array the same size as `num_bins`, containing a 1
#'         at the input's bin index. If the last dimension is size 1,
#'         will encode on that dimension.
#'         If the last dimension is not size 1, will append a new
#'         dimension for the encoded output.
#'     - `"multi_hot"`: Encodes each sample in the input into a
#'         single array the same size as `num_bins`,
#'         containing a 1 for each bin index
#'         index present in the sample. Treats the last dimension
#'         as the sample dimension, if input shape is
#'         `(..., sample_length)`, output shape will be
#'         `(..., num_tokens)`.
#'     - `"count"`: As `"multi_hot"`, but the int array contains a count of
#'         the number of times the bin index appeared in the sample.
#'     Defaults to `"int"`.
#' @param sparse Boolean. Only applicable to `"one_hot"`, `"multi_hot"`,
#'     and `"count"` output modes. Only supported with TensorFlow
#'     backend. If `True`, returns a `SparseTensor` instead of
#'     a dense `Tensor`. Defaults to `False`.
#' @param ... Keyword arguments to construct a layer.
#' @param object Object to compose the layer with. A tensor, array, or sequential model.
#'
#' @export
#' @family preprocessing layers
#' @seealso
#' + <https://www.tensorflow.org/api_docs/python/tf/keras/layers/Hashing>
layer_hashing <-
function (object, num_bins, mask_value = NULL, salt = NULL, output_mode = "int",
    sparse = FALSE, ...)
{
    args <- capture_args2(list(salt = as_integer, output_mode = as_integer,
        input_shape = normalize_shape, batch_size = as_integer,
        batch_input_shape = normalize_shape, num_bins = as_integer),
        ignore = "object")
    create_layer(keras$layers$Hashing, object, args)
}


# keras$layers$IntegerLookup
# keras_core.src.layers.preprocessing.integer_lookup.IntegerLookup
r"-(A preprocessing layer that maps integers to (possibly encoded) indices.

    This layer maps a set of arbitrary integer input tokens into indexed integer
    output via a table-based vocabulary lookup. The layer's output indices will
    be contiguously arranged up to the maximum vocab size, even if the input
    tokens are non-continguous or unbounded. The layer supports multiple options
    for encoding the output via `output_mode`, and has optional support for
    out-of-vocabulary (OOV) tokens and masking.

    The vocabulary for the layer must be either supplied on construction or
    learned via `adapt()`. During `adapt()`, the layer will analyze a data set,
    determine the frequency of individual integer tokens, and create a
    vocabulary from them. If the vocabulary is capped in size, the most frequent
    tokens will be used to create the vocabulary and all others will be treated
    as OOV.

    There are two possible output modes for the layer.  When `output_mode` is
    `"int"`, input integers are converted to their index in the vocabulary (an
    integer).  When `output_mode` is `"multi_hot"`, `"count"`, or `"tf_idf"`,
    input integers are encoded into an array where each dimension corresponds to
    an element in the vocabulary.

    The vocabulary can optionally contain a mask token as well as an OOV token
    (which can optionally occupy multiple indices in the vocabulary, as set
    by `num_oov_indices`).
    The position of these tokens in the vocabulary is fixed. When `output_mode`
    is `"int"`, the vocabulary will begin with the mask token at index 0,
    followed by OOV indices, followed by the rest of the vocabulary. When
    `output_mode` is `"multi_hot"`, `"count"`, or `"tf_idf"` the vocabulary will
    begin with OOV indices and instances of the mask token will be dropped.

    **Note:** This layer uses TensorFlow internally. It cannot
    be used as part of the compiled computation graph of a model with
    any backend other than TensorFlow.
    It can however be used with any backend when running eagerly.
    It can also always be used as part of an input preprocessing pipeline
    with any backend (outside the model itself), which is how we recommend
    to use this layer.

    **Note:** This layer is safe to use inside a `tf.data` pipeline
    (independently of which backend you're using).

    Args:
        max_tokens: Maximum size of the vocabulary for this layer. This should
            only be specified when adapting the vocabulary or when setting
            `pad_to_max_tokens=True`. If None, there is no cap on the size of
            the vocabulary. Note that this size includes the OOV
            and mask tokens. Defaults to `None`.
        num_oov_indices: The number of out-of-vocabulary tokens to use.
            If this value is more than 1, OOV inputs are modulated to
            determine their OOV value.
            If this value is 0, OOV inputs will cause an error when calling
            the layer. Defaults to `1`.
        mask_token: An integer token that represents masked inputs. When
            `output_mode` is `"int"`, the token is included in vocabulary
            and mapped to index 0. In other output modes,
            the token will not appear in the vocabulary and instances
            of the mask token in the input will be dropped.
            If set to None, no mask term will be added. Defaults to `None`.
        oov_token: Only used when `invert` is `True`. The token to return
            for OOV indices. Defaults to `-1`.
        vocabulary: Optional. Either an array of integers or a string path to a
            text file. If passing an array, can pass a tuple, list,
            1D NumPy array, or 1D tensor containing the integer vocbulary terms.
            If passing a file path, the file should contain one line per term
            in the vocabulary. If this argument is set,
            there is no need to `adapt()` the layer.
        vocabulary_dtype: The dtype of the vocabulary terms, for example
            `"int64"` or `"int32"`. Defaults to `"int64"`.
        idf_weights: Only valid when `output_mode` is `"tf_idf"`.
            A tuple, list, 1D NumPy array, or 1D tensor or the same length
            as the vocabulary, containing the floating point inverse document
            frequency weights, which will be multiplied by per sample term
            counts for the final TF-IDF weight.
            If the `vocabulary` argument is set, and `output_mode` is
            `"tf_idf"`, this argument must be supplied.
        invert: Only valid when `output_mode` is `"int"`.
            If `True`, this layer will map indices to vocabulary items
            instead of mapping vocabulary items to indices.
            Defaults to `False`.
        output_mode: Specification for the output of the layer. Values can be
            `"int"`, `"one_hot"`, `"multi_hot"`, `"count"`, or `"tf_idf"`
            configuring the layer as follows:
            - `"int"`: Return the vocabulary indices of the input tokens.
            - `"one_hot"`: Encodes each individual element in the input into an
                array the same size as the vocabulary,
                containing a 1 at the element index. If the last dimension
                is size 1, will encode on that dimension.
                If the last dimension is not size 1, will append a new
                dimension for the encoded output.
            - `"multi_hot"`: Encodes each sample in the input into a single
                array the same size as the vocabulary,
                containing a 1 for each vocabulary term present in the sample.
                Treats the last dimension as the sample dimension,
                if input shape is `(..., sample_length)`,
                output shape will be `(..., num_tokens)`.
            - `"count"`: As `"multi_hot"`, but the int array contains
                a count of the number of times the token at that index
                appeared in the sample.
            - `"tf_idf"`: As `"multi_hot"`, but the TF-IDF algorithm is
                applied to find the value in each token slot.
            For `"int"` output, any shape of input and output is supported.
            For all other output modes, currently only output up to rank 2
            is supported. Defaults to `"int"`.
        pad_to_max_tokens: Only applicable when `output_mode` is `"multi_hot"`,
            `"count"`, or `"tf_idf"`. If `True`, the output will have
            its feature axis padded to `max_tokens` even if the number
            of unique tokens in the vocabulary is less than `max_tokens`,
            resulting in a tensor of shape `(batch_size, max_tokens)`
            regardless of vocabulary size. Defaults to `False`.
        sparse: Boolean. Only applicable to `"multi_hot"`, `"count"`, and
            `"tf_idf"` output modes. Only supported with TensorFlow
            backend. If `True`, returns a `SparseTensor`
            instead of a dense `Tensor`. Defaults to `False`.

    Examples:

    **Creating a lookup layer with a known vocabulary**

    This example creates a lookup layer with a pre-existing vocabulary.

    >>> vocab = [12, 36, 1138, 42]
    >>> data = np.array([[12, 1138, 42], [42, 1000, 36]])  # Note OOV tokens
    >>> layer = IntegerLookup(vocabulary=vocab)
    >>> layer(data)
    array([[1, 3, 4],
           [4, 0, 2]])

    **Creating a lookup layer with an adapted vocabulary**

    This example creates a lookup layer and generates the vocabulary by
    analyzing the dataset.

    >>> data = np.array([[12, 1138, 42], [42, 1000, 36]])
    >>> layer = IntegerLookup()
    >>> layer.adapt(data)
    >>> layer.get_vocabulary()
    [-1, 42, 1138, 1000, 36, 12]

    Note that the OOV token -1 have been added to the vocabulary. The remaining
    tokens are sorted by frequency (42, which has 2 occurrences, is first) then
    by inverse sort order.

    >>> data = np.array([[12, 1138, 42], [42, 1000, 36]])
    >>> layer = IntegerLookup()
    >>> layer.adapt(data)
    >>> layer(data)
    array([[5, 2, 1],
           [1, 3, 4]])

    **Lookups with multiple OOV indices**

    This example demonstrates how to use a lookup layer with multiple OOV
    indices.  When a layer is created with more than one OOV index, any OOV
    tokens are hashed into the number of OOV buckets, distributing OOV tokens in
    a deterministic fashion across the set.

    >>> vocab = [12, 36, 1138, 42]
    >>> data = np.array([[12, 1138, 42], [37, 1000, 36]])
    >>> layer = IntegerLookup(vocabulary=vocab, num_oov_indices=2)
    >>> layer(data)
    array([[2, 4, 5],
           [1, 0, 3]])

    Note that the output for OOV token 37 is 1, while the output for OOV token
    1000 is 0. The in-vocab terms have their output index increased by 1 from
    earlier examples (12 maps to 2, etc) in order to make space for the extra
    OOV token.

    **One-hot output**

    Configure the layer with `output_mode='one_hot'`. Note that the first
    `num_oov_indices` dimensions in the ont_hot encoding represent OOV values.

    >>> vocab = [12, 36, 1138, 42]
    >>> data = np.array([12, 36, 1138, 42, 7])  # Note OOV tokens
    >>> layer = IntegerLookup(vocabulary=vocab, output_mode='one_hot')
    >>> layer(data)
    array([[0., 1., 0., 0., 0.],
            [0., 0., 1., 0., 0.],
            [0., 0., 0., 1., 0.],
            [0., 0., 0., 0., 1.],
            [1., 0., 0., 0., 0.]], dtype=float32)

    **Multi-hot output**

    Configure the layer with `output_mode='multi_hot'`. Note that the first
    `num_oov_indices` dimensions in the multi_hot encoding represent OOV tokens

    >>> vocab = [12, 36, 1138, 42]
    >>> data = np.array([[12, 1138, 42, 42],
    ...                  [42,    7, 36,  7]])  # Note OOV tokens
    >>> layer = IntegerLookup(vocabulary=vocab, output_mode='multi_hot')
    >>> layer(data)
    array([[0., 1., 0., 1., 1.],
           [1., 0., 1., 0., 1.]], dtype=float32)

    **Token count output**

    Configure the layer with `output_mode='count'`. As with multi_hot output,
    the first `num_oov_indices` dimensions in the output represent OOV tokens.

    >>> vocab = [12, 36, 1138, 42]
    >>> data = np.array([[12, 1138, 42, 42],
    ...                  [42,    7, 36,  7]])  # Note OOV tokens
    >>> layer = IntegerLookup(vocabulary=vocab, output_mode='count')
    >>> layer(data)
    array([[0., 1., 0., 1., 2.],
           [2., 0., 1., 0., 1.]], dtype=float32)

    **TF-IDF output**

    Configure the layer with `output_mode='tf_idf'`. As with multi_hot output,
    the first `num_oov_indices` dimensions in the output represent OOV tokens.

    Each token bin will output `token_count * idf_weight`, where the idf weights
    are the inverse document frequency weights per token. These should be
    provided along with the vocabulary. Note that the `idf_weight` for OOV
    tokens will default to the average of all idf weights passed in.

    >>> vocab = [12, 36, 1138, 42]
    >>> idf_weights = [0.25, 0.75, 0.6, 0.4]
    >>> data = np.array([[12, 1138, 42, 42],
    ...                  [42,    7, 36,  7]])  # Note OOV tokens
    >>> layer = IntegerLookup(
    ...     output_mode='tf_idf', vocabulary=vocab, idf_weights=idf_weights)
    >>> layer(data)
    array([[0.  , 0.25, 0.  , 0.6 , 0.8 ],
            [1.0 , 0.  , 0.75, 0.  , 0.4 ]], dtype=float32)

    To specify the idf weights for oov tokens, you will need to pass the entire
    vocabularly including the leading oov token.

    >>> vocab = [-1, 12, 36, 1138, 42]
    >>> idf_weights = [0.9, 0.25, 0.75, 0.6, 0.4]
    >>> data = np.array([[12, 1138, 42, 42],
    ...                  [42,    7, 36,  7]])  # Note OOV tokens
    >>> layer = IntegerLookup(
    ...     output_mode='tf_idf', vocabulary=vocab, idf_weights=idf_weights)
    >>> layer(data)
    array([[0.  , 0.25, 0.  , 0.6 , 0.8 ],
            [1.8 , 0.  , 0.75, 0.  , 0.4 ]], dtype=float32)

    When adapting the layer in `"tf_idf"` mode, each input sample will
    be considered a document, and IDF weight per token will be
    calculated as:
    `log(1 + num_documents / (1 + token_document_count))`.

    **Inverse lookup**

    This example demonstrates how to map indices to tokens using this layer.
    (You can also use `adapt()` with `inverse=True`, but for simplicity we'll
    pass the vocab in this example.)

    >>> vocab = [12, 36, 1138, 42]
    >>> data = np.array([[1, 3, 4], [4, 0, 2]])
    >>> layer = IntegerLookup(vocabulary=vocab, invert=True)
    >>> layer(data)
    array([[  12, 1138,   42],
           [  42,   -1,   36]])

    Note that the first index correspond to the oov token by default.

    **Forward and inverse lookup pairs**

    This example demonstrates how to use the vocabulary of a standard lookup
    layer to create an inverse lookup layer.

    >>> vocab = [12, 36, 1138, 42]
    >>> data = np.array([[12, 1138, 42], [42, 1000, 36]])
    >>> layer = IntegerLookup(vocabulary=vocab)
    >>> i_layer = IntegerLookup(
    ...     vocabulary=layer.get_vocabulary(), invert=True)
    >>> int_data = layer(data)
    >>> i_layer(int_data)
    array([[  12, 1138,   42],
           [  42,   -1,   36]])

    In this example, the input token 1000 resulted in an output of -1, since
    1000 was not in the vocabulary - it got represented as an OOV, and all OOV
    tokens are returned as -1 in the inverse layer. Also, note that for the
    inverse to work, you must have already set the forward layer vocabulary
    either directly or via `adapt()` before calling `get_vocabulary()`.
    )-"


# keras_core.src.layers.preprocessing.integer_lookup.IntegerLookup
#' A preprocessing layer that maps integers to (possibly encoded) indices.
#'
#' @description
#' This layer maps a set of arbitrary integer input tokens into indexed integer
#' output via a table-based vocabulary lookup. The layer's output indices will
#' be contiguously arranged up to the maximum vocab size, even if the input
#' tokens are non-continguous or unbounded. The layer supports multiple options
#' for encoding the output via `output_mode`, and has optional support for
#' out-of-vocabulary (OOV) tokens and masking.
#'
#' The vocabulary for the layer must be either supplied on construction or
#' learned via `adapt()`. During `adapt()`, the layer will analyze a data set,
#' determine the frequency of individual integer tokens, and create a
#' vocabulary from them. If the vocabulary is capped in size, the most frequent
#' tokens will be used to create the vocabulary and all others will be treated
#' as OOV.
#'
#' There are two possible output modes for the layer.  When `output_mode` is
#' `"int"`, input integers are converted to their index in the vocabulary (an
#' integer).  When `output_mode` is `"multi_hot"`, `"count"`, or `"tf_idf"`,
#' input integers are encoded into an array where each dimension corresponds to
#' an element in the vocabulary.
#'
#' The vocabulary can optionally contain a mask token as well as an OOV token
#' (which can optionally occupy multiple indices in the vocabulary, as set
#' by `num_oov_indices`).
#' The position of these tokens in the vocabulary is fixed. When `output_mode`
#' is `"int"`, the vocabulary will begin with the mask token at index 0,
#' followed by OOV indices, followed by the rest of the vocabulary. When
#' `output_mode` is `"multi_hot"`, `"count"`, or `"tf_idf"` the vocabulary will
#' begin with OOV indices and instances of the mask token will be dropped.
#'
#' **Note:** This layer uses TensorFlow internally. It cannot
#' be used as part of the compiled computation graph of a model with
#' any backend other than TensorFlow.
#' It can however be used with any backend when running eagerly.
#' It can also always be used as part of an input preprocessing pipeline
#' with any backend (outside the model itself), which is how we recommend
#' to use this layer.
#'
#' **Note:** This layer is safe to use inside a `tf.data` pipeline
#' (independently of which backend you're using).
#'
#' # Examples
#' **Creating a lookup layer with a known vocabulary**
#'
#' This example creates a lookup layer with a pre-existing vocabulary.
#'
#' ```python
#' vocab = [12, 36, 1138, 42]
#' data = np.array([[12, 1138, 42], [42, 1000, 36]])  # Note OOV tokens
#' layer = IntegerLookup(vocabulary=vocab)
#' layer(data)
#' # array([[1, 3, 4],
#' #        [4, 0, 2]])
#' ```
#'
#' **Creating a lookup layer with an adapted vocabulary**
#'
#' This example creates a lookup layer and generates the vocabulary by
#' analyzing the dataset.
#'
#' ```python
#' data = np.array([[12, 1138, 42], [42, 1000, 36]])
#' layer = IntegerLookup()
#' layer.adapt(data)
#' layer.get_vocabulary()
#' # [-1, 42, 1138, 1000, 36, 12]
#' ```
#'
#' Note that the OOV token -1 have been added to the vocabulary. The remaining
#' tokens are sorted by frequency (42, which has 2 occurrences, is first) then
#' by inverse sort order.
#'
#' ```python
#' data = np.array([[12, 1138, 42], [42, 1000, 36]])
#' layer = IntegerLookup()
#' layer.adapt(data)
#' layer(data)
#' # array([[5, 2, 1],
#' #        [1, 3, 4]])
#' ```
#'
#' **Lookups with multiple OOV indices**
#'
#' This example demonstrates how to use a lookup layer with multiple OOV
#' indices.  When a layer is created with more than one OOV index, any OOV
#' tokens are hashed into the number of OOV buckets, distributing OOV tokens in
#' a deterministic fashion across the set.
#'
#' ```python
#' vocab = [12, 36, 1138, 42]
#' data = np.array([[12, 1138, 42], [37, 1000, 36]])
#' layer = IntegerLookup(vocabulary=vocab, num_oov_indices=2)
#' layer(data)
#' # array([[2, 4, 5],
#' #        [1, 0, 3]])
#' ```
#'
#' Note that the output for OOV token 37 is 1, while the output for OOV token
#' 1000 is 0. The in-vocab terms have their output index increased by 1 from
#' earlier examples (12 maps to 2, etc) in order to make space for the extra
#' OOV token.
#'
#' **One-hot output**
#'
#' Configure the layer with `output_mode='one_hot'`. Note that the first
#' `num_oov_indices` dimensions in the ont_hot encoding represent OOV values.
#'
#' ```python
#' vocab = [12, 36, 1138, 42]
#' data = np.array([12, 36, 1138, 42, 7])  # Note OOV tokens
#' layer = IntegerLookup(vocabulary=vocab, output_mode='one_hot')
#' layer(data)
#' # array([[0., 1., 0., 0., 0.],
#' #         [0., 0., 1., 0., 0.],
#' #         [0., 0., 0., 1., 0.],
#' #         [0., 0., 0., 0., 1.],
#' #         [1., 0., 0., 0., 0.]], dtype=float32)
#' ```
#'
#' **Multi-hot output**
#'
#' Configure the layer with `output_mode='multi_hot'`. Note that the first
#' `num_oov_indices` dimensions in the multi_hot encoding represent OOV tokens
#'
#' ```python
#' vocab = [12, 36, 1138, 42]
#' data = np.array([[12, 1138, 42, 42],
#'                  [42,    7, 36,  7]])  # Note OOV tokens
#' layer = IntegerLookup(vocabulary=vocab, output_mode='multi_hot')
#' layer(data)
#' # array([[0., 1., 0., 1., 1.],
#' #        [1., 0., 1., 0., 1.]], dtype=float32)
#' ```
#'
#' **Token count output**
#'
#' Configure the layer with `output_mode='count'`. As with multi_hot output,
#' the first `num_oov_indices` dimensions in the output represent OOV tokens.
#'
#' ```python
#' vocab = [12, 36, 1138, 42]
#' data = np.array([[12, 1138, 42, 42],
#'                  [42,    7, 36,  7]])  # Note OOV tokens
#' layer = IntegerLookup(vocabulary=vocab, output_mode='count')
#' layer(data)
#' # array([[0., 1., 0., 1., 2.],
#' #        [2., 0., 1., 0., 1.]], dtype=float32)
#' ```
#'
#' **TF-IDF output**
#'
#' Configure the layer with `output_mode='tf_idf'`. As with multi_hot output,
#' the first `num_oov_indices` dimensions in the output represent OOV tokens.
#'
#' Each token bin will output `token_count * idf_weight`, where the idf weights
#' are the inverse document frequency weights per token. These should be
#' provided along with the vocabulary. Note that the `idf_weight` for OOV
#' tokens will default to the average of all idf weights passed in.
#'
#' ```python
#' vocab = [12, 36, 1138, 42]
#' idf_weights = [0.25, 0.75, 0.6, 0.4]
#' data = np.array([[12, 1138, 42, 42],
#'                  [42,    7, 36,  7]])  # Note OOV tokens
#' layer = IntegerLookup(
#'     output_mode='tf_idf', vocabulary=vocab, idf_weights=idf_weights)
#' layer(data)
#' # array([[0.  , 0.25, 0.  , 0.6 , 0.8 ],
#' #         [1.0 , 0.  , 0.75, 0.  , 0.4 ]], dtype=float32)
#' ```
#'
#' To specify the idf weights for oov tokens, you will need to pass the entire
#' vocabularly including the leading oov token.
#'
#' ```python
#' vocab = [-1, 12, 36, 1138, 42]
#' idf_weights = [0.9, 0.25, 0.75, 0.6, 0.4]
#' data = np.array([[12, 1138, 42, 42],
#'                  [42,    7, 36,  7]])  # Note OOV tokens
#' layer = IntegerLookup(
#'     output_mode='tf_idf', vocabulary=vocab, idf_weights=idf_weights)
#' layer(data)
#' # array([[0.  , 0.25, 0.  , 0.6 , 0.8 ],
#' #         [1.8 , 0.  , 0.75, 0.  , 0.4 ]], dtype=float32)
#' ```
#'
#' When adapting the layer in `"tf_idf"` mode, each input sample will
#' be considered a document, and IDF weight per token will be
#' calculated as:
#' `log(1 + num_documents / (1 + token_document_count))`.
#'
#' **Inverse lookup**
#'
#' This example demonstrates how to map indices to tokens using this layer.
#' (You can also use `adapt()` with `inverse=True`, but for simplicity we'll
#' pass the vocab in this example.)
#'
#' ```python
#' vocab = [12, 36, 1138, 42]
#' data = np.array([[1, 3, 4], [4, 0, 2]])
#' layer = IntegerLookup(vocabulary=vocab, invert=True)
#' layer(data)
#' # array([[  12, 1138,   42],
#' #        [  42,   -1,   36]])
#' ```
#'
#' Note that the first index correspond to the oov token by default.
#'
#' **Forward and inverse lookup pairs**
#'
#' This example demonstrates how to use the vocabulary of a standard lookup
#' layer to create an inverse lookup layer.
#'
#' ```python
#' vocab = [12, 36, 1138, 42]
#' data = np.array([[12, 1138, 42], [42, 1000, 36]])
#' layer = IntegerLookup(vocabulary=vocab)
#' i_layer = IntegerLookup(
#'     vocabulary=layer.get_vocabulary(), invert=True)
#' int_data = layer(data)
#' i_layer(int_data)
#' # array([[  12, 1138,   42],
#' #        [  42,   -1,   36]])
#' ```
#'
#' In this example, the input token 1000 resulted in an output of -1, since
#' 1000 was not in the vocabulary - it got represented as an OOV, and all OOV
#' tokens are returned as -1 in the inverse layer. Also, note that for the
#' inverse to work, you must have already set the forward layer vocabulary
#' either directly or via `adapt()` before calling `get_vocabulary()`.
#'
#' @param max_tokens Maximum size of the vocabulary for this layer. This should
#'     only be specified when adapting the vocabulary or when setting
#'     `pad_to_max_tokens=True`. If None, there is no cap on the size of
#'     the vocabulary. Note that this size includes the OOV
#'     and mask tokens. Defaults to `None`.
#' @param num_oov_indices The number of out-of-vocabulary tokens to use.
#'     If this value is more than 1, OOV inputs are modulated to
#'     determine their OOV value.
#'     If this value is 0, OOV inputs will cause an error when calling
#'     the layer. Defaults to `1`.
#' @param mask_token An integer token that represents masked inputs. When
#'     `output_mode` is `"int"`, the token is included in vocabulary
#'     and mapped to index 0. In other output modes,
#'     the token will not appear in the vocabulary and instances
#'     of the mask token in the input will be dropped.
#'     If set to None, no mask term will be added. Defaults to `None`.
#' @param oov_token Only used when `invert` is `True`. The token to return
#'     for OOV indices. Defaults to `-1`.
#' @param vocabulary Optional. Either an array of integers or a string path to a
#'     text file. If passing an array, can pass a tuple, list,
#'     1D NumPy array, or 1D tensor containing the integer vocbulary terms.
#'     If passing a file path, the file should contain one line per term
#'     in the vocabulary. If this argument is set,
#'     there is no need to `adapt()` the layer.
#' @param vocabulary_dtype The dtype of the vocabulary terms, for example
#'     `"int64"` or `"int32"`. Defaults to `"int64"`.
#' @param idf_weights Only valid when `output_mode` is `"tf_idf"`.
#'     A tuple, list, 1D NumPy array, or 1D tensor or the same length
#'     as the vocabulary, containing the floating point inverse document
#'     frequency weights, which will be multiplied by per sample term
#'     counts for the final TF-IDF weight.
#'     If the `vocabulary` argument is set, and `output_mode` is
#'     `"tf_idf"`, this argument must be supplied.
#' @param invert Only valid when `output_mode` is `"int"`.
#'     If `True`, this layer will map indices to vocabulary items
#'     instead of mapping vocabulary items to indices.
#'     Defaults to `False`.
#' @param output_mode Specification for the output of the layer. Values can be
#'     `"int"`, `"one_hot"`, `"multi_hot"`, `"count"`, or `"tf_idf"`
#'     configuring the layer as follows:
#'     - `"int"`: Return the vocabulary indices of the input tokens.
#'     - `"one_hot"`: Encodes each individual element in the input into an
#'         array the same size as the vocabulary,
#'         containing a 1 at the element index. If the last dimension
#'         is size 1, will encode on that dimension.
#'         If the last dimension is not size 1, will append a new
#'         dimension for the encoded output.
#'     - `"multi_hot"`: Encodes each sample in the input into a single
#'         array the same size as the vocabulary,
#'         containing a 1 for each vocabulary term present in the sample.
#'         Treats the last dimension as the sample dimension,
#'         if input shape is `(..., sample_length)`,
#'         output shape will be `(..., num_tokens)`.
#'     - `"count"`: As `"multi_hot"`, but the int array contains
#'         a count of the number of times the token at that index
#'         appeared in the sample.
#'     - `"tf_idf"`: As `"multi_hot"`, but the TF-IDF algorithm is
#'         applied to find the value in each token slot.
#'     For `"int"` output, any shape of input and output is supported.
#'     For all other output modes, currently only output up to rank 2
#'     is supported. Defaults to `"int"`.
#' @param pad_to_max_tokens Only applicable when `output_mode` is `"multi_hot"`,
#'     `"count"`, or `"tf_idf"`. If `True`, the output will have
#'     its feature axis padded to `max_tokens` even if the number
#'     of unique tokens in the vocabulary is less than `max_tokens`,
#'     resulting in a tensor of shape `(batch_size, max_tokens)`
#'     regardless of vocabulary size. Defaults to `False`.
#' @param sparse Boolean. Only applicable to `"multi_hot"`, `"count"`, and
#'     `"tf_idf"` output modes. Only supported with TensorFlow
#'     backend. If `True`, returns a `SparseTensor`
#'     instead of a dense `Tensor`. Defaults to `False`.
#' @param object Object to compose the layer with. A tensor, array, or sequential model.
#' @param ... Passed on to the Python callable
#' @param name name for the layer
#'
#' @export
#' @family preprocessing layers
#' @seealso
#' + <https://www.tensorflow.org/api_docs/python/tf/keras/layers/IntegerLookup>
layer_integer_lookup <-
function (object, max_tokens = NULL, num_oov_indices = 1L, mask_token = NULL,
    oov_token = -1L, vocabulary = NULL, vocabulary_dtype = "int64",
    idf_weights = NULL, invert = FALSE, output_mode = "int",
    sparse = FALSE, pad_to_max_tokens = FALSE, name = NULL, ...)
{
    args <- capture_args2(list(num_oov_indices = as_integer,
        mask_token = as_integer, oov_token = as_integer, vocabulary = as_integer,
        invert = as_integer, output_mode = as_integer, input_shape = normalize_shape,
        batch_size = as_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$IntegerLookup, object, args)
}


# keras$layers$Normalization
# keras_core.src.layers.preprocessing.normalization.Normalization
r"-(A preprocessing layer that normalizes continuous features.

    This layer will shift and scale inputs into a distribution centered around
    0 with standard deviation 1. It accomplishes this by precomputing the mean
    and variance of the data, and calling `(input - mean) / sqrt(var)` at
    runtime.

    The mean and variance values for the layer must be either supplied on
    construction or learned via `adapt()`. `adapt()` will compute the mean and
    variance of the data and store them as the layer's weights. `adapt()` should
    be called before `fit()`, `evaluate()`, or `predict()`.

    Args:
        axis: Integer, tuple of integers, or None. The axis or axes that should
            have a separate mean and variance for each index in the shape.
            For example, if shape is `(None, 5)` and `axis=1`, the layer will
            track 5 separate mean and variance values for the last axis.
            If `axis` is set to `None`, the layer will normalize
            all elements in the input by a scalar mean and variance.
            When `-1`, the last axis of the input is assumed to be a
            feature dimension and is normalized per index.
            Note that in the specific case of batched scalar inputs where
            the only axis is the batch axis, the default will normalize
            each index in the batch separately.
            In this case, consider passing `axis=None`. Defaults to `-1`.
        mean: The mean value(s) to use during normalization. The passed value(s)
            will be broadcast to the shape of the kept axes above;
            if the value(s) cannot be broadcast, an error will be raised when
            this layer's `build()` method is called.
        variance: The variance value(s) to use during normalization. The passed
            value(s) will be broadcast to the shape of the kept axes above;
            if the value(s) cannot be broadcast, an error will be raised when
            this layer's `build()` method is called.
        invert: If `True`, this layer will apply the inverse transformation
            to its inputs: it would turn a normalized input back into its
            original form.

    Examples:

    Calculate a global mean and variance by analyzing the dataset in `adapt()`.

    >>> adapt_data = np.array([1., 2., 3., 4., 5.], dtype='float32')
    >>> input_data = np.array([1., 2., 3.], dtype='float32')
    >>> layer = keras.layers.Normalization(axis=None)
    >>> layer.adapt(adapt_data)
    >>> layer(input_data)
    array([-1.4142135, -0.70710677, 0.], dtype=float32)

    Calculate a mean and variance for each index on the last axis.

    >>> adapt_data = np.array([[0., 7., 4.],
    ...                        [2., 9., 6.],
    ...                        [0., 7., 4.],
    ...                        [2., 9., 6.]], dtype='float32')
    >>> input_data = np.array([[0., 7., 4.]], dtype='float32')
    >>> layer = keras.layers.Normalization(axis=-1)
    >>> layer.adapt(adapt_data)
    >>> layer(input_data)
    array([-1., -1., -1.], dtype=float32)

    Pass the mean and variance directly.

    >>> input_data = np.array([[1.], [2.], [3.]], dtype='float32')
    >>> layer = keras.layers.Normalization(mean=3., variance=2.)
    >>> layer(input_data)
    array([[-1.4142135 ],
           [-0.70710677],
           [ 0.        ]], dtype=float32)

    Use the layer to de-normalize inputs (after adapting the layer).

    >>> adapt_data = np.array([[0., 7., 4.],
    ...                        [2., 9., 6.],
    ...                        [0., 7., 4.],
    ...                        [2., 9., 6.]], dtype='float32')
    >>> input_data = np.array([[1., 2., 3.]], dtype='float32')
    >>> layer = keras.layers.Normalization(axis=-1, invert=True)
    >>> layer.adapt(adapt_data)
    >>> layer(input_data)
    array([2., 10., 8.], dtype=float32)
    )-"


# keras_core.src.layers.preprocessing.normalization.Normalization
#' A preprocessing layer that normalizes continuous features.
#'
#' @description
#' This layer will shift and scale inputs into a distribution centered around
#' 0 with standard deviation 1. It accomplishes this by precomputing the mean
#' and variance of the data, and calling `(input - mean) / sqrt(var)` at
#' runtime.
#'
#' The mean and variance values for the layer must be either supplied on
#' construction or learned via `adapt()`. `adapt()` will compute the mean and
#' variance of the data and store them as the layer's weights. `adapt()` should
#' be called before `fit()`, `evaluate()`, or `predict()`.
#'
#' # Examples
#' Calculate a global mean and variance by analyzing the dataset in `adapt()`.
#'
#' ```python
#' adapt_data = np.array([1., 2., 3., 4., 5.], dtype='float32')
#' input_data = np.array([1., 2., 3.], dtype='float32')
#' layer = keras.layers.Normalization(axis=None)
#' layer.adapt(adapt_data)
#' layer(input_data)
#' # array([-1.4142135, -0.70710677, 0.], dtype=float32)
#' ```
#'
#' Calculate a mean and variance for each index on the last axis.
#'
#' ```python
#' adapt_data = np.array([[0., 7., 4.],
#'                        [2., 9., 6.],
#'                        [0., 7., 4.],
#'                        [2., 9., 6.]], dtype='float32')
#' input_data = np.array([[0., 7., 4.]], dtype='float32')
#' layer = keras.layers.Normalization(axis=-1)
#' layer.adapt(adapt_data)
#' layer(input_data)
#' # array([-1., -1., -1.], dtype=float32)
#' ```
#'
#' Pass the mean and variance directly.
#'
#' ```python
#' input_data = np.array([[1.], [2.], [3.]], dtype='float32')
#' layer = keras.layers.Normalization(mean=3., variance=2.)
#' layer(input_data)
#' # array([[-1.4142135 ],
#' #        [-0.70710677],
#' #        [ 0.        ]], dtype=float32)
#' ```
#'
#' Use the layer to de-normalize inputs (after adapting the layer).
#'
#' ```python
#' adapt_data = np.array([[0., 7., 4.],
#'                        [2., 9., 6.],
#'                        [0., 7., 4.],
#'                        [2., 9., 6.]], dtype='float32')
#' input_data = np.array([[1., 2., 3.]], dtype='float32')
#' layer = keras.layers.Normalization(axis=-1, invert=True)
#' layer.adapt(adapt_data)
#' layer(input_data)
#' # array([2., 10., 8.], dtype=float32)
#' ```
#'
#' @param axis Integer, tuple of integers, or None. The axis or axes that should
#'     have a separate mean and variance for each index in the shape.
#'     For example, if shape is `(None, 5)` and `axis=1`, the layer will
#'     track 5 separate mean and variance values for the last axis.
#'     If `axis` is set to `None`, the layer will normalize
#'     all elements in the input by a scalar mean and variance.
#'     When `-1`, the last axis of the input is assumed to be a
#'     feature dimension and is normalized per index.
#'     Note that in the specific case of batched scalar inputs where
#'     the only axis is the batch axis, the default will normalize
#'     each index in the batch separately.
#'     In this case, consider passing `axis=None`. Defaults to `-1`.
#' @param mean The mean value(s) to use during normalization. The passed value(s)
#'     will be broadcast to the shape of the kept axes above;
#'     if the value(s) cannot be broadcast, an error will be raised when
#'     this layer's `build()` method is called.
#' @param variance The variance value(s) to use during normalization. The passed
#'     value(s) will be broadcast to the shape of the kept axes above;
#'     if the value(s) cannot be broadcast, an error will be raised when
#'     this layer's `build()` method is called.
#' @param invert If `True`, this layer will apply the inverse transformation
#'     to its inputs: it would turn a normalized input back into its
#'     original form.
#' @param object Object to compose the layer with. A tensor, array, or sequential model.
#' @param ... Passed on to the Python callable
#'
#' @export
#' @family preprocessing layers
#' @seealso
#' + <https://www.tensorflow.org/api_docs/python/tf/keras/layers/Normalization>
layer_normalization <-
function (object, axis = -1L, mean = NULL, variance = NULL, invert = FALSE,
    ...)
{
    args <- capture_args2(list(axis = as_axis, input_shape = normalize_shape,
        batch_size = as_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$Normalization, object, args)
}


# keras$layers$RandomBrightness
# keras_core.src.layers.preprocessing.random_brightness.RandomBrightness
r"-(A preprocessing layer which randomly adjusts brightness during training.

    This layer will randomly increase/reduce the brightness for the input RGB
    images. At inference time, the output will be identical to the input.
    Call the layer with `training=True` to adjust the brightness of the input.

    **Note:** This layer is safe to use inside a `tf.data` pipeline
    (independently of which backend you're using).

    Args:
        factor: Float or a list/tuple of 2 floats between -1.0 and 1.0. The
            factor is used to determine the lower bound and upper bound of the
            brightness adjustment. A float value will be chosen randomly between
            the limits. When -1.0 is chosen, the output image will be black, and
            when 1.0 is chosen, the image will be fully white.
            When only one float is provided, eg, 0.2,
            then -0.2 will be used for lower bound and 0.2
            will be used for upper bound.
        value_range: Optional list/tuple of 2 floats
            for the lower and upper limit
            of the values of the input data.
            To make no change, use `[0.0, 1.0]`, e.g., if the image input
            has been scaled before this layer. Defaults to `[0.0, 255.0]`.
            The brightness adjustment will be scaled to this range, and the
            output values will be clipped to this range.
        seed: optional integer, for fixed RNG behavior.

    Inputs: 3D (HWC) or 4D (NHWC) tensor, with float or int dtype. Input pixel
        values can be of any range (e.g. `[0., 1.)` or `[0, 255]`)

    Output: 3D (HWC) or 4D (NHWC) tensor with brightness adjusted based on the
        `factor`. By default, the layer will output floats.
        The output value will be clipped to the range `[0, 255]`,
        the valid range of RGB colors, and
        rescaled based on the `value_range` if needed.

    Sample usage:

    ```python
    random_bright = keras.layers.RandomBrightness(factor=0.2)

    # An image with shape [2, 2, 3]
    image = [[[1, 2, 3], [4 ,5 ,6]], [[7, 8, 9], [10, 11, 12]]]

    # Assume we randomly select the factor to be 0.1, then it will apply
    # 0.1 * 255 to all the channel
    output = random_bright(image, training=True)

    # output will be int64 with 25.5 added to each channel and round down.
    >>> array([[[26.5, 27.5, 28.5]
                [29.5, 30.5, 31.5]]
               [[32.5, 33.5, 34.5]
                [35.5, 36.5, 37.5]]],
              shape=(2, 2, 3), dtype=int64)
    ```
    )-"


# keras_core.src.layers.preprocessing.random_brightness.RandomBrightness
#' A preprocessing layer which randomly adjusts brightness during training.
#'
#' @description
#' This layer will randomly increase/reduce the brightness for the input RGB
#' images. At inference time, the output will be identical to the input.
#' Call the layer with `training=True` to adjust the brightness of the input.
#'
#' **Note:** This layer is safe to use inside a `tf.data` pipeline
#' (independently of which backend you're using).
#'
#' # Inputs
#' 3D (HWC) or 4D (NHWC) tensor, with float or int dtype. Input pixel
#' values can be of any range (e.g. `[0., 1.)` or `[0, 255]`)
#'
#' # Output
#' 3D (HWC) or 4D (NHWC) tensor with brightness adjusted based on the
#'     `factor`. By default, the layer will output floats.
#'     The output value will be clipped to the range `[0, 255]`,
#'     the valid range of RGB colors, and
#'     rescaled based on the `value_range` if needed.
#'
#' Sample usage:
#'
#' ```python
#' random_bright = keras.layers.RandomBrightness(factor=0.2)
#'
#' # An image with shape [2, 2, 3]
#' image = [[[1, 2, 3], [4 ,5 ,6]], [[7, 8, 9], [10, 11, 12]]]
#'
#' # Assume we randomly select the factor to be 0.1, then it will apply
#' # 0.1 * 255 to all the channel
#' output = random_bright(image, training=True)
#'
#' # output will be int64 with 25.5 added to each channel and round down.
#' ```python
#' array([[[26.5, 27.5, 28.5]
#' #             [29.5, 30.5, 31.5]]
#' #            [[32.5, 33.5, 34.5]
#' #             [35.5, 36.5, 37.5]]],
#' #           shape=(2, 2, 3), dtype=int64)
#' # ```
#' ```
#'
#' @param factor Float or a list/tuple of 2 floats between -1.0 and 1.0. The
#'     factor is used to determine the lower bound and upper bound of the
#'     brightness adjustment. A float value will be chosen randomly between
#'     the limits. When -1.0 is chosen, the output image will be black, and
#'     when 1.0 is chosen, the image will be fully white.
#'     When only one float is provided, eg, 0.2,
#'     then -0.2 will be used for lower bound and 0.2
#'     will be used for upper bound.
#' @param value_range Optional list/tuple of 2 floats
#'     for the lower and upper limit
#'     of the values of the input data.
#'     To make no change, use `[0.0, 1.0]`, e.g., if the image input
#'     has been scaled before this layer. Defaults to `[0.0, 255.0]`.
#'     The brightness adjustment will be scaled to this range, and the
#'     output values will be clipped to this range.
#' @param seed optional integer, for fixed RNG behavior.
#'
#' @param object Object to compose the layer with. A tensor, array, or sequential model.
#' @param ... Passed on to the Python callable
#'
#' @export
#' @family preprocessing layers
#' @seealso
#' + <https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomBrightness>
layer_random_brightness <-
function (object, factor, value_range = list(0L, 255L), seed = NULL,
    ...)
{
    args <- capture_args2(list(seed = as_integer, input_shape = normalize_shape,
        batch_size = as_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$RandomBrightness, object, args)
}


# keras$layers$RandomContrast
# keras_core.src.layers.preprocessing.random_contrast.RandomContrast
r"-(A preprocessing layer which randomly adjusts contrast during training.

    This layer will randomly adjust the contrast of an image or images
    by a random factor. Contrast is adjusted independently
    for each channel of each image during training.

    For each channel, this layer computes the mean of the image pixels in the
    channel and then adjusts each component `x` of each pixel to
    `(x - mean) * contrast_factor + mean`.

    Input pixel values can be of any range (e.g. `[0., 1.)` or `[0, 255]`) and
    in integer or floating point dtype.
    By default, the layer will output floats.

    **Note:** This layer is safe to use inside a `tf.data` pipeline
    (independently of which backend you're using).

    Input shape:
        3D (unbatched) or 4D (batched) tensor with shape:
        `(..., height, width, channels)`, in `"channels_last"` format.

    Output shape:
        3D (unbatched) or 4D (batched) tensor with shape:
        `(..., height, width, channels)`, in `"channels_last"` format.

    Args:
        factor: a positive float represented as fraction of value, or a tuple of
            size 2 representing lower and upper bound.
            When represented as a single float, lower = upper.
            The contrast factor will be randomly picked between
            `[1.0 - lower, 1.0 + upper]`. For any pixel x in the channel,
            the output will be `(x - mean) * factor + mean`
            where `mean` is the mean value of the channel.
        seed: Integer. Used to create a random seed.
    )-"


# keras_core.src.layers.preprocessing.random_contrast.RandomContrast
#' A preprocessing layer which randomly adjusts contrast during training.
#'
#' @description
#' This layer will randomly adjust the contrast of an image or images
#' by a random factor. Contrast is adjusted independently
#' for each channel of each image during training.
#'
#' For each channel, this layer computes the mean of the image pixels in the
#' channel and then adjusts each component `x` of each pixel to
#' `(x - mean) * contrast_factor + mean`.
#'
#' Input pixel values can be of any range (e.g. `[0., 1.)` or `[0, 255]`) and
#' in integer or floating point dtype.
#' By default, the layer will output floats.
#'
#' **Note:** This layer is safe to use inside a `tf.data` pipeline
#' (independently of which backend you're using).
#'
#' # Input Shape
#' 3D (unbatched) or 4D (batched) tensor with shape:
#' `(..., height, width, channels)`, in `"channels_last"` format.
#'
#' # Output Shape
#' 3D (unbatched) or 4D (batched) tensor with shape:
#' `(..., height, width, channels)`, in `"channels_last"` format.
#'
#' @param factor a positive float represented as fraction of value, or a tuple of
#'     size 2 representing lower and upper bound.
#'     When represented as a single float, lower = upper.
#'     The contrast factor will be randomly picked between
#'     `[1.0 - lower, 1.0 + upper]`. For any pixel x in the channel,
#'     the output will be `(x - mean) * factor + mean`
#'     where `mean` is the mean value of the channel.
#' @param seed Integer. Used to create a random seed.
#' @param object Object to compose the layer with. A tensor, array, or sequential model.
#' @param ... Passed on to the Python callable
#'
#' @export
#' @family preprocessing layers
#' @seealso
#' + <https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomContrast>
layer_random_contrast <-
function (object, factor, seed = NULL, ...)
{
    args <- capture_args2(list(seed = as_integer, input_shape = normalize_shape,
        batch_size = as_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$RandomContrast, object, args)
}


# keras$layers$RandomCrop
# keras_core.src.layers.preprocessing.random_crop.RandomCrop
r"-(A preprocessing layer which randomly crops images during training.

    During training, this layer will randomly choose a location to crop images
    down to a target size. The layer will crop all the images in the same batch
    to the same cropping location.

    At inference time, and during training if an input image is smaller than the
    target size, the input will be resized and cropped so as to return the
    largest possible window in the image that matches the target aspect ratio.
    If you need to apply random cropping at inference time, set `training` to
    True when calling the layer.

    Input pixel values can be of any range (e.g. `[0., 1.)` or `[0, 255]`) and
    of integer or floating point dtype. By default, the layer will output
    floats.

    **Note:** This layer is safe to use inside a `tf.data` pipeline
    (independently of which backend you're using).

    Input shape:
        3D (unbatched) or 4D (batched) tensor with shape:
        `(..., height, width, channels)`, in `"channels_last"` format.

    Output shape:
        3D (unbatched) or 4D (batched) tensor with shape:
        `(..., target_height, target_width, channels)`.

    Args:
        height: Integer, the height of the output shape.
        width: Integer, the width of the output shape.
        seed: Integer. Used to create a random seed.
        **kwargs: Base layer keyword arguments, such as
            `name` and `dtype`.
    )-"


# keras_core.src.layers.preprocessing.random_crop.RandomCrop
#' A preprocessing layer which randomly crops images during training.
#'
#' @description
#' During training, this layer will randomly choose a location to crop images
#' down to a target size. The layer will crop all the images in the same batch
#' to the same cropping location.
#'
#' At inference time, and during training if an input image is smaller than the
#' target size, the input will be resized and cropped so as to return the
#' largest possible window in the image that matches the target aspect ratio.
#' If you need to apply random cropping at inference time, set `training` to
#' True when calling the layer.
#'
#' Input pixel values can be of any range (e.g. `[0., 1.)` or `[0, 255]`) and
#' of integer or floating point dtype. By default, the layer will output
#' floats.
#'
#' **Note:** This layer is safe to use inside a `tf.data` pipeline
#' (independently of which backend you're using).
#'
#' # Input Shape
#' 3D (unbatched) or 4D (batched) tensor with shape:
#' `(..., height, width, channels)`, in `"channels_last"` format.
#'
#' # Output Shape
#' 3D (unbatched) or 4D (batched) tensor with shape:
#' `(..., target_height, target_width, channels)`.
#'
#' @param height Integer, the height of the output shape.
#' @param width Integer, the width of the output shape.
#' @param seed Integer. Used to create a random seed.
#' @param ... Base layer keyword arguments, such as
#'     `name` and `dtype`.
#' @param object Object to compose the layer with. A tensor, array, or sequential model.
#' @param name name for the layer
#'
#' @export
#' @family preprocessing layers
#' @seealso
#' + <https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomCrop>
layer_random_crop <-
function (object, height, width, seed = NULL, data_format = NULL,
    name = NULL, ...)
{
    args <- capture_args2(list(height = as_integer, width = as_integer,
        seed = as_integer, input_shape = normalize_shape, batch_size = as_integer,
        batch_input_shape = normalize_shape), ignore = "object")
    create_layer(keras$layers$RandomCrop, object, args)
}


# keras$layers$RandomFlip
# keras_core.src.layers.preprocessing.random_flip.RandomFlip
r"-(A preprocessing layer which randomly flips images during training.

    This layer will flip the images horizontally and or vertically based on the
    `mode` attribute. During inference time, the output will be identical to
    input. Call the layer with `training=True` to flip the input.
    Input pixel values can be of any range (e.g. `[0., 1.)` or `[0, 255]`) and
    of integer or floating point dtype.
    By default, the layer will output floats.

    **Note:** This layer is safe to use inside a `tf.data` pipeline
    (independently of which backend you're using).

    Input shape:
        3D (unbatched) or 4D (batched) tensor with shape:
        `(..., height, width, channels)`, in `"channels_last"` format.

    Output shape:
        3D (unbatched) or 4D (batched) tensor with shape:
        `(..., height, width, channels)`, in `"channels_last"` format.

    Args:
        mode: String indicating which flip mode to use. Can be `"horizontal"`,
            `"vertical"`, or `"horizontal_and_vertical"`. `"horizontal"` is a
            left-right flip and `"vertical"` is a top-bottom flip. Defaults to
            `"horizontal_and_vertical"`
        seed: Integer. Used to create a random seed.
        **kwargs: Base layer keyword arguments, such as
            `name` and `dtype`.
    )-"


# keras_core.src.layers.preprocessing.random_flip.RandomFlip
#' A preprocessing layer which randomly flips images during training.
#'
#' @description
#' This layer will flip the images horizontally and or vertically based on the
#' `mode` attribute. During inference time, the output will be identical to
#' input. Call the layer with `training=True` to flip the input.
#' Input pixel values can be of any range (e.g. `[0., 1.)` or `[0, 255]`) and
#' of integer or floating point dtype.
#' By default, the layer will output floats.
#'
#' **Note:** This layer is safe to use inside a `tf.data` pipeline
#' (independently of which backend you're using).
#'
#' # Input Shape
#' 3D (unbatched) or 4D (batched) tensor with shape:
#' `(..., height, width, channels)`, in `"channels_last"` format.
#'
#' # Output Shape
#' 3D (unbatched) or 4D (batched) tensor with shape:
#' `(..., height, width, channels)`, in `"channels_last"` format.
#'
#' @param mode String indicating which flip mode to use. Can be `"horizontal"`,
#'     `"vertical"`, or `"horizontal_and_vertical"`. `"horizontal"` is a
#'     left-right flip and `"vertical"` is a top-bottom flip. Defaults to
#'     `"horizontal_and_vertical"`
#' @param seed Integer. Used to create a random seed.
#' @param ... Base layer keyword arguments, such as
#'     `name` and `dtype`.
#' @param object Object to compose the layer with. A tensor, array, or sequential model.
#'
#' @export
#' @family preprocessing layers
#' @seealso
#' + <https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomFlip>
layer_random_flip <-
function (object, mode = "horizontal_and_vertical", seed = NULL,
    ...)
{
    args <- capture_args2(list(seed = as_integer, input_shape = normalize_shape,
        batch_size = as_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$RandomFlip, object, args)
}


# keras$layers$RandomRotation
# keras_core.src.layers.preprocessing.random_rotation.RandomRotation
r"-(A preprocessing layer which randomly rotates images during training.

    This layer will apply random rotations to each image, filling empty space
    according to `fill_mode`.

    By default, random rotations are only applied during training.
    At inference time, the layer does nothing. If you need to apply random
    rotations at inference time, set `training` to True when calling the layer.

    Input pixel values can be of any range (e.g. `[0., 1.)` or `[0, 255]`) and
    of integer or floating point dtype.
    By default, the layer will output floats.

    **Note:** This layer is safe to use inside a `tf.data` pipeline
    (independently of which backend you're using).

    Input shape:
        3D (unbatched) or 4D (batched) tensor with shape:
        `(..., height, width, channels)`, in `"channels_last"` format

    Output shape:
        3D (unbatched) or 4D (batched) tensor with shape:
        `(..., height, width, channels)`, in `"channels_last"` format

    Args:
        factor: a float represented as fraction of 2 Pi, or a tuple of size 2
            representing lower and upper bound for rotating clockwise and
            counter-clockwise. A positive values means rotating
            counter clock-wise,
            while a negative value means clock-wise.
            When represented as a single
            float, this value is used for both the upper and lower bound.
            For instance, `factor=(-0.2, 0.3)`
            results in an output rotation by a random
            amount in the range `[-20% * 2pi, 30% * 2pi]`.
            `factor=0.2` results in an
            output rotating by a random amount
            in the range `[-20% * 2pi, 20% * 2pi]`.
        fill_mode: Points outside the boundaries of the input are filled
            according to the given mode
            (one of `{"constant", "reflect", "wrap", "nearest"}`).
            - *reflect*: `(d c b a | a b c d | d c b a)`
                The input is extended by reflecting about
                the edge of the last pixel.
            - *constant*: `(k k k k | a b c d | k k k k)`
                The input is extended by
                filling all values beyond the edge with
                the same constant value k = 0.
            - *wrap*: `(a b c d | a b c d | a b c d)` The input is extended by
                wrapping around to the opposite edge.
            - *nearest*: `(a a a a | a b c d | d d d d)`
                The input is extended by the nearest pixel.
        interpolation: Interpolation mode. Supported values: `"nearest"`,
            `"bilinear"`.
        seed: Integer. Used to create a random seed.
        fill_value: a float represents the value to be filled outside
            the boundaries when `fill_mode="constant"`.
    )-"


# keras_core.src.layers.preprocessing.random_rotation.RandomRotation
#' A preprocessing layer which randomly rotates images during training.
#'
#' @description
#' This layer will apply random rotations to each image, filling empty space
#' according to `fill_mode`.
#'
#' By default, random rotations are only applied during training.
#' At inference time, the layer does nothing. If you need to apply random
#' rotations at inference time, set `training` to True when calling the layer.
#'
#' Input pixel values can be of any range (e.g. `[0., 1.)` or `[0, 255]`) and
#' of integer or floating point dtype.
#' By default, the layer will output floats.
#'
#' **Note:** This layer is safe to use inside a `tf.data` pipeline
#' (independently of which backend you're using).
#'
#' # Input Shape
#' 3D (unbatched) or 4D (batched) tensor with shape:
#' `(..., height, width, channels)`, in `"channels_last"` format
#'
#' # Output Shape
#' 3D (unbatched) or 4D (batched) tensor with shape:
#' `(..., height, width, channels)`, in `"channels_last"` format
#'
#' @param factor a float represented as fraction of 2 Pi, or a tuple of size 2
#'     representing lower and upper bound for rotating clockwise and
#'     counter-clockwise. A positive values means rotating
#'     counter clock-wise,
#'     while a negative value means clock-wise.
#'     When represented as a single
#'     float, this value is used for both the upper and lower bound.
#'     For instance, `factor=(-0.2, 0.3)`
#'     results in an output rotation by a random
#'     amount in the range `[-20% * 2pi, 30% * 2pi]`.
#'     `factor=0.2` results in an
#'     output rotating by a random amount
#'     in the range `[-20% * 2pi, 20% * 2pi]`.
#' @param fill_mode Points outside the boundaries of the input are filled
#'     according to the given mode
#'     (one of `{"constant", "reflect", "wrap", "nearest"}`).
#'     - *reflect*: `(d c b a | a b c d | d c b a)`
#'         The input is extended by reflecting about
#'         the edge of the last pixel.
#'     - *constant*: `(k k k k | a b c d | k k k k)`
#'         The input is extended by
#'         filling all values beyond the edge with
#'         the same constant value k = 0.
#'     - *wrap*: `(a b c d | a b c d | a b c d)` The input is extended by
#'         wrapping around to the opposite edge.
#'     - *nearest*: `(a a a a | a b c d | d d d d)`
#'         The input is extended by the nearest pixel.
#' @param interpolation Interpolation mode. Supported values: `"nearest"`,
#'     `"bilinear"`.
#' @param seed Integer. Used to create a random seed.
#' @param fill_value a float represents the value to be filled outside
#'     the boundaries when `fill_mode="constant"`.
#' @param object Object to compose the layer with. A tensor, array, or sequential model.
#' @param ... Passed on to the Python callable
#'
#' @export
#' @family preprocessing layers
#' @seealso
#' + <https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomRotation>
layer_random_rotation <-
function (object, factor, fill_mode = "reflect", interpolation = "bilinear",
    seed = NULL, fill_value = 0, value_range = list(0L, 255L),
    data_format = NULL, ...)
{
    args <- capture_args2(list(seed = as_integer, input_shape = normalize_shape,
        batch_size = as_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$RandomRotation, object, args)
}


# keras$layers$RandomTranslation
# keras_core.src.layers.preprocessing.random_translation.RandomTranslation
r"-(A preprocessing layer which randomly translates images during training.

    This layer will apply random translations to each image during training,
    filling empty space according to `fill_mode`.

    Input pixel values can be of any range (e.g. `[0., 1.)` or `[0, 255]`) and
    of integer or floating point dtype. By default, the layer will output
    floats.

    Input shape:
        3D (unbatched) or 4D (batched) tensor with shape:
        `(..., height, width, channels)`, in `"channels_last"` format,
        or `(..., channels, height, width)`, in `"channels_first"` format.

    Output shape:
        3D (unbatched) or 4D (batched) tensor with shape:
        `(..., target_height, target_width, channels)`,
        or `(..., channels, target_height, target_width)`,
        in `"channels_first"` format.

    **Note:** This layer is safe to use inside a `tf.data` pipeline
    (independently of which backend you're using).

    Args:
        height_factor: a float represented as fraction of value, or a tuple of
            size 2 representing lower and upper bound for shifting vertically. A
            negative value means shifting image up, while a positive value means
            shifting image down. When represented as a single positive float,
            this value is used for both the upper and lower bound. For instance,
            `height_factor=(-0.2, 0.3)` results in an output shifted by a random
            amount in the range `[-20%, +30%]`. `height_factor=0.2` results in
            an output height shifted by a random amount in the range
            `[-20%, +20%]`.
        width_factor: a float represented as fraction of value, or a tuple of
            size 2 representing lower and upper bound for shifting horizontally.
            A negative value means shifting image left, while a positive value
            means shifting image right. When represented as a single positive
            float, this value is used for both the upper and lower bound. For
            instance, `width_factor=(-0.2, 0.3)` results in an output shifted
            left by 20%, and shifted right by 30%. `width_factor=0.2` results
            in an output height shifted left or right by 20%.
        fill_mode: Points outside the boundaries of the input are filled
            according to the given mode. Available methods are `"constant"`,
            `"nearest"`, `"wrap"` and `"reflect"`. Defaults to `"constant"`.
            - `"reflect"`: `(d c b a | a b c d | d c b a)`
                The input is extended by reflecting about the edge of the last
                pixel.
            - `"constant"`: `(k k k k | a b c d | k k k k)`
                The input is extended by filling all values beyond
                the edge with the same constant value k specified by
                `fill_value`.
            - `"wrap"`: `(a b c d | a b c d | a b c d)`
                The input is extended by wrapping around to the opposite edge.
            - `"nearest"`: `(a a a a | a b c d | d d d d)`
                The input is extended by the nearest pixel.
            Note that when using torch backend, `"reflect"` is redirected to
            `"mirror"` `(c d c b | a b c d | c b a b)` because torch does not
            support `"reflect"`.
            Note that torch backend does not support `"wrap"`.
        interpolation: Interpolation mode. Supported values: `"nearest"`,
            `"bilinear"`.
        seed: Integer. Used to create a random seed.
        fill_value: a float represents the value to be filled outside the
            boundaries when `fill_mode="constant"`.
        data_format: string, either `"channels_last"` or `"channels_first"`.
            The ordering of the dimensions in the inputs. `"channels_last"`
            corresponds to inputs with shape `(batch, height, width, channels)`
            while `"channels_first"` corresponds to inputs with shape
            `(batch, channels, height, width)`. It defaults to the
            `image_data_format` value found in your Keras config file at
            `~/.keras/keras.json`. If you never set it, then it will be
            `"channels_last"`.
        **kwargs: Base layer keyword arguments, such as `name` and `dtype`.
    )-"


# keras_core.src.layers.preprocessing.random_translation.RandomTranslation
#' A preprocessing layer which randomly translates images during training.
#'
#' @description
#' This layer will apply random translations to each image during training,
#' filling empty space according to `fill_mode`.
#'
#' Input pixel values can be of any range (e.g. `[0., 1.)` or `[0, 255]`) and
#' of integer or floating point dtype. By default, the layer will output
#' floats.
#'
#' # Input Shape
#' 3D (unbatched) or 4D (batched) tensor with shape:
#' `(..., height, width, channels)`, in `"channels_last"` format,
#' or `(..., channels, height, width)`, in `"channels_first"` format.
#'
#' # Output Shape
#' 3D (unbatched) or 4D (batched) tensor with shape:
#'     `(..., target_height, target_width, channels)`,
#'     or `(..., channels, target_height, target_width)`,
#'     in `"channels_first"` format.
#'
#' **Note:** This layer is safe to use inside a `tf.data` pipeline
#' (independently of which backend you're using).
#'
#' @param height_factor a float represented as fraction of value, or a tuple of
#'     size 2 representing lower and upper bound for shifting vertically. A
#'     negative value means shifting image up, while a positive value means
#'     shifting image down. When represented as a single positive float,
#'     this value is used for both the upper and lower bound. For instance,
#'     `height_factor=(-0.2, 0.3)` results in an output shifted by a random
#'     amount in the range `[-20%, +30%]`. `height_factor=0.2` results in
#'     an output height shifted by a random amount in the range
#'     `[-20%, +20%]`.
#' @param width_factor a float represented as fraction of value, or a tuple of
#'     size 2 representing lower and upper bound for shifting horizontally.
#'     A negative value means shifting image left, while a positive value
#'     means shifting image right. When represented as a single positive
#'     float, this value is used for both the upper and lower bound. For
#'     instance, `width_factor=(-0.2, 0.3)` results in an output shifted
#'     left by 20%, and shifted right by 30%. `width_factor=0.2` results
#'     in an output height shifted left or right by 20%.
#' @param fill_mode Points outside the boundaries of the input are filled
#'     according to the given mode. Available methods are `"constant"`,
#'     `"nearest"`, `"wrap"` and `"reflect"`. Defaults to `"constant"`.
#'     - `"reflect"`: `(d c b a | a b c d | d c b a)`
#'         The input is extended by reflecting about the edge of the last
#'         pixel.
#'     - `"constant"`: `(k k k k | a b c d | k k k k)`
#'         The input is extended by filling all values beyond
#'         the edge with the same constant value k specified by
#'         `fill_value`.
#'     - `"wrap"`: `(a b c d | a b c d | a b c d)`
#'         The input is extended by wrapping around to the opposite edge.
#'     - `"nearest"`: `(a a a a | a b c d | d d d d)`
#'         The input is extended by the nearest pixel.
#'     Note that when using torch backend, `"reflect"` is redirected to
#'     `"mirror"` `(c d c b | a b c d | c b a b)` because torch does not
#'     support `"reflect"`.
#'     Note that torch backend does not support `"wrap"`.
#' @param interpolation Interpolation mode. Supported values: `"nearest"`,
#'     `"bilinear"`.
#' @param seed Integer. Used to create a random seed.
#' @param fill_value a float represents the value to be filled outside the
#'     boundaries when `fill_mode="constant"`.
#' @param data_format string, either `"channels_last"` or `"channels_first"`.
#'     The ordering of the dimensions in the inputs. `"channels_last"`
#'     corresponds to inputs with shape `(batch, height, width, channels)`
#'     while `"channels_first"` corresponds to inputs with shape
#'     `(batch, channels, height, width)`. It defaults to the
#'     `image_data_format` value found in your Keras config file at
#'     `~/.keras/keras.json`. If you never set it, then it will be
#'     `"channels_last"`.
#' @param ... Base layer keyword arguments, such as `name` and `dtype`.
#' @param object Object to compose the layer with. A tensor, array, or sequential model.
#'
#' @export
#' @family preprocessing layers
#' @seealso
#' + <https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomTranslation>
layer_random_translation <-
function (object, height_factor, width_factor, fill_mode = "reflect",
    interpolation = "bilinear", seed = NULL, fill_value = 0,
    data_format = NULL, ...)
{
    args <- capture_args2(list(seed = as_integer, input_shape = normalize_shape,
        batch_size = as_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$RandomTranslation, object, args)
}


# keras$layers$RandomZoom
# keras_core.src.layers.preprocessing.random_zoom.RandomZoom
r"-(A preprocessing layer which randomly zooms images during training.

    This layer will randomly zoom in or out on each axis of an image
    independently, filling empty space according to `fill_mode`.

    Input pixel values can be of any range (e.g. `[0., 1.)` or `[0, 255]`) and
    of integer or floating point dtype.
    By default, the layer will output floats.

    Input shape:
        3D (unbatched) or 4D (batched) tensor with shape:
        `(..., height, width, channels)`, in `"channels_last"` format,
        or `(..., channels, height, width)`, in `"channels_first"` format.

    Output shape:
        3D (unbatched) or 4D (batched) tensor with shape:
        `(..., target_height, target_width, channels)`,
        or `(..., channels, target_height, target_width)`,
        in `"channels_first"` format.

    **Note:** This layer is safe to use inside a `tf.data` pipeline
    (independently of which backend you're using).

    Args:
        height_factor: a float represented as fraction of value, or a tuple of
            size 2 representing lower and upper bound for zooming vertically.
            When represented as a single float, this value is used for both the
            upper and lower bound. A positive value means zooming out, while a
            negative value means zooming in. For instance,
            `height_factor=(0.2, 0.3)` result in an output zoomed out by a
            random amount in the range `[+20%, +30%]`.
            `height_factor=(-0.3, -0.2)` result in an output zoomed in by a
            random amount in the range `[+20%, +30%]`.
        width_factor: a float represented as fraction of value, or a tuple of
            size 2 representing lower and upper bound for zooming horizontally.
            When represented as a single float, this value is used for both the
            upper and lower bound. For instance, `width_factor=(0.2, 0.3)`
            result in an output zooming out between 20% to 30%.
            `width_factor=(-0.3, -0.2)` result in an output zooming in between
            20% to 30%. `None` means i.e., zooming vertical and horizontal
            directions by preserving the aspect ratio. Defaults to `None`.
        fill_mode: Points outside the boundaries of the input are filled
            according to the given mode. Available methods are `"constant"`,
            `"nearest"`, `"wrap"` and `"reflect"`. Defaults to `"constant"`.
            - `"reflect"`: `(d c b a | a b c d | d c b a)`
                The input is extended by reflecting about the edge of the last
                pixel.
            - `"constant"`: `(k k k k | a b c d | k k k k)`
                The input is extended by filling all values beyond
                the edge with the same constant value k specified by
                `fill_value`.
            - `"wrap"`: `(a b c d | a b c d | a b c d)`
                The input is extended by wrapping around to the opposite edge.
            - `"nearest"`: `(a a a a | a b c d | d d d d)`
                The input is extended by the nearest pixel.
            Note that when using torch backend, `"reflect"` is redirected to
            `"mirror"` `(c d c b | a b c d | c b a b)` because torch does not
            support `"reflect"`.
            Note that torch backend does not support `"wrap"`.
        interpolation: Interpolation mode. Supported values: `"nearest"`,
            `"bilinear"`.
        seed: Integer. Used to create a random seed.
        fill_value: a float represents the value to be filled outside
            the boundaries when `fill_mode="constant"`.
        data_format: string, either `"channels_last"` or `"channels_first"`.
            The ordering of the dimensions in the inputs. `"channels_last"`
            corresponds to inputs with shape `(batch, height, width, channels)`
            while `"channels_first"` corresponds to inputs with shape
            `(batch, channels, height, width)`. It defaults to the
            `image_data_format` value found in your Keras config file at
            `~/.keras/keras.json`. If you never set it, then it will be
            `"channels_last"`.
        **kwargs: Base layer keyword arguments, such as `name` and `dtype`.

    Example:

    >>> input_img = np.random.random((32, 224, 224, 3))
    >>> layer = keras.layers.RandomZoom(.5, .2)
    >>> out_img = layer(input_img)
    )-"


# keras_core.src.layers.preprocessing.random_zoom.RandomZoom
#' A preprocessing layer which randomly zooms images during training.
#'
#' @description
#' This layer will randomly zoom in or out on each axis of an image
#' independently, filling empty space according to `fill_mode`.
#'
#' Input pixel values can be of any range (e.g. `[0., 1.)` or `[0, 255]`) and
#' of integer or floating point dtype.
#' By default, the layer will output floats.
#'
#' # Input Shape
#' 3D (unbatched) or 4D (batched) tensor with shape:
#' `(..., height, width, channels)`, in `"channels_last"` format,
#' or `(..., channels, height, width)`, in `"channels_first"` format.
#'
#' # Output Shape
#' 3D (unbatched) or 4D (batched) tensor with shape:
#'     `(..., target_height, target_width, channels)`,
#'     or `(..., channels, target_height, target_width)`,
#'     in `"channels_first"` format.
#'
#' **Note:** This layer is safe to use inside a `tf.data` pipeline
#' (independently of which backend you're using).
#'
#' # Examples
#' ```python
#' input_img = np.random.random((32, 224, 224, 3))
#' layer = keras.layers.RandomZoom(.5, .2)
#' out_img = layer(input_img)
#' ```
#'
#' @param height_factor a float represented as fraction of value, or a tuple of
#'     size 2 representing lower and upper bound for zooming vertically.
#'     When represented as a single float, this value is used for both the
#'     upper and lower bound. A positive value means zooming out, while a
#'     negative value means zooming in. For instance,
#'     `height_factor=(0.2, 0.3)` result in an output zoomed out by a
#'     random amount in the range `[+20%, +30%]`.
#'     `height_factor=(-0.3, -0.2)` result in an output zoomed in by a
#'     random amount in the range `[+20%, +30%]`.
#' @param width_factor a float represented as fraction of value, or a tuple of
#'     size 2 representing lower and upper bound for zooming horizontally.
#'     When represented as a single float, this value is used for both the
#'     upper and lower bound. For instance, `width_factor=(0.2, 0.3)`
#'     result in an output zooming out between 20% to 30%.
#'     `width_factor=(-0.3, -0.2)` result in an output zooming in between
#'     20% to 30%. `None` means i.e., zooming vertical and horizontal
#'     directions by preserving the aspect ratio. Defaults to `None`.
#' @param fill_mode Points outside the boundaries of the input are filled
#'     according to the given mode. Available methods are `"constant"`,
#'     `"nearest"`, `"wrap"` and `"reflect"`. Defaults to `"constant"`.
#'     - `"reflect"`: `(d c b a | a b c d | d c b a)`
#'         The input is extended by reflecting about the edge of the last
#'         pixel.
#'     - `"constant"`: `(k k k k | a b c d | k k k k)`
#'         The input is extended by filling all values beyond
#'         the edge with the same constant value k specified by
#'         `fill_value`.
#'     - `"wrap"`: `(a b c d | a b c d | a b c d)`
#'         The input is extended by wrapping around to the opposite edge.
#'     - `"nearest"`: `(a a a a | a b c d | d d d d)`
#'         The input is extended by the nearest pixel.
#'     Note that when using torch backend, `"reflect"` is redirected to
#'     `"mirror"` `(c d c b | a b c d | c b a b)` because torch does not
#'     support `"reflect"`.
#'     Note that torch backend does not support `"wrap"`.
#' @param interpolation Interpolation mode. Supported values: `"nearest"`,
#'     `"bilinear"`.
#' @param seed Integer. Used to create a random seed.
#' @param fill_value a float represents the value to be filled outside
#'     the boundaries when `fill_mode="constant"`.
#' @param data_format string, either `"channels_last"` or `"channels_first"`.
#'     The ordering of the dimensions in the inputs. `"channels_last"`
#'     corresponds to inputs with shape `(batch, height, width, channels)`
#'     while `"channels_first"` corresponds to inputs with shape
#'     `(batch, channels, height, width)`. It defaults to the
#'     `image_data_format` value found in your Keras config file at
#'     `~/.keras/keras.json`. If you never set it, then it will be
#'     `"channels_last"`.
#' @param ... Base layer keyword arguments, such as `name` and `dtype`.
#' @param object Object to compose the layer with. A tensor, array, or sequential model.
#'
#' @export
#' @family preprocessing layers
#' @seealso
#' + <https://www.tensorflow.org/api_docs/python/tf/keras/layers/RandomZoom>
layer_random_zoom <-
function (object, height_factor, width_factor = NULL, fill_mode = "reflect",
    interpolation = "bilinear", seed = NULL, fill_value = 0,
    data_format = NULL, ...)
{
    args <- capture_args2(list(seed = as_integer, input_shape = normalize_shape,
        batch_size = as_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$RandomZoom, object, args)
}


# keras$layers$Rescaling
# keras_core.src.layers.preprocessing.rescaling.Rescaling
r"-(A preprocessing layer which rescales input values to a new range.

    This layer rescales every value of an input (often an image) by multiplying
    by `scale` and adding `offset`.

    For instance:

    1. To rescale an input in the `[0, 255]` range
    to be in the `[0, 1]` range, you would pass `scale=1./255`.

    2. To rescale an input in the `[0, 255]` range to be in the `[-1, 1]` range,
    you would pass `scale=1./127.5, offset=-1`.

    The rescaling is applied both during training and inference. Inputs can be
    of integer or floating point dtype, and by default the layer will output
    floats.

    **Note:** This layer is safe to use inside a `tf.data` pipeline
    (independently of which backend you're using).

    Args:
        scale: Float, the scale to apply to the inputs.
        offset: Float, the offset to apply to the inputs.
        **kwargs: Base layer keyword arguments, such as `name` and `dtype`.
    )-"


# keras_core.src.layers.preprocessing.rescaling.Rescaling
#' A preprocessing layer which rescales input values to a new range.
#'
#' @description
#' This layer rescales every value of an input (often an image) by multiplying
#' by `scale` and adding `offset`.
#'
#' For instance:
#'
#' 1. To rescale an input in the `[0, 255]` range
#' to be in the `[0, 1]` range, you would pass `scale=1./255`.
#'
#' 2. To rescale an input in the `[0, 255]` range to be in the `[-1, 1]` range,
#' you would pass `scale=1./127.5, offset=-1`.
#'
#' The rescaling is applied both during training and inference. Inputs can be
#' of integer or floating point dtype, and by default the layer will output
#' floats.
#'
#' **Note:** This layer is safe to use inside a `tf.data` pipeline
#' (independently of which backend you're using).
#'
#' @param scale Float, the scale to apply to the inputs.
#' @param offset Float, the offset to apply to the inputs.
#' @param ... Base layer keyword arguments, such as `name` and `dtype`.
#' @param object Object to compose the layer with. A tensor, array, or sequential model.
#'
#' @export
#' @family preprocessing layers
#' @seealso
#' + <https://www.tensorflow.org/api_docs/python/tf/keras/layers/Rescaling>
layer_rescaling <-
function (object, scale, offset = 0, ...)
{
    args <- capture_args2(list(input_shape = normalize_shape,
        batch_size = as_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$Rescaling, object, args)
}


# keras$layers$Resizing
# keras_core.src.layers.preprocessing.resizing.Resizing
r"-(A preprocessing layer which resizes images.

    This layer resizes an image input to a target height and width. The input
    should be a 4D (batched) or 3D (unbatched) tensor in `"channels_last"`
    format. Input pixel values can be of any range
    (e.g. `[0., 1.)` or `[0, 255]`).

    Input shape:
        3D (unbatched) or 4D (batched) tensor with shape:
        `(..., height, width, channels)`, in `"channels_last"` format,
        or `(..., channels, height, width)`, in `"channels_first"` format.

    Output shape:
        3D (unbatched) or 4D (batched) tensor with shape:
        `(..., target_height, target_width, channels)`,
        or `(..., channels, target_height, target_width)`,
        in `"channels_first"` format.

    **Note:** This layer is safe to use inside a `tf.data` pipeline
    (independently of which backend you're using).

    Args:
        height: Integer, the height of the output shape.
        width: Integer, the width of the output shape.
        interpolation: String, the interpolation method.
            Supports `"bilinear"`, `"nearest"`, `"bicubic"`,
            `"lanczos3"`, `"lanczos5"`. Defaults to `"bilinear"`.
        crop_to_aspect_ratio: If `True`, resize the images without aspect
            ratio distortion. When the original aspect ratio differs
            from the target aspect ratio, the output image will be
            cropped so as to return the
            largest possible window in the image (of size `(height, width)`)
            that matches the target aspect ratio. By default
            (`crop_to_aspect_ratio=False`), aspect ratio may not be preserved.
        data_format: string, either `"channels_last"` or `"channels_first"`.
            The ordering of the dimensions in the inputs. `"channels_last"`
            corresponds to inputs with shape `(batch, height, width, channels)`
            while `"channels_first"` corresponds to inputs with shape
            `(batch, channels, height, width)`. It defaults to the
            `image_data_format` value found in your Keras config file at
            `~/.keras/keras.json`. If you never set it, then it will be
            `"channels_last"`.
        **kwargs: Base layer keyword arguments, such as `name` and `dtype`.
    )-"


# keras_core.src.layers.preprocessing.resizing.Resizing
#' A preprocessing layer which resizes images.
#'
#' @description
#' This layer resizes an image input to a target height and width. The input
#' should be a 4D (batched) or 3D (unbatched) tensor in `"channels_last"`
#' format. Input pixel values can be of any range
#' (e.g. `[0., 1.)` or `[0, 255]`).
#'
#' # Input Shape
#' 3D (unbatched) or 4D (batched) tensor with shape:
#' `(..., height, width, channels)`, in `"channels_last"` format,
#' or `(..., channels, height, width)`, in `"channels_first"` format.
#'
#' # Output Shape
#' 3D (unbatched) or 4D (batched) tensor with shape:
#'     `(..., target_height, target_width, channels)`,
#'     or `(..., channels, target_height, target_width)`,
#'     in `"channels_first"` format.
#'
#' **Note:** This layer is safe to use inside a `tf.data` pipeline
#' (independently of which backend you're using).
#'
#' @param height Integer, the height of the output shape.
#' @param width Integer, the width of the output shape.
#' @param interpolation String, the interpolation method.
#'     Supports `"bilinear"`, `"nearest"`, `"bicubic"`,
#'     `"lanczos3"`, `"lanczos5"`. Defaults to `"bilinear"`.
#' @param crop_to_aspect_ratio If `True`, resize the images without aspect
#'     ratio distortion. When the original aspect ratio differs
#'     from the target aspect ratio, the output image will be
#'     cropped so as to return the
#'     largest possible window in the image (of size `(height, width)`)
#'     that matches the target aspect ratio. By default
#'     (`crop_to_aspect_ratio=False`), aspect ratio may not be preserved.
#' @param data_format string, either `"channels_last"` or `"channels_first"`.
#'     The ordering of the dimensions in the inputs. `"channels_last"`
#'     corresponds to inputs with shape `(batch, height, width, channels)`
#'     while `"channels_first"` corresponds to inputs with shape
#'     `(batch, channels, height, width)`. It defaults to the
#'     `image_data_format` value found in your Keras config file at
#'     `~/.keras/keras.json`. If you never set it, then it will be
#'     `"channels_last"`.
#' @param ... Base layer keyword arguments, such as `name` and `dtype`.
#' @param object Object to compose the layer with. A tensor, array, or sequential model.
#'
#' @export
#' @family preprocessing layers
#' @seealso
#' + <https://www.tensorflow.org/api_docs/python/tf/keras/layers/Resizing>
layer_resizing <-
function (object, height, width, interpolation = "bilinear",
    crop_to_aspect_ratio = FALSE, data_format = NULL, ...)
{
    args <- capture_args2(list(height = as_integer, width = as_integer,
        input_shape = normalize_shape, batch_size = as_integer,
        batch_input_shape = normalize_shape), ignore = "object")
    create_layer(keras$layers$Resizing, object, args)
}


# keras$layers$StringLookup
# keras_core.src.layers.preprocessing.string_lookup.StringLookup
r"-(A preprocessing layer that maps strings to (possibly encoded) indices.

    This layer translates a set of arbitrary strings into integer output via a
    table-based vocabulary lookup. This layer will perform no splitting or
    transformation of input strings. For a layer than can split and tokenize
    natural language, see the `keras.layers.TextVectorization` layer.

    The vocabulary for the layer must be either supplied on construction or
    learned via `adapt()`. During `adapt()`, the layer will analyze a data set,
    determine the frequency of individual strings tokens, and create a
    vocabulary from them. If the vocabulary is capped in size, the most frequent
    tokens will be used to create the vocabulary and all others will be treated
    as out-of-vocabulary (OOV).

    There are two possible output modes for the layer.
    When `output_mode` is `"int"`,
    input strings are converted to their index in the vocabulary (an integer).
    When `output_mode` is `"multi_hot"`, `"count"`, or `"tf_idf"`, input strings
    are encoded into an array where each dimension corresponds to an element in
    the vocabulary.

    The vocabulary can optionally contain a mask token as well as an OOV token
    (which can optionally occupy multiple indices in the vocabulary, as set
    by `num_oov_indices`).
    The position of these tokens in the vocabulary is fixed. When `output_mode`
    is `"int"`, the vocabulary will begin with the mask token (if set), followed
    by OOV indices, followed by the rest of the vocabulary. When `output_mode`
    is `"multi_hot"`, `"count"`, or `"tf_idf"` the vocabulary will begin with
    OOV indices and instances of the mask token will be dropped.

    **Note:** This layer uses TensorFlow internally. It cannot
    be used as part of the compiled computation graph of a model with
    any backend other than TensorFlow.
    It can however be used with any backend when running eagerly.
    It can also always be used as part of an input preprocessing pipeline
    with any backend (outside the model itself), which is how we recommend
    to use this layer.

    **Note:** This layer is safe to use inside a `tf.data` pipeline
    (independently of which backend you're using).

    Args:
        max_tokens: Maximum size of the vocabulary for this layer. This should
            only be specified when adapting the vocabulary or when setting
            `pad_to_max_tokens=True`. If None, there is no cap on the size of
            the vocabulary. Note that this size includes the OOV
            and mask tokens. Defaults to `None`.
        num_oov_indices: The number of out-of-vocabulary tokens to use.
            If this value is more than 1, OOV inputs are modulated to
            determine their OOV value.
            If this value is 0, OOV inputs will cause an error when calling
            the layer. Defaults to `1`.
        mask_token: A token that represents masked inputs. When `output_mode` is
            `"int"`, the token is included in vocabulary and mapped to index 0.
            In other output modes, the token will not appear
            in the vocabulary and instances of the mask token
            in the input will be dropped. If set to `None`,
            no mask term will be added. Defaults to `None`.
        oov_token: Only used when `invert` is True. The token to return for OOV
            indices. Defaults to `"[UNK]"`.
        vocabulary: Optional. Either an array of integers or a string path to a
            text file. If passing an array, can pass a tuple, list,
            1D NumPy array, or 1D tensor containing the integer vocbulary terms.
            If passing a file path, the file should contain one line per term
            in the vocabulary. If this argument is set,
            there is no need to `adapt()` the layer.
        vocabulary_dtype: The dtype of the vocabulary terms, for example
            `"int64"` or `"int32"`. Defaults to `"int64"`.
        idf_weights: Only valid when `output_mode` is `"tf_idf"`.
            A tuple, list, 1D NumPy array, or 1D tensor or the same length
            as the vocabulary, containing the floating point inverse document
            frequency weights, which will be multiplied by per sample term
            counts for the final TF-IDF weight.
            If the `vocabulary` argument is set, and `output_mode` is
            `"tf_idf"`, this argument must be supplied.
        invert: Only valid when `output_mode` is `"int"`.
            If `True`, this layer will map indices to vocabulary items
            instead of mapping vocabulary items to indices.
            Defaults to `False`.
        output_mode: Specification for the output of the layer. Values can be
            `"int"`, `"one_hot"`, `"multi_hot"`, `"count"`, or `"tf_idf"`
            configuring the layer as follows:
            - `"int"`: Return the vocabulary indices of the input tokens.
            - `"one_hot"`: Encodes each individual element in the input into an
                array the same size as the vocabulary,
                containing a 1 at the element index. If the last dimension
                is size 1, will encode on that dimension.
                If the last dimension is not size 1, will append a new
                dimension for the encoded output.
            - `"multi_hot"`: Encodes each sample in the input into a single
                array the same size as the vocabulary,
                containing a 1 for each vocabulary term present in the sample.
                Treats the last dimension as the sample dimension,
                if input shape is `(..., sample_length)`,
                output shape will be `(..., num_tokens)`.
            - `"count"`: As `"multi_hot"`, but the int array contains
                a count of the number of times the token at that index
                appeared in the sample.
            - `"tf_idf"`: As `"multi_hot"`, but the TF-IDF algorithm is
                applied to find the value in each token slot.
            For `"int"` output, any shape of input and output is supported.
            For all other output modes, currently only output up to rank 2
            is supported. Defaults to `"int"`.
        pad_to_max_tokens: Only applicable when `output_mode` is `"multi_hot"`,
            `"count"`, or `"tf_idf"`. If `True`, the output will have
            its feature axis padded to `max_tokens` even if the number
            of unique tokens in the vocabulary is less than `max_tokens`,
            resulting in a tensor of shape `(batch_size, max_tokens)`
            regardless of vocabulary size. Defaults to `False`.
        sparse: Boolean. Only applicable to `"multi_hot"`, `"count"`, and
            `"tf_idf"` output modes. Only supported with TensorFlow
            backend. If `True`, returns a `SparseTensor`
            instead of a dense `Tensor`. Defaults to `False`.
        encoding: Optional. The text encoding to use to interpret the input
            strings. Defaults to `"utf-8"`.

    Examples:

    **Creating a lookup layer with a known vocabulary**

    This example creates a lookup layer with a pre-existing vocabulary.

    >>> vocab = ["a", "b", "c", "d"]
    >>> data = [["a", "c", "d"], ["d", "z", "b"]]
    >>> layer = StringLookup(vocabulary=vocab)
    >>> layer(data)
    array([[1, 3, 4],
           [4, 0, 2]])

    **Creating a lookup layer with an adapted vocabulary**

    This example creates a lookup layer and generates the vocabulary by
    analyzing the dataset.

    >>> data = [["a", "c", "d"], ["d", "z", "b"]]
    >>> layer = StringLookup()
    >>> layer.adapt(data)
    >>> layer.get_vocabulary()
    ['[UNK]', 'd', 'z', 'c', 'b', 'a']

    Note that the OOV token `"[UNK]"` has been added to the vocabulary.
    The remaining tokens are sorted by frequency
    (`"d"`, which has 2 occurrences, is first) then by inverse sort order.

    >>> data = [["a", "c", "d"], ["d", "z", "b"]]
    >>> layer = StringLookup()
    >>> layer.adapt(data)
    >>> layer(data)
    array([[5, 3, 1],
           [1, 2, 4]])

    **Lookups with multiple OOV indices**

    This example demonstrates how to use a lookup layer with multiple OOV
    indices.  When a layer is created with more than one OOV index, any OOV
    values are hashed into the number of OOV buckets, distributing OOV values in
    a deterministic fashion across the set.

    >>> vocab = ["a", "b", "c", "d"]
    >>> data = [["a", "c", "d"], ["m", "z", "b"]]
    >>> layer = StringLookup(vocabulary=vocab, num_oov_indices=2)
    >>> layer(data)
    array([[2, 4, 5],
           [0, 1, 3]])

    Note that the output for OOV value 'm' is 0, while the output for OOV value
    `"z"` is 1. The in-vocab terms have their output index increased by 1 from
    earlier examples (a maps to 2, etc) in order to make space for the extra OOV
    value.

    **One-hot output**

    Configure the layer with `output_mode='one_hot'`. Note that the first
    `num_oov_indices` dimensions in the ont_hot encoding represent OOV values.

    >>> vocab = ["a", "b", "c", "d"]
    >>> data = ["a", "b", "c", "d", "z"]
    >>> layer = StringLookup(vocabulary=vocab, output_mode='one_hot')
    >>> layer(data)
    array([[0., 1., 0., 0., 0.],
           [0., 0., 1., 0., 0.],
           [0., 0., 0., 1., 0.],
           [0., 0., 0., 0., 1.],
           [1., 0., 0., 0., 0.]], dtype=float32)

    **Multi-hot output**

    Configure the layer with `output_mode='multi_hot'`. Note that the first
    `num_oov_indices` dimensions in the multi_hot encoding represent OOV values.

    >>> vocab = ["a", "b", "c", "d"]
    >>> data = [["a", "c", "d", "d"], ["d", "z", "b", "z"]]
    >>> layer = StringLookup(vocabulary=vocab, output_mode='multi_hot')
    >>> layer(data)
    array([[0., 1., 0., 1., 1.],
           [1., 0., 1., 0., 1.]], dtype=float32)

    **Token count output**

    Configure the layer with `output_mode='count'`. As with multi_hot output,
    the first `num_oov_indices` dimensions in the output represent OOV values.

    >>> vocab = ["a", "b", "c", "d"]
    >>> data = [["a", "c", "d", "d"], ["d", "z", "b", "z"]]
    >>> layer = StringLookup(vocabulary=vocab, output_mode='count')
    >>> layer(data)
    array([[0., 1., 0., 1., 2.],
           [2., 0., 1., 0., 1.]], dtype=float32)

    **TF-IDF output**

    Configure the layer with `output_mode="tf_idf"`. As with multi_hot output,
    the first `num_oov_indices` dimensions in the output represent OOV values.

    Each token bin will output `token_count * idf_weight`, where the idf weights
    are the inverse document frequency weights per token. These should be
    provided along with the vocabulary. Note that the `idf_weight` for OOV
    values will default to the average of all idf weights passed in.

    >>> vocab = ["a", "b", "c", "d"]
    >>> idf_weights = [0.25, 0.75, 0.6, 0.4]
    >>> data = [["a", "c", "d", "d"], ["d", "z", "b", "z"]]
    >>> layer = StringLookup(output_mode="tf_idf")
    >>> layer.set_vocabulary(vocab, idf_weights=idf_weights)
    >>> layer(data)
    array([[0.  , 0.25, 0.  , 0.6 , 0.8 ],
           [1.0 , 0.  , 0.75, 0.  , 0.4 ]], dtype=float32)

    To specify the idf weights for oov values, you will need to pass the entire
    vocabularly including the leading oov token.

    >>> vocab = ["[UNK]", "a", "b", "c", "d"]
    >>> idf_weights = [0.9, 0.25, 0.75, 0.6, 0.4]
    >>> data = [["a", "c", "d", "d"], ["d", "z", "b", "z"]]
    >>> layer = StringLookup(output_mode="tf_idf")
    >>> layer.set_vocabulary(vocab, idf_weights=idf_weights)
    >>> layer(data)
    array([[0.  , 0.25, 0.  , 0.6 , 0.8 ],
           [1.8 , 0.  , 0.75, 0.  , 0.4 ]], dtype=float32)

    When adapting the layer in `"tf_idf"` mode, each input sample will be
    considered a document, and IDF weight per token will be calculated as
    `log(1 + num_documents / (1 + token_document_count))`.

    **Inverse lookup**

    This example demonstrates how to map indices to strings using this layer.
    (You can also use `adapt()` with `inverse=True`, but for simplicity we'll
    pass the vocab in this example.)

    >>> vocab = ["a", "b", "c", "d"]
    >>> data = [[1, 3, 4], [4, 0, 2]]
    >>> layer = StringLookup(vocabulary=vocab, invert=True)
    >>> layer(data)
    array([[b'a', b'c', b'd'],
           [b'd', b'[UNK]', b'b']], dtype=object)

    Note that the first index correspond to the oov token by default.


    **Forward and inverse lookup pairs**

    This example demonstrates how to use the vocabulary of a standard lookup
    layer to create an inverse lookup layer.

    >>> vocab = ["a", "b", "c", "d"]
    >>> data = [["a", "c", "d"], ["d", "z", "b"]]
    >>> layer = StringLookup(vocabulary=vocab)
    >>> i_layer = StringLookup(vocabulary=vocab, invert=True)
    >>> int_data = layer(data)
    >>> i_layer(int_data)
    array([[b'a', b'c', b'd'],
           [b'd', b'[UNK]', b'b']], dtype=object)

    In this example, the input value `"z"` resulted in an output of `"[UNK]"`,
    since 1000 was not in the vocabulary - it got represented as an OOV, and all
    OOV values are returned as `"[UNK]"` in the inverse layer. Also, note that
    for the inverse to work, you must have already set the forward layer
    vocabulary either directly or via `adapt()` before calling
    `get_vocabulary()`.
    )-"


# keras_core.src.layers.preprocessing.string_lookup.StringLookup
#' A preprocessing layer that maps strings to (possibly encoded) indices.
#'
#' @description
#' This layer translates a set of arbitrary strings into integer output via a
#' table-based vocabulary lookup. This layer will perform no splitting or
#' transformation of input strings. For a layer than can split and tokenize
#' natural language, see the `keras.layers.TextVectorization` layer.
#'
#' The vocabulary for the layer must be either supplied on construction or
#' learned via `adapt()`. During `adapt()`, the layer will analyze a data set,
#' determine the frequency of individual strings tokens, and create a
#' vocabulary from them. If the vocabulary is capped in size, the most frequent
#' tokens will be used to create the vocabulary and all others will be treated
#' as out-of-vocabulary (OOV).
#'
#' There are two possible output modes for the layer.
#' When `output_mode` is `"int"`,
#' input strings are converted to their index in the vocabulary (an integer).
#' When `output_mode` is `"multi_hot"`, `"count"`, or `"tf_idf"`, input strings
#' are encoded into an array where each dimension corresponds to an element in
#' the vocabulary.
#'
#' The vocabulary can optionally contain a mask token as well as an OOV token
#' (which can optionally occupy multiple indices in the vocabulary, as set
#' by `num_oov_indices`).
#' The position of these tokens in the vocabulary is fixed. When `output_mode`
#' is `"int"`, the vocabulary will begin with the mask token (if set), followed
#' by OOV indices, followed by the rest of the vocabulary. When `output_mode`
#' is `"multi_hot"`, `"count"`, or `"tf_idf"` the vocabulary will begin with
#' OOV indices and instances of the mask token will be dropped.
#'
#' **Note:** This layer uses TensorFlow internally. It cannot
#' be used as part of the compiled computation graph of a model with
#' any backend other than TensorFlow.
#' It can however be used with any backend when running eagerly.
#' It can also always be used as part of an input preprocessing pipeline
#' with any backend (outside the model itself), which is how we recommend
#' to use this layer.
#'
#' **Note:** This layer is safe to use inside a `tf.data` pipeline
#' (independently of which backend you're using).
#'
#' # Examples
#' **Creating a lookup layer with a known vocabulary**
#'
#' This example creates a lookup layer with a pre-existing vocabulary.
#'
#' ```python
#' vocab = ["a", "b", "c", "d"]
#' data = [["a", "c", "d"], ["d", "z", "b"]]
#' layer = StringLookup(vocabulary=vocab)
#' layer(data)
#' # array([[1, 3, 4],
#' #        [4, 0, 2]])
#' ```
#'
#' **Creating a lookup layer with an adapted vocabulary**
#'
#' This example creates a lookup layer and generates the vocabulary by
#' analyzing the dataset.
#'
#' ```python
#' data = [["a", "c", "d"], ["d", "z", "b"]]
#' layer = StringLookup()
#' layer.adapt(data)
#' layer.get_vocabulary()
#' # ['[UNK]', 'd', 'z', 'c', 'b', 'a']
#' ```
#'
#' Note that the OOV token `"[UNK]"` has been added to the vocabulary.
#' The remaining tokens are sorted by frequency
#' (`"d"`, which has 2 occurrences, is first) then by inverse sort order.
#'
#' ```python
#' data = [["a", "c", "d"], ["d", "z", "b"]]
#' layer = StringLookup()
#' layer.adapt(data)
#' layer(data)
#' # array([[5, 3, 1],
#' #        [1, 2, 4]])
#' ```
#'
#' **Lookups with multiple OOV indices**
#'
#' This example demonstrates how to use a lookup layer with multiple OOV
#' indices.  When a layer is created with more than one OOV index, any OOV
#' values are hashed into the number of OOV buckets, distributing OOV values in
#' a deterministic fashion across the set.
#'
#' ```python
#' vocab = ["a", "b", "c", "d"]
#' data = [["a", "c", "d"], ["m", "z", "b"]]
#' layer = StringLookup(vocabulary=vocab, num_oov_indices=2)
#' layer(data)
#' # array([[2, 4, 5],
#' #        [0, 1, 3]])
#' ```
#'
#' Note that the output for OOV value 'm' is 0, while the output for OOV value
#' `"z"` is 1. The in-vocab terms have their output index increased by 1 from
#' earlier examples (a maps to 2, etc) in order to make space for the extra OOV
#' value.
#'
#' **One-hot output**
#'
#' Configure the layer with `output_mode='one_hot'`. Note that the first
#' `num_oov_indices` dimensions in the ont_hot encoding represent OOV values.
#'
#' ```python
#' vocab = ["a", "b", "c", "d"]
#' data = ["a", "b", "c", "d", "z"]
#' layer = StringLookup(vocabulary=vocab, output_mode='one_hot')
#' layer(data)
#' # array([[0., 1., 0., 0., 0.],
#' #        [0., 0., 1., 0., 0.],
#' #        [0., 0., 0., 1., 0.],
#' #        [0., 0., 0., 0., 1.],
#' #        [1., 0., 0., 0., 0.]], dtype=float32)
#' ```
#'
#' **Multi-hot output**
#'
#' Configure the layer with `output_mode='multi_hot'`. Note that the first
#' `num_oov_indices` dimensions in the multi_hot encoding represent OOV values.
#'
#' ```python
#' vocab = ["a", "b", "c", "d"]
#' data = [["a", "c", "d", "d"], ["d", "z", "b", "z"]]
#' layer = StringLookup(vocabulary=vocab, output_mode='multi_hot')
#' layer(data)
#' # array([[0., 1., 0., 1., 1.],
#' #        [1., 0., 1., 0., 1.]], dtype=float32)
#' ```
#'
#' **Token count output**
#'
#' Configure the layer with `output_mode='count'`. As with multi_hot output,
#' the first `num_oov_indices` dimensions in the output represent OOV values.
#'
#' ```python
#' vocab = ["a", "b", "c", "d"]
#' data = [["a", "c", "d", "d"], ["d", "z", "b", "z"]]
#' layer = StringLookup(vocabulary=vocab, output_mode='count')
#' layer(data)
#' # array([[0., 1., 0., 1., 2.],
#' #        [2., 0., 1., 0., 1.]], dtype=float32)
#' ```
#'
#' **TF-IDF output**
#'
#' Configure the layer with `output_mode="tf_idf"`. As with multi_hot output,
#' the first `num_oov_indices` dimensions in the output represent OOV values.
#'
#' Each token bin will output `token_count * idf_weight`, where the idf weights
#' are the inverse document frequency weights per token. These should be
#' provided along with the vocabulary. Note that the `idf_weight` for OOV
#' values will default to the average of all idf weights passed in.
#'
#' ```python
#' vocab = ["a", "b", "c", "d"]
#' idf_weights = [0.25, 0.75, 0.6, 0.4]
#' data = [["a", "c", "d", "d"], ["d", "z", "b", "z"]]
#' layer = StringLookup(output_mode="tf_idf")
#' layer.set_vocabulary(vocab, idf_weights=idf_weights)
#' layer(data)
#' # array([[0.  , 0.25, 0.  , 0.6 , 0.8 ],
#' #        [1.0 , 0.  , 0.75, 0.  , 0.4 ]], dtype=float32)
#' ```
#'
#' To specify the idf weights for oov values, you will need to pass the entire
#' vocabularly including the leading oov token.
#'
#' ```python
#' vocab = ["[UNK]", "a", "b", "c", "d"]
#' idf_weights = [0.9, 0.25, 0.75, 0.6, 0.4]
#' data = [["a", "c", "d", "d"], ["d", "z", "b", "z"]]
#' layer = StringLookup(output_mode="tf_idf")
#' layer.set_vocabulary(vocab, idf_weights=idf_weights)
#' layer(data)
#' # array([[0.  , 0.25, 0.  , 0.6 , 0.8 ],
#' #        [1.8 , 0.  , 0.75, 0.  , 0.4 ]], dtype=float32)
#' ```
#'
#' When adapting the layer in `"tf_idf"` mode, each input sample will be
#' considered a document, and IDF weight per token will be calculated as
#' `log(1 + num_documents / (1 + token_document_count))`.
#'
#' **Inverse lookup**
#'
#' This example demonstrates how to map indices to strings using this layer.
#' (You can also use `adapt()` with `inverse=True`, but for simplicity we'll
#' pass the vocab in this example.)
#'
#' ```python
#' vocab = ["a", "b", "c", "d"]
#' data = [[1, 3, 4], [4, 0, 2]]
#' layer = StringLookup(vocabulary=vocab, invert=True)
#' layer(data)
#' # array([[b'a', b'c', b'd'],
#' #        [b'd', b'[UNK]', b'b']], dtype=object)
#' ```
#'
#' Note that the first index correspond to the oov token by default.
#'
#' **Forward and inverse lookup pairs**
#'
#' This example demonstrates how to use the vocabulary of a standard lookup
#' layer to create an inverse lookup layer.
#'
#' ```python
#' vocab = ["a", "b", "c", "d"]
#' data = [["a", "c", "d"], ["d", "z", "b"]]
#' layer = StringLookup(vocabulary=vocab)
#' i_layer = StringLookup(vocabulary=vocab, invert=True)
#' int_data = layer(data)
#' i_layer(int_data)
#' # array([[b'a', b'c', b'd'],
#' #        [b'd', b'[UNK]', b'b']], dtype=object)
#' ```
#'
#' In this example, the input value `"z"` resulted in an output of `"[UNK]"`,
#' since 1000 was not in the vocabulary - it got represented as an OOV, and all
#' OOV values are returned as `"[UNK]"` in the inverse layer. Also, note that
#' for the inverse to work, you must have already set the forward layer
#' vocabulary either directly or via `adapt()` before calling
#' `get_vocabulary()`.
#'
#' @param max_tokens Maximum size of the vocabulary for this layer. This should
#'     only be specified when adapting the vocabulary or when setting
#'     `pad_to_max_tokens=True`. If None, there is no cap on the size of
#'     the vocabulary. Note that this size includes the OOV
#'     and mask tokens. Defaults to `None`.
#' @param num_oov_indices The number of out-of-vocabulary tokens to use.
#'     If this value is more than 1, OOV inputs are modulated to
#'     determine their OOV value.
#'     If this value is 0, OOV inputs will cause an error when calling
#'     the layer. Defaults to `1`.
#' @param mask_token A token that represents masked inputs. When `output_mode` is
#'     `"int"`, the token is included in vocabulary and mapped to index 0.
#'     In other output modes, the token will not appear
#'     in the vocabulary and instances of the mask token
#'     in the input will be dropped. If set to `None`,
#'     no mask term will be added. Defaults to `None`.
#' @param oov_token Only used when `invert` is True. The token to return for OOV
#'     indices. Defaults to `"[UNK]"`.
#' @param vocabulary Optional. Either an array of integers or a string path to a
#'     text file. If passing an array, can pass a tuple, list,
#'     1D NumPy array, or 1D tensor containing the integer vocbulary terms.
#'     If passing a file path, the file should contain one line per term
#'     in the vocabulary. If this argument is set,
#'     there is no need to `adapt()` the layer.
#' @param vocabulary_dtype The dtype of the vocabulary terms, for example
#'     `"int64"` or `"int32"`. Defaults to `"int64"`.
#' @param idf_weights Only valid when `output_mode` is `"tf_idf"`.
#'     A tuple, list, 1D NumPy array, or 1D tensor or the same length
#'     as the vocabulary, containing the floating point inverse document
#'     frequency weights, which will be multiplied by per sample term
#'     counts for the final TF-IDF weight.
#'     If the `vocabulary` argument is set, and `output_mode` is
#'     `"tf_idf"`, this argument must be supplied.
#' @param invert Only valid when `output_mode` is `"int"`.
#'     If `True`, this layer will map indices to vocabulary items
#'     instead of mapping vocabulary items to indices.
#'     Defaults to `False`.
#' @param output_mode Specification for the output of the layer. Values can be
#'     `"int"`, `"one_hot"`, `"multi_hot"`, `"count"`, or `"tf_idf"`
#'     configuring the layer as follows:
#'     - `"int"`: Return the vocabulary indices of the input tokens.
#'     - `"one_hot"`: Encodes each individual element in the input into an
#'         array the same size as the vocabulary,
#'         containing a 1 at the element index. If the last dimension
#'         is size 1, will encode on that dimension.
#'         If the last dimension is not size 1, will append a new
#'         dimension for the encoded output.
#'     - `"multi_hot"`: Encodes each sample in the input into a single
#'         array the same size as the vocabulary,
#'         containing a 1 for each vocabulary term present in the sample.
#'         Treats the last dimension as the sample dimension,
#'         if input shape is `(..., sample_length)`,
#'         output shape will be `(..., num_tokens)`.
#'     - `"count"`: As `"multi_hot"`, but the int array contains
#'         a count of the number of times the token at that index
#'         appeared in the sample.
#'     - `"tf_idf"`: As `"multi_hot"`, but the TF-IDF algorithm is
#'         applied to find the value in each token slot.
#'     For `"int"` output, any shape of input and output is supported.
#'     For all other output modes, currently only output up to rank 2
#'     is supported. Defaults to `"int"`.
#' @param pad_to_max_tokens Only applicable when `output_mode` is `"multi_hot"`,
#'     `"count"`, or `"tf_idf"`. If `True`, the output will have
#'     its feature axis padded to `max_tokens` even if the number
#'     of unique tokens in the vocabulary is less than `max_tokens`,
#'     resulting in a tensor of shape `(batch_size, max_tokens)`
#'     regardless of vocabulary size. Defaults to `False`.
#' @param sparse Boolean. Only applicable to `"multi_hot"`, `"count"`, and
#'     `"tf_idf"` output modes. Only supported with TensorFlow
#'     backend. If `True`, returns a `SparseTensor`
#'     instead of a dense `Tensor`. Defaults to `False`.
#' @param encoding Optional. The text encoding to use to interpret the input
#'     strings. Defaults to `"utf-8"`.
#' @param object Object to compose the layer with. A tensor, array, or sequential model.
#' @param ... Passed on to the Python callable
#' @param name name for the layer
#'
#' @export
#' @family preprocessing layers
#' @seealso
#' + <https://www.tensorflow.org/api_docs/python/tf/keras/layers/StringLookup>
layer_string_lookup <-
function (object, max_tokens = NULL, num_oov_indices = 1L, mask_token = NULL,
    oov_token = "[UNK]", vocabulary = NULL, idf_weights = NULL,
    invert = FALSE, output_mode = "int", pad_to_max_tokens = FALSE,
    sparse = FALSE, encoding = "utf-8", name = NULL, ...)
{
    args <- capture_args2(list(num_oov_indices = as_integer,
        mask_token = as_integer, vocabulary = as_integer, invert = as_integer,
        output_mode = as_integer, input_shape = normalize_shape,
        batch_size = as_integer, batch_input_shape = normalize_shape),
        ignore = "object")
    create_layer(keras$layers$StringLookup, object, args)
}


# keras$layers$TextVectorization
# keras_core.src.layers.preprocessing.text_vectorization.TextVectorization
r"-(A preprocessing layer which maps text features to integer sequences.

    This layer has basic options for managing text in a Keras model. It
    transforms a batch of strings (one example = one string) into either a list
    of token indices (one example = 1D tensor of integer token indices) or a
    dense representation (one example = 1D tensor of float values representing
    data about the example's tokens). This layer is meant to handle natural
    language inputs. To handle simple string inputs (categorical strings or
    pre-tokenized strings) see `kers_core.layers.StringLookup`.

    The vocabulary for the layer must be either supplied on construction or
    learned via `adapt()`. When this layer is adapted, it will analyze the
    dataset, determine the frequency of individual string values, and create a
    vocabulary from them. This vocabulary can have unlimited size or be capped,
    depending on the configuration options for this layer; if there are more
    unique values in the input than the maximum vocabulary size, the most
    frequent terms will be used to create the vocabulary.

    The processing of each example contains the following steps:

    1. Standardize each example (usually lowercasing + punctuation stripping)
    2. Split each example into substrings (usually words)
    3. Recombine substrings into tokens (usually ngrams)
    4. Index tokens (associate a unique int value with each token)
    5. Transform each example using this index, either into a vector of ints or
       a dense float vector.

    Some notes on passing callables to customize splitting and normalization for
    this layer:

    1. Any callable can be passed to this Layer, but if you want to serialize
       this object you should only pass functions that are registered Keras
       serializables (see `keras.saving.register_keras_serializable`
       for more details).
    2. When using a custom callable for `standardize`, the data received
       by the callable will be exactly as passed to this layer. The callable
       should return a tensor of the same shape as the input.
    3. When using a custom callable for `split`, the data received by the
       callable will have the 1st dimension squeezed out - instead of
       `[["string to split"], ["another string to split"]]`, the Callable will
       see `["string to split", "another string to split"]`.
       The callable should return a `tf.Tensor` of dtype `string`
       with the first dimension containing the split tokens -
       in this example, we should see something like `[["string", "to",
       "split"], ["another", "string", "to", "split"]]`.

    **Note:** This layer uses TensorFlow internally. It cannot
    be used as part of the compiled computation graph of a model with
    any backend other than TensorFlow.
    It can however be used with any backend when running eagerly.
    It can also always be used as part of an input preprocessing pipeline
    with any backend (outside the model itself), which is how we recommend
    to use this layer.

    **Note:** This layer is safe to use inside a `tf.data` pipeline
    (independently of which backend you're using).

    Args:
        max_tokens: Maximum size of the vocabulary for this layer. This should
            only be specified when adapting a vocabulary or when setting
            `pad_to_max_tokens=True`. Note that this vocabulary
            contains 1 OOV token, so the effective number of tokens is
            `(max_tokens - 1 - (1 if output_mode == "int" else 0))`.
        standardize: Optional specification for standardization to apply to the
            input text. Values can be:
            - `None`: No standardization.
            - `"lower_and_strip_punctuation"`: Text will be lowercased and all
                punctuation removed.
            - `"lower"`: Text will be lowercased.
            - `"strip_punctuation"`: All punctuation will be removed.
            - Callable: Inputs will passed to the callable function,
                which should be standardized and returned.
        split: Optional specification for splitting the input text.
            Values can be:
            - `None`: No splitting.
            - `"whitespace"`: Split on whitespace.
            - `"character"`: Split on each unicode character.
            - Callable: Standardized inputs will passed to the callable
                function, which should be split and returned.
        ngrams: Optional specification for ngrams to create from the
            possibly-split input text. Values can be `None`, an integer
            or tuple of integers; passing an integer will create ngrams
            up to that integer, and passing a tuple of integers will
            create ngrams for the specified values in the tuple.
            Passing `None` means that no ngrams will be created.
        output_mode: Optional specification for the output of the layer.
            Values can be `"int"`, `"multi_hot"`, `"count"` or `"tf_idf"`,
            configuring the layer as follows:
            - `"int"`: Outputs integer indices, one integer index per split
                string token. When `output_mode == "int"`,
                0 is reserved for masked locations;
                this reduces the vocab size to `max_tokens - 2`
                instead of `max_tokens - 1`.
            - `"multi_hot"`: Outputs a single int array per batch, of either
                vocab_size or max_tokens size, containing 1s in all elements
                where the token mapped to that index exists at least
                once in the batch item.
            - `"count"`: Like `"multi_hot"`, but the int array contains
                a count of the number of times the token at that index
                appeared in the batch item.
            - `"tf_idf"`: Like `"multi_hot"`, but the TF-IDF algorithm
                is applied to find the value in each token slot.
            For `"int"` output, any shape of input and output is supported.
            For all other output modes, currently only rank 1 inputs
            (and rank 2 outputs after splitting) are supported.
        output_sequence_length: Only valid in INT mode. If set, the output will
            have its time dimension padded or truncated to exactly
            `output_sequence_length` values, resulting in a tensor of shape
            `(batch_size, output_sequence_length)` regardless of how many tokens
            resulted from the splitting step. Defaults to `None`.
        pad_to_max_tokens: Only valid in  `"multi_hot"`, `"count"`,
            and `"tf_idf"` modes. If `True`, the output will have
            its feature axis padded to `max_tokens` even if the number
            of unique tokens in the vocabulary is less than `max_tokens`,
            resulting in a tensor of shape `(batch_size, max_tokens)`
            regardless of vocabulary size. Defaults to `False`.
        vocabulary: Optional. Either an array of strings or a string path to a
            text file. If passing an array, can pass a tuple, list,
            1D NumPy array, or 1D tensor containing the string vocabulary terms.
            If passing a file path, the file should contain one line per term
            in the vocabulary. If this argument is set,
            there is no need to `adapt()` the layer.
        idf_weights: Only valid when `output_mode` is `"tf_idf"`. A tuple, list,
            1D NumPy array, or 1D tensor of the same length as the vocabulary,
            containing the floating point inverse document frequency weights,
            which will be multiplied by per sample term counts for
            the final `tf_idf` weight. If the `vocabulary` argument is set,
            and `output_mode` is `"tf_idf"`, this argument must be supplied.
        ragged: Boolean. Only applicable to `"int"` output mode.
            Only supported with TensorFlow backend.
            If `True`, returns a `RaggedTensor` instead of a dense `Tensor`,
            where each sequence may have a different length
            after string splitting. Defaults to `False`.
        sparse: Boolean. Only applicable to `"multi_hot"`, `"count"`, and
            `"tf_idf"` output modes. Only supported with TensorFlow
            backend. If `True`, returns a `SparseTensor`
            instead of a dense `Tensor`. Defaults to `False`.
        encoding: Optional. The text encoding to use to interpret the input
            strings. Defaults to `"utf-8"`.

    Examples:

    This example instantiates a `TextVectorization` layer that lowercases text,
    splits on whitespace, strips punctuation, and outputs integer vocab indices.

    >>> max_tokens = 5000  # Maximum vocab size.
    >>> max_len = 4  # Sequence length to pad the outputs to.
    >>> # Create the layer.
    >>> vectorize_layer = TextVectorization(
    ...     max_tokens=max_tokens,
    ...     output_mode='int',
    ...     output_sequence_length=max_len)

    >>> # Now that the vocab layer has been created, call `adapt` on the
    >>> # list of strings to create the vocabulary.
    >>> vectorize_layer.adapt(["foo bar", "bar baz", "baz bada boom"])

    >>> # Now, the layer can map strings to integers -- you can use an
    >>> # embedding layer to map these integers to learned embeddings.
    >>> input_data = [["foo qux bar"], ["qux baz"]]
    >>> vectorize_layer(input_data)
    array([[4, 1, 3, 0],
           [1, 2, 0, 0]])

    This example instantiates a `TextVectorization` layer by passing a list
    of vocabulary terms to the layer's `__init__()` method.

    >>> vocab_data = ["earth", "wind", "and", "fire"]
    >>> max_len = 4  # Sequence length to pad the outputs to.
    >>> # Create the layer, passing the vocab directly. You can also pass the
    >>> # vocabulary arg a path to a file containing one vocabulary word per
    >>> # line.
    >>> vectorize_layer = keras.layers.TextVectorization(
    ...     max_tokens=max_tokens,
    ...     output_mode='int',
    ...     output_sequence_length=max_len,
    ...     vocabulary=vocab_data)

    >>> # Because we've passed the vocabulary directly, we don't need to adapt
    >>> # the layer - the vocabulary is already set. The vocabulary contains the
    >>> # padding token ('') and OOV token ('[UNK]')
    >>> # as well as the passed tokens.
    >>> vectorize_layer.get_vocabulary()
    ['', '[UNK]', 'earth', 'wind', 'and', 'fire']
    )-"


# keras_core.src.layers.preprocessing.text_vectorization.TextVectorization
#' A preprocessing layer which maps text features to integer sequences.
#'
#' @description
#' This layer has basic options for managing text in a Keras model. It
#' transforms a batch of strings (one example = one string) into either a list
#' of token indices (one example = 1D tensor of integer token indices) or a
#' dense representation (one example = 1D tensor of float values representing
#' data about the example's tokens). This layer is meant to handle natural
#' language inputs. To handle simple string inputs (categorical strings or
#' pre-tokenized strings) see `kers_core.layers.StringLookup`.
#'
#' The vocabulary for the layer must be either supplied on construction or
#' learned via `adapt()`. When this layer is adapted, it will analyze the
#' dataset, determine the frequency of individual string values, and create a
#' vocabulary from them. This vocabulary can have unlimited size or be capped,
#' depending on the configuration options for this layer; if there are more
#' unique values in the input than the maximum vocabulary size, the most
#' frequent terms will be used to create the vocabulary.
#'
#' The processing of each example contains the following steps:
#'
#' 1. Standardize each example (usually lowercasing + punctuation stripping)
#' 2. Split each example into substrings (usually words)
#' 3. Recombine substrings into tokens (usually ngrams)
#' 4. Index tokens (associate a unique int value with each token)
#' 5. Transform each example using this index, either into a vector of ints or
#'    a dense float vector.
#'
#' Some notes on passing callables to customize splitting and normalization for
#' this layer:
#'
#' 1. Any callable can be passed to this Layer, but if you want to serialize
#'    this object you should only pass functions that are registered Keras
#'    serializables (see `keras.saving.register_keras_serializable`
#'    for more details).
#' 2. When using a custom callable for `standardize`, the data received
#'    by the callable will be exactly as passed to this layer. The callable
#'    should return a tensor of the same shape as the input.
#' 3. When using a custom callable for `split`, the data received by the
#'    callable will have the 1st dimension squeezed out - instead of
#'    `[["string to split"], ["another string to split"]]`, the Callable will
#'    see `["string to split", "another string to split"]`.
#'    The callable should return a `tf.Tensor` of dtype `string`
#'    with the first dimension containing the split tokens -
#'    in this example, we should see something like `[["string", "to",
#'    "split"], ["another", "string", "to", "split"]]`.
#'
#' **Note:** This layer uses TensorFlow internally. It cannot
#' be used as part of the compiled computation graph of a model with
#' any backend other than TensorFlow.
#' It can however be used with any backend when running eagerly.
#' It can also always be used as part of an input preprocessing pipeline
#' with any backend (outside the model itself), which is how we recommend
#' to use this layer.
#'
#' **Note:** This layer is safe to use inside a `tf.data` pipeline
#' (independently of which backend you're using).
#'
#' # Examples
#' This example instantiates a `TextVectorization` layer that lowercases text,
#' splits on whitespace, strips punctuation, and outputs integer vocab indices.
#'
#' ```python
#' max_tokens = 5000  # Maximum vocab size.
#' max_len = 4  # Sequence length to pad the outputs to.
#' # Create the layer.
#' vectorize_layer = TextVectorization(
#'     max_tokens=max_tokens,
#'     output_mode='int',
#'     output_sequence_length=max_len)
#' ```
#'
#' ```python
#' # Now that the vocab layer has been created, call `adapt` on the
#' # list of strings to create the vocabulary.
#' vectorize_layer.adapt(["foo bar", "bar baz", "baz bada boom"])
#' ```
#'
#' ```python
#' # Now, the layer can map strings to integers -- you can use an
#' # embedding layer to map these integers to learned embeddings.
#' input_data = [["foo qux bar"], ["qux baz"]]
#' vectorize_layer(input_data)
#' # array([[4, 1, 3, 0],
#' #        [1, 2, 0, 0]])
#' ```
#'
#' This example instantiates a `TextVectorization` layer by passing a list
#' of vocabulary terms to the layer's `__init__()` method.
#'
#' ```python
#' vocab_data = ["earth", "wind", "and", "fire"]
#' max_len = 4  # Sequence length to pad the outputs to.
#' # Create the layer, passing the vocab directly. You can also pass the
#' # vocabulary arg a path to a file containing one vocabulary word per
#' # line.
#' vectorize_layer = keras.layers.TextVectorization(
#'     max_tokens=max_tokens,
#'     output_mode='int',
#'     output_sequence_length=max_len,
#'     vocabulary=vocab_data)
#' ```
#'
#' ```python
#' # Because we've passed the vocabulary directly, we don't need to adapt
#' # the layer - the vocabulary is already set. The vocabulary contains the
#' # padding token ('') and OOV token ('[UNK]')
#' # as well as the passed tokens.
#' vectorize_layer.get_vocabulary()
#' # ['', '[UNK]', 'earth', 'wind', 'and', 'fire']
#' ```
#'
#' @param max_tokens Maximum size of the vocabulary for this layer. This should
#'     only be specified when adapting a vocabulary or when setting
#'     `pad_to_max_tokens=True`. Note that this vocabulary
#'     contains 1 OOV token, so the effective number of tokens is
#'     `(max_tokens - 1 - (1 if output_mode == "int" else 0))`.
#' @param standardize Optional specification for standardization to apply to the
#'     input text. Values can be:
#'     - `None`: No standardization.
#'     - `"lower_and_strip_punctuation"`: Text will be lowercased and all
#'         punctuation removed.
#'     - `"lower"`: Text will be lowercased.
#'     - `"strip_punctuation"`: All punctuation will be removed.
#'     - Callable: Inputs will passed to the callable function,
#'         which should be standardized and returned.
#' @param split Optional specification for splitting the input text.
#'     Values can be:
#'     - `None`: No splitting.
#'     - `"whitespace"`: Split on whitespace.
#'     - `"character"`: Split on each unicode character.
#'     - Callable: Standardized inputs will passed to the callable
#'         function, which should be split and returned.
#' @param ngrams Optional specification for ngrams to create from the
#'     possibly-split input text. Values can be `None`, an integer
#'     or tuple of integers; passing an integer will create ngrams
#'     up to that integer, and passing a tuple of integers will
#'     create ngrams for the specified values in the tuple.
#'     Passing `None` means that no ngrams will be created.
#' @param output_mode Optional specification for the output of the layer.
#'     Values can be `"int"`, `"multi_hot"`, `"count"` or `"tf_idf"`,
#'     configuring the layer as follows:
#'     - `"int"`: Outputs integer indices, one integer index per split
#'         string token. When `output_mode == "int"`,
#'         0 is reserved for masked locations;
#'         this reduces the vocab size to `max_tokens - 2`
#'         instead of `max_tokens - 1`.
#'     - `"multi_hot"`: Outputs a single int array per batch, of either
#'         vocab_size or max_tokens size, containing 1s in all elements
#'         where the token mapped to that index exists at least
#'         once in the batch item.
#'     - `"count"`: Like `"multi_hot"`, but the int array contains
#'         a count of the number of times the token at that index
#'         appeared in the batch item.
#'     - `"tf_idf"`: Like `"multi_hot"`, but the TF-IDF algorithm
#'         is applied to find the value in each token slot.
#'     For `"int"` output, any shape of input and output is supported.
#'     For all other output modes, currently only rank 1 inputs
#'     (and rank 2 outputs after splitting) are supported.
#' @param output_sequence_length Only valid in INT mode. If set, the output will
#'     have its time dimension padded or truncated to exactly
#'     `output_sequence_length` values, resulting in a tensor of shape
#'     `(batch_size, output_sequence_length)` regardless of how many tokens
#'     resulted from the splitting step. Defaults to `None`.
#' @param pad_to_max_tokens Only valid in  `"multi_hot"`, `"count"`,
#'     and `"tf_idf"` modes. If `True`, the output will have
#'     its feature axis padded to `max_tokens` even if the number
#'     of unique tokens in the vocabulary is less than `max_tokens`,
#'     resulting in a tensor of shape `(batch_size, max_tokens)`
#'     regardless of vocabulary size. Defaults to `False`.
#' @param vocabulary Optional. Either an array of strings or a string path to a
#'     text file. If passing an array, can pass a tuple, list,
#'     1D NumPy array, or 1D tensor containing the string vocabulary terms.
#'     If passing a file path, the file should contain one line per term
#'     in the vocabulary. If this argument is set,
#'     there is no need to `adapt()` the layer.
#' @param idf_weights Only valid when `output_mode` is `"tf_idf"`. A tuple, list,
#'     1D NumPy array, or 1D tensor of the same length as the vocabulary,
#'     containing the floating point inverse document frequency weights,
#'     which will be multiplied by per sample term counts for
#'     the final `tf_idf` weight. If the `vocabulary` argument is set,
#'     and `output_mode` is `"tf_idf"`, this argument must be supplied.
#' @param ragged Boolean. Only applicable to `"int"` output mode.
#'     Only supported with TensorFlow backend.
#'     If `True`, returns a `RaggedTensor` instead of a dense `Tensor`,
#'     where each sequence may have a different length
#'     after string splitting. Defaults to `False`.
#' @param sparse Boolean. Only applicable to `"multi_hot"`, `"count"`, and
#'     `"tf_idf"` output modes. Only supported with TensorFlow
#'     backend. If `True`, returns a `SparseTensor`
#'     instead of a dense `Tensor`. Defaults to `False`.
#' @param encoding Optional. The text encoding to use to interpret the input
#'     strings. Defaults to `"utf-8"`.
#' @param object Object to compose the layer with. A tensor, array, or sequential model.
#' @param ... Passed on to the Python callable
#' @param name name for the layer
#'
#' @export
#' @family preprocessing layers
#' @seealso
#' + <https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization>
layer_text_vectorization <-
function (object, max_tokens = NULL, standardize = "lower_and_strip_punctuation",
    split = "whitespace", ngrams = NULL, output_mode = "int",
    output_sequence_length = NULL, pad_to_max_tokens = FALSE,
    vocabulary = NULL, idf_weights = NULL, sparse = FALSE, ragged = FALSE,
    encoding = "utf-8", name = NULL, ...)
{
    args <- capture_args2(list(max_tokens = as_integer, ngrams = function (x)
    if (length(x) > 1)
        as_integer_tuple(x)
    else as_integer(x), output_mode = as_integer, output_sequence_length = as_integer,
        ragged = as_integer, input_shape = normalize_shape, batch_size = as_integer,
        batch_input_shape = normalize_shape), ignore = "object")
    create_layer(keras$layers$TextVectorization, object, args)
}
