

#' Input layer
#' 
#' Layer to be used as an entry point into a graph.
#' 
#' @param shape Shapes, not including the batch size. For instance, 
#'   `shape=c(32)` indicates that the expected input will be batches of 
#'   32-dimensional vectors.
#' @param batch_shape Shapes, including the batch size. For instance, 
#'   `batch_shape= c(10, 32)` indicates that the expected input will be batches 
#'   of 10 32-dimensional vectors. batch_shape=c(NULL, 32)` indicates batches of
#'   an arbitrary number of 32-dimensional vectors.
#' @param name An optional name string for the layer. Should be unique in a 
#'   model (do not reuse the same name twice). It will be autogenerated if it 
#'   isn't provided.
#' @param dtype  The data type expected by the input, as a string (`float32`,
#'   `float64`, `int32`...)
#' @param sparse Boolean, whether the placeholder created is meant to be sparse.
#'   
#' @details It can either wrap an existing tensor (pass an `input_tensor` 
#'   argument) or create its a placeholder tensor (pass arguments `input_shape` 
#'   or `batch_input_shape` as well as `input_dtype`).
#'   
#' @export
layer_input <- function(shape = NULL, batch_shape = NULL, name = NULL,
                        dtype = "float32", sparse = FALSE) {
  keras$layers$Input(
    shape = normalize_shape(shape),
    batch_shape = normalize_shape(batch_shape),
    name = name,
    dtype = dtype,
    sparse = sparse
  )
}

#' Add a densely-connected NN layer to an output
#' 
#' @param x Model or layer
#' @param output_dim Output dimension
#' @param init Name of initialization function for the weights of the layer or 
#'   alternatively, function to use for weights initialization. This parameter 
#'   is only relevant if you don't pass a `weights` argument.
#' @param activation Name of activation function to use, or alternatively, 
#'   elementwise function. If you don't specify anything, no activation is 
#'   applied (ie. "linear" activation: a(x) = x).
#' @param weights List of vectors, matrixes, or arrays to set as initial 
#'   weights. The list should have 2 elements, of shape `(input_dim, 
#'   output_dim)` and (output_dim,) for weights and biases respectively.
#' @param W_regularizer Weight regularizer applied to the main weights matrix.
#' @param b_regularizer Weight regularizer applied to the bias.
#' @param activity_regularizer Activity regularizer applied to the network
#'   output.
#' @param W_constraint Constraint applied to the main weights matrix.
#' @param b_constraint Constraint applied to the bias.
#' @param bias Whether to include a bias (i.e. make the layer affine rather than
#'   linear).
#' @param input_dim Dimensionality of the input (integer). This argument (or
#'   alternatively, the keyword argument `input_shape`) is required when using
#'   this layer as the first layer in a model.
#'   
#'   
#' @section Input and Output Shapes:
#'   
#'   Input shape: nD tensor with shape: `(nb_samples, ..., input_dim)`. The most
#'   common situation would be a 2D input with shape `(nb_samples, input_dim)`.
#'   
#'   Output shape: nD tensor with shape: `(nb_samples, ..., output_dim)`. For 
#'   instance, for a 2D input with shape `(nb_samples, input_dim)`, the output 
#'   would have shape `(nb_samples, output_dim)`.
#'   
#' @export
layer_dense <- function(x, output_dim, init = 'glorot_uniform', activation = NULL, weights = NULL, 
                           W_regularizer = NULL, b_regularizer = NULL, activity_regularizer = NULL, 
                           W_constraint = NULL, b_constraint = NULL, bias = TRUE, input_dim = NULL) {
  layer <- keras$layers$Dense(
    output_dim = as.integer(output_dim),
    init = init,
    activation = activation,
    weights = weights,
    W_regularizer = W_regularizer,
    b_regularizer = b_regularizer,
    activity_regularizer = activity_regularizer,
    W_constraint = W_constraint,
    b_constraint = b_constraint, 
    bias = bias,
    input_dim = as.integer(input_dim)
  )
  compose_layer(x, layer)
}

#' Apply an activation function to an output.
#' 
#' @inheritParams layer_dense
#'   
#' @param ... Additional keyword arguments to generic to all layers, including
#'   `input_shape` (list of integers, does not include the samples axis) which
#'   is required when using this layer as the first layer in a model.
#'   
#' @export
layer_activation <- function(x, activation, ...) {
  layer <- keras$layers$Activation(
    activation = activation,
    ...
  )
  compose_layer(x, layer)
}



# Helper function to compose a layer with an object of type Model or Layer
compose_layer <- function(x, layer) {
  
  # if a sequential is passed then add it to the model
  if (inherits(x, "keras.models.Sequential")) {
    
    x <- clone_model_if_possible(x)
    x$add(layer)
    x
    
  # if a layer is passed then wrap the layer
  } else if (inherits(x, "tensorflow.python.framework.ops.Tensor") ||
             inherits(x, "keras.engine.topology.Layer")) {
    
    py_call(layer, x)
    
  # otherwie it's an unexpected type
  } else {
    
    stop("Invalid input to layer function (must be a model or a tensor)",
         call. = FALSE)
  }
}


normalize_shape <- function(shape) {
  if (is.null(shape))
    shape
  else {
    if (is.list(shape) || is.numeric(shape))
      shape <- as.integer(shape)
    tuple(shape)
  }
}


