

#' Input layer
#' 
#' Layer to be used as an entry point into a graph.
#' 
#' @param shape Shape, not including the batch size. For instance, 
#'   `shape=shape(32)` indicates that the expected input will be batches
#'   of 32-dimensional vectors.
#' @param batch_shape Shapes, including the batch size. For instance, 
#'   `batch_shape=shape(10, 32)` indicates that the expected input will be
#'   batches of 10 32-dimensional vectors. `batch_shape=shape(NULL, 32)`
#'   indicates batches of an arbitrary number of 32-dimensional vectors.
#' @param name An optional name string for the layer. Should be unique in a 
#'   model (do not reuse the same name twice). It will be autogenerated if it 
#'   isn't provided.
#' @param dtype  The data type expected by the input, as a string (`float32`, 
#'   `float64`, `int32`...)
#' @param sparse Boolean, whether the placeholder created is meant to be sparse.
#' @param tensor Existing tensor to wrap into the `Input` layer. If set, the
#'   layer will not create a placeholder tensor.
#'   
#' @details It can either wrap an existing tensor (pass an `input_tensor` 
#'   argument) or create its a placeholder tensor (pass arguments `input_shape` 
#'   or `batch_input_shape` as well as `input_dtype`).
#'   
#' @return A tensor   
#'   
#' @export
layer_input <- function(shape = NULL, batch_shape = NULL, name = NULL,
                        dtype = NULL, sparse = FALSE, tensor = NULL) {
  keras$layers$Input(
    shape = shape(shape),
    batch_shape = shape(batch_shape),
    name = name,
    dtype = keras$backend$floatx(),
    sparse = sparse,
    tensor = tensor
  )
}

#' Add a densely-connected NN layer to an output
#' 
#' @param x Model or layer
#' @param units Output dimension
#' @param kernel_initializer Name of initialization function for the weights of the layer or 
#'   alternatively, function to use for weights initialization. This parameter 
#'   is only relevant if you don't pass a `weights` argument.
#' @param activation Name of activation function to use, or alternatively, 
#'   elementwise function. If you don't specify anything, no activation is 
#'   applied (ie. "linear" activation: a(x) = x).
#' @param weights List of vectors, matrixes, or arrays to set as initial 
#'   weights. The list should have 2 elements, of shape `(input_dim, 
#'   output_dim)` and (output_dim,) for weights and biases respectively.
#' @param kernel_regularizer Weight regularizer applied to the main weights matrix.
#' @param bias_regularizer Weight regularizer applied to the bias.
#' @param activity_regularizer Activity regularizer applied to the network
#'   output.
#' @param kernel_constraint Constraint applied to the main weights matrix.
#' @param bias_constraint Constraint applied to the bias.
#' @param use_bias Whether to include a bias (i.e. make the layer affine rather than
#'   linear).
#' @param input_dim Dimensionality of the input (integer). This argument (or
#'   alternatively, the keyword argument `input_shape`) is required when using
#'   this layer as the first layer in a model.
#'   
#'   
#' @section Input and Output Shapes:
#'   
#'   Input shape: nD tensor with shape: `(nb_samples, ..., input_dim)`. The most
#'   common situation would be a 2D input with shape `(nb_samples, input_dim)`.
#'   
#'   Output shape: nD tensor with shape: `(nb_samples, ..., output_dim)`. For 
#'   instance, for a 2D input with shape `(nb_samples, input_dim)`, the output 
#'   would have shape `(nb_samples, output_dim)`.
#'   
#' @export
layer_dense <- function(x, units, kernel_initializer = 'glorot_uniform', activation = NULL, weights = NULL, 
                           kernel_regularizer = NULL, bias_regularizer = NULL, activity_regularizer = NULL, 
                           kernel_constraint = NULL, bias_constraint = NULL, use_bias = TRUE, input_dim = NULL) {
  layer <- keras$layers$Dense(
    units = as.integer(units),
    kernel_initializer = kernel_initializer,
    activation = activation,
    weights = weights,
    kernel_regularizer = kernel_regularizer,
    bias_regularizer = bias_regularizer,
    activity_regularizer = activity_regularizer,
    kernel_constraint = kernel_constraint,
    bias_constraint = bias_constraint, 
    use_bias = use_bias,
    input_dim = as.integer(input_dim)
  )
  compose_layer(x, layer)
}

#' Apply an activation function to an output.
#' 
#' @inheritParams layer_dense
#'   
#' @param input_shape Input shape (list of integers, does not include the
#'   samples axis) which is required when using this layer as the first layer in
#'   a model.
#'   
#' @export
layer_activation <- function(x, activation, input_shape = NULL) {
  
  # build args
  args <- list(activation = activation)
  if (!is.null(input_shape))
    args$input_shape <- as.integer(input_shape)
  
  # call function
  layer <- do.call(keras$layers$Activation, args)
  
  # compose
  compose_layer(x, layer)
}

#' Reshapes an output to a certain shape.
#' 
#' @inheritParams layer_activation
#'   
#' @param target_shape List of integers, does not include the
#'   samples dimension (batch size).
#'   
#' @note The output shape will be `(batch_size,) + target_shape`.  
#'   
#' @export
layer_reshape <- function(x, target_shape, input_shape = NULL) {
  
  # build args
  args <- list(target_shape = as.integer(target_shape))
  if (!is.null(input_shape))
    args$input_shape <- as.integer(input_shape)
  
  # call function
  layer <- do.call(keras$layers$Reshape, args)
  
  # compose
  compose_layer(x, layer)
}


#' Permute the dimensions of an input according to a given pattern
#' 
#' @param dims List of integers. Permutation pattern, does not include the 
#'   samples dimension. Indexing starts at 1. For instance, `(2, 1)` permutes
#'   the first and second dimension of the input.
#'   
#' @inheritParams layer_activation
#'   
#' @note Useful for e.g. connecting RNNs and convnets together.
#'   
#' @export
layer_permute <- function(x, dims, input_shape = NULL) {
  
  # build args
  args <- list(dims = list(as.integer(dims)))
  if (!is.null(input_shape))
    args$input_shape <- as.integer(input_shape)
  
  # call function
  layer <- do.call(keras$layers$Permute, args)
  
  # compose
  compose_layer(x, layer)
}


#' Flattens an input
#' 
#' Flatten a given input, does not affect the batch size.
#' 
#' @inheritParams layer_activation
#' 
#' @export
layer_flatten <- function(x, input_shape = NULL) {
  
  # build args
  args <- list()
  if (!is.null(input_shape))
    args$input_shape <- as.integer(input_shape)
  
  # call function
  layer <- do.call(keras$layers$Flatten, args)
  
  # compose
  compose_layer(x, layer)
}




# Helper function to compose a layer with an object of type Model or Layer
compose_layer <- function(x, layer) {
  
  # if a sequential is passed then add it to the model
  if (inherits(x, "tensorflow.contrib.keras.python.keras.models.Sequential")) {
    
    x <- clone_model_if_possible(x)
    x$add(layer)
    x
    
  # if a layer is passed then wrap the layer
  } else if (inherits(x, "tensorflow.python.framework.ops.Tensor") ||
             inherits(x, "tensorflow.contrib.keras.python.keras.engine.topology.Layer")) {
    
    py_call(layer, x)
    
  # otherwie it's an unexpected type
  } else {
    
    stop("Invalid input to layer function (must be a model or a tensor)",
         call. = FALSE)
  }
}



