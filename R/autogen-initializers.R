## Autogenerated. Do not modify manually.


# keras$initializers$constant
# keras.initializers.constant
# keras_core.src.initializers.constant_initializers.Constant
r"-(Initializer that generates tensors with constant values.

    Only scalar values are allowed.
    The constant value provided must be convertible to the dtype requested
    when calling the initializer.

    Examples:

    >>> # Standalone usage:
    >>> initializer = Constant(10.)
    >>> values = initializer(shape=(2, 2))

    >>> # Usage in a Keras layer:
    >>> initializer = Constant(10.)
    >>> layer = Dense(3, kernel_initializer=initializer)

    Args:
        value: A Python scalar.
    )-"


# keras_core.src.initializers.constant_initializers.Constant
#' Initializer that generates tensors with constant values.
#'
#' @description
#' Only scalar values are allowed.
#' The constant value provided must be convertible to the dtype requested
#' when calling the initializer.
#'
#' # Examples
#' ```python
#' # Standalone usage:
#' initializer = Constant(10.)
#' values = initializer(shape=(2, 2))
#' ```
#'
#' ```python
#' # Usage in a Keras layer:
#' initializer = Constant(10.)
#' layer = Dense(3, kernel_initializer=initializer)
#' ```
#'
#' @param value A Python scalar.
#'
#' @export
#' @family initializer
#' @seealso
#' + <https://www.tensorflow.org/api_docs/python/tf/keras/initializers/constant>
initializer_constant <-
function (value = 0)
{
    args <- capture_args2(NULL)
    do.call(keras$initializers$constant, args)
}


# keras$initializers$identity
# keras.initializers.identity
# keras_core.src.initializers.constant_initializers.Identity
r"-(Initializer that generates the identity matrix.

    Only usable for generating 2D matrices.

    Examples:

    >>> # Standalone usage:
    >>> initializer = Identity()
    >>> values = initializer(shape=(2, 2))

    >>> # Usage in a Keras layer:
    >>> initializer = Identity()
    >>> layer = Dense(3, kernel_initializer=initializer)

    Args:
        gain: Multiplicative factor to apply to the identity matrix.
    )-"


# keras_core.src.initializers.constant_initializers.Identity
#' Initializer that generates the identity matrix.
#'
#' @description
#' Only usable for generating 2D matrices.
#'
#' # Examples
#' ```python
#' # Standalone usage:
#' initializer = Identity()
#' values = initializer(shape=(2, 2))
#' ```
#'
#' ```python
#' # Usage in a Keras layer:
#' initializer = Identity()
#' layer = Dense(3, kernel_initializer=initializer)
#' ```
#'
#' @param gain Multiplicative factor to apply to the identity matrix.
#'
#' @export
#' @family initializer
#' @seealso
#' + <https://www.tensorflow.org/api_docs/python/tf/keras/initializers/identity>
initializer_identity <-
function (gain = 1)
{
    args <- capture_args2(NULL)
    do.call(keras$initializers$identity, args)
}


# keras$initializers$ones
# keras.initializers.ones
# keras_core.src.initializers.constant_initializers.Ones
r"-(Initializer that generates tensors initialized to 1.

    Also available via the shortcut function `ones`.

    Examples:

    >>> # Standalone usage:
    >>> initializer = Ones()
    >>> values = initializer(shape=(2, 2))

    >>> # Usage in a Keras layer:
    >>> initializer = Ones()
    >>> layer = Dense(3, kernel_initializer=initializer)
    )-"


# keras_core.src.initializers.constant_initializers.Ones
#' Initializer that generates tensors initialized to 1.
#'
#' @description
#' Also available via the shortcut function `ones`.
#'
#' # Examples
#' ```python
#' # Standalone usage:
#' initializer = Ones()
#' values = initializer(shape=(2, 2))
#' ```
#'
#' ```python
#' # Usage in a Keras layer:
#' initializer = Ones()
#' layer = Dense(3, kernel_initializer=initializer)
#' ```
#'
#' @export
#' @family initializer
#' @seealso
#' + <https://www.tensorflow.org/api_docs/python/tf/keras/initializers/ones>
initializer_ones <-
function ()
{
    args <- capture_args2(NULL)
    do.call(keras$initializers$ones, args)
}


# keras$initializers$zeros
# keras.initializers.zeros
# keras_core.src.initializers.constant_initializers.Zeros
r"-(Initializer that generates tensors initialized to 0.

    Examples:

    >>> # Standalone usage:
    >>> initializer = Zeros()
    >>> values = initializer(shape=(2, 2))

    >>> # Usage in a Keras layer:
    >>> initializer = Zeros()
    >>> layer = Dense(units=3, kernel_initializer=initializer)
    )-"


# keras_core.src.initializers.constant_initializers.Zeros
#' Initializer that generates tensors initialized to 0.
#'
#' @description
#'
#' # Examples
#' ```python
#' # Standalone usage:
#' initializer = Zeros()
#' values = initializer(shape=(2, 2))
#' ```
#'
#' ```python
#' # Usage in a Keras layer:
#' initializer = Zeros()
#' layer = Dense(units=3, kernel_initializer=initializer)
#' ```
#'
#' @export
#' @family initializer
#' @seealso
#' + <https://www.tensorflow.org/api_docs/python/tf/keras/initializers/zeros>
initializer_zeros <-
function ()
{
    args <- capture_args2(NULL)
    do.call(keras$initializers$zeros, args)
}


# keras$initializers$GlorotNormal
# keras.initializers.GlorotNormal
# keras_core.src.initializers.random_initializers.GlorotNormal
r"-(The Glorot normal initializer, also called Xavier normal initializer.

    Draws samples from a truncated normal distribution centered on 0 with
    `stddev = sqrt(2 / (fan_in + fan_out))` where `fan_in` is the number of
    input units in the weight tensor and `fan_out` is the number of output units
    in the weight tensor.

    Examples:

    >>> # Standalone usage:
    >>> initializer = GlorotNormal()
    >>> values = initializer(shape=(2, 2))

    >>> # Usage in a Keras layer:
    >>> initializer = GlorotNormal()
    >>> layer = Dense(3, kernel_initializer=initializer)

    Args:
        seed: A Python integer or instance of
            `keras.backend.SeedGenerator`.
            Used to make the behavior of the initializer
            deterministic. Note that an initializer seeded with an integer
            or `None` (unseeded) will produce the same random values
            across multiple calls. To get different random values
            across multiple calls, use as seed an instance
            of `keras.backend.SeedGenerator`.

    Reference:

    - [Glorot et al., 2010](http://proceedings.mlr.press/v9/glorot10a.html)
    )-"


# keras_core.src.initializers.random_initializers.GlorotNormal
#' The Glorot normal initializer, also called Xavier normal initializer.
#'
#' @description
#' Draws samples from a truncated normal distribution centered on 0 with
#' `stddev = sqrt(2 / (fan_in + fan_out))` where `fan_in` is the number of
#' input units in the weight tensor and `fan_out` is the number of output units
#' in the weight tensor.
#'
#' # Examples
#' ```python
#' # Standalone usage:
#' initializer = GlorotNormal()
#' values = initializer(shape=(2, 2))
#' ```
#'
#' ```python
#' # Usage in a Keras layer:
#' initializer = GlorotNormal()
#' layer = Dense(3, kernel_initializer=initializer)
#' ```
#'
#' # Reference
#' - [Glorot et al., 2010](http://proceedings.mlr.press/v9/glorot10a.html)
#'
#' @param seed A Python integer or instance of
#' `keras.backend.SeedGenerator`.
#' Used to make the behavior of the initializer
#' deterministic. Note that an initializer seeded with an integer
#' or `None` (unseeded) will produce the same random values
#' across multiple calls. To get different random values
#' across multiple calls, use as seed an instance
#' of `keras.backend.SeedGenerator`.
#'
#' @export
#' @family initializer
#' @seealso
#' + <https://www.tensorflow.org/api_docs/python/tf/keras/initializers/GlorotNormal>
initializer_glorot_normal <-
function (seed = NULL)
{
    args <- capture_args2(list(seed = as_integer))
    do.call(keras$initializers$GlorotNormal, args)
}


# keras$initializers$GlorotUniform
# keras.initializers.GlorotUniform
# keras_core.src.initializers.random_initializers.GlorotUniform
r"-(The Glorot uniform initializer, also called Xavier uniform initializer.

    Draws samples from a uniform distribution within `[-limit, limit]`, where
    `limit = sqrt(6 / (fan_in + fan_out))` (`fan_in` is the number of input
    units in the weight tensor and `fan_out` is the number of output units).

    Examples:

    >>> # Standalone usage:
    >>> initializer = GlorotUniform()
    >>> values = initializer(shape=(2, 2))

    >>> # Usage in a Keras layer:
    >>> initializer = GlorotUniform()
    >>> layer = Dense(3, kernel_initializer=initializer)

    Args:
        seed: A Python integer or instance of
            `keras.backend.SeedGenerator`.
            Used to make the behavior of the initializer
            deterministic. Note that an initializer seeded with an integer
            or `None` (unseeded) will produce the same random values
            across multiple calls. To get different random values
            across multiple calls, use as seed an instance
            of `keras.backend.SeedGenerator`.

    Reference:

    - [Glorot et al., 2010](http://proceedings.mlr.press/v9/glorot10a.html)
    )-"


# keras_core.src.initializers.random_initializers.GlorotUniform
#' The Glorot uniform initializer, also called Xavier uniform initializer.
#'
#' @description
#' Draws samples from a uniform distribution within `[-limit, limit]`, where
#' `limit = sqrt(6 / (fan_in + fan_out))` (`fan_in` is the number of input
#' units in the weight tensor and `fan_out` is the number of output units).
#'
#' # Examples
#' ```python
#' # Standalone usage:
#' initializer = GlorotUniform()
#' values = initializer(shape=(2, 2))
#' ```
#'
#' ```python
#' # Usage in a Keras layer:
#' initializer = GlorotUniform()
#' layer = Dense(3, kernel_initializer=initializer)
#' ```
#'
#' # Reference
#' - [Glorot et al., 2010](http://proceedings.mlr.press/v9/glorot10a.html)
#'
#' @param seed A Python integer or instance of
#' `keras.backend.SeedGenerator`.
#' Used to make the behavior of the initializer
#' deterministic. Note that an initializer seeded with an integer
#' or `None` (unseeded) will produce the same random values
#' across multiple calls. To get different random values
#' across multiple calls, use as seed an instance
#' of `keras.backend.SeedGenerator`.
#'
#' @export
#' @family initializer
#' @seealso
#' + <https://www.tensorflow.org/api_docs/python/tf/keras/initializers/GlorotUniform>
initializer_glorot_uniform <-
function (seed = NULL)
{
    args <- capture_args2(list(seed = as_integer))
    do.call(keras$initializers$GlorotUniform, args)
}


# keras$initializers$HeNormal
# keras.initializers.HeNormal
# keras_core.src.initializers.random_initializers.HeNormal
r"-(He normal initializer.

    It draws samples from a truncated normal distribution centered on 0 with
    `stddev = sqrt(2 / fan_in)` where `fan_in` is the number of input units in
    the weight tensor.

    Examples:

    >>> # Standalone usage:
    >>> initializer = HeNormal()
    >>> values = initializer(shape=(2, 2))

    >>> # Usage in a Keras layer:
    >>> initializer = HeNormal()
    >>> layer = Dense(3, kernel_initializer=initializer)

    Args:
        seed: A Python integer or instance of
            `keras.backend.SeedGenerator`.
            Used to make the behavior of the initializer
            deterministic. Note that an initializer seeded with an integer
            or `None` (unseeded) will produce the same random values
            across multiple calls. To get different random values
            across multiple calls, use as seed an instance
            of `keras.backend.SeedGenerator`.

    Reference:

    - [He et al., 2015](https://arxiv.org/abs/1502.01852)
    )-"


# keras_core.src.initializers.random_initializers.HeNormal
#' He normal initializer.
#'
#' @description
#' It draws samples from a truncated normal distribution centered on 0 with
#' `stddev = sqrt(2 / fan_in)` where `fan_in` is the number of input units in
#' the weight tensor.
#'
#' # Examples
#' ```python
#' # Standalone usage:
#' initializer = HeNormal()
#' values = initializer(shape=(2, 2))
#' ```
#'
#' ```python
#' # Usage in a Keras layer:
#' initializer = HeNormal()
#' layer = Dense(3, kernel_initializer=initializer)
#' ```
#'
#' # Reference
#' - [He et al., 2015](https://arxiv.org/abs/1502.01852)
#'
#' @param seed A Python integer or instance of
#' `keras.backend.SeedGenerator`.
#' Used to make the behavior of the initializer
#' deterministic. Note that an initializer seeded with an integer
#' or `None` (unseeded) will produce the same random values
#' across multiple calls. To get different random values
#' across multiple calls, use as seed an instance
#' of `keras.backend.SeedGenerator`.
#'
#' @export
#' @family initializer
#' @seealso
#' + <https://www.tensorflow.org/api_docs/python/tf/keras/initializers/HeNormal>
initializer_he_normal <-
function (seed = NULL)
{
    args <- capture_args2(list(seed = as_integer))
    do.call(keras$initializers$HeNormal, args)
}


# keras$initializers$HeUniform
# keras.initializers.HeUniform
# keras_core.src.initializers.random_initializers.HeUniform
r"-(He uniform variance scaling initializer.

    Draws samples from a uniform distribution within `[-limit, limit]`, where
    `limit = sqrt(6 / fan_in)` (`fan_in` is the number of input units in the
    weight tensor).

    Examples:

    >>> # Standalone usage:
    >>> initializer = HeUniform()
    >>> values = initializer(shape=(2, 2))

    >>> # Usage in a Keras layer:
    >>> initializer = HeUniform()
    >>> layer = Dense(3, kernel_initializer=initializer)

    Args:
        seed: A Python integer or instance of
            `keras.backend.SeedGenerator`.
            Used to make the behavior of the initializer
            deterministic. Note that an initializer seeded with an integer
            or `None` (unseeded) will produce the same random values
            across multiple calls. To get different random values
            across multiple calls, use as seed an instance
            of `keras.backend.SeedGenerator`.

    Reference:

    - [He et al., 2015](https://arxiv.org/abs/1502.01852)
    )-"


# keras_core.src.initializers.random_initializers.HeUniform
#' He uniform variance scaling initializer.
#'
#' @description
#' Draws samples from a uniform distribution within `[-limit, limit]`, where
#' `limit = sqrt(6 / fan_in)` (`fan_in` is the number of input units in the
#' weight tensor).
#'
#' # Examples
#' ```python
#' # Standalone usage:
#' initializer = HeUniform()
#' values = initializer(shape=(2, 2))
#' ```
#'
#' ```python
#' # Usage in a Keras layer:
#' initializer = HeUniform()
#' layer = Dense(3, kernel_initializer=initializer)
#' ```
#'
#' # Reference
#' - [He et al., 2015](https://arxiv.org/abs/1502.01852)
#'
#' @param seed A Python integer or instance of
#' `keras.backend.SeedGenerator`.
#' Used to make the behavior of the initializer
#' deterministic. Note that an initializer seeded with an integer
#' or `None` (unseeded) will produce the same random values
#' across multiple calls. To get different random values
#' across multiple calls, use as seed an instance
#' of `keras.backend.SeedGenerator`.
#'
#' @export
#' @family initializer
#' @seealso
#' + <https://www.tensorflow.org/api_docs/python/tf/keras/initializers/HeUniform>
initializer_he_uniform <-
function (seed = NULL)
{
    args <- capture_args2(list(seed = as_integer))
    do.call(keras$initializers$HeUniform, args)
}


# keras$initializers$LecunNormal
# keras.initializers.LecunNormal
# keras_core.src.initializers.random_initializers.LecunNormal
r"-(Lecun normal initializer.

    Initializers allow you to pre-specify an initialization strategy, encoded in
    the Initializer object, without knowing the shape and dtype of the variable
    being initialized.

    Draws samples from a truncated normal distribution centered on 0 with
    `stddev = sqrt(1 / fan_in)` where `fan_in` is the number of input units in
    the weight tensor.

    Examples:

    >>> # Standalone usage:
    >>> initializer = LecunNormal()
    >>> values = initializer(shape=(2, 2))

    >>> # Usage in a Keras layer:
    >>> initializer = LecunNormal()
    >>> layer = Dense(3, kernel_initializer=initializer)

    Args:
        seed: A Python integer or instance of
            `keras.backend.SeedGenerator`.
            Used to make the behavior of the initializer
            deterministic. Note that an initializer seeded with an integer
            or `None` (unseeded) will produce the same random values
            across multiple calls. To get different random values
            across multiple calls, use as seed an instance
            of `keras.backend.SeedGenerator`.

    Reference:

    - [Klambauer et al., 2017](https://arxiv.org/abs/1706.02515)
    )-"


# keras_core.src.initializers.random_initializers.LecunNormal
#' Lecun normal initializer.
#'
#' @description
#' Initializers allow you to pre-specify an initialization strategy, encoded in
#' the Initializer object, without knowing the shape and dtype of the variable
#' being initialized.
#'
#' Draws samples from a truncated normal distribution centered on 0 with
#' `stddev = sqrt(1 / fan_in)` where `fan_in` is the number of input units in
#' the weight tensor.
#'
#' # Examples
#' ```python
#' # Standalone usage:
#' initializer = LecunNormal()
#' values = initializer(shape=(2, 2))
#' ```
#'
#' ```python
#' # Usage in a Keras layer:
#' initializer = LecunNormal()
#' layer = Dense(3, kernel_initializer=initializer)
#' ```
#'
#' # Reference
#' - [Klambauer et al., 2017](https://arxiv.org/abs/1706.02515)
#'
#' @param seed A Python integer or instance of
#' `keras.backend.SeedGenerator`.
#' Used to make the behavior of the initializer
#' deterministic. Note that an initializer seeded with an integer
#' or `None` (unseeded) will produce the same random values
#' across multiple calls. To get different random values
#' across multiple calls, use as seed an instance
#' of `keras.backend.SeedGenerator`.
#'
#' @export
#' @family initializer
#' @seealso
#' + <https://www.tensorflow.org/api_docs/python/tf/keras/initializers/LecunNormal>
initializer_lecun_normal <-
function (seed = NULL)
{
    args <- capture_args2(list(seed = as_integer))
    do.call(keras$initializers$LecunNormal, args)
}


# keras$initializers$LecunUniform
# keras.initializers.LecunUniform
# keras_core.src.initializers.random_initializers.LecunUniform
r"-(Lecun uniform initializer.

    Draws samples from a uniform distribution within `[-limit, limit]`, where
    `limit = sqrt(3 / fan_in)` (`fan_in` is the number of input units in the
    weight tensor).

    Examples:

    >>> # Standalone usage:
    >>> initializer = LecunUniform()
    >>> values = initializer(shape=(2, 2))

    >>> # Usage in a Keras layer:
    >>> initializer = LecunUniform()
    >>> layer = Dense(3, kernel_initializer=initializer)

    Args:
        seed: A Python integer or instance of
            `keras.backend.SeedGenerator`.
            Used to make the behavior of the initializer
            deterministic. Note that an initializer seeded with an integer
            or `None` (unseeded) will produce the same random values
            across multiple calls. To get different random values
            across multiple calls, use as seed an instance
            of `keras.backend.SeedGenerator`.

    Reference:

    - [Klambauer et al., 2017](https://arxiv.org/abs/1706.02515)
    )-"


# keras_core.src.initializers.random_initializers.LecunUniform
#' Lecun uniform initializer.
#'
#' @description
#' Draws samples from a uniform distribution within `[-limit, limit]`, where
#' `limit = sqrt(3 / fan_in)` (`fan_in` is the number of input units in the
#' weight tensor).
#'
#' # Examples
#' ```python
#' # Standalone usage:
#' initializer = LecunUniform()
#' values = initializer(shape=(2, 2))
#' ```
#'
#' ```python
#' # Usage in a Keras layer:
#' initializer = LecunUniform()
#' layer = Dense(3, kernel_initializer=initializer)
#' ```
#'
#' # Reference
#' - [Klambauer et al., 2017](https://arxiv.org/abs/1706.02515)
#'
#' @param seed A Python integer or instance of
#' `keras.backend.SeedGenerator`.
#' Used to make the behavior of the initializer
#' deterministic. Note that an initializer seeded with an integer
#' or `None` (unseeded) will produce the same random values
#' across multiple calls. To get different random values
#' across multiple calls, use as seed an instance
#' of `keras.backend.SeedGenerator`.
#'
#' @export
#' @family initializer
#' @seealso
#' + <https://www.tensorflow.org/api_docs/python/tf/keras/initializers/LecunUniform>
initializer_lecun_uniform <-
function (seed = NULL)
{
    args <- capture_args2(list(seed = as_integer))
    do.call(keras$initializers$LecunUniform, args)
}


# keras$initializers$orthogonal
# keras.initializers.orthogonal
# keras_core.src.initializers.random_initializers.OrthogonalInitializer
r"-(Initializer that generates an orthogonal matrix.

    If the shape of the tensor to initialize is two-dimensional, it is
    initialized with an orthogonal matrix obtained from the QR decomposition of
    a matrix of random numbers drawn from a normal distribution. If the matrix
    has fewer rows than columns then the output will have orthogonal rows.
    Otherwise, the output will have orthogonal columns.

    If the shape of the tensor to initialize is more than two-dimensional,
    a matrix of shape `(shape[0] * ... * shape[n - 2], shape[n - 1])`
    is initialized, where `n` is the length of the shape vector.
    The matrix is subsequently reshaped to give a tensor of the desired shape.

    Examples:

    >>> # Standalone usage:
    >>> initializer = keras.initializers.Orthogonal()
    >>> values = initializer(shape=(2, 2))

    >>> # Usage in a Keras layer:
    >>> initializer = keras.initializers.Orthogonal()
    >>> layer = keras.layers.Dense(3, kernel_initializer=initializer)

    Args:
        gain: Multiplicative factor to apply to the orthogonal matrix.
        seed: A Python integer. Used to make the behavior of the initializer
            deterministic.

    Reference:

    - [Saxe et al., 2014](https://openreview.net/forum?id=_wzZwKpTDF_9C)
    )-"


# keras_core.src.initializers.random_initializers.OrthogonalInitializer
#' Initializer that generates an orthogonal matrix.
#'
#' @description
#' If the shape of the tensor to initialize is two-dimensional, it is
#' initialized with an orthogonal matrix obtained from the QR decomposition of
#' a matrix of random numbers drawn from a normal distribution. If the matrix
#' has fewer rows than columns then the output will have orthogonal rows.
#' Otherwise, the output will have orthogonal columns.
#'
#' If the shape of the tensor to initialize is more than two-dimensional,
#' a matrix of shape `(shape[0] * ... * shape[n - 2], shape[n - 1])`
#' is initialized, where `n` is the length of the shape vector.
#' The matrix is subsequently reshaped to give a tensor of the desired shape.
#'
#' # Examples
#' ```python
#' # Standalone usage:
#' initializer = keras.initializers.Orthogonal()
#' values = initializer(shape=(2, 2))
#' ```
#'
#' ```python
#' # Usage in a Keras layer:
#' initializer = keras.initializers.Orthogonal()
#' layer = keras.layers.Dense(3, kernel_initializer=initializer)
#' ```
#'
#' # Reference
#' - [Saxe et al., 2014](https://openreview.net/forum?id=_wzZwKpTDF_9C)
#'
#' @param gain Multiplicative factor to apply to the orthogonal matrix.
#' @param seed A Python integer. Used to make the behavior of the initializer
#'     deterministic.
#'
#' @export
#' @family initializer
#' @seealso
#' + <https://www.tensorflow.org/api_docs/python/tf/keras/initializers/orthogonal>
initializer_orthogonal <-
function (gain = 1, seed = NULL)
{
    args <- capture_args2(list(seed = as_integer))
    do.call(keras$initializers$orthogonal, args)
}


# keras$initializers$RandomNormal
# keras.initializers.RandomNormal
# keras_core.src.initializers.random_initializers.RandomNormal
r"-(Random normal initializer.

    Draws samples from a normal distribution for given parameters.

    Examples:

    >>> # Standalone usage:
    >>> initializer = RandomNormal(mean=0.0, stddev=1.0)
    >>> values = initializer(shape=(2, 2))

    >>> # Usage in a Keras layer:
    >>> initializer = RandomNormal(mean=0.0, stddev=1.0)
    >>> layer = Dense(3, kernel_initializer=initializer)

    Args:
        mean: A python scalar or a scalar keras tensor. Mean of the random
            values to generate.
        stddev: A python scalar or a scalar keras tensor. Standard deviation of
           the random values to generate.
        seed: A Python integer or instance of
            `keras.backend.SeedGenerator`.
            Used to make the behavior of the initializer
            deterministic. Note that an initializer seeded with an integer
            or `None` (unseeded) will produce the same random values
            across multiple calls. To get different random values
            across multiple calls, use as seed an instance
            of `keras.backend.SeedGenerator`.
    )-"


# keras_core.src.initializers.random_initializers.RandomNormal
#' Random normal initializer.
#'
#' @description
#' Draws samples from a normal distribution for given parameters.
#'
#' # Examples
#' ```python
#' # Standalone usage:
#' initializer = RandomNormal(mean=0.0, stddev=1.0)
#' values = initializer(shape=(2, 2))
#' ```
#'
#' ```python
#' # Usage in a Keras layer:
#' initializer = RandomNormal(mean=0.0, stddev=1.0)
#' layer = Dense(3, kernel_initializer=initializer)
#' ```
#'
#' @param mean A python scalar or a scalar keras tensor. Mean of the random
#'     values to generate.
#' @param stddev A python scalar or a scalar keras tensor. Standard deviation of
#'    the random values to generate.
#' @param seed A Python integer or instance of
#'     `keras.backend.SeedGenerator`.
#'     Used to make the behavior of the initializer
#'     deterministic. Note that an initializer seeded with an integer
#'     or `None` (unseeded) will produce the same random values
#'     across multiple calls. To get different random values
#'     across multiple calls, use as seed an instance
#'     of `keras.backend.SeedGenerator`.
#'
#' @export
#' @family initializer
#' @seealso
#' + <https://www.tensorflow.org/api_docs/python/tf/keras/initializers/RandomNormal>
initializer_random_normal <-
function (mean = 0, stddev = 0.05, seed = NULL)
{
    args <- capture_args2(list(seed = as_integer))
    do.call(keras$initializers$RandomNormal, args)
}


# keras$initializers$RandomUniform
# keras.initializers.RandomUniform
# keras_core.src.initializers.random_initializers.RandomUniform
r"-(Random uniform initializer.

    Draws samples from a uniform distribution for given parameters.

    Examples:

    >>> # Standalone usage:
    >>> initializer = RandomUniform(minval=0.0, maxval=1.0)
    >>> values = initializer(shape=(2, 2))

    >>> # Usage in a Keras layer:
    >>> initializer = RandomUniform(minval=0.0, maxval=1.0)
    >>> layer = Dense(3, kernel_initializer=initializer)

    Args:
        minval: A python scalar or a scalar keras tensor. Lower bound of the
            range of random values to generate (inclusive).
        maxval: A python scalar or a scalar keras tensor. Upper bound of the
            range of random values to generate (exclusive).
        seed: A Python integer or instance of
            `keras.backend.SeedGenerator`.
            Used to make the behavior of the initializer
            deterministic. Note that an initializer seeded with an integer
            or `None` (unseeded) will produce the same random values
            across multiple calls. To get different random values
            across multiple calls, use as seed an instance
            of `keras.backend.SeedGenerator`.
    )-"


# keras_core.src.initializers.random_initializers.RandomUniform
#' Random uniform initializer.
#'
#' @description
#' Draws samples from a uniform distribution for given parameters.
#'
#' # Examples
#' ```python
#' # Standalone usage:
#' initializer = RandomUniform(minval=0.0, maxval=1.0)
#' values = initializer(shape=(2, 2))
#' ```
#'
#' ```python
#' # Usage in a Keras layer:
#' initializer = RandomUniform(minval=0.0, maxval=1.0)
#' layer = Dense(3, kernel_initializer=initializer)
#' ```
#'
#' @param minval A python scalar or a scalar keras tensor. Lower bound of the
#'     range of random values to generate (inclusive).
#' @param maxval A python scalar or a scalar keras tensor. Upper bound of the
#'     range of random values to generate (exclusive).
#' @param seed A Python integer or instance of
#'     `keras.backend.SeedGenerator`.
#'     Used to make the behavior of the initializer
#'     deterministic. Note that an initializer seeded with an integer
#'     or `None` (unseeded) will produce the same random values
#'     across multiple calls. To get different random values
#'     across multiple calls, use as seed an instance
#'     of `keras.backend.SeedGenerator`.
#'
#' @export
#' @family initializer
#' @seealso
#' + <https://www.tensorflow.org/api_docs/python/tf/keras/initializers/RandomUniform>
initializer_random_uniform <-
function (minval = -0.05, maxval = 0.05, seed = NULL)
{
    args <- capture_args2(list(seed = as_integer))
    do.call(keras$initializers$RandomUniform, args)
}


# keras$initializers$TruncatedNormal
# keras.initializers.TruncatedNormal
# keras_core.src.initializers.random_initializers.TruncatedNormal
r"-(Initializer that generates a truncated normal distribution.

    The values generated are similar to values from a
    `RandomNormal` initializer, except that values more
    than two standard deviations from the mean are
    discarded and re-drawn.

    Examples:

    >>> # Standalone usage:
    >>> initializer = TruncatedNormal(mean=0., stddev=1.)
    >>> values = initializer(shape=(2, 2))

    >>> # Usage in a Keras layer:
    >>> initializer = TruncatedNormal(mean=0., stddev=1.)
    >>> layer = Dense(3, kernel_initializer=initializer)

    Args:
        mean: A python scalar or a scalar keras tensor. Mean of the random
            values to generate.
        stddev: A python scalar or a scalar keras tensor. Standard deviation of
           the random values to generate.
        seed: A Python integer or instance of
            `keras.backend.SeedGenerator`.
            Used to make the behavior of the initializer
            deterministic. Note that an initializer seeded with an integer
            or `None` (unseeded) will produce the same random values
            across multiple calls. To get different random values
            across multiple calls, use as seed an instance
            of `keras.backend.SeedGenerator`.
    )-"


# keras_core.src.initializers.random_initializers.TruncatedNormal
#' Initializer that generates a truncated normal distribution.
#'
#' @description
#' The values generated are similar to values from a
#' `RandomNormal` initializer, except that values more
#' than two standard deviations from the mean are
#' discarded and re-drawn.
#'
#' # Examples
#' ```python
#' # Standalone usage:
#' initializer = TruncatedNormal(mean=0., stddev=1.)
#' values = initializer(shape=(2, 2))
#' ```
#'
#' ```python
#' # Usage in a Keras layer:
#' initializer = TruncatedNormal(mean=0., stddev=1.)
#' layer = Dense(3, kernel_initializer=initializer)
#' ```
#'
#' @param mean A python scalar or a scalar keras tensor. Mean of the random
#'     values to generate.
#' @param stddev A python scalar or a scalar keras tensor. Standard deviation of
#'    the random values to generate.
#' @param seed A Python integer or instance of
#'     `keras.backend.SeedGenerator`.
#'     Used to make the behavior of the initializer
#'     deterministic. Note that an initializer seeded with an integer
#'     or `None` (unseeded) will produce the same random values
#'     across multiple calls. To get different random values
#'     across multiple calls, use as seed an instance
#'     of `keras.backend.SeedGenerator`.
#'
#' @export
#' @family initializer
#' @seealso
#' + <https://www.tensorflow.org/api_docs/python/tf/keras/initializers/TruncatedNormal>
initializer_truncated_normal <-
function (mean = 0, stddev = 0.05, seed = NULL)
{
    args <- capture_args2(list(seed = as_integer))
    do.call(keras$initializers$TruncatedNormal, args)
}


# keras$initializers$VarianceScaling
# keras.initializers.VarianceScaling
# keras_core.src.initializers.random_initializers.VarianceScaling
r"-(Initializer that adapts its scale to the shape of its input tensors.

    With `distribution="truncated_normal" or "untruncated_normal"`, samples are
    drawn from a truncated/untruncated normal distribution with a mean of zero
    and a standard deviation (after truncation, if used) `stddev = sqrt(scale /
    n)`, where `n` is:

    - number of input units in the weight tensor, if `mode="fan_in"`
    - number of output units, if `mode="fan_out"`
    - average of the numbers of input and output units, if `mode="fan_avg"`

    With `distribution="uniform"`, samples are drawn from a uniform distribution
    within `[-limit, limit]`, where `limit = sqrt(3 * scale / n)`.

    Examples:

    >>> # Standalone usage:
    >>> initializer = VarianceScaling(
        scale=0.1, mode='fan_in', distribution='uniform')
    >>> values = initializer(shape=(2, 2))

    >>> # Usage in a Keras layer:
    >>> initializer = VarianceScaling(
        scale=0.1, mode='fan_in', distribution='uniform')
    >>> layer = Dense(3, kernel_initializer=initializer)

    Args:
        scale: Scaling factor (positive float).
        mode: One of `"fan_in"`, `"fan_out"`, `"fan_avg"`.
        distribution: Random distribution to use.
            One of `"truncated_normal"`, `"untruncated_normal"`, or `"uniform"`.
        seed: A Python integer or instance of
            `keras.backend.SeedGenerator`.
            Used to make the behavior of the initializer
            deterministic. Note that an initializer seeded with an integer
            or `None` (unseeded) will produce the same random values
            across multiple calls. To get different random values
            across multiple calls, use as seed an instance
            of `keras.backend.SeedGenerator`.
    )-"


# keras_core.src.initializers.random_initializers.VarianceScaling
#' Initializer that adapts its scale to the shape of its input tensors.
#'
#' @description
#' With `distribution="truncated_normal" or "untruncated_normal"`, samples are
#' drawn from a truncated/untruncated normal distribution with a mean of zero
#' and a standard deviation (after truncation, if used) `stddev = sqrt(scale /
#' n)`, where `n` is:
#'
#' - number of input units in the weight tensor, if `mode="fan_in"`
#' - number of output units, if `mode="fan_out"`
#' - average of the numbers of input and output units, if `mode="fan_avg"`
#'
#' With `distribution="uniform"`, samples are drawn from a uniform distribution
#' within `[-limit, limit]`, where `limit = sqrt(3 * scale / n)`.
#'
#' # Examples
#' ```python
#' # Standalone usage:
#' initializer = VarianceScaling(
#' #     scale=0.1, mode='fan_in', distribution='uniform')
#' values = initializer(shape=(2, 2))
#' ```
#'
#' ```python
#' # Usage in a Keras layer:
#' initializer = VarianceScaling(
#' #     scale=0.1, mode='fan_in', distribution='uniform')
#' layer = Dense(3, kernel_initializer=initializer)
#' ```
#'
#' @param scale Scaling factor (positive float).
#' @param mode One of `"fan_in"`, `"fan_out"`, `"fan_avg"`.
#' @param distribution Random distribution to use.
#'     One of `"truncated_normal"`, `"untruncated_normal"`, or `"uniform"`.
#' @param seed A Python integer or instance of
#'     `keras.backend.SeedGenerator`.
#'     Used to make the behavior of the initializer
#'     deterministic. Note that an initializer seeded with an integer
#'     or `None` (unseeded) will produce the same random values
#'     across multiple calls. To get different random values
#'     across multiple calls, use as seed an instance
#'     of `keras.backend.SeedGenerator`.
#'
#' @export
#' @family initializer
#' @seealso
#' + <https://www.tensorflow.org/api_docs/python/tf/keras/initializers/VarianceScaling>
initializer_variance_scaling <-
function (scale = 1, mode = "fan_in", distribution = "truncated_normal",
    seed = NULL)
{
    args <- capture_args2(list(seed = as_integer))
    do.call(keras$initializers$VarianceScaling, args)
}
