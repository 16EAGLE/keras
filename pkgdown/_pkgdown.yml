
destination: website

# template:
#   params:
#     bootswatch: cosmo

url: https://keras.posit.co

template:
  bootstrap: 5
  bslib:
    primary: "#bf281b"
    navbar-light-color: "white"
    navbar-light-brand-color: "white"
    navbar-light-brand-hover-color: "white"
    code_font: {google: {family: "Fira Mono", wght: "400;600;700"}}
    # https://fonts.google.com/?classification=Monospace&stylecount=5

navbar:
  title: "Keras for R"
  bg: primary
  type: inverse
  left:
    - text: "Getting Started"
      href: articles/getting_started.html

    # - text: "Getting Started"
    #   menu:
    #     - text: "Introduction to Keras for engineers"
    #       href: articles/intro_to_keras_for_engineers.html
    #     - text: "Tutorials"
    #     - text: "Getting Started"
    #       href: articles/getting_started.html
    #     - text: "Basic Classification"
    #       href: articles/tutorial_basic_classification.html
    #     - text: "Text Classification"
    #       href: articles/tutorial_basic_text_classification.html
    #     - text: "Basic Regression"
    #       href: articles/tutorial_basic_regression.html
    #     - text: "Overfitting and Underfitting"
    #       href: articles/tutorial_overfit_underfit.html
    #     - text: "Save and Restore Models"
    #       href: articles/tutorial_save_and_restore.html

    - text: "Guides"
      menu:
        - text: "Model definition"
        - text: "Functional API"
          href: articles/functional_api.html
        - text: "Sequential Model"
          href: articles/sequential_model.html
        - text: "Extending and customizing"
        - text: "Making new layers and models via subclassing"
          href: articles/making_new_layers_and_models_via_subclassing.html
        - text: "Training & evaluation with the built-in methods"
          href: articles/training_with_built_in_methods.html
        - text: "Writing a training loop from scratch in TensorFlow"
          href: articles/writing_a_custom_training_loop_in_tensorflow.html
        - text: "Writing Your Own Callbacks"
          href: articles/writing_your_own_callbacks.html
        - text: "Other topics"
        - text: "Transfer learning and fine tuning"
          href: articles/transfer_learning.html
        - text: "Distributed training with TensorFlow"
          href: articles/distributed_training_with_tensorflow.html

    - text: Examples
      href: articles/examples/index.html

    - text: "Reference"
      href: reference/index.html

    - text: "News"
      href: news/index.html

reference:
  - title: "Keras Models"

  - subtitle: "Create Models"
    contents:
      - keras_model_sequential
      - keras_model
      - clone_model

  - subtitle: "Train Models"
    contents:
      - compile.keras.src.models.model.Model
      - fit.keras.src.models.model.Model
      - predict.keras.src.models.model.Model
      - evaluate.keras.src.models.model.Model
      - train_on_batch
      - predict_on_batch
      - test_on_batch
      - freeze_weights

  - subtitle: "Inspect Models"
    contents:
      - summary.keras.src.models.model.Model
      - get_config
      - get_weights
      - get_layer
      - pop_layer

  - subtitle: "Save & Load Models"
    contents:
      - save_model
      - export_savedmodel.keras.src.models.model.Model
      - save_model_weights
      - save_model_config
      - load_model_weights
      - has_concept("saving")


  - title: "Layers"

  - subtitle: "Core Layers"
    contents:
      - has_concept("core layers")

  - subtitle: "Reshaping Layers"
    contents:
      - has_concept("reshaping layers")
      # - has_concept("zero reshaping layers") # layer_zero_padding_2d
      # - has_concept("up reshaping layers")  # upsampling

  - subtitle: "Convolutional Layers"
    contents:
      - has_concept("convolutional layers")

  - subtitle: "Pooling Layers"
    contents:
      - has_concept("pooling layers")
      # - has_concept("average pooling layers")
      # - has_concept("average global pooling layers")
      # - has_concept("global pooling layers")
      # - has_concept("max pooling layers")
      # - has_concept("max global pooling layers")


  - subtitle: "Activation Layers"
    contents:
      - has_concept("activation layers")
      # - starts_with("layer_activation")

  - subtitle: "Recurrent Layers"
    contents:
      - has_concept("rnn layers")
      # - has_concept("conv rnn layers")
      # - has_concept("recurrent layers")

  - subtitle: "preprocessing Layers"
    contents:
      - has_concept("preprocessing layers")
      # - has_concept("random preprocessing layers")

  - subtitle: "Attention Layers"
    contents:
      - has_concept("attention layers")

  - subtitle: "Normalization Layers"
    contents:
      - has_concept("normalization layers")

  - subtitle: "Regularization Layers"
    contents:
      - has_concept("regularization layers")
      # - has_concept("spatial regularization layers")
      # - has_concept("dropout spatial regularization layers")

  - subtitle: "Merging Layers"
    contents:
      - has_concept("merging layers")

  # - subtitle: "Other Layers"
  #   contents:
  #     - starts_with("layer_")

  - title: "Layer Methods"
    contents:
      - get_config
      - get_weights
      - count_params
      - reset_states

  - title: "Custom Layers"
    contents:
      - "%py_class%"
      - Layer
      - create_layer_wrapper
      - create_layer


  - title: "Datasets"
    contents:
      - starts_with("dataset_")

  - title: "Applications"
    contents:
      - starts_with("application_")

  - title: "Sequence Preprocessing"
    contents:
      - pad_sequences
      - timeseries_dataset_from_array



  - title: "Text Preprocessing"
    contents:
      - text_dataset_from_directory
      # - text_tokenizer
      # - fit_text_tokenizer
      # - save_text_tokenizer
      # - texts_to_sequences
      # - texts_to_sequences_generator
      # - texts_to_matrix
      # - sequences_to_matrix
      # - text_one_hot
      # - text_hashing_trick
      # - text_to_word_sequence
      # - layer_text_vectorization
      # - set_vocabulary
      # - get_vocabulary
      # - adapt

  - title: "Image Preprocessing"
    contents:
      - starts_with("image_")
      - starts_with("k_image_")
      # - image_data_generator
      # - fit_image_data_generator
      # - flow_images_from_data
      # - flow_images_from_directory
      # - flow_images_from_dataframe
      # - generator_next

  - title: "Optimizers"
    contents:
      # - starts_with("optimizer")
      - has_concept("optimizers")

  - title: "Learning Rate Schedules"
    contents:
      - starts_with("learning_rate_schedule_")
      - new_learning_rate_schedule_class

  - title: "Callbacks"
    contents:
      # - starts_with("callback_")
      - has_concept("callbacks")

  - title: "Initializers"
    contents:
      # - has_concept("initializer")
      - has_concept("initializers")

  - title: "Constraints"
    contents:
      # - has_concept("constraint")
      - has_concept("constraints")
      - Constraint

  - title: "Utils"
    contents:

      - has_concept("utils")
      - plot.keras_training_history
      - plot.keras.src.models.model.Model
      - zip_lists
      - active_property
      - to_categorical
      - normalize
      - with_custom_object_scope
      - keras_array
      # - hdf5_matrix
      - get_file
      # - use_session_with_seed
      - install_keras
      - is_keras_available
      - use_backend
      - shape

  - title: "Losses"
    contents:
      - loss_mean_squared_error
      - starts_with("loss_")
      - Loss

  - title: "Metrics"
    contents:
      - Metric
      - starts_with("metric_")
      - custom_metric
      - new_metric_class

  - title: "Regularizers"
    contents:
      - starts_with("regularizer")

  - title: "Activations"
    contents:
      - starts_with("activation")
      - activation_relu

  - title: "Misc other layers"
    contents:
      - starts_with("layer_")

  - title: "Random Tensor Generators"
    contents:
      - starts_with("random")
      - has_concept("random")

  - title: "Operations"
    desc: >
      Functions that are safe to call in Eager and Graph mode

  - subtitle: Core Operations
    contents:
      - has_concept("core ops")

  - subtitle: Math Operations
    contents:
      - has_concept("math ops")

  - subtitle: General Tensor Operations
    contents:
      - has_concept("numpy ops")

  - subtitle: "Neural Network Operations"
    contents:
      - has_concept("nn ops")

  - subtitle: "Image Operations"
    contents:
      - has_concept("image ops")
      - starts_with("k_")

  - title: "Configuration"
    contents:
      - starts_with("config_")

  - title: "Backend"
    contents:
      - has_concept("backend")

  - title: "Trainers"
    contents:
      - has_concept("trainers")

  - title: "Python"
    contents:
      - keras
      - "%py_class%"
      - "%<-active%"

  - title: "Questioning"
    contents:
      - get_source_inputs
      - predict_on_batch

  - title: "Deprecated"
    contents:
      - adapt
      - bidirectional
      - keras-package
      - time_distributed
      # - KerasWrapper
      # - create_wrapper
      # - loss_cosine_proximity
      # - layer_cudnn_gru
      # - layer_cudnn_lstm
      # - layer_dense_features



#
#   - title: "Noise Layers"
#     contents:
#       - layer_gaussian_noise
#       - layer_gaussian_dropout
#       - layer_alpha_dropout
#
#
#   - title: "Image Preprocessing Layers"
#     contents:
#       - layer_resizing
#       - layer_rescaling
#       - layer_center_crop
#
#   - title: "Image Augmentation Layers"
#     contents:
#       -  layer_random_contrast
#       -  layer_random_crop
#       -  layer_random_flip
#       -  layer_random_height
#       -  layer_random_rotation
#       -  layer_random_translation
#       -  layer_random_width
#       -  layer_random_zoom
#
#   - title: "Categorical Features Preprocessing"
#     contents:
#       -  layer_category_encoding
#       -  layer_hashing
#       -  layer_integer_lookup
#       -  layer_string_lookup
#
#   - title: "Numerical Features Preprocessing"
#     contents:
#       -  layer_normalization
#       -  layer_discretization
#
#   - title: "Attention Layers"
#     contents:
#       - layer_attention
#       - layer_multi_head_attention
#       - layer_additive_attention
#
#   - title: "Layer Wrappers"
#     contents:
#       - time_distributed
#       - bidirectional


      # - has_concept("ops")
      # - has_concept("metrics")
      # - has_concept("utils")
      # - has_concept("losses")
      # - has_concept("activations")
      # - has_concept("random initializers")
      # - has_concept("confusion metrics")
      # - has_concept("regression metrics")
      # - has_concept("backend")
      # - has_concept("config backend")
      # - has_concept("schedules optimizers")
      # - has_concept("schedule rate learning schedules optimizers")
      # - has_concept("rate learning schedules optimizers")
      # - has_concept("learning schedules optimizers")
      # - has_concept("image utils")
      # - has_concept("probabilistic metrics")
      # - has_concept("iou metrics")
      # - has_concept("accuracy metrics")
      # - has_concept("saving")
      # - has_concept("regularizers")
      # - has_concept("constant initializers")
      # - has_concept("traceback utils")
      # - has_concept("registration object saving")
      # - has_concept("reduction metrics")
      # - has_concept("object saving")
      # - has_concept("io utils")
      # - has_concept("hinge metrics")
